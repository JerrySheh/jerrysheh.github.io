{"pages":[{"title":"ComputerScienceEnglishQuickCheck","text":"技术英语快速查阅 基本编程 变量(variable) 常量(constant) 声明(declare) 数组(array) 初始化(initialize) 参数(argument) - 函数调用时的实际参数（实参） 参数(parameter) - 函数定义中参数（形参） 垃圾回收(garbage collection) 嵌套 (nest) 转义符(Escape sequence) 断言(assert) 转换（convert） 集成（integrate） 样式（pattern） 属性（attribute） 属性（property） 提示（prompt） 可擦除的（erasable） 面向对象（Object Oriented, OO） 对象(Object) 域(field) 方法(method) 实例(instance) 类(class) 衍生类(derived class) 基类(base class) 抽象类(abstract class) 构造器(constructor) 封装(encapsulation) 接口(interface) 实现(implementation) 继承(inheritance) 组合(composition) 多态(polymorphism) 不可变对象(immutable object) 集合（collection） 容器(container) //容器是用对象封装的数据结构 集合类工具（collections） 列表（list） 元组（set），或者tuple 映射（map），或者称字典（dict） 迭代器（iterator） 可迭代的（iterrable） 数据结构（data structure） 前驱（predecessor） 后继（successor） 前缀（prefix） 后缀（suffix） 数组（array） 链表(linked list) 二叉树(Binary Tree) 左子树(left subtree) 排序（sort） 序列（sequence） 栈（stack） 堆（heap） 有向无环图（Directed Acyclic Graph, DAG） 遍历（traversing） Web Deploy (部署) template（模板） render（渲染） validate（验证） SPA（Single Page web Application，单页面 Web 应用） SOA（Service-Oriented Architecture，面向服务的架构） SOE（Search Engine Optimization，搜索引擎优化） 数据库 列（column） 查询（query） 注入（inject） 大数据 数据集（data-set） 块（chunks） 调度（scheduling） 其他 伪代码（pseudo code） 解析（parse） 兼容性（Compatibility） 分配（allocates） 缓冲区(buffers) 泛型(Generic type) 收缩变换(narrowing conversion) 宽松变换(widening conversion) 异常处理器(Exception Handler) 闭包(closure) 减去(substract) 截断（truncate） 转换（cast） 函数式编程（Functional Programming） JAVA虚拟机(JVM，Java Virtual Machine) 图形用户接口 (GUI，Graphical User Interface) 运行时类型识别(RTTI, Run-Time Type Identification) 可移植操作系统接口（POSIX,Portable Operating System Interface） 统一可扩展固件接口（UEFI，Unified Extensible Firmware Interface） REPL（Read-Eval-Print Loop，交互式解释器） 组成原理 指令 (instruction) 主存(Main Memory, MM) 存储器地址寄存器(Memory Address Register，MAR) 存储器数据寄存器(Memory Data Register，MDR) 中央处理器(Central Processsing Unit, CPU) 算数逻辑单元(Arthmetic Logic Unit, ALU) 控制单元(Control Unit, CU) 程序计数器(Program Counter，PC) 输入输出设备(Input/Output Equipment) 基本输入输出系统(Basic Input Output System,BIOS) 通用串行总线(Universal Serial Bus,USB) 操作系统(Operating System)与并发编程 硬件抽象层（Hardware Abstraction Layer, HAL） 解释器(interpreter) 阻塞（block） 挂起（suspend） 信号量（Semaphores） 并发(concunrrency) 并行（parallel） 竞争条件(race condition) 原子操作(atomic operation) 同步(synchronization) 互斥(mutex) 条件变量(condition variable) 读写锁(reader-writer lock) 线程局部存储(thread local storage, TLS) 计算机网络(network) 主机（host） 端系统（end system） 分组 （packet） 因特网服务提供商（Internet Sevice Provider, ISP） 协议（protocol） 传输控制协议（Transmission Control Protocol，TCP） 网际协议（Internet Protocol，IP） 应用程序编程接口 (API，Application Programming Interface) 面向连接的(connection-oriented) 广播（Broadcast） 通用网关接口（Common Gateway Interface， CGI） request（请求） response（响应） IO编程 文本流(byte stream) Android 布局（layout） 视图（view） 广播接收器（Broadcast Receiver） 内容提供器（Content Providers） 内边距（padding） 外边距（margin） 线性（Linear） 垂直（vertical） 水平（horizontal） 方向（orientation） 进制转换 十进制（Decimal） 二进制（Binary） 八进制（Octal） 十六进制（Hexadecimal）","link":"/ComputerScienceEnglishQuickCheck/index.html"},{"title":"Java必知必会","text":"1. 八种基本数据类型 boolean 1字节：byte 2字节：char、short 4字节：int、float 8字节：long、double 2. 自动转换和强制转换自动转换是系统悄然进行的，从低位转换到高位。例如 int + short ，结果为 int， int + double，结果为 double 。 强制转换需要显式声明，Java可以强制向下转型。比如double转int（会损失精度），子类转父类（丢失部分属性），父类转子类（前提是声明时必须用父类引用指向子类对象，即多态声明）。 3. i++ 和 ++ii++ 是先把 i 压入操作栈，然后用 iinc 直接在局部变量表对 i 加一，再把操作栈顶赋给 a 12345a = i++0: iload_11: iinc 1, 14: istore_2 ++i 是先用 iinc 直接在局部变量表对 i 加一，然后把 i 压入操作栈，再把操作栈顶赋给 a 12345a = ++i0: iinc 1,13: iload_14: istore_2 一般要对一个数进行修改，要先从局部变量表把数压入操作栈，修改完再赋值回去。但 iinc 这个指令比较特殊，直接在局部变量表里就可以+1操作。 4. 拆箱和装箱什么时候自动装箱? 字面量直接赋值给 Integer，比如 Integer i = 100 什么时候自动拆箱？ 用 == 比较Integer和int时，比如 int a = 5; Integer b = 50; a == b 5. 任意数据类型都可转 Object基本数据类型也可以，会自动装箱 6. equals 和 == Object类的 == 和 equals 没区别， equals 实际上判断的就是 == String类的 == 比较的是内存地址，equals比较的是值 String 的 equals 过程？ 先比较 == ，如果相同返回 true， 不同继续判断 是否能转型为 String（instanceof操作符），不能直接返回 false 比较长度，不同返回 false，相同继续判断 逐个字符比较 7. Integer的缓存《阿里巴巴Java开发手册》中提到，对于 Integer var =? 在 -128 至 127 之间的赋值， Integer 对象是在IntegerCache.cache 产生，会复用已有对象，这个区间内的 Integer 值可以直接使用 == 进行判断，但是这个区间之外的所有数据，都会在堆上产生，并不会复用已有对象，这是一个大坑，因此推荐使用 equals 方法进行判断。 8. JAVA创建对象的过程简要回答： 在堆中创建对象 在栈中创建引用 引用指向对象 从虚拟机角度回答: 虚拟机遇到new指令，从常量池定位该类的符号引用 如果定位不到，说明对象所属的类还没有被JVM加载，则用classloader进行类的加载、解析、初始化 为对象分配内存 为对象赋零值（不包括对象头） 调用对象的 方法，开始应用层面的初始化 9. 类块加载顺序 父类静态块 子类静态块 父类构造块 父类构造方法 子类构造块 子类构造方法 10. 面向对象的三个特征 封装 继承 多态 多态前提：有继承关系、子类重写父类方法、父类引用指向子类对象多态好处：屏蔽子类间的差异，写出通用的代码（SQLDao dao = new MySQLDao()）多态弊端：不能用子类特有的方法，解决办法：instanceof操作符，向下转型 11. public、protected、private public：所有类可访问 protected：子类、同包 无修饰符：同包 private：私有，内部类可访问 12. 局部变量和类变量的初始化 局部变量：初始化必须赋值，否则编译不通过 类变量：有默认值， int 0，char 空字符’\\u0000’，String null 13. 成员内部类可以访问外部类的 private 属性，为什么？成员内部类在编译时会生成单独的 .class 文件 Outter.class Outter$Inner.class 编译器默认会为成员内部类添加了一个指向外部类对象的引用，也就是说，内部类对象被构造的时候，自动传入了一个外部类对象的引用，因此可以在成员内部类中随意访问外部类的成员。 14. 为什么局部内部类只能访问 final ？避免外部作用域提前结束。 方法 A 中定义了局部内部类 B，当 方法A 执行完毕，已经结束作用域，如果内部类 B 的方法（可能由另一个线程执行）还没结束，但由于 A 结束作用域，方法 A 的变量 a 会不可访问。为了解决这一问题， Java 采用了 复制 的手段，即把方法 A 的变量 a 复制一份到内部类 B 的常量池。 但是复制过后会产生不一致的问题，也就是内部类的方法修改了 a ， 但是外部类的 a 没有改变。 因此，Java 规定，只能访问 final ，以避免上述问题。 15. 接口中的方法有哪些修饰符？ public static（必须提供实现） default（必须提供实现） abstract default有什么用？ 接口演化 16. JAVA 标准类库常用接口 comparable接口，实现了这个接口的类，其对象能够进行比较 comparator，比较器，用于提供多样的比较方法，自定义多种比较 runnable，用于执行线程 serializable，标记接口，用于序列化 17. 接口和抽象类的区别抽象类是 is-a 关系，接口是 like-a 关系。抽象类一般用作基类，让具体类去实现。接口一般用作某个类具有哪些功能。接口表示一种能力，类表示一类事物抽象。 抽象类可以有成员变量和实现方法，接口只能有常量，static 和 default 方法有实现。 抽象类可以有构造器，接口没有。 18. Overload和Override的区别 Overload是重载，一个类中可以多个名字一样，但参数类型或个数不一样的方法 Override是重写，子类重写父类的方法 19. Object类有哪些方法？ clone，用于对象复制 toString equals，比较 hashcode，哈希 wait，让一个线程放弃锁，进入等待状态 notify/notifyAll，唤醒线程，让线程进入就绪状态 getClass，获取类对象 finalize，垃圾回收相关 20. 什么时候重写 equals，什么时候重写 hashcode ？当多个对象之间，只需要某些字段相等而不必是同一个对象我们就认为他相等的时候，需要重写 equals 方法。重写了 equals 方法最好也重写 hashcode 方法，因为 hashcode 方法常用在 HashSet 或 HashMap 计算 key。 equals 的两个对象，却有不同的 hashcode，会被存入 Set 或 Map 中的不同位置，这和 HashSet 的设计初衷相悖。HashMap取的时候也可能因 HashCode 的改变而取不到。 21. HashMap如何存储键值对HashMap底层是使用 Node 对象数组存储的，Node 是一个单项的链表。当这个链表长度超过 8 时，转换成红黑树 TreeNode 。 put() 过程 确定要存入的桶。先使用 hash() 函数获取该对象的 hash 值，高16位和低16位异或后跟 Node 对象数组大小-1 进行与操作，得到应该存入数组的下标。 链表插入。假如该位置为空，就将value值插入，如果该下标不为空，则要遍历该下标上面的对象，使用equals方法进行判断，如果遇到equals()方法返回真则进行替换，否则将其插入到链表尾部（JDK1.8） 为什么要将hash的高16位和低16位异或？让高位也参与计算，减少某些数值的hash冲突。例如，Float类型的 1f, 2f ,3f ,4f 的 hash值 低16位全部都是0，只有高16位不同。因此采用异或让高位也参与计算。 get() 过程 根据 key 对象的 hash 值找到 Entry 对象数组的对应下标。 判断Entry的 key 和 给定的 key 是否相同（equals或==），以及 hash 是否也相同，如果不是，访问链表下一个 Entry ，如果是，返回 Entry 的 value，如果遍历完了也没有，返回 null hashmap扩容过程何时扩容懒加载。首次调用 put方法 时，HashMap 会发现 table 为空，然后调用 resize方法 进行初始化（默认为16）。当添加完元素后，如果HashMap发现size（元素总数）大于 threshold（阈值，默认16*0.75），则会调用resize方法进行扩容。 如何扩容table大小变为原来的两倍，也就是2的n次方变为2的n+1次方。之后对table进行调整：若元素hash值第N+1位为0：不需要进行位置调整，若元素hash值第N+1位为1：调整至原索引的两倍位置。 为什么扩容是2倍，而不是1.5倍或3倍？因为要保证table的长度为 2^n （即 2，4，8，16，32…） 为什么 table 的长度要为 2^n ？ 均匀分布，减少碰撞。计算 hash 的时候，hash值要跟 table长度-1 进行与操作, table长度为 2^n，也就是二进制100000， 而 2^n -1 是二进制 11111， hash值跟 1 与，更不容易碰撞。 22. HashMap 的 key 有什么要求？key 可不可以为 null ？ 最好不要用可变对象。如果一定要是可变对象，也要保证 hashcode 方法的结果不会变。因为 HashMap 的 get 方法是会去判断 hashcode 值，如果 hash 值变了，有可能就取不到。 使用不可变对象是明智的。 key 可不可以为 null，为 null 时怎么存储 ？可以。上源码。在 talbe[0] 链表中查找 key 为 null 的元素，如果找到，则将 value 重新赋值给这个元素的 value，并返回原来的value。 如果上面for循环没找到则将这个元素添加到 talbe[0] 链表的表头。 12345678910111213141516if (key == null) return putForNullKey(value); private V putForNullKey(V value) { for (Entry&lt;K,V&gt; e = table[0]; e != null; e = e.next) { if (e.key == null) { V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; } } modCount++; addEntry(0, null, value, 0); return null; } 23. ArrayList 和 LinkedList 的区别 ？ArrayList 继承于 java.util.AbstractList ，底层数组实现，遍历快，中间插入慢。因为数组的物理地址上是连续的，所以遍历快，插入的时候后面的元素都要响应地往后挪，带来额外的时间开销。ArrayList的扩容是 1.5 倍。 LinkedList 继承于 java.util.AbstractSequentialList 底层链表实现，中间插入快，遍历慢。因为物理上不连续，直接把前一个元素指向插入元素，插入元素指向原来的后一个元素即可，所以插入快。但是获取第 n 个元素，要从1开始逐个访问，所以遍历比较慢。LinkedList不需要扩容。 24. Java.util.concurrent包（Java并发工具包）concurrent包包含了一些帮助我们编写并发程序的有用的类（比如BlockingQueue阻塞队列，SynchronousQueue同步队列）以及线程安全的原子类（如AtomicInteger）。 学习参考：http://tutorials.jenkov.com/java-util-concurrent/index.html 中文：https://blog.csdn.net/axi295309066/article/details/65665090 25. fail-fast 和 fail-safejava.util 包下的集合类都是快速失败（fail—fast）的，不能在多线程下发生并发修改（迭代过程中被修改）。java.util.concurrent包下的容器都是安全失败（fail—safe），可以在多线程下并发使用，并发修改。 用迭代器遍历一个java.util集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception。java.util.concurrent包下则不会。 26. Collection 和 Collections 的区别Collection是集合类的上级接口，包含了 list、Set、Map 等子接口。Collections是集合工具类，提供了一些常用的集合操作。例如对各种集合的搜索、排序、线程安全化等操作。 27. 为什么 String 要设计成 final ？ 维护一个常量池，节省堆空间。 final类由于不可修改性，多线程并发访问也不会有任何问题 支持hash映射和缓存 28. String s = new String(“abc”) 创建几个对象？2个。第一在常量池中生成 abc 对象，第二在堆中生成 abc 对象。 29. String 的 + 号 如何连接字符串 ？编译器优化，StringBuilder().append() 30. StringBuffer 和 StringBuilderStringBuilder 比 StringBuffer 快，但涉及线程安全必须用StringBuffer。StringBuffer通过 synchronized 保证线程安全。它们两者与 String 的不同点在于对象能被多次修改，而 String 是 final 的。 31. Java中的异常分为 Error 和 Exception Error代表严重错误，比如 OutOfMemory 和 StackOverFlow Exception 分为 checkException 和 uncheckException （也叫runtimeException） checkException 是我们需要在程序中捕获处理或抛出的异常，比如IO、Network Exception uncheckException 是可以通过优化程序逻辑来避免的，不应该捕获，常见的有 nullpointerException 和 ClassNotFoundException 和 ArrayIndexOutOfBoundsException 32. try里面有 return， finally 还执行吗？执行。先保存 return 的内容，finally 里执行完之后再 return 但是 finally 里有 return， 会提前返回 33. Java中的IO ？普通IO：IO面向字节流和字符流 InputStream 和 OutputStream 处理字节流（一个字节8位bit） reader 或 writer 处理字符流（Unicode 字符） BufferedWriter 和 BufferedReader 缓存流 NIO：面向的是 channels 和 buffers 33.1 什么时候用IO什么时候NIO？如果只有少量的连接，但是每个连接同时发送很多数据，用传统IO。如果有许多连接，但是每个连接都只发送少量数据，选择NIO。（如网络聊天室、P2P网络） 34. 线程的三种创建方式？ 继承Thread类 实现Runnable方法（推荐） 实现Callable方法 34.1 Runnable 和 Callable 创建线程有什么区别？第一，Callable 可以用 call() 方法可以获取线程的返回值，而 Runnable 的 run() 方法没有返回值。 第二， call() 方法可以抛出异常，主线程可以直接捕获子线程异常。但 Runnable 只能通过 setDefaultUncaughtExceptionHandler() 的方式来捕获。 第三，运行 Callable 任务可以拿到一个 Future 对象，表示异步计算的结果。它提供了检查计算是否完成的方法，以等待计算的完成，并检索计算的结果。通过 Future 对象可以了解任务执行情况，可取消任务的执行，还可获取执行结果。 35. 线程 Thread 类的 join 方法是干什么用的？让线程串行执行。 36. Java中线程同步有几种方式？ synchronized ，解决竞争条件问题（多个线程同时访问一段内存区域），也可以解决可见性问题。 Volatile ，解决可见性问题（线程栈、CPU缓存），但不能保证原子性问题 java.util.concurrent包下的Atomic原子类，无锁保证原子性。多线程 i++ 问题 Atomic 已足够。 java.util.concurrent.Lock.ReentrantLock，是一个可重入、互斥、实现了Lock接口的锁。 ThreadLocal类，线程局部变量。 java.util.concurrent包下的其他工具。例如阻塞队列（BlockingQueue），concurrentHashMap，CopyOnWriteArrayList ，栅栏（CyclicBarrier）、闭锁（CountDownLatch）、信号量(Semaphore) 37. JVM的组成？ 类加载器：用于加载 .class 文件并初始化类 内存区域：数据存放的模型 执行引擎：执行字节码 本地方法调用：调用 native 本地方法（C/C++） 38. 类加载器如何加载一个类？ 加载（读取.class二进制字节流，转换成方法区动态数据结构，堆中创建对象） 链接（校验、准备（静态变量赋默认值）、解析（符号引用-&gt;直接引用）） 初始化（静态变量赋初值） 39. 什么时候初始化 ? 遇到 new、getstatic、putstatic、invokestatic 字节码关键字 反射 父类未初始化先初始化父类 虚拟机启动时，主类 40. 全盘负责双亲委派机制 当一个 classloader 加载一个类时，其依赖和引用也由这个类加载器加载 类加载器先委派父加载器加载，父加载器找不到目标类才由子加载器加载 好处？安全，保证所有基础的类都是由 RootClassLoader 来加载的。 有没有例外？有。线程上下文类加载器（Thread Context ClassLoader），父类加载器可以请求子类加载器去完成类加载的动作。 41. 类加载器如何判断两个类相同？ 类全限定名相同 加载该类的类加载器相同 42. JVM的内存模型 程序计数器（线程隔离） 本地方法栈（线程隔离） Java虚拟机栈（线程隔离） 堆（线程共享） 方法区（线程共享）（JDK1.8升级为元空间） 43. 什么是动态链接？.class文件中有很多符号引用，一部分在类加载的时候转化为直接引用（称为静态链接），另一部分在每一次运行期间转化为直接引用，这部分被称为动态链接。 44. 垃圾回收算法针对新生代，很多被清理，用标记-清除法，但效率低，碎片多。用复制算法较好（Eden、Survior1、Survior2） 复制算法先只使用 Eden、Survior1，垃圾回收的时候，把幸存的复制到 Survior2，然后清空 Eden和Survior1，之后只使用 Eden、Survior2 。 针对老年代，只有很少被清理，标记-整理算法。从GC Roots出发标记存活的对象，移动到内存的一端，将另一端全部清除。 45.哪些可以作为 GC-ROOT ？ 类静态属性中引用的对象 常量引用的对象 Java虚拟机栈和本地方法栈引用的对象 46. 什么是CAS ？CAS（Compare and swap）用于实现非阻塞并发算法。一个线程在修改一个变量时，先将当前值（当前内存地址值）跟预期值进行比较，如果一致，则进行修改，如果不一致，说明这个变量被其他线程改了，就不进行修改。 但是 CAS 也不是完美的，比如经典的ABA问题：一个变量 V 初次读取的时候是 A值，之后被其他线程修改为 B，然后又修改为 A，那 CAS 会认为它从来没有变过。 在 java.util.concurrent.atomic 里面，像 AtomicBoolean 这些原子类就有 compareAndSet 方法。 参考：http://tutorials.jenkov.com/java-concurrency/compare-and-swap.html 47. 多线程应该注意哪些问题？如何避免？三个问题： 安全性问题（竞争条件、可见性） 活跃性问题（死锁） 性能问题（为了解决上述问题而导致的性能下降） 解决安全性问题，可以用 synchronized 关键字， 或者 ReentrantLock 同步锁，Volatile用于解决可见性问题，Threadlocal类等。 解决死锁问题，可以让线程一开始就持有所有需要的资源，但这样会造成资源浪费，变成一个性能问题。第二种方式是，当需要新的资源而不能满足时，必须先释放自己持有的锁。 48. 写出单例模式单例模式是指一个类只能有一个对象实例。好的单例模式应该满足两点要求：延时加载 和 线程安全。 静态内部类写法： 用静态内部类构造实例 构造函数私有 12345678910111213public class Singleton{ private static class Holder{ private static Singleton singleton = new Singleton(); } private Singleton(); public static Singleton get(){ return Holder.singleton; }} 49. 基本数据类型及其包装类有什么区别？ Java是一门纯粹的OO语言，但基本数据类型不是对象，为了让他们有对象的特征，Java设计了对应的包装类。包装类是对象，就要有对象的特征，有可调用的方法，而基本类型没有。 包装类可放入如HashMap、HashSet等集合中，基本数据类型不可以。但是存入时会被Java自动装箱。 基本数据类型初始化值为0（char为\\u0000）,if 判断时要用 if(i == 0)，而包装类要用 if(i==null) 50. 面向对象和面向过程的区别面向过程是按计算机的逻辑去顺序执行程序，性能高，但是代码较难维护，不利于复用和扩展。单片机、嵌入式、Linux内核等都采用面向过程开发，因为性能是最重要的。 面向对象把一切当作对象，从人理解世界的角度去看待，由于面向对象有封装、继承、多态等特点，我们可以设计出低耦合的系统，使系统更加灵活、更加易于维护。 51. ReentrantLock 和 Synchronized 的区别都是可重入锁，但 ReentrantLock 多了三个高级特性： 等待可中断：如果持有锁的线程长期不释放锁，正在等待的线程可以放弃等待，改为处理别的事情。 可实现公平锁：公平锁是指按照申请锁的时间顺序依次获得锁，而非随机获得。可以通过带 boolean 值的构造函数要求使用公平锁。 锁可以绑定多个条件：一个 ReentrantLock对象可以绑定多个 Condition 对象。 52. 重量级锁和轻量级锁每个对象都有一个对象头（Object Header），官方叫做 Mark Word，用于存储对象自身的运行时数据（hashcode、GC age等）和指向方法区对象类型数据的指针。为了节省空间，这个对象头（32bit或64bit）的存储空间是复用的。它有一个标志位，01时表示未锁定，存储hashcode、GC age等，00时表示轻量级锁定，10时表示重量级锁定，11是GC标记，01时是可偏向。不同标志位下这 32bit 存储的东西也都不一样。 52.1 重量级锁进入 syncronized 块的线程默认是重量级锁。其他线程进入时，发现锁被占用，会进入阻塞状态（这个过程由操作系统完成）。 52.2 轻量级锁当一个线程访问了这个对象的同步块，发现标志位为01（未锁定），就会在当前线程的栈帧中复制一份 Mark Word（复制后的这块区域叫 Lock Record）。然后用 CAS 尝试去将 Mark Word 更新为指向栈帧Lock Record的指针。如果成功，该线程获得该对象的锁。如果失败，虚拟机会检查 Mark Word 是否已经指向当前线程栈帧，如果是，说明该线程已经获得该锁，允许进入同步块（重入），否则说明锁对象已经被其他线程占有了。 如果两个线程争用同一个锁，轻量级锁就不再有效，升级为重量级锁，标志位变成10，Mark Word存储指向重量级锁的指针，后面等待锁的线程要阻塞。 轻量级锁的目的是，在无竞争的条件下，用 CAS 去消除同步带来的互斥量。 53. 自旋锁和自适应自旋锁为什么要有？因为同步是比较重的操作（挂起线程和恢复线程都要转入内核态），给系统的并发性能带来压力。 如果系统有两个CPU，前面请求锁的线程获得锁，后面请求锁的线程不必挂起，不必放弃CPU，只需要让它执行一个忙循环（自旋），看看前面的线程是否很快会释放锁。 自旋的时间非常短，效果好，反之自旋时间很长还得不到锁，会白白消耗处理器资源。因此自旋的次数有限制。默认是10，但是 Java 1.6 后提供了自适应，如果一个线程自旋期间经常成功获得锁，就把自旋时间调长，否则就调短或干脆不自旋，改为传统的挂起（wait）。 54. 锁消除有一些做了同步的代码，但虚拟机即时编译器运行时发现这部分代码不可能存在共享数据竞争，那 Java 就会自动移除这部分的锁，这称为锁消除。例如在一个方法中，堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它们当作栈上的数据对待，也就无需同步加锁了。 一个例子就是 JDK 1.5 之前的版本，String 的 + 号会被优化成 Stringbuffer.append()，这个方法是同步的，但如果只有一个线程在操作它，就可以进行锁消除。 55. 偏向锁偏向锁是轻量级锁的进一步，连 CAS 都不做了，无竞争时，直接消除整个同步。当 Mark Word 标志位为01时，代表可偏向。持有偏向锁的线程以后每次进入锁的同步块时，虚拟机不再做任何同步。 当另一个线程尝试获取该锁，偏向模式就结束了，进入了未锁定或轻量级锁状态，如果两个线程在争用该锁，甚至会升级为重量级锁。 56. 锁优化如果程序中大多数锁总是被多个线程同时访问（争用），那偏向模式就是多余的。具体分析后，可通过 -XX:UseBiasedLocking 来进制偏向锁优化，这样反而提升了性能。 57. 静态抽象内部类static 只能用来修饰类的成员，所以顶级类不能用 static 修饰。所以 static class 只能是内部类。 静态内部类与外部类之间并没有任何关系，其外部类仅仅起到一个名字空间的作用，和包名起差不多的作用。而 静态内部类也不持有外部类的引用，也不能引用外部类的private成员。 一个静态内部类其实是具有顶级类的地位，那么和一般的抽象类其实并没有什么不同。 58. concurrentHashMapconcurrentHashMap是线程安全的 hashmap 。在 jdk 1.7 采用分段锁保证线程安全和并发性能。但在 jdk 1.8 中改用 CAS + synchronized 控制。ConcurrentHashMap 迭代时不会抛出 ConcurrentModificationException，是 fail-safe 的。 58-1 concurrentHashMap 的 key 能否为 null ？不能。因为当我们去 get(key) 的时候，如果得到一个 null ，无法判断这个 key 究竟是没有做过映射，还是之前 put(key) 时 value 就是为 null。 58-2 那为什么 HashMap 的 key 可以为 null？因为 HashMap 不是为多线程设计的，可以用 contains(key) 来判断 key 是否做过映射。而 concurrentHashMap 因为支持并发，在调用 m.contains(key) 和 m.get(key) 时， m 的值可能被别的线程修改了。 59. HashSet 的底层原理HashSet 本质上是一个 HashMap ，因为 Map 存储的是键值对，键不允许重复。所以 HashSet 存放的对象实际上是存放到 HashMap 的 Key 进去。然后 Value 部分用一个空对象代替。 1private static final Object PRESENT = new Object(); 60. String.intern() 方法的作用String.intern()是一个 native 方法。如果字符串常量池里面已经包含一个等于此 String 对象的字符串，则返回池中的这个字符串String对象，否则，先将该String对象包含的字符串添加进常量池，然后返回此String对象的引用。 61. Java四种引用？后三种引用只是可以让开发者通过代码方式来决定对象回收时机。一般不需要做调整，JVM GC 会为我们做垃圾回收。 强引用：new 对象，宁愿 OOM 也不回收 软引用：内存快不够时回收 弱引用：下一次GC就回收 虚引用：对象被回收时我们会收到一个通知 62. CopyOnWriteArrayList ?替代了同步的List，采用写时复制技术。当对List内容进行修改时，复制原来的List。迭代的是原List，fail-safe，适合一写多读的场景。 63. Java 线程池submit和execute 的区别？ execute(Runnable x)：没有返回值。可以执行任务，但无法判断任务是否成功完成。——实现Runnable接口 submit(Runnable x)：返回一个future。可以用这个future来判断任务是否成功完成。——实现Callable接口 如果提交的任务不需要一个结果的话直接用execute() 64. new 对象跟 clone() 的区别clone()与 new 都能创建对象。但 new 通过构造方法为对象赋初值，而 clone() 不会调用构造方法，只是把原有对象的属性复制给新对象。 65. 什么是浅拷贝？什么是深拷贝？Object.clone() 是浅拷贝。如果一个对象里面包含引用类型，拷贝的只是值的地址，而没有在堆中开辟新的内存空间。也就是说，引用类型指向原有对象。 如果我们重写clone()方法，对于引用类型成员变量，重新在堆中开辟新的内存空间。那就是深拷贝。 66. synchronized 原理？同步代码块基于 monitorenter 和 monitorexit 字节码指令来实现。编译后的代码，monitorenter 指令会被插入到同步代码块的开始位置，而 monitorexit 会被插入到代码块结束处和异常处。 线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 所有权。 67. Atomic原子类原理？非阻塞并发算法。具体是用了 CAS，（比较并交换 compare and swap）。它包含三个数：需要读写的内存位置V、进行比较的值A、拟写入的新值B。当 V 和 A 相等时，才将 V 的值更新为 B。无论是否更新成功，都返回当前内存位置 V 值。 可以这样理解CAS：我认为 V 的值应该为 A，如果是，那么将 V 的值更新为 B，否则不修改并告诉 V 的值实际为多少。 68. 重入原理？重入的一种实现方式是，为每个锁关联一个获取计数值和一个所有者线程。当计数值为0时，锁没有被任何线程持有。当一个线程获取该锁，JVM将记下锁的持有者，并把计数值+1，这个线程第二次请求该锁，计数值再+1。第二次请求的操作执行完毕后，计数值-1，第一次请求的操作执行完毕后，计数值再-1，便恢复到0，锁被释放。 69. 为什么 volatile 能解决重排序问题？声明为 volatile 的变量，实际上相当于程序员显式地告诉编译器和处理器不要使用重排序。汇编指令中多出来的 Lock，实际上也就是一道内存屏障。处理器遇到内存屏障时，就会知道不要对此处乱序执行。事实上，Linux 或 Windows 作为操作系统，也只是调用 CPU 所实现的内存屏障指令而已，归根结底这个不是操作系统或者编译器去实现，而是硬件实现了然后供软件调用。","link":"/Java/index.html"},{"title":"About","text":"I am Jerry, a coding enthusiast, graduated from University of Electronic Science and Technology of China, Zhongshan Institute in 2019. Now working for Ping An Insurance (Group) as a backend software engineer.","link":"/about/index.html"},{"title":"DailyEnglishQuickCheck","text":"日常英语快速查阅 A B 任意地（arbitrarily） 确定（determine） 推断（inferred） 递增的（incremental） 侵入的（invasive） 废止、清除（invalidate） 意图、打算（intend） 模糊地（ambiguous） 提炼（refine） 熟悉（get a flavour for） A B 一堆、一些（a bunch of） 胜利（triumph） 分号（Semicolons） 限制（restrictions） 省略（omitted） 明确地（explicitly） 晦涩的（obscure） 后悔（regret） 优缺点（strengths and flaws） 场景（scenarios） 特权（privilege） 检索（retrieves） A B 无穷（infinite） 普通的（plain） 分隔符（delimiter） 企业（corporate） 压缩（deflated） 容错（fault-tolerant） 操纵（manipulated）伴随（accompanying） zh en en explain 半.. semi- half 常规的 conventional based on or in accordance with what is generally done or believed. 生态系统 ecosystem a biological community of interacting organisms and their physical environment. 尺寸 dimension an aspect or feature of a situation, problem, or thing. 所有权 proprietary of or relating to an owner or ownership. / an owner; proprietor. 图表 schema a representation of a plan or theory in the form of an outline or model.","link":"/DailyEnglishQuickCheck/index.html"},{"title":"数据结构和算法","text":"1. 选择排序、冒泡排序、插入排序的区别选择选择排序是先遍历数组，找到最小的元素，放到前面。第二趟从第二个元素开始，找到次小元素，放到前面。每次都选出当前躺最小的元素，放到前面。 1234567891011public static void selectSort(int[] arr){ int size = arr.length; for (int i = 0; i &lt; size; i++) { int min = i; // 第二个for循环找出最小元素 for (int j = i; j &lt; size; j++) { if (arr[j] &lt; arr[min]) min = j; } Swap.swap(arr, min, i); }} 冒泡冒泡排序是比较两两相邻的两个元素，如果前一个元素比后一个元素大，就交换。不断地往后换下去。 123456789public static void bubbleSort(int[] arr){ int size = arr.length; for (int i = 0; i &lt; size; i++) { // 第一躺结束后，最右元素一定是最大的，因此第二趟最右元素不参与，即 size - i - 1 for (int j = 0; j &lt; size - i - 1; j++) { if (arr[j] &gt; arr[j+1]) Swap.swap(arr, j, j+1); } }} 插入插入排序是将待排序的元素插入到前面已经有序的元素里面。它是将待排序元素不断从后往前换到前面的,如果待排序元素比前一个元素小，就换到前面去。 1234567private static void sort(int[] arr){ for (int i = 1; i &lt; arr.length; i++) { for (int j = i; j &gt; 0 &amp;&amp; arr[j] &lt; arr[j-1]; j--) { Swap.swap(arr, j, j-1); } }} 三者的时间复杂度都是 O(n^2)，空间复杂度为 1 2. 归并排序和快速排序的区别归并归并排序的思想是，找到中间点，将数组分成两个子数组，排序左半边，再排序右半边，再将两边合并起来。 123456789101112131415public static void mergeSort(int[] arr, int low, int high){ if (high &lt;= low ) return; // 找到中间点 int mid = (low + high) / 2; // 排序左半边 mergeSort(arr, low, mid); // 排序右半边 mergeSort(arr, mid+1, high); // 左右两边归并 merge(arr, low, mid, high);} 快速快速排序的思想是，选一个参考元素，比参考元素小的放左边，比参考元素大的放右边。然后左边排序，右边排序。 123456789101112public static void quickSort(int[] arr, int low, int high){ if (high &lt;= low) return; // partition返回的是参考元素的下标 int refer = partition(arr, low, high); // 将切分的左半部分快排 quickSort(arr, low, refer - 1); // 将切分的右半部分快排 quickSort(arr, refer + 1, high);} 快速排序和归并排序的时间复杂度都是 O(NlogN)，但是快速排序在最糟糕的情况下可能会是 O(n^2)。 3.快速排序的 partition 方法 选取第一个元素为参考元素 从左向右，每个元素都跟参考元素做比较，直到找到比参考元素大的 从右向左，每个元素都跟参考元素做比较，直到找到比参考元素小的 把第 2 步比较大的数 和 第 3 步 比较小的数 交换 不断重复直到扫描完（left &gt; right） 把参考元素放在正确的位置（swap low right） 返回参考元素（return right） 123456789101112131415161718192021222324252627282930313233343536public static int partition(int[] arr, int low, int high) { // 1.选取第一个元素为参考元素 int refer = arr[low]; int left = low; int right = high + 1 ; // 这里要加一 // 重复 2.3.4 while (true){ // 2.从左边向右，每一个元素都跟参考元素做比较，直到找到比参考元素大的 while ( arr[++left] &lt; refer ){ // 如果到达最右了，不再向右 if (left == high) break; } // 3.从右边向左，每一个元素都跟参考元素做比较，直到找到比参考元素小的 while ( arr[--right] &gt; refer ){ // 如果到达最左了，不再向左 if (right == low) break; } // 5. 检查是否扫描完 if (left &gt;= right) break; // 4. 交换刚刚两个元素 Swap.swap(arr, left, right); } // 6. 将参考元素`arr[low]`放到中间位置 Swap.swap(arr, low, right); // 返回的是下标 return right;} 4.归并排序的 merge 方法 先将原数组全部复制到辅助数组 tempArr[] 中，然后依次判断（from low to high） 左半边是否用尽，如果用尽，取右半边的元素，否则2 右半边是否用尽，如果用尽，取左半边的元素，否则3 右&lt;左？取右，否则取左（取比较小的） 12345678910111213141516171819202122232425public static void merge(int[] arr, int low, int mid, int high){ int left = low; int right = mid + 1; // 将数组复制到一个新的临时数组中 int[] tempArr = new int[high+1]; for (int i = low; i &lt;= high; i++) { tempArr[i] = arr[i]; } for (int i = low; i &lt;= high; i++) { // 左半边是否用尽，如果用尽，取右半边的元素 if ( left &gt; mid ) arr[i] = tempArr[right++]; // 右半边是否用尽，如果用尽，取左半边的元素 else if ( right &gt; high ) arr[i] = tempArr[left++]; // 右半边的当前元素是否小于左半边的当前元素，如果是，取右半边的元素 else if ( tempArr[right] &lt; tempArr[left]) arr[i] = tempArr[right++]; // 否则取左半边的元素 else arr[i] = tempArr[left++]; }} 5. 找出1到1000之间的素数判断一个数是否素数： 一个数 n，分别去除以 [2,(√n)] 的每个数，如果都不能整数（n % i != 0），那这个数就是素数。 1234567891011private static boolean isPrime(int n){ if ( n &lt; 0 ) return false; if ( n ==1 ) return true; for (int i = 2; i &lt;= Math.sqrt(n); i++) { if ( n % i == 0) return false; } return true;} 找出1到1000之间的素数，除了暴力遍历 isPrime() ，有没有什么高效方法？埃拉托色尼筛选法。用一个bool数组，存储n个数的状态，初始化都为true，然后从2开始，如果2的状态为true，就开始遍历比n小的所有的2的倍数，将其全部置为false。把2的倍数遍历完后，继续往下找下一个状态为true的数，即3，遍历比n小的所有的3的倍数（按33，34，35这样遍历，注意不需要从32开始了）。最后剩下的状态为true的数全为质数。 123456789101112131415161718192021222324private static void printPrime(int range){ // 一个 boolean 数组，一开始全部是 true boolean[] status = new boolean[range]; for (int i = 0; i &lt; range; i++) { status[i] = true; } for (int i = 2; i &lt; range; i++) { // 如果 i 为 true ，是素数 if (status[i]){ // 那 i 的倍数肯定不是素数，置为 false for (int j = i; j * i &lt; range; j++) { status[i*j] = false; } } } // 剩下为 true 的就都是素数了 for (int i = 0; i &lt; range; i++) { if (status[i]) System.out.println(i); }} 6. [字符串]给定一个 32 位有符号整数，将整数中的数字进行反转。Leetcode 第七题 如，输入 123，输出 321 。 自然想到要栈来实现 ，但是可以用代数方法模拟栈：一个数 n ，比如 123，要取出其末位，只需要 n % 10， 如 123 % 10 = 3， 然后 123 / 10 = 12, 把数字规模缩小。反过来，入栈的时候，一个数 m 从0开始， 只需要 m * 10 + n % 10 即可。 溢出处理：如果一个数溢出，那反回去运算肯定不会得到先前的数字，可借助这一点来判断是否溢出了。 123456789101112131415public int reverse(int n) { int result = 0; int temp = 0; while ( n != 0 ){ temp = result * 10 + n % 10; // 可能导致溢出 if ( temp/10 != result ){ // 检查溢出 return 0; } result = temp; n = n / 10; } return result;} 另一种思路是，用一个 long 来存储临时的数 temp， 如果 temp &gt; MAX_INT ，那肯定溢出。 7. [字符串]回文数判断一个整数是否是回文数。回文数是指正序（从左向右）和倒序（从右向左）读都是一样的整数。 转换成字符串，两个指针，A指针从前往后，B指针从后往前，依次比较。 1234567891011121314private static boolean isPalindrome(int x) { // 当测试用例有大量负数时，才加这一句 if (x &lt; 0) return false; char[] cs = String.valueOf(x).toCharArray(); int left = 0; int right = cs.length - 1; while ( left &lt;= right ) { if (cs[left++] != cs[right--]) return false; } return true;} 8. [排序] [位运算]文件排序编程珠玑开篇题目 有一个电话簿文件，里面记录的都是7位数的电话号码（如 3485712），没有重复数字，请排序并输出。 用一个容量为10000000的 boolean 数组，依次读取input.txt，并把对应的下标置为 true 。 例如读取到 1258021 ，就把 boolean[1258021] 置为 true 。然后遍历boolean数组，遇到 true 的把下标写入 output.txt 12345678910111213141516171819202122232425private static void readAndSort() throws IOException { // 初始化 boolean 数组 boolean[] set = new boolean[10000000]; for (int i = 0; i &lt; set.length; i++) { set[i] = false; } // 遍历输入文件 BufferedReader br = new BufferedReader(new FileReader(\"input.txt\")); String s; while ( (s = br.readLine()) != null){ int index = Integer.parseInt(s); set[index] = true; // 输出 BufferedWriter bw = new BufferedWriter(new FileWriter(\"output.txt\")); for (int i = 0; i &lt; set.length; i++) { if (set[i]){ bw.write(Integer.valueOf(i).toString()); bw.write(\"\\r\\n\"); bw.flush(); } }}","link":"/algo/index.html"},{"title":"安溥 - 與你握手","text":"安溥 anpu - 官方網站 2012 - 超级面对面 第14期 张悬：歌者也可以是战士张悬谈新专辑《神的游戏》： 对我来说第一张是非常苦涩的专辑，但大家却觉得很甜。对于我来说，这张专辑（神的游戏）反而其实做得自然，我觉得它也完成了我当下最想做的事情。别人觉得沉重，要看他是觉得来自于曲风还是来自于里面承载的情感，但对于我来说，这张专辑还算是这四张里面最不苦闷的一张。虽然也许很深，但我认为深跟沉重，对于群众来说是很值得分辨的字眼。这个专辑其实算是长长的，在我经历青春期之后这几年的时光里面陶选出来的东西，所以我认为它必须有深刻的部分在，不然就不值得保留或记录。但是呢，毕竟它是从我的生命里面长出来的东西，它不可能那么好，或者一下子就被群众辨识，但是我相信这张专辑还蛮有生命力的就是了。也因为这样，所以在一般的对于歌词或音乐的聆听上面比较奇形怪状也是。 爱情不是创作的灵感，自在做自己： 坟墓哈，我也不知道这是谁发明的词，但我每一次听到“婚姻是爱情的坟墓”、“幸福是创作的坟墓”我都会觉得很好玩，就是说也许很多创作者很希望自己就这样死了不是很好吗？至少我自己心底的感觉是这样。毕竟爱情不是我创作的灵感，所以爱情是我生命中非常可贵的一部分生存的条件。所以能够拥有它对我来说生命当然意义就变得更可贵，或者说更微妙了。但因为毕竟它不是用来写歌的灵感，所以它就不构成坟墓这件事情，我可能就是因为这样看待爱情，所以在我能够拥有真实、可贵的爱情的时候，我反而越安心。而这份安心可能就变成让我更能够自在地做自己。 …以前没有爱情的时候可以无欲则刚，因为这比较像是我的个性，但有了爱情之后更加无欲则刚，而且那个成分可能更纯粹了。因为你放眼望去这个世界，你可以因为有一个圆满的内心，所以面对愤怒，面对哀伤，面对残忍或慈悲的东西，你都可以有一个完全自我的解读，而不是被别人硬要碰撞出来的东西。 出处：超级面对面 第14期 张悬：歌者也可以是战士 20120805 - 神的遊戲音樂會 台中 勤美術館媒体自由和群众选择： 你們一定要知道，新聞媒體的自由，其實在於群眾的選擇上面……然後你們一定要知道今天的重點，絕對不是蔡衍明先生，也不是什麼旺仔小饅頭，什麼都不是，重要其實是我們要做出是我們自己群眾的選擇跟示範。讓NCC的各式各樣的審查制度，可以因為看見民意的訴求，而真的被迫導向一個比較健全而且比較審慎，而且不能夠再輕易地私相授受，回到一個正常的管道上面，這樣國家機制才能夠真正的運作，而不是空有其名。 “我们不需要一個站出來然後就去死的英雄”： 然後，請讓我們尊重每一個我們所見到的記者，不要因為一個標題或一則新聞，就覺得別人有沒有良心、缺不缺德。那一點都不是重點，通常控制我們的，其實是財團跟超級企業，每一個人其實都是在某一個機制下面被運作，被要求服務與工作。但是我們今天需要不是一個站出來然後就去死的英雄，我們要停止覺得某個人好勇敢，而是你要相信多數人，多數人如果有同樣的意見而且敢於發聲，你們就不是一個人。 如果你不是一個人，你的生路不會輕易地就被阻絕……你知道，如果有五十個，五百個歌手跟我一樣，歌手就是不會因為這樣的言論被封殺的，就沒有封殺這件事情了，所以請你們一定要去搜索一下，最近就是台灣最重要的幾件事情。 付出你們的選擇跟聲音，千萬不要流於意識形態的鬥爭。什麼買不買什麼東西。你平常就不買旺仔小饅頭不是嗎？那現在說你不買旺仔小饅頭幹嘛？於你無傷。但更重要的其實是我們在尊重每一個在努力的記者背後，我們其實反過來用民眾的身分，要去維護新聞媒體文化的自由與健全，這樣所有的新聞媒體工作者，也才能回饋給我們更好的節目、更好的報導，跟一個真正宏觀而且公平的報導立場。 好，我講完了。謝謝大家！ 出处：令人感動的安可加演—張懸的一段話(完整版) 201208 - Y!oung報 專訪張懸：沒有實踐，文青只是個貶抑詞如何定义“文青”： 文青就跟摇滚，就跟名牌，或者是就跟女生胸部大小是一样的，就是说，炒久了，它基本上不过是一个再也没有任何意义的标签。所以对我来说，知识青年这个事情就应该概括在所有青年身上。一个懂得如何把田种好的青年，他也算是一个知青，因为他拥有的知识别人没有。所以我认为藉由自己的知识跟生活经验，去产生自己的价值观的人，对我来说才应该是所谓的知识青年或者是文青。但在现在的话应该就是泛指你追求某种价值观，而不是在实践某种价值观的年轻人们。文青两个字，对我来说，去掉了实践，它就是个贬义词。 如何实践自己的价值： 我一直觉得先去实践才有追求这个选项值得讨论，因为如果一开始你并不知道你要做什么，那你要去追求的东西应该都是你看上去觉得很美的东西，你看上去以为自己的同路人的东西，那样的追求基本上就是跟从。跟从和追求很容易混在一起。我们假设旅行，在旅行里面不要藉由消费或者是藉由拍照去看这个世界你新发现的角落，而是真实地去体验走一段路，去为自己规划一个身体力行的旅行，而不是报了名然后买了机票去的旅行，那么这就不会是浏览风景的经验。我是建议如果你是文青或者你不想当文青，那最好的方法真的就是去感受一下为什么纽约是纽约，为什么他们的地下铁永远都有游民，为什么旧金山的游民在旧金山哪里都可以去。每个城市有他们对待穷人跟富人的方法，有他们阶级分明可是又可以轻易打破阶级的一些文化的层面，每个社会也都有他们的政治形态……这些东西其实你走在路上，够用心，不要用观光的方式去看的时候，你一定可以感觉得到。 作为青年人： 作为一个青年人，你就是这个社会最大的资产。而你把自己的价值看得非常飘渺，飘渺到你只愿意为自己消费，而不愿意生产值得别人消费的东西的时候，那我觉得，我们的资产先否定自己的时候，这个社会的资产当然就会泡沫化了。我觉得要是我七十岁，我就懒得有自己的思想啊，很烦啊，对不对，但是你年轻的时候，你一无所有，你唯一有的就是一颗空荡荡的心，跟完全不会累的身体，这两个加在一起，我的天啊，你可以一个人造就一整个世界啊！这个世界其实有很多选项是你爱怎么填就怎么填的。 出处：【Y!oung報】專訪張懸：沒有實踐，文青只是個貶抑詞 201209 - KKBOX 采访如何对待他人眼光： 我觉得我很在意，可是我也非常不在意。我并不觉得这矛盾。就是不管我多在意别人的眼光，回过头来我最后还是会选我当初要做的那个事情。只不过可能是我的个性或者是从小跟爸爸妈妈相处的过程中，常常让我养成你千万不要放弃跟别人沟通的机会。你千万也不要只因为自己的性格，所以你就不去关心或不去看别人给你的回应。因为这个世界永远都是相对的。你永远都可以坚持自己，然后你也永远都可以用你那一套过活。可是那并不代表你需要永远对别人 say no。我只是觉得，这世界上正是因为有各式各样的人，所以每一个人都有自己精彩的某一个极限跟境界，把它表现出来也许就是音乐的真谛。而你不需要去达到某一种音乐的境界，你只要完成自己就好了。 对缘分的见解： 因为其实这几年对我来说，我感受最深的，应该是人长大之后面对缘分这件事情，然后我一向是一个非常不认为人定胜天的人。我不觉得人一定要克服或征服什么东西，才能完成自己心目中对这个世界的想象。所以其实长大了以后尤其是这几年我发现，缘分比起之前自己为自己的那个努力，其实决定了更多的事情。当你接受了缘分的存在的时候，对我来说这个游戏就不需要用同样一种方式去转，这个游戏反而很大，它就在天地之间，就在人群里面。最怕的是你在这个游戏里面挑挑拣拣，你只想要当赢家，或者你永远觉得你（怎么）总是输，如果是用这种方式的话，你在这个寻常事物里面，很难很难遇到新的契机或者新的缘分去打开你对于活着这件事情另外的一种感受。 张悬的处世之道： 我是一个积极的悲观主义者。很多事情我都想过最坏的打算。也想过自己可能会失去或承担什么，想好了，但是想做的事情比这个东西还是重要得很多，那你就用一个疯婆子的心态很开心地把它做完吧。因为这个世界上除了你以外，没有人能帮你很开心地玩一场游戏。 20120901 - 文茜大讲堂关于文字： 长大以后觉得，其实字很重，因为人家会觉得你其实深思熟虑，所以把它诉诸于文字，而不是随手讲两句这样子。 流浪是否有追寻梦想的成分： 其实我觉得每一个人因为性格或者机遇的不同，遇到的谷底都差很多。并不是说肉体的痛苦就一定大过精神或者精神的痛苦就一定无法解决，但每一个人他一定会在性格上有一个心魔或者一个从来没有探过的底。可能对于我来说，那几年就是幻灭的成分也有，与其说音乐是一个梦，倒不如说那几年其实我跟所有出社会的年轻人都一样，就是说文字可能是我在我自己身上或者别人看我身上，在我求学阶段可能算比较明显的一些可以培养的才华嘛。所以你就开始尝试这样子的一个写作有没有可能有任何方法可以养活自己，或者达到一个新的生活的形态。那几年基本是完全不可得的嘛。所以梦想的成分其实在最早离家的时候就已经消灭了。更多的时候其实你在面对的是你在生活里面如何自处。要把自己看得更高或更低。 关于才能跟价值： 我觉得唱歌其实是我知道的自己身上少数自己没有刻意开发，却莫名其妙地在我身上变成一个跟外界有最强烈互动的一个东西。因为有时候你自己的才能跟你自己最独特的价值其实是分开的，我觉得这很有趣。可能我在写作上面不可能满足所有人，然后这也是我想要、我希望能够为我的文字服务的地方。 关于角逐奖项和为什么编曲用本名： 我不太愿意角逐奖项，因为角逐奖项要有报名的过程，我自己是觉得不用报名很好。我本身并不是很认同竞赛产生出来的遴选。后来发现角逐奖项这件事通常对自己的关系还小一点，它通常肯定的是你背后的整个团队……奖项对我来说唯一的价值就是让爸爸妈妈开心。（所以一定要打本名） 出处：2012文茜大講堂！張懸專訪（內有live吉他🎸槍與玫瑰🌹經典曲） 20131116 - 台东铁花村独立思考： 我欢迎各式各样的年轻朋友不止是听我们这种人讲或者只听媒体讲，干脆你都不要听我们讲，你回家去 Google， Google 台湾能源政策，Google 台湾的地质是不是真的适合盖核电厂，还是比起断层带，某个地方相形之下比较适合……这些都是很值得讲究，很中性的问题，只要你找到关键字，去查一下，这个世界上有好多人都愿意跟你分享他们知道的知识————从工程师的身份，从政治的角度，或者是从社会的角度，或者是哪怕从年轻人的角度，我们都可以找到非常多的咨询去交换意见，直到你们产生自己的意见跟选择。所以我很希望，如果你们很想知道这个地方正在发生什么，Google！Yahoo也可以查到很多东西，对，这个世界上有很多方法可以帮助你了解这些事情，不只是透过媒体或者是所谓的新闻。新闻帮我们总结一些事情，但是为了得到我们自己真正的想法，最好是不要听太多被过滤过的咨询，反而是自己去找一次来龙去脉，就像看金庸不能只看角色一样，最好是知道杨过跟小龙女中间多曲折还是很相爱，你才会知道他们很值得厮守一生。很烂的比喻对不对，所以我不是讲话得罪人，就是打很烂的比喻。所以，欢迎大家永远为了一个你知道但还不是很清楚的事情，多去 Google 一下，我相信我们就会拥有更多独立思考，而且懂得怎么去诠释这些事情的年轻人。 出处：張懸／b18 喜歡 (鐵花村 2013.11.16.) 20131230 - mellow new year@女巫店关于我爱你： 《关于我爱你》里面有两句歌词大家都很喜欢——“我拥有的都是侥幸，我失去的都是人生”。我跟很多人说过，我一直不确定这是我写的一个词，我有在我的笔记里面看到我写过大概20万遍，但是我一直不确定那到底是我看某一本书得到的一个心得还是我抄下来的，这是我写这么多歌以来第一次搞不清楚那句话到底来自哪里。那太像是我会想的东西，但是又没有那个把握。 之后在我整理房间的时候看到，我以前爱过一个女孩子非常多年，原来这两句话是当年那个女孩子写给我的，我们后来没有在一起。然后我发现那本书里面夹着的是我整个青春期最重要的一封信，那封信就是她写给我的。当我看到那里面有那两句话的时候，我赫然觉得，这十年来悬着的一直解不开的记不起来的可是我也找不到证据的一个东西出现在我眼前的时候，我好高兴我曾经有过青春这件事情，我也好高兴我并没有把它当作一个像刺青一样的东西一直在想，它并没有那么明显以至于我从来都觉得它模糊。但曾经深爱一个人或者被一个人深深爱过的那个痕迹，这一刻就让我觉得充满了感激。 所以真的是非常非常谢谢有这么多人爱过我，我也有那么多机会去深深地爱过一些人，希望这首歌能够代替我人生背后的一些故事，这些故事可以不用到处跟别人说，但是却可以影响我这个人或者更多人。 出处：20131230 張懸 關於我愛你 20140406 - 一席·香港·我们并不孤单 比起意见，更多想分享和互相鼓励： …前面两首歌是我平常跟乐团常常表演的作品，下面要唱的这首歌，我已经有一阵子没有唱了，这首歌叫《城市》。然后今天唱木吉他的版本，其实也不知道为什么这两年我好像，也不是莫名其妙，应该就是活该，活该变成了一个，好像大家见到我都不太再问音乐的事情了，都在问我对于不同的社会有什么意见，就是仿佛我是因为因为有很多意见所以才上台表演。其实我一直觉得我是一个意见很少的人，那我觉得这也只是这个世代，这个generation的一个现象，我觉得在我们这个年代的出现的一些歌手出来之前，尤其是亚洲啦，或者是唱华文歌曲的歌手，很少有被教育或是被鼓励说当一个entertainer，或是当一个performer你要有自己的意见，仿佛自己的意见其实都要打包，带回家里面，然后留在台上的其实都是，所有人或大部分的人想看到的东西，那才会完成娱乐这件事情，然后那也才叫做「敬业」。 但是我觉得，我跟很多人比较，其实蛮幸运的地方是在我们出生的80年代，在我们长大面对的这个千禧年的世代，很多观念或者是很多，这个世界不同的危机，其实都慢慢浮现。人有一些，就是你可以看得到这个世界在讨论，很多新的期待或愿望。然后它也反映出其实我们，眼前的这个人类的各种不同的社会的形态里面，有哪些危机或是有哪些隐忧。 于是我就觉得其实这个年代需要的娱乐，已经慢慢在亚洲开始不太一样了。它不再只是，人只要看到有漂亮的女孩或男孩在台上唱歌，心里就可以得到所有的满足，因为千禧年过后，我们发现这个世界，因为信息的流传变得非常的广泛，然后也因为网络很发达的关系，你发现这个世界原来充斥着这么多你无法想象，或是你不曾想象过，或者是电视不会告诉你，要去想象看看的东西。 所以我觉得，在我们这个世代，要不然其实就是不看不听，所以变得很虚无，要不然的话其实就是因为想看想听，所以知道多一点事情，你就在大家深夜入睡的时候，一个人觉得焦虑，然后觉得痛苦，或者是你对于这些还没有答案，或自己帮不了自己的东西感到非常无助，会不会我希望有人跟我一样有时候半夜是这样过的，这样代表I’m not alone，you are not alone，either。所以其实这几年，我用当歌手这件事情，其实要传达的意见不多，但是想要跟人分享或者是互相鼓励的东西，也许比意见要再更多一点。 接受既成事实，不如亲自去实验找答案： 我一直相信这个世界很多人其实是因为在成长的过程里面，就没有人告诉你，或者是没有人愿意让你这样想，所以我们以为这个世界发生的事情都是已经，都是既成的事实，是无法改变的事。就好像小小的一个我，基本上能够在这个世界上，好好地生存完八十年，其实就是一件了不起的事，那但是在我们这个generation，我觉得我得到更多的信息或者是长辈的新的启发其实是，因为人只有八十年，所以你想做什么其实你就应该要，你就要趁还有这个热情的时候，去实验，去为人类的一些问题找答案。答案并不是点石成金的一件事情，不是我对着自己喊两个口号，这个事情其实就不会再犯错，或者是不会有新的变化，许多人与人之间的事情，或者是我们社会要面临的很多事情，需要很多讨论，讨论会带来混乱，但混乱也就是代表你有好多个选项，可以选择你想要怎样看待一件事情。或者是一个社会的发展，那如何在这么多的选项里面，找到一个自己要的答案。那我会说，与其去找一个自己要的答案，其实有点像是在超市里面选东西，再多的答案其实都比不上你为自己找到，或者是为自己去做实验，所以印证出来的心得，对于这个世界或对于自己来说帮助更大。 所以，我觉得这几年我在台上最想讲的东西其实也就是这些，因为很多事情，它也许在爆发的时候有对有错，那也许它的下场，令人难过，或令人愤怒，或令人快乐，但其实那从来都不是，决定我们这个，一起生活的未来最重要的一些事情，决定我们的未来最重要的其实是人心，人的心，在每一个年代，一起决定做的事情，我一直很相信这个事情。 但在台上讲有点天真，但是表演者、写诗啊唱歌本来就是很梦幻的事情，我们就是提供一个美梦，或者是一个幻觉，让你相信你的寂寞是真的，然后你或者是那个女孩，跟你分手她真的是错的，我们的贡献其实就是告诉你 You are right. 所以这一刻其实我觉得，这几年我想要在台上说的话也是这样，我想要说一些 Yes, you are right. So, why don’t you just get up and do it,for yourself, not for any others.希望我们终其一生去找的每个答案，都会是因为为了自己的生命有独一无二的体验，所以我们可以提供给这个世界一个独一无二的观点。 那我觉得越多我们这个年代，我们这个generation的年轻人，如果可以突破上一代的政治啊、经济、或者是上一代没有解决的一些事情，而为自己去找不是新的出口，而是新的申论的方法，而不只是yes or no，或者是I want or I don’t want的话，其实我觉得，我很希望我们这个generation可以一起做一些，自己觉得这一辈子很值得，也因为这样所以有小小的存在感，但更重要的是我们不会消灭下一个generation的存在感的事情。 关于《城市》这首歌： 所以，让我上台的是这些。但是我的歌，其实想要给的还是一个美梦。下面的这首歌《城市》，其实就是我当年希望给年轻人的一个美梦。虽然比较像催眠曲啦，它在讲我看待一个城市，不断流动的一些东西。有时候你去观察一个城市，它有硬件的建筑，也有软件，就是人与人之间的交流的气氛，或者是人与人在一个硬件的架构里面做的事情，这造成了每一个城市有自己不同的面貌，我们希望自己的城市长什么样子，其实都是可以下手去做的。 我们一边观察它现在的样子，一边要永远地去体会到，我们都是构成这个城市里面的，一个结构一个原子，所以当你是一个城市里面突变的个体，你做了一些这个城市从来没见过的事情，这个城市就再也不一样了。所以，希望，你们都是学生对不对，希望我讲的话有一点点作用，或者是对你们来说有任何用得到的地方，然后也可以让你们在不同的城市里面，也像癌细胞一样扩散，知道你们每一个人都是独一无二的癌细胞，把一个坏掉的身体给吞光，但是产生一个非常强韧的城市的新的灵魂。 「坏人奸 好人要更奸」： 我在鬼扯对不对？这是我这几天最大的心得，就是你知道周星驰有一句话影响我很深，就叫做「坏人奸 好人要更奸」，你们知道那句话吗，知道吗，对不对？我们在台湾看电影的时候都会听到这句话，《九品芝麻官》嘛，这句话就让我每一次在做事情的时候都会一直在想，到底要怎么样更奸，到底要怎么样？ 我觉得这是我们这个generation其实永远可以思考的问题，其实它是无所谓奸的，但是如果我们可以比坏人看得到坏人，也就是说不为别人跟自己着想的人，我们都简称是「坏人」好了，如果我们对于这个世界想要发生的一些好的事情、好的现象还有一些期待的话，我们有没有可能比不在乎这个世界的人看到更远的几步。于是，我们也许可以更超越地去看待它更大的前景，也于是我们做的每个决定，其实都不是为了当下小小的利益，也不会畏惧当下小小的所谓的孤独或不被了解，反而是用更宏观或更开朗的心情去让一件事情发生。也许这个就是「坏人奸 好人要更奸」的第一步。那接下来的手法的话就是做实验了，我希望更多年轻人能够在这个时代里面不要放弃做实验，我相信，因为实验的关系，我们一定可以找出上一代根本不被允许去找的一些新的答案，然后用新的方式，于是我们有一些新的结果，谢谢大家。 观点只是一个交流的过程： 下面这首歌，我自己很喜欢的一首歌，我平常在家里面想事情，写东西的时候比较常练的就是这首歌，这首歌是来自Pink Floyd的Wish You Were Here，我要送给你们。 其实，大部分的时间，台上的歌手其实从来都不是万能的，所以你们也要知道任何一个你们相信，或者是现在正在关注的公众人物，都不是万能的，我们都只能够给，不管是自己观点能够呈现出来的人的想法的某一面，然后，或者是我们能够表达一个很独特的品味跟你们作交流。除此之外没有一个东西，台上的人物或者这个世界上面，看起来所谓的名人，没有人应该要告诉你，或者是应该要让你用他的方法活，我觉得这一代我们要做的事情，并不是要在这个观点，每一个人交换不同观点的时候，用谁去压制对方，用一个观点去解释这个世界。观点只是一个交流的过程，它应该永远是一个鼓励，鼓励下一次当你跟更多不一样的人说话的时候，我更确定我想要这样想，我想要这样说。而我看到的世界是如何，对于我来说这个东西其实比谁跟我一样或者是谁愿意听我说话其实要来得可贵很多。 存在感： 但我相信在寻找的过程里面，就好像我在Facebook常常都会收到很多人的来信，「人到底要怎么样可以不寂寞」啊，「到底不看电视的话我能看什么」啊，「我去网络上找数据我更无助啦」，找不到答案或者解决的方法的时候，人都会特别的心慌。以至于你就会觉得你是不是又回到旧的道德观或者既有的观点里面最安全，因为那边人多。而且那个东西已经被用了好久了，所以好像那样子过也没有什么问题，但这就会带来新的问题，我就会觉得，我好虚无啊，我没有存在感啊，或者是，我好渺小啊，因为我没有自己的观点。 你总有一天会看到，一些东西又重新引发那种，我想要知道我是谁的渴望。所以，关于虚无没有存在感，跟有存在感但很痛苦，这两个东西其实在每个阶段里面，都会体会。你也可以,在每个阶段换着去当当看，直到你发现，我愿意有感觉。所以有痛苦也有快乐地活着，或者是说，诶，其实我希望我心如止水，也可以这个选择都是你自己的，只要这对你来说这是你人生，因为体验所以做的决定，而有的心得，我相信这个世界都会祝福我们的，但在此之前千万不要拿一句标语，或拿一个人，别人做的事情企图套在我们身上，以为就可以定义生命的意义或活着的存在感这件事情。 所以当你无助或心慌的时候，我希望把这首歌送给你们，就是我们都会有同样的心情，但是我们也同样都在寻找，希望台上的人如果让你觉得坚强，毫无畏惧，能够给你一点鼓励。让你勇敢地也去寻找自己，而台上的人如果有很落寞或很脆弱的时候，希望这份脆弱，或者是要表达的这份寂寞，可以让你觉得你并不孤单，每一个人都有这个时刻，谢谢。 出处：一席·我们并不孤单（一席官网）（Youtube） 20141006 - 纽约 Live Show张悬谈《日子》： 这首歌是我少数写我自己和写给自己的一首歌。大部分时间你写的东西都来自于你的观察，或者是一些想诉说的东西，所以这首歌也正是在讲我自己。希望这首歌可以陪伴你们在这个城市或者是任何别的地方，能够找到一个不求所有美好的事情都要发生，但求所有发生在你身上的都可以让你觉得那是唯一会发生，所以非常值得的一个人生。 出处：Deserts Anpu 10/6/14 New York Performance 張懸/张悬 纽约 Live Show 20150117 - 台湾高雄 潮水箴言 终场 谢谢你们那么多年来听我的音乐，我希望这些歌可以陪伴你们的人生。希望我能给的那么渺小的东西，因为可以陪你走一段，于是让你觉得自己的人生很大，很宽很远。也因为这样可以容纳更多自己想发生的与这个世界值得发生的更多事情，请不要忘记你们有一颗因为慈悲而毫无畏惧的心，去面对这个时代，加入这个时代，让更多不一样的事情从这个世界上从奇迹变成一种常态，再从常态变成一种莫大的自然。谢谢！ 出处：焦安溥潮水箴言終場安可謝語 張懸《潮水箴言To ebb》一段話 20151008 - 听说 第一季 第十六说：再见张悬马世芳谈张悬和她的歌： 《如何》这首歌我第一次听到的时候就非常感动，你问我她歌词到底在唱什么，这也是很多听张悬的人会有的困惑，张悬有时候自己会在舞台上说关于这首歌的种种，她常常越说你越觉得云里雾里，到底她在说什么，有时候你听完了你对整个歌不见得会更懂得。我觉得我们在听歌的时候，就像我们在面对诗的时候一样，保留一点不可解的部分，那个在核心闪烁着微光的那个谜一样的东西，有的时候它才是这首歌最迷人的部分。 马世芳谈《神的游戏》： 就拿《神的游戏》这张专辑来说，它是一张很耐咀嚼但是不是那么容易消化的作品，可是这张唱片还没有上市它的预售的数量就达到一万两千张。这在当时台湾的世道是非常惊人的纪录。而且你想想张悬在这几年根本就没做什么宣传，在媒体上也消失了，但是就是有这么多张耳朵在那等着盼着，你一发表了要发片的消息大家就马上要来支持，甚至连里面的歌可能都还没听到。后来唱片很快卖到两万张，这两万张里面每一个人都是真心地实实在在地在乎这些作品，在乎张悬想要说的话，这样的关系才是这个行业最重要的核心价值。张悬示范了你可以做一个不要特别去讨好谁的音乐人，你只要能够去掌握好自己的技术的能力，你把自己的手艺磨练好，你认认真真地把你想做的东西做到你觉得最好的状态，然后认认真真地把它用最好的方式端出来，自然会有千千万万双耳朵靠过来仔细地聆听。 出处：听说 第一季 第十六说：再见张悬 20181103 - 杭州ADM 城市音乐分享会关于诗歌的魅力： 不知道大家有没有在听音乐，或者看一首歌词（的时候），除了觉得全心投入，或者是觉得心有戚戚焉、念念不忘的同时，有去想过 为什么打动你的是一首你几乎不能够马上拆解成你可以解释的东西却能够击中你的心（的歌）呢？我觉得这就是诗词的魅力。因为诗歌算是早于文字的人类用于沟通和表达自我的一个方式，它的起源造就了后来的文字。文字跟语言这件事情反而变成了我们借由发明的符号去沟通的一个共同的工具。而诗歌在工具上的功能反而小过于当代我们所认识的语言，但它却能拓展人类在所谓有限的生命里面无限的对于世界、对于自然、对于生命的体会。 关于交集： …这个画家的东西，不是我看不看得懂的问题，而是我应该更努力去开发，去打破那个语言的障碍、领域的障碍，以至于我可以有机会去看见那个密码并且深入去了解。其实我的歌词我觉得我也有留下一些密码，它绝对不是字面上的意义。所以通常在字面上不缺乏，在文法上面不违和以后，创作者通常都会在里面留下一些像签名一样的密码，我会很希望拿这个去祝福今天所有的听众。我知道你们都是一些深爱音乐，深爱艺术跟文学，或者深爱科学的人，所以我把几个关键字留给你们，希望也许有人今天回家或许会听听梅香，或者特斯拉的故事……于是我们开始有了一个新的语言，而这个语言来自于我们生活上的交集，也因为这样我们也发明了一个不像货币一样却因为互相分享我们开始建立起来的一个共通的语言，这个共通的语言是无私的，跟知识有关的，希望它们能够陪着你们去领会一首又一首伟大的作品。 如果诗歌代表精神世界，又如何处理精神世界与现实生活的关系： 我以前在台北演讲的时候也说过，哲学可以拿来活吗？不行的。所以其实对我来说，靠音乐或者诗歌这件事情来凌驾生活，我觉得反而会有点本末倒置了。其实诗歌一直都来自于生活，诗歌是人类最早的表达活动的起源，我们一定是先有了自己的精神性，所以才要想去表达它。为什么会有精神性这件事情呢？它一定来自于你的体验与感受，所以我们永远不能够放弃生活，包括我们永远不能够试着要求生活是没有杂质的。对我来说诗歌代表了哲学上的可能性，哲学可以在每一个面向上面做到纯粹，就是沿着这个脉络下去它是一个纯粹的思考的逻辑，但是生活是非常放射状的，我们跟别人的经验，我们跟别人的维度会不断地交错，这个部分有时候你如果要用放大镜去看会觉得痛苦不已，如果用鸟瞰去看又觉得距离太遥远。于是我觉得生活跟艺术之间唯一的调节是来自于我们自己，我们可以决定我们与人类的这些艺术的关系是可近还是可远，而一旦我们想要去界定，我们也许从此就切开了人与人之间的相处，也就是生活这件事情跟艺术之间的关系。因为我们决定了它必须要是什么，如果它没有达到标准就会被弃置的话那么我觉得是一件非常可惜的事情。希望我们都可以继续去做在精神层面上和现实世界上透过我们的体会，透过我们的观察，反而是因为这样，所以你自己可以把自己当作一个伟大的作品，在你自己身上留下“思考”这样伟大的密码。 生活和艺术： 我从来不会觉得我的生活一定要往艺术的层面走，艺术其实是自己的事。生活不必艺术。反而是我们让我们的生活变成了哪种艺术，这个因果是可以颠倒过来的，这也比较像是我的人生观。 安溥谈歌曲《城市》： 我发现我生命中写作也好，做人也好，不断精进自己或去体会他人，实际都是来自一些看似“腐败”的事物，比如你在生活里面遇见不如意，人与人之间的一些陈腐，心机，或者是自己觉得无能为力的一些体会，它都是一种“腐败”，它都会让你的心情觉得暗淡，但是这个东西却变成了下一次你能体会光明面，或者是愿意直视自己黑暗面最大的养分和基础。于是我就把这个心得变成了《城市》这首歌的slogen，也就是说，我很心爱当代跟我一起生活的城市，我不求它多好，也不会硬要去看它非得多坏，而是我愿意陪它一起生生死死地面对每一个年代，一个城市的兴盛与衰败。回过头来，《城市》这首歌也就暗喻了我把城市当作人生这件事情。它虽然讲的是非常社会面的东西，但提到精神面时实际上用来比喻我们的人生。我们的人生如果是这么的一座城的话，我会怎么陪你过或者我会怎么看待你，看你身上的好与坏，高潮与低潮，觉得荣幸，或者觉得屈辱。 出处：杭州ADM城市音乐分享会 20181103焦安溥 201811 - BAZAAR 访问安溥谈《炼云》： 其实它（炼云）就是我这几年消化出来我想做的演出作品的所谓的尝试，It’s a big one.但是我觉得，既然是要做尝试，既然你要试试看一个东西，你可以从最小的念头开始，但是你不能用最小的方式去做。所以我觉得它是一个很好的尝试。有一部分内容，我把曾经感动过我的 concert，为什么可以做得那么好，这件事情回过头来传递给我能碰到的观众。 安溥谈 Clockenflap 演出： 我会希望把演出当作作品去做。虽然它要花费的时间跟成本比较高，但我会觉得人只活一次，所以你有这个领悟就应该要去完成它。也因为这样所以 clockenflap 是今年我觉得我少数接下来的演出里面非常特别的一场。我选的曲目应该其实就只会在今年唱第一次跟最后一次，然后应该以后也不会再特别公开。它大概是这几年我用很普通人的身份，曾经跟我有机会见到面聊天，或者是有一些人在上一次的演唱会《潮水箴言》之后写信给我，还要其他最早开始听我音乐一路以来的一些故事的人，所以我特别选了来过的信件里面，有一些人的心情、心得或者是感想是曾经很感动我的，所以我把他们很在乎的那些歌，特别重新做一次编曲。 出处：安溥復出後的訪問 | Harper’s BAZAAR HK TV 20181109 - 香港 Clockenflap无所谓抵抗: 我今天想把这首歌（Wicked little Town）和这首歌的歌词送给每一个珍惜自己所爱，不管这个世界分分秒秒在变化、依然可以保有最大的勇气和幽默感在别人的祝福我们以前先祝福自己的人。然后我要拿这个陪伴所有不同性向的朋友们，包括我自己。希望我们的无所畏惧不是来自于抵抗、而是来自于我们无所谓抵抗。 出处：Clockenflap焦安溥talk 求婚现场之“我们无所畏抵抗” 20181117 - 台湾高雄takaorock 安溥在 takaorock 的talking： …今年我想了很多事情，万一灿烂或者是成功的背后，或者说当你得到成功之后，你发现你从不想赢怎么办？万一总有人生一个阶段，或者是说在这个世界提出很多主题或是希望能够诉诸一些输赢的时候，你完全只想输怎么办？…希望这短短的八九首歌可以陪伴跟我一样今年刚好在同一个交集点在思考，万一打空挡的人生才是容纳最多思考跟看见更多真正重要的事情重新开始发生的时候，所以比起鼓励，这次音乐节的歌单我特别希望送心里面其实还有很多在想，还有很多要说的人。 出处：安溥-碎碎念talking录制 201812 - 成功郵便局 回信信件1 - 怎样才称得上成功人生？ 网友来信： 你好， 我想知道人生中有这么多角色需要去扮演，我要当女儿、妈妈、老婆、便宜、主管、下属，还要当尽责的社会公民，是不是每个角色都要扮演得好，才称得上是成功的人生呢？刚我做不到面面俱到，我该如何释怀呢？ 安溥回信： 你好， 在眼前媒体与社会与舆论诉诸二元式观点激增的现象中，能意识到我们与他人皆有着多重复合身份是多么重要并可贵的事。于是”成功”一词之于每一个人和他所面对的处境和人生也是，没有必然的标准或恒常可言。也或许，我们太相信（或需要相信）所谓成功这件事的存在，若是这样，我们就反而在取舍之间，问心之间，和举措之间遗弃了真正值得驻足观察、感受和值得我们生出勇气和相辅佐的智慧的机会。 对我来说，生存与爱人都非常需要一份心甘情愿的勇气。每天，每种处境里我们都得对它们一次一次自问自己是否仍情愿，仍选择它们。处理自己对每个每次这样的自处于处世的思考和领悟就是智慧。生命的存在是无所谓成功与否的，而能在我们的一生中安顿每个阶段对人生的思索，安顿自己每个身份的得与失，这份安顿里就有着对完美或成功这些词语的包容和宽爱。 与你分享这些体会，祝福我们因不迷惘和执着于成功一字，于是常常感受真正的圆满。寻常即圆满。 安溥 祝福 2018.Dec 信件2 - 有污点的人生还跟成功有关系吗？ 网友来信： 您好，我是一个更生人，曾经去里面蹲过。出来后，我参加了更生人的辅导计划，我也很积极的想要让自己重新开始，但这个污点在我身上怎么样也洗不掉，求职处处受挫，即便最后我在辅导的安排下开始了工作，受到的白眼与歧视却也从来没有少过。 尽管我很努力地抛开我的过去，但它就是现实的跟着我，而且这一跟，就是一辈子…我慢慢开始麻木，很多事情都看得很平淡，当初的目标也变得无所谓了，我想问，成功这两个字，就现在这样看起来，跟我一点关系也没有了，是吧？ 安溥回信： 给亲爱的署名更生人的朋友你好， 如果我们身边的人告诉我们这个社会（或世界）并没有如想象中残忍、现实与可怕，那一定是一份鼓励与安慰，而不是真的。这个世界的确让任何一种人都受过伤、跌过跤；它常常充斥着各种纷争、误解和扭曲片面的解读和轻易否定我们存在的事情，所以你的挫折和对未来的茫然是一定会发生的。其实不只是你，看似没有过错的人也往往仍面对自己别的地方的失败，也会不停地出现找不到活着的意义的念头。朋友，辛苦了。 也许我们终究都要有这些看似无解的烦恼，要去承认这个社会不会等待我们，是吧。所谓的人们眼里的成功，之所以离我们遥远，并不是因为我们失败。其实是人的一生中有那么多数不清的得失和悲喜，有各式各样的际遇在变化着，在成功的定义面前，没有人时时刻刻每个阶段都能符合成功的标准，尤其是以我的经验或体会，很多人的成功，背后都有艰难的故事跟不足为外人道的落魄时光和“失败”。有时我们的际遇也需要我们自己去转化它们，或诠释它们，因我们的领悟于是将逆境与失意变成了人生中的哪种养分和动力。 我想我能分享给你的，是一个念头，就是一个圆满而能承担许多困难的人生的人，一定都有两个世界，一个世界留给外界，在这个世界里我们认知自己需要面对的问题，练习解决困难克服困境的方法，和去体验自己做的每个选择对自己和不同人的影响；一个世界留给自己和自我认同，去珍惜、培养和照顾自己的优点、能力和心愿，哪怕是自己深爱的人事物或爱好。两个世界不必重叠或相通，偶尔相连或相容就好，这样我们的精神世界与现实生活就有各自喘口气甚至互相充实的可能。 所有的突破与转机都来自于细处的累积，有时坏事或危机也是啊。每当还算平安，去观察小事情里可能有的漏失，每当身处逆境或也许感到绝望，希望你愿意试试，静下心想想自己有没有任何一件还感兴趣的事想做，或向做得更好，就从最小的这种事情去做，去进步，去发展看看。至少我是这样长大的，很多我后来的遭遇和机缘是因为这样而起步的。深深祝福你，盼望这封信能带来的，是肯定自己的一份勇气或是一个契机。 我们的一生之中，每个能不求他人打分数就能肯定自己的时刻，就是真实的也最了不起的成功。 祝福无限。 安溥 与台北 2018.Dec 出处：華康字型 - 脸书 20190126 - 台北花博公園，大暖季 我想把这首歌（wild horses）送给我生命中一个很重要的朋友，她叫巴奈。天气太冷了，过去两年我自己身体也不好，所以我不像一个可以时时刻刻可以一起混的朋友一样，在她很需要持续的关心和支持的时候可以身体力行地陪伴着她，大部分时间我都在尝试自救。但因为今天太冷了，我就想说，啊我有一个朋友叫巴奈，跟我在同一个城市台北市，她过了700天睡在街上的日子，这件事情没有让我感伤，但很想让我跟人们说一句话：其实我们论述的论调、看待这个世界的方式或者是想跟别人讨论的事情真的很不一样。 承认人类的世界彼此就是不相容： 所以其实这一两年(看待事情)我都放去写歌，写完后放在那里像酿酒一样等待着它发酵。我每次想到巴奈跟她在街上露宿的日子我其实都会想说，有时候我们几乎要承认，人类的世界彼此就是不相容，人类容不下动物，容不下跟自己不一样的种族，容不下不一样的观念，容不下不一样的生活习惯，容不下不一样的年纪，容不下不一样的性别……人类什么都容不下，然后通常都是自己都觉得自己崩溃了，当别人也容不下你的时候，可能我们就会在宗教信仰里面打开心房去接受全世界。 剥夺和给予： 在这么极端的人类的行为表现里面，我总在想，有没有可能其实，我们的存在剥夺了别人的什么，但我们也一定给与了些什么，我们拿走了一些，也一定留下了一些东西。当我们想起我们在别人的生命里或者是跟别人一起生活的时候，不管我们做得多好或多坏，一定会带来些什么，也会拿走些什么。带走跟留下其实是很中性的字眼，完全取决在你知不知道自己留给了别人什么东西而你又拿走了什么。剥夺说不定是很美好的剥夺，说不定也是一个帮忙承受，但有时候给予也可以是一种暴力。 相处不必共识： 我想在今天这个这么冷的日子里，把这首歌送给我的好朋友巴奈。希望如果我们有机会的话，有没有可能永远不要意见一致，永远不用用同一个观念去达成一个共识。有没有可能人与人之间不需要共识。可是需要的是我们怎样看待彼此的观点的方法，这样就好了。有没有可能，我们就是要承认，你跟我不一样……或者是有没有可能，不要互相阉割，但找到一个可以讨论事情的方式，这个是我大概未来几年最想看到的事情吧。所以我今天要把这首歌送到每一个感受得到天气，也去思考每一个在街上、在奔波的人。有没有可能我们都是为了要生存下去，有些人要的是生存的尊严，有些人要生存的品质，有些人只是要钱，但都没有什么不好的。但如果我们都得生活在一起，我们还有没有什么别的方法呢？ 出处：台北花博公園，大暖季、安溥（talking +singing) （图片来自：blow.streetvoice）","link":"/anpu/index.html"},{"title":"分类","text":"","link":"/categories/index.html"},{"title":"剑指offer","text":"1.赋值运算符函数略 2.实现 Singleton 模式 构造函数私有 静态内部类保证线程安全（静态内部类在类初始化时只会被加载一次，因此是线程安全的） 1234567891011121314public class Singleton{ private static class Holder{ private static Singleton s = new Signleton(); } private Singleton (){ } public static get(){ return Holder.s; }} 3.数组中重复的数字题目：长度为 n 的数组，数字在 0 ~ n-1 范围内，有些数字是重复的，但不知道几个和几次。找出任意一个重复的数字。例如：输入长度为 7 的数组{2,3,1,0,2,5,3}，数字在 0 ~ 6 范围内，输出 2 或者 输出 3 思路一：排序先排序，然后从头到尾扫描数组。排序一个长度为 n 的数组需要的时间为 O(nlogn) 思路二：哈希表扫描数组，每扫描到一个数字，都用 O(1) 的时间来判断哈希表是否已经包含该数字。如果没包含，就加入哈希表。该算法时间复杂度为 O(n)。但哈希表需要占用O(n)空间复杂度。 12345678910111213private static int isDuplicateEleByHashSet(int[] arr) { HashSet&lt;Integer&gt; set = new HashSet&lt;&gt;(); for (int i = 0; i &lt; arr.length; i++) { if (set.contains(arr[i])){ return arr[i]; } else { set.add(arr[i]); } } return -1;} 思路三：arr[i] 交换到下标为 i 的地方在数组中，从 index = 0 开始，将arr[i] 交换到下标为 i 的地方，如果要交换的数字跟当前数字一样，说明是重复的。尽管代码中有两个循环，但每个数字最多只要交换两次就能找到自己的位置，因此总的时间复杂度也是 O(n)。 12345678910111213public static int isDuplicateEle(int[] arr){ for (int i = 0; i &lt; arr.length; i++) { // 只要 arr[i] 跟 i 不同，就比较下去 while (arr[i] != i){ // arr[i]是数组当前值， arr[arr[i]] 是即将要比较的值 if (arr[arr[i]] == arr[i]){ return arr[i]; } Swap.swap(arr, arr[i], i); } } return -1;} 4. 二维数组的查找在二维数组中，每一行从左到右递增，每一列从上到下递增。给定一个二维数组和一个整数，该整数是否在数组里 12345 → 递增 1 2 8 9↓ 2 4 9 12递 4 7 10 13增 6 8 11 15 思路二维数组arr[row][column] 中，第一个中括号控制行（row），第二个中括号控制列（column）。可以从右上角开始，右上角为 arr[0][arr[0].length - 1]，如果目标值大于右上角，跳到下一行（row++），如果目标值小于右上角，跳到上一列（column–） 1234567891011121314151617181920212223242526272829public static boolean find(int[][] arr, int target){ // 右上角的行号为 0，列号为 arr[0].length - 1 int row = 0; int column = arr[0].length - 1; // 行依次递增，但要保证小于arr[0].length // 列依次递减，但要保证大于0 while (row &lt; arr[0].length &amp;&amp; column &gt;= 0){ // 如果命中，返回 true if (target == arr[row][column]){ return true; } // 如果 target 大于当前值，在下一行找 else if(target &gt; arr[row][column] ) { row++; } // 如果 target 小于当前值，在上一列找 else if (target &lt; arr[row][column]){ column--; } } return false;} 5. 替换空格实现一个函数，把字符串中的空格替换成 %20，例如输入 We are happy.，输出We%20are%20happy。 思路第一步：先计算原字符串空格数，如果有 n 个空格，那么新字符串长度应该是 原长度 + 2*n。第二步：用两个下标，一个是原字符串下标，一个是新字符串下标，依次从后往前拷贝，遇到空格时，依次赋值0、2、%，非空格直接拷贝原字符串内容。 123456789101112131415161718192021222324252627282930313233private static String replace(String str){ char[] cs = str.toCharArray(); // 计算空格数 int blankNum = 0; for (int i = 0; i &lt; cs.length; i++) { if (cs[i] == ' ') blankNum++; } // 创建新数组 char[] resultCs = new char[cs.length + blankNum*2]; // 两个下标，一个指向原数组，一个指向新数组 int index_ori = cs.length - 1; int index_result = resultCs.length - 1; // 从后往前遍历原数组 while (index_ori &gt;= 0){ // 遇到空格，新数组添加 %20 if (cs[index_ori] == ' '){ resultCs[index_result--] = '0'; resultCs[index_result--] = '2'; resultCs[index_result--] = '%'; index_ori--; } else { // 不是空格，直接拷贝原数组内容 resultCs[index_result--] = cs[index_ori--]; } } return new String(resultCs);} 如果允许我们用 java 内置方法，直接 replaceAll 搞定。 123private static String replaceByReplaceMethod(String s){ return s.replaceAll(\" \", \"%20\");} 如果要求是 StringBuffer，没有 replaceAll 方法，但可以用 replace 方法 12345678910111213// 如果要求是 StringBuffer，没有 replaceAllprivate static String replaceByBuffer(StringBuffer sb){ for (int i = 0; i &lt; sb.length(); i++) { int index = sb.charAt(i); if (index == ' '){ sb.replace(i, i+1, \"%20\"); } } return sb.toString();} 6. 从尾到头打印链表输入一个链表的头节点，从尾到头打印出每个节点的值 1234567891011121314151617181920// 链表定义如下static class ListNode{ int value; ListNode next = null; ListNode(int val){ this.value = val; }}// 测试用例如下public static void main(String[] args) { ListNode n1 = new ListNode(1); n1.next = new ListNode(44); n1.next.next = new ListNode(80); n1.next.next.next = new ListNode(17); reversePrint(n1);} 思路逆向输出链表，自然会想到用后进先出的栈。先遍历链表，把遍历的值依次写入栈，然后再出栈即可。 12345678910111213private static void reversePrintByStack(ListNode node){ Stack&lt;Integer&gt; stack = new Stack&lt;&gt;(); do{ stack.add(node.value); } while ((node = node.next) != null); while (!stack.isEmpty()){ System.out.println(stack.pop()); }} 事实上，递归本身就是栈结构，这道题可以直接用递归代替栈 12345678910// 递归实现private static void reversePrint(ListNode node){ if (node.next != null) { reversePrint(node.next); } System.out.println(node.value);} 7. 重建二叉树待完成 8. 二叉树的下一个节点待完成 9. 用两个栈实现队列思路：分为 stackA 和 stackB ，队列进时，往 stackA 进，队列出时先判断 StackB是否为空，不为空直接出，为空先把 stackA 全部倒进 stackB，再出。 12345678910111213141516171819202122232425262728293031public class twoStack { Stack&lt;Integer&gt; StackA = new Stack&lt;&gt;(); Stack&lt;Integer&gt; StackB = new Stack&lt;&gt;(); // 插入队列 public void insert(int a){ StackA.push(a); } // 出队列 public void delete(){ // 如果 B 栈不空，直接出 if (!StackB.isEmpty()){ StackB.pop(); return; } // 如果 B 栈空 // 1.先将 A 栈全部倒入 B 栈 while (!StackA.isEmpty()){ int a = StackA.pop(); StackB.push(a); } // 2.然后正常出 StackB.pop(); }} 10. 斐波那契数列（Fibonacci）写一个函数，输入n，输出斐波那契数列的第 n 项。 递归写法 12345private static int getFib(int n){ if (n &lt; 1) return -1; if (n == 1 || n == 2) return 1; return getFib(n-2) + getFib(n-1);} 遍历写法 1234567891011121314private static int getFib2(int n){ if (n &lt; 1) return -1; int last = 0; int current = 1; int next = last + current; for (int i = 1; i &lt; n; i++) { current = next; next = current + last; last = current; } return next;} 扩展问题： 一只青蛙依次可以跳上1级台阶，也可以跳上2级，求该青蛙跳上一个 n 级台阶总共由多少种跳法。 有一对兔子，从出生后第3个月起每个月都生一对兔子，小兔子长到第三个月后每个月又生一对兔子，假如兔子都不死，问每个月的兔子对数为多少？ 以青蛙为例： 台阶数 跳法 说明 1 1 只能跳一下 2 1 先1，后1 3 2 先1后2，或者先2后1 4 3 111，12，21 5 4 1111，112， 121， 211， 22 显然是斐波那契数列问题 11. 旋转数组最小数字数组旋转：把一个数组最开始的几个元素搬到数组的末尾。 要求：输入一个递增数组的旋转，输出旋转数组的最小元素 如：输入{3，4，5，1，2} （它是{1, 2, 3, 4, 5}的旋转），最小值为 1 思路直观解法：遍历，但是时间复杂度为 O(n) 两个指针解法： 123456789前：6 7 8 9 10 1 2↑ ↑A B后：6 7 8 9 10 1 2 ↑ ↑ A B 判断中间元素 9 是否大于第一个指针元素 6 ，如果是，说明最小元素在右边，把第一个指针指向中间缩小范围 123456789前：6 7 1 2 3 4 5↑ ↑A B后：6 7 1 2 3 4 5↑ ↑A B 反之，如果第一个指针元素大于中间元素，说明最小元素在左边，把第二个指针指向中间缩小范围。 即： 中间&gt;左边，移动第一指针到中间 中间&lt;左边，移动第二指针到中间 结束条件：第一个指针跟第二个指针相邻，第二个指针指向的元素就是最小元素 实现： 123456789101112131415161718192021private static int getMin(int[] arr){ int left = 0; int right = arr.length - 1; // 如果数组本身是有序的（旋转0）直接返回最左元素 if (arr[left] &lt; arr[right]) return arr[left]; while (left + 1 != right){ int mid = (left + right) / 2; //中间&gt;左边，移动第一指针到中间 if (arr[left] &lt; arr[mid]) left = mid; //中间&lt;左边，移动第二指针到中间 else if (arr[left] &gt;= arr[mid]) right = mid; } return arr[right];} 12. 矩阵中的路径回溯法 13. 机器人的运动范围回溯法 14. 剪绳子动态规划 + 贪婪 15. 二进制中1的个数求一个二进制数字中 1 的个数，如 110101001 ，返回 5 分析：把一个整数减去1，再和原整数【与】运算，会把该整数最右边的1变成0 12345678原整数：11011001010减去1：11011001001与运算：11011001000 利用这个特性，只要计算与运算的次数即可 12345678private static int numberOf1(int n){ int count = 0; while(n != 0){ ++count; n = (n-1) &amp; n; }} 16. 数值的整数次方输入一个double数 base ，求它的 n 次方，n是整数。 12 17. 打印从1到最大的n位数略 18. 删除链表的节点删除链表节点的两种方法(比如要删除 i 节点)： 方法一: 遍历到 i 的前一个节点 h，将 h 指向 i 的下一个节点 j，然后删除 i 方法二：把节点 j 的内容复制到 i，将 i.next 指向 j 的下一节点 k，然后删除 j 21. 调整数组顺序使奇数位于偶数前面输入一个数组，写一个函数调整该数组的顺序，使得奇数在前，偶数在后。 思路：两个指针，一个在前（A），一个在后（B）。A往后遍历，直到遇到偶数，B往前遍历，直到遇到奇数，交换AB。 123456789101112131415161718192021222324252627private static void adjust(int[] arr){ // left - 1 是因为稍后 ++left 会把 left 变大 1 ， right + 1 同理 int left = 0 - 1; int right = arr.length - 1 + 1 ; while (left &lt; right){ //A往后遍历，直到遇到偶数 while ((arr[++left] % 2) != 0){ if (left &gt; arr.length - 1) break; } //B往前遍历，直到遇到奇数 while ((arr[--right] % 2) == 0){ if (right &lt;= 0) break; } // 交换 if (left &lt; right){ Swap.swap(arr, left, right); } } System.out.println(Arrays.toString(arr));} 22. 链表中倒数第 k 个节点思路：两个指针，如求倒数第 3 个节点，A指针先走3步，然后B指针开始走，当A指针到尾的时候，B指针所指就是倒数第 k 个节点 链表定义如下 12345678static class ListNode{ int value; ListNode next = null; ListNode(int val){ this.value = val; }} 123452 → 88 → 60 → 21 → 6 → 13 → 78↑（B） ↑（A）2 → 88 → 60 → 21 → 6 → 13 → 78 ↑（B） ↑（A） 实现： 1234567891011121314151617181920212223private static int printReciNode(ListNode head, int k){ if (k &lt;= 0) return -1; ListNode nodeA = head; ListNode nodeB = head; //A指针先走k步 for (int i = 0; i &lt; k; i++) { // 求倒数第3个节点，但万一链表只有 2 个节点呢？ if (nodeA.next == null){ return -1; } nodeA = nodeA.next; } // A、B都走，直到 A 到末尾 do { nodeB = nodeB.next; } while ((nodeA = nodeA.next) != null); return nodeB.value;} 23. 链表中环的入口节点如果一个链表中包含环，如何找出环的入口节点？ 两个指针，一个一次走一步，另一个一次走两步，如果快的指针追上了慢的指针，那链表就包含环。否则如果走得快的到了末尾（node.next = null）都没追上慢的，就不包括环。 相遇节点就是入口节点。 12345678910111213141516171819202122// 只实现是否包含环private static boolean isCircle(ListNode head){ ListNode pointA = head; ListNode pointB = head; while (true){ pointA = pointA.next.next; pointB = pointB.next; if (pointA==null){ break; } if (pointA.value == pointB.value &amp;&amp; pointA.next.equals(pointB.next)) { return true; } } return false;} 24. 反转链表输入一个链表的头节点，反转该链表并输出反转后链表的头节点。 12345678910111213141516171819202122232425private static ListNode reverse(ListNode head){ // 反转后的头节点 ListNode reverseHead = null; ListNode pre = null; ListNode current = head; while (current != null){ ListNode next = current.next; // 如果 next 是空，说明到末尾了，是反转后的第一个元素 if (next == null){ reverseHead = current; } // 掉头，反指 current.next = pre; pre = current; current = next; } return reverseHead;} 25. 合并两个排序的链表合并两个递增排序的链表，新链表的节点依然是排序的 12345List1: 1 → 3 → 5 → 7List2：2 → 4 → 6 → 8合并后：1 → 2 → 3 → 4 → 5 → 6 → 7 → 8 思路：递归法，如果 A值 小于 B值， merge节点为A， 然后继续比较 A.next 和 B ，反之 如果 B值 小于 A， merge节点为B，然后继续比较 A 和 B.next 123456789101112131415161718private static ListNode merge(ListNode A, ListNode B){ if( A == null) { return B; } else if( B == null) return A; ListNode mergeHead; if (A.value &lt; B.value){ mergeHead = A; mergeHead.next = merge(A.next, B); } else { mergeHead = B; mergeHead.next = merge(A, B.next); } return mergeHead;} 30. 包含min函数的栈设计一个栈，除了可以 pop 和 push 之外，还能 getMin 获取栈中的最小值 思路：用一个辅助栈，主栈入栈时，如果栈顶 &lt; 要插入的值，辅助栈压入要插入的值，如果 栈顶 &gt;= 要插入的值，辅助栈压入原来的值。 12345678910111213141516171819202122232425262728293031class myStack{ Stack&lt;Integer&gt; stackA; Stack&lt;Integer&gt; stackB; public Integer pop(){ stackB.pop(); return stackA.pop(); } public Integer push(Integer v){ if (stackA.isEmpty()){ stackB.push(v); } if (stackA.peek() &gt;= v ){ stackB.push(stackB.peek()); } if (stackA.peek() &lt; v){ stackB.push(v); } return stackA.push(v); } public Integer getMin(){ return stackB.peek(); }} 38. 字符串的排列输入一个字符串，打印该字符串的所有排列。如，输入 abc， 输出 abc, acb, bac, bca, cab, cba 思路把字符串分为两部分，第一部分为首字符，第二部分为剩下的字符，首字符确定下来后，剩下的字符递归进行全排列。这样一趟完了之后。会发生： 123456a-bcda-bdca-cbda-cdba-dbca-dcb 然后把首字符和第二个字符交换，进行第二趟递归全排列 123456b-acdb-adcb-cadb-cdab-dacb-dca 实现 12345678910111213141516private static void permutation(String str, int start, int end){ if (end &lt;= 1) return; char[] cs = str.toCharArray(); if (start == end){ System.out.println(new String(cs)); } else { for (int i = start; i &lt;= end; i++) { Swap.swap(cs, i, start); permutation(String.valueOf(cs), start+1, end); Swap.swap(cs, start, i); } }} 40. 最小的 k 个数输入 n 个整数，找出其中最小的 k 个数。 思路一：用快排的 partition 函数因为 partition 函数本质上是将比参考元素大的放左边，比参考元素小的放右边。如果 partition 后参考元素的下标正好是 k ，那说明 k 左边的都是比 k 小的。这种解法时间复杂度只有 O(n) 12345678910111213141516171819202122232425public static int[] partitionAndFind(int[] arr, int k){ if (k &gt; arr.length){ return null; } int start = 0; int end = arr.length - 1; int index = QuickSort.partition(arr, start, end); // 如果 partition 后下标大了，调小，否则调大 while (index != k-1){ if(index &gt; k-1){ end = index - 1; }else{ start = index + 1; } index = QuickSort.partition(arr,start, end); } int[] output = new int[k]; System.arraycopy(arr, 0, output, 0, k); return output;} 思路二：优先队列（堆）或红黑树用一个大小为 k 的最大堆（本质是二叉树）作为数据容器 （也可以用红黑树作为数据容器），当容器未满，每次输入的数字直接加到堆里面，当容器已满，需要完成，判断堆顶（最大值）和即将添加的元素谁大，保留更小的。 需要 O(logk)的时间完成删除及插入操作。对于大小为 n 的输入，找到最小的 k 个，时间复杂度是 O(nlogk)，但是这种解法适合海量数据。 123456789101112131415161718192021222324252627282930public static int[] heapAndFind(int[] arr, int k){ // o2 - o1， 最大堆， o1 - o2（默认） 最小堆 PriorityQueue&lt;Integer&gt; q = new PriorityQueue&lt;&gt;(k, (o1, o2) -&gt; o2-o1); for (int i = 0; i &lt; arr.length; i++) { // 如果容器未满，直接添加 if (!isFull(q, k)){ q.add(arr[i]); } else { // 如果容器已满，将待添加元素和堆顶（最大值）比较，更小的放进堆里 if (arr[i] &lt; q.peek()){ q.poll(); q.add(arr[i]); } } } // 一个新的数组用来存放结果 int[] output = new int[k]; for (int i = 0; i &lt; k; i++) { output[i] = q.poll(); } return output;}// 优先队列（堆）是否满了private static boolean isFull(PriorityQueue q, int k){ return q.size() &gt;= k;} #","link":"/offer/index.html"},{"title":"tags","text":"","link":"/tags/index.html"},{"title":"Spring了然于心","text":"1. MVC 结构流程 Web浏览器发送HTTP请求到服务端，被Controller(Servlet)获取并进行处理（例如参数解析、请求转发） Controller 调用核心业务逻辑——Model部分 Model进行数据库存取操作，并将操作结果返回 Controller 将业务逻辑处理结果交给View（JSP），动态输出HTML内容 动态生成的HTML内容返回到浏览器显示 2. 什么是 Ioc ？Ioc（Inversion of Control）是控制反转，具体做法的依赖注入（DI，Dependency Inject）。即 某一接口的实现类的选择控制权从调用类中移除，转交由第三方决定，当需要的时候，由第三方进行注入，而不由调用类 new，这就是反转控制。 Spring 提供了一个反转控制容器，当我们要使用某个对象，只需要从 Spring 容器中获取需要使用的对象，不关心对象的创建过程，把创建对象的控制权反转给了 Spring 框架，而 Spring 容器是通过 DI，在创建对象的过程中将对象依赖属性（简单值，集合，对象）通过配置设值给该对象。 3. Ioc是如何实现的? 读取注解或者配置文件，看看 bean 依赖的是哪个Source，拿到类名 使用反射的API，基于类名实例化对应的对象实例 将对象实例通过构造函数或者 setter，注入给 bean 4. 什么是 AOP ？Aspect Oriented Program，面向切面编程。即把功能分为 核心业务功能 和 周边功能。两者分别独立进行开发，然后把切面功能和核心业务功能 “编织” 在一起。 AOP 的好处是允许我们把遍布应用各处的功能分离出来形成可重用的组件。 5. 什么是 Spring Boot ？Spring Boot并不是什么新的框架，而是默认配置了很多框架的使用方式，就像 Maven 整合了所有的 jar 包一样，Spring Boot 整合了大部分框架，比如Mybatis、Hibernate、Spring MVC。 Spring Boot使用 “习惯优于配置” （项目中存在大量的配置，此外还内置一个习惯性的配置）的理念让你的项目快速运行起来。 6. 什么是 Spring ？Spring 是一个开源框架大家族，包含很多子项目，例如 Spring Core、Spring data、Spring Web MVC 以及最新的 Spring Boot 和 Spirng Could。它的核心理念是 依赖注入 和 面向切面。 传统的 Java 项目，类和类之间经常有依赖关系，一般调用类通过 new 关键字构造依赖类的实例。当工程变大，依赖关系会变得十分复杂，使项目难以维护。Spring 提供了依赖注入容器，相当于在 Java 类当中充当一个中间人，管理着类与类之间的依赖关系。 7. 什么是 Spring Cloud ？Spring Cloud是一套分布式服务治理的框架。可以理解成是一个注册中心，提供如服务发现注册、配置中心、消息总线、负载均衡、断路器、数据监控等。 Spring Cloud + Spring Boot 非常适合做微服务架构，Boot的轻量级适合开发单个微服务，多个服务再统一在 Cloud 中注册。 8. BeanFactory 和 ApplicationContext 的区别一般称 BeanFactory 为 IoC 容器，而 ApplicationContext 为应用上下文。 BeanFactory 是解析、管理、实例化所有容器的 Bean 的入口，面向 Spring 本身。且是 Spring Framework 最核心的接口，提供了高级的 Ioc 配置机制，使管理不同类型的 Java 对象成为可能。 ApplicationContext 面向框架的开发者，提供国际化支持、统一的资源文件读取方式、框架事件体系等。 BeanFactory 在启动的时候不会实例化Bean，getBean() 的时候才会实例化。ApplicationContext在解析配置文件时会对配置文件所有对象都初始化（默认情况下）。 9. Spring Bean的5种作用域(Scope)在 applicationContext.xml 中声明 scope: 123&lt;bean id=\"hello\" scope=\"singleton\" class=\"io.jerrysheh.Hello\"&gt;&lt;/bean&gt; singleton: 是 Spring Bean 的默认配置，这个 Bean 在 Spring 容器是 单例 的。 prototype: 和 singleton 相反，为每个 Bean 请求提供一个 Bean 实例 request：在请求 Bean 范围内会给每个客户端的网络请求创建一个实例，请求结束之后会回收 session: 在每个 session 中有一个 Bean 的实例，session 结束后回收 global-session: 所有 Portlet 共享的 Bean 注意，Singleton Bean不是线程安全的，需要自行保证线程安全。 10. Spring 的5种自动装配模式 no：Spring 框架的默认设置，开发者要在 Bean 中明确定义依赖 byName：在配置文件中查找相同名字的 Bean 进行装配 byType：在配置文件中查找相同类型的 Bean 进行装配 constructor：寻找有相同构造参数的 Bean 进行装配 autodetect：先尝试以 constructor 的方法进行装配，失败后 byType 进行装配 11. SpringMVC处理请求的流程 用户发送请求，被DispatcherServlet拦截，DispatcherServlet收到请求之后自己不处理，而是交给其他的Handler进行处理 DispatcherServlet初始化HandlerMapping，HandlerMapping会把请求映射成一个HandlerExecutionChain对象，这个对象包括一个Handler和多个Interceptor，然后把这个Handler适配成HandlerAdapter DispatcherServlet传过来的请求会和HandlerAdapter进行适配，先要进行一些数据转换，然后调用HandlerAdapter的handle()，返回一个ModelAndView对象 mv.render()，通过ViewResolver进行渲染，把刚才HandlerAdapter返回的Model渲染到View上 最后进行请求的转发 12. 什么是微服务？微服务是一个松耦合的分布式服务。微服务允许将一个大型的应用分解成许多独立的组件，每个组件单独部署。 微服务有什么好处？ 职责明确：细粒度组件，组件职责领域明确，并且可以完全独立部署 组件复用：一个微服务组件可以跨多个应用程序复用 通信规范：组件之间通过 HTTP 、JSON 进行轻量级通信 底层透明：一个服务的底层用什么技术实现并没有什么影响，不同的开发小组可以用不同的技术栈 13. 什么是RESTREST（Representational State Transfer）省略了主语 Resource，翻译成中文是：资源表述性状态转移。简单地说，就是用 URI 来定位资源，用 http 方法（GET、POST、DELETE、PUT等动词）来表示行为，用 http 状态码来表示结果。 14. AOP底层怎么实现？两种代理有什么区别？AOP底层实现是动态代理。 什么是动态代理动态代理，即利用 Java 的反射技术(Java Reflection)，在运行时创建一个实现某些给定接口的新类（也称“动态代理类”）及其实例（对象）。代理的是接口(Interfaces)，不是类(Class)，更不是抽象类。 动态代理用来解决一个接口的实现在编译时无法知道，需要在运行时才能实现的问题。也可以用来实现某些设计模式，如适配器(Adapter)或修饰器(Decorator)。以及实现面向切面编程：如AOP in Spring。 AOP底层的两种代理和区别？JDK动态代理 和 Cglib动态代理 。 15. SpringMVC启动会加装几种容器？他们的关系是怎样的？todo 16. SpringMVC 如何知道要加装的 Spring 配置在哪里？todo 17. Spring 容器创建对象的时机默认情况下，当我们启动 Spring applicationContext 时： 1ApplicationContext context = new ClassPathXmlApplicationContext(\"applicationContext.xml\"); applicationContext 会去寻找 applicationContext.xml 配置文件，里面有许多 的定义，遇到 时就创建对象。 当我们给 bean 加上 lazy-init=&quot;true&quot; 属性 123&lt;bean id=\"hello\" lazy-init=\"true\" class=\"io.jerrysheh.Hello\"&gt;&lt;/bean&gt; 则在应用中，遇到 getBean 时才创建。 1Hello h = (Hello) context.getBean(\"hello\"); 18. AutoWired 自动装配如果有多个符合的bean在 Service 层自动注入一个 Dao，通常： 1234567@Servicepublic class PersonService{ @AutoWired private PersonDao personDao;} 如果 PersonDao 有多个实现如何解决？ 第一种方法，改名字，改为实现类的名字。 12345@AutoWiredprivate PersonDao personMysqlDaoImpl;@AutoWiredprivate PersonDao personOracleDaoImpl; 第二种方法，配合 @Qualifier 注解 123@AutoWired@Qualifier(\"personMysqlDaoImpl\")private PersonDao personDao;","link":"/spring/index.html"},{"title":"数据库SQL了然于心","text":"1. 存储引擎有哪些？ InnoDB MySQL默认引擎。支持事务、高并发能力（MVCC）、崩溃修复能力、行锁、聚簇索引。底层B+树实现，页结点就是数据本身。 MyISAM 读取速度快，但不支持事务，崩溃修复能力差，表锁，非聚簇索引（索引和数据分开，.MYD用来存放数据文件，.MYI用来存放索引文件）。底层也是B+树，但页节点是指针。 如何选择？ 如果表经常读取，且不需要事务，MyISAM是合适的选择。如果需要事务和崩溃安全修复，必须选 InnoDB。 2. MVCC 是什么？多版本并发控制。通过保存数据在某个时间点的快照来实现非锁并发控制。不管事务执行多少时间，每个事务看到的数据都是一致的。在InnoDB中，MVCC的实现是：在每行记录后面保存两个隐藏列。一个保存行的创建时间，一个保存行的过期时间（删除时间）。 3.索引是什么？索引是帮助提高查询效率的数据结构。从底层实现的角度，索引包括 BTree索引 和 Hash索引，InnoDB和MyISAM只支持BTree索引，Meemory两种都支持。从功能的角度，索引分为普通索引、唯一索引、组合索引、空间索引、全文索引。从结构组织的角度，索引分为聚簇索引和非聚簇索引。 4. 什么时候该创建索引？ 主键：对于主键，会自动建立一个唯一索引，以保证值唯一 频繁查询：对于频繁查询的表或字段，建立索引无疑会提高查询效率 查询中需要排序的字段：使用索引去访问排序字段将大大提高排序速度 查询中需要统计或者分组字段 5. 什么时候不该使用索引？ 表记录太少 查询少，增删改多的字段（因为修改字段的同时还要动态维护索引） WHERE 条件用不到的字段不需要索引 过滤性（选择性）不好的字段不适合使用索引，例如0/1，男/女 6. 什么时候索引会失效？索引可以包含多个列的值，但是列的顺序十分重要，MySQL只能高效地使用索引的最左前缀列。 WHERE 条件有 不等于号 WHERE 条件使用了表达式或函数，如SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; JOIN中，MySQL只有在 主键和外键的数据类型相同 时才能使用索引，否则无效 LIKE ‘abc%’，MYSQL将使用索引；但 LIKE ‘%abc’，MySQL将不使用索引。 使用 OR 一般会使索引失效 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来，否则不使用索引。 对于基于BTree的组合索引，非最左、跳过列、范围查询 都会使索引失效。 7. 什么是事务？事务就是由一组SQL语句组成的逻辑处理单元，一个事务中的SQL语句组，要么全部执行，要么全部不执行。 8. 事务有哪些并发问题？ 脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据 不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。 幻读：事务A在读取某个范围内的记录时，事务B又在该范围内插入新的记录，事务A再次读取该范围的记录时会产生幻行。（两次不一致） 不可重复读侧重于记录被修改，幻读侧重于新增或删除了记录。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表。 9. 事务的四大特征是？A、C、I、D 原子性（Atomicity）：一个事务必须被视为不可分割的最小工作单元。一个事务中的所有操作，要么全部成功提交，要么全部失败回滚。不可能只执行其中的一部分操作。 一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态。不会出现查询开始时的数据跟查询到一半的数据不一样的情况。 隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的独立环境执行。这意味着 事务处理过程中的中间状态对外部是不可见的，反之亦然。事务隔离分为不同级别，包括读未提交（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性（Durability）: 事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。 10. 事务的隔离级别？事务的隔离级别规定了哪些修改在事务内和事务间是可见的，哪些是不可见的。较低级别的隔离并发程度高，开销低。 未提交读(Read uncommitted)：事务中的修改，即使未提交，对其他事务也都是可见的。事务可以读取未提交的数据，这也称为 脏读（Dirty Read）。该级别很少被使用。 提交读(read committed)：一个事务从开始到提交之前，所做的任何修改对其他事务都是不可见的，这个级别有时候叫做不可重复读，因为同一事务自己两次执行同样的查询，期间可能有其他事务修改并提交了数据，因此两次查询可能会得到不一样的结果。 可重复读(repeatable read)：解决了脏读问题，该级别保证了在同一个事务中多次读同样记录的结果是一致的，理论上无法解决幻读问题。 可串行化(Serializable):它通过强制事务串行执行，避免了前面说的幻读的问题。该级别用得较少。 MySQL 默认的事务隔离是第 3 级别，可重复读。 11. 死锁问题怎么解决？ 当查询超时自动放弃锁请求，这种方式不太友好。 InnoDB 的做法是，将持有最少行级排他锁的事务进行回滚。 12. 共享锁的排他锁共享锁（shared lock）也叫做读锁，如果一个事务对数据对象A加了共享锁，其他事务只能读而不能写，直至当前事务释放该锁。 排他锁（exclusive lock）也叫做写锁，如果一个事务对数据对象A加了排他锁，其他事务不能再对A加锁，包括读和写，直至当前事务释放该锁。 13. 乐观锁和悲观锁乐观锁假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。注意，乐观锁 不能 解决脏读的问题。所谓脏读，就是一个事务读取了另一个事务未提交的数据。 悲观锁假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。 14. 数据库三大范式 第一范式：字段不可再分 第二范式：符合1NF，并且表中的每列都和主键相关。即一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。 第三范式：符合2NF，并且，消除传递依赖。即每一列数据都和主键直接相关，而不能间接相关。 15. 什么是事务日志事务日志用于提高事务效率。存储引擎修改表数据时，只需修改内存拷贝，然后把修改记录持久在硬盘的事务日志中，而不用每次都把修改的数据本身持久到硬盘中。之后把再内存修改的数据再慢慢刷回磁盘中。 16. 大表优化 限制查询范围 读写分离 分库分表 17. 谈谈分库分表？垂直拆分和水平拆分。 垂直拆分是把一个很多列的表拆分成多个表，使列数据变小，优点是在查询时减少读取的Block数，减少I/O次数，同时可以简化表的结构，易于维护。缺点是会引起Join操作，事务变得更加复杂，可以通过在应用层进行Join来解决。 水平拆分 是把一个很多行的表拆分到不同的分表和分库中去。常见的做法有客户端代理（如Sharding-JDBC）和 中间件代理（如MyCAT）。 18. 分库分表后主键怎么处理？ UUID：不建议，无序，对mysql聚簇索引来说读写效率低 自增id：需要独立部署在不同的mysql服务器 redis：性能比较好，灵活方便，不依赖于数据库，但引入了新的组件造成系统更加复杂 Twitter的snowflake算法 美团的Leaf分布式ID生成系统","link":"/sql/index.html"},{"title":"字符串","text":"1. 三步反转abcde， 2， 把前两个字符换到后面，输出 cdeab 思路：三步反转。 把字符串分成两部分， ab 和 cde 分别反转，得到 ba 和 edc 整串反转，得到 cdeab 2.","link":"/algo/string/index.html"}],"posts":[{"title":"Android 零碎知识","text":"使用WebView如果要在一个 Activity 上显示图片， 可以用 imageView + ScrollView 组合。但如果是长图片，其实还可以用 WebView 但是 WebView 有内存泄漏的风险，使用时要谨慎。 WebView布局 12345678910&lt;ScrollView android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:fillViewport=\"true\"&gt; &lt;WebView android:id=\"@+id/detail_image\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\"&gt; &lt;/WebView&gt;&lt;/ScrollView&gt; 调用 12345678String image = \"http://read.html5.qq.com/image?src=share&amp;imageUrl=http://s.cimg.163.com/i/abco1.heibaimanhua.com/wp-content/uploads/2018/05/20180510_5af3d93ebc915.jpg.0x0.auto.jpg\"detialImage = findViewById(R.id.detail_image);detialImage.getSettings().setUseWideViewPort(true);detialImage.loadUrl(image);// 适应手机屏幕detialImage.getSettings().setLoadWithOverviewMode(true); 使用 CardView卡片布局，非常好用。 注意一点，添加下面这一行属性可以设置CardView和Button长按或者点击时的涟漪效果： 1android:foreground=\"?attr/selectableItemBackgroundBorderless\" 参考布局 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:orientation=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\"&gt; &lt;android.support.v7.widget.CardView xmlns:card_view=\"http://schemas.android.com/apk/res-auto\" android:id=\"@+id/card_view\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" card_view:cardBackgroundColor=\"#FFFFFF\" card_view:cardCornerRadius=\"4dp\" card_view:cardUseCompatPadding=\"true\" android:foreground=\"?attr/selectableItemBackgroundBorderless\" android:layout_gravity=\"center\"&gt; &lt;RelativeLayout android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:orientation=\"vertical\"&gt; &lt;TextView android:id=\"@+id/news_title\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:padding=\"5dp\" android:textSize=\"20sp\" android:lines=\"3\" android:text=\"ss\"/&gt; &lt;Button android:id=\"@+id/button_link\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:background=\"#00000000\" android:layout_below=\"@id/news_title\" android:textColor=\"?attr/colorAccent\" android:text=\"@string/btn_link\" android:layout_toStartOf=\"@id/button_share\" android:foreground=\"?attr/selectableItemBackgroundBorderless\" /&gt; &lt;Button android:id=\"@+id/button_share\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:background=\"#00000000\" android:text=\"@string/btn_share\" android:textColor=\"?attr/colorAccent\" android:layout_below=\"@id/news_title\" android:layout_alignParentEnd=\"true\" android:foreground=\"?attr/selectableItemBackgroundBorderless\" /&gt; &lt;/RelativeLayout&gt; &lt;/android.support.v7.widget.CardView&gt;&lt;/LinearLayout&gt; 分享功能1234567String shareContent = context.getString(R.string.share_content) + oneComic.getLink();Intent intent = new Intent(Intent.ACTION_SEND);intent.setType(\"text/plain\");intent.putExtra(Intent.EXTRA_SUBJECT, \"share\");intent.putExtra(Intent.EXTRA_TEXT, shareContent);intent.setFlags(Intent.FLAG_ACTIVITY_NEW_TASK);context.startActivity(Intent.createChooser(intent,\"分享到：\")); 在浏览器中打开1234Intent intent = new Intent(Intent.ACTION_VIEW);Uri content_url = Uri.parse(oneComic.getLink());intent.setData(content_url);context.startActivity(intent); 隐藏状态栏和标题栏AndroidManifest.xml 在对应的 activity 下添加： 1234&lt;activity android:name=\".DetailActivity\" android:theme=\"@android:style/Theme.NoTitleBar.Fullscreen\"&gt;&lt;/activity&gt; 如果 activity 是继承 AppCompatActivity 的，会导致报错， 可以修改为： 1234&lt;activity android:name=\".DetailActivity\" android:theme=\"@style/Theme.AppCompat.Light.NoActionBar\"&gt;&lt;/activity&gt; 或者把 activity 改为继承 Activity 使用 Glide 加载图片简单用法 1Glide.with(context).load(imageUrl).into(mImageView); 如果需要获取图片属性 1234567891011121314151617String imageUrl = imageList.get(position);Glide.with(context).load(imageUrl).into(new SimpleTarget&lt;Drawable&gt;() { @Override public void onResourceReady(@NonNull Drawable resource, @Nullable Transition&lt;? super Drawable&gt; transition) { // 获取到图片的高 int height = resource.getIntrinsicHeight(); // do more things // 把图片显示到 detialImageView 里面 holder.detialImage.setImageDrawable(resource); }});} 如果需要高级功能(placeholder、firCenter之类，具体见官方文档)，需要写一个类继承AppGlideModule 1234567import com.bumptech.glide.annotation.GlideModule;import com.bumptech.glide.module.AppGlideModule;@GlideModulepublic final class MyAppGlideModule extends AppGlideModule { // 无需写任何代码} 然后 rebuild project 然后用 GlideApp 12345GlideApp.with(fragment) .load(myUrl) .placeholder(placeholder) .fitCenter() .into(imageView); 项目地址：https://github.com/bumptech/glide 项目文档：https://bumptech.github.io/glide/doc/getting-started.html","link":"/post/335b62ef.html"},{"title":"Android笔记（一） 初识","text":"Android 简介 Android，常见的非官方中文名称为安卓，是一个基于Linux内核的开放源代码移动操作系统，由Google成立的Open Handset Alliance（OHA，开放手持设备联盟）持续领导与开发，主要设计用于触屏移动设备如智能手机和平板电脑与其他便携式设备。 Android最初由安迪·鲁宾等人开发制作，最初开发这个系统的目的是创建一个数码相机的先进操作系统；但是后来发现市场需求不够大，加上智能手机市场快速成长，于是Android成为一款面向智能手机的操作系统。 于2005年7月11日被美国科技企业Google收购。 2007年11月，Google与84家硬件制造商、软件开发商及电信营运商成立开放手持设备联盟来共同研发改良Android，随后，Google以Apache免费开放源代码许可证的授权方式，发布了Android的源代码（Android OpenSource Projet），开放源代码加速了Android普及，让生产商推出搭载Android的智能手机，Android后来更逐渐拓展到平板电脑及其他领域上。 2010年末数据显示，仅正式推出两年的Android操作系统在市场占有率上已经超越称霸逾十年的诺基亚Symbian系统，成为全球第一大智能手机操作系统。 在2014年Google I/O开发者大会上Google宣布过去30天里有10亿台活跃的安卓设备，相较于2013年6月则是5.38亿。 2017年3月，Android全球网络流量和设备超越Microsoft Windows，正式成为全球第一大操作系统。 2017年8月，Android O发布。 以上简介来自Wikipedia，可见 Android 前景还是非常大的。作为一个移动开发者，学习Android也是势在必行了。 本次Android的学习，我采用书本+视频的方式。 参考书籍是： 第一行代码（第二版）（郭霖） 参考视频： 对于没有编程基础的: Android 基础：用户界面 Android 基础：用户输入 Android 基础：多屏应用 Android 基础：网络 Android 基础：数据存储 有编程基础可以直接从这个开始： Android应用开发 Android 系统架构Android系统架构可以分为五层，分别是： 应用层（System app），所有安装在手机上的app都是应用层的，包括系统自带app和第三方开发的app。 应用框架层（Java API Framework），提供了构建应用程序时需要的API。 系统运行库（Native C/C++ Libraries） 和 Android Runtime， 通过C/C++库来为Android系统提供主要的特性支持。如SQLite库提供数据库支持，OpenGL/ES库提供3D绘图支持，Webkit库提供浏览器内核支持等。Android Runtime是Android的核心库，为Android应用跨平台使用提供的可靠方案，每个app都会有自己独立的运行空间和虚拟机。允许开发者使用Java、Kotlin编写Android应用。 硬件抽象层（Hardware Abstraction Layer, HAL） 主要与manufacture和chip vendor相关，manufacture提供HAL的实现以及各种硬件设备的驱动和集成chip vendor提供的firmware。 Linux内核层（Linux Kernel），为硬件提供了底层驱动，如显示驱动，照相机驱动，音频驱动，蓝牙驱动等。 关于 Framework 的一些知识点： 隐藏在每个应用后面的是一系列的服务和系统, 其中包括； a. 丰富而又可扩展的视图（Views），可以用来构建应用程序， 它包括列表（lists），网格（grids），文本框（text boxes），按钮（buttons）， 甚至可嵌入的web浏览器。 b. 内容提供器（Content Providers） 使得应用程序可以访问另一个应用程序的数据（如联系人数据库）， 或者共享它们自己的数据。 c. 资源管理器（Resource Manager） 提供非代码资源的访问，如本地字符串，图形，和布局文件（layout files）。 d. 通知管理器（Notification Manager） 使得应用程序可以在状态栏中显示自定义的提示信息。 e. 活动管理器（Activity Manager） 用来管理应用程序生命周期并提供常用的导航回退功能。 Android 四大组件Android 系统的四大组件分别是活动（Activity）、服务（Service）、广播接收器（Broadcast Receiver）、内容提供器（Content Providers）。 活动（Activity）在 Android 应用中我们能看到的东西，都是放在活动当中的。活动是一种能够包含用户界面的组件，主要用于和用户交互。值得注意的是，在Android中，有一种能够嵌入在活动当中的UI片段，称为碎片（Fragment），它和活动十分相似。 服务（Service）服务是 Android 中实现程序后台运行的解决方案。它非常适合去执行那些不需要和用户交互而且需要长期运行的任务。服务依赖于所在应用程序的进程，不单独运行。值得注意的是，服务不会自动开启线程，所有的代码默认在主线程运行。因此需要我们手动在服务内部创建子线程。 广播接收器（Broadcast Receiver）广播接收器允许你的应用接收来自各处的广播消息，比如电话、短信等。同样也可以向外发出广播消息。Android 中的广播可以分为以下两种： 标准广播（Normal Broadcast），一种完全异步执行的广播，当广播发出后，所有的广播接收器几乎同一时刻接收到这条广播信息，没有先后顺序之分。这种广播效率高，但无法截断。 有序广播（Ordered Broadcast），一种同步执行的广播，当广播发出后，同一时刻只有一个广播接收器收到这条广播，当这个广播接收器的逻辑执行完毕后，广播才会继续传递。这样一来，优先级高的广播接收器可以先收到广播，并且前面的广播接收器可以截断正在传递的广播。 内容提供器（Content Providers）内容提供器则是为应用程序之间共享数据提供可能的机制。比如，你的应用程序需要读取系统通讯录中的联系人信息，就需要通过内容提供器实现。 Material DesignMaterial Design(材料设计语言)，是由Google推出的全新的设计语言，谷歌表示，这种设计语言旨在为手机、平板电脑、台式机和“其他平台”提供更一致、更广泛的“外观和感觉”。 Android StudioAndroid Studio 是 Google 官方提供的 Android IDE，提供用于为各类 Android 设备开发应用的最快速的工具。 下载地址：https://developer.android.com/studio/index.html 下载和使用 Android Studio 需要连接 Goole 服务器下载数据，然而根据众所周知的原因，无法科学上网的童鞋需要另辟蹊径了。最好还是学会如何科学上网。（当然，是为了学习和开发） 在第一次创建Android Studio project的时候，如果没有科学上网，有可能会遇到卡在building “project name”gradle project info的问题。可以通过下载离线gradle包手动安装。 参考链接 HelloWorld使用 Android Studio 创建第一个 helloworld project之后，会自动生成一些代码。先来看一下这些自动生成的代码都表示什么。 AndroidManifest.xml在工程目录下可以看到AndroidManifest.xml，在这个xml里面有如下语句 1234567&lt;activity android:name=\".MainActivity\"&gt; &lt;intent-filter&gt; &lt;action android:name=\"android.intent.action.MAIN\" /&gt; &lt;category android:name=\"android.intent.category.LAUNCHER\" /&gt; &lt;/intent-filter&gt;&lt;/activity&gt; Android 应用程序基于活动，而每一个活动都要在 AndroidManifest.xml 进行注册，没有注册的活动是不能使用的。这段代码就是注册了 MainActivity这个活动。 MainActivity.javaMainActivity.java中自动生成的代码如下： 12345678910111213package com.jerrysheh.hello;import android.support.v7.app.AppCompatActivity;import android.os.Bundle;public class MainActivity extends AppCompatActivity { @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); }} 分析： MainActivity继承自AppCompatActivity，让这个活动支持系统版本向下兼容。 Activity是 Android 系统提供的一个活动基类，我们项目中所有的活动都必须继承它或者它的子类。AppCompatActivity是Activity的子类。 onCreate方法第二行调用了setContentView()，参数指向了layout.activity_main。也就是说，setContentView()方法将我们的activity_main.xml和MainActivity.java关联了起来。 不妨打开activity_main.xml看看。 activity_main.xml打开activity_main.xml，Android Studio默认是Design视图，在下面按钮切换到text视图。 可以看到，activity_main中有几行关键代码： 12345678&lt;TextView android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"Hello World!\" app:layout_constraintBottom_toBottomOf=\"parent\" app:layout_constraintLeft_toLeftOf=\"parent\" app:layout_constraintRight_toRightOf=\"parent\" app:layout_constraintTop_toTopOf=\"parent\" /&gt; 不用说，定义了视图界面以及显示的信息。 我们熟悉的Hello World!正是在这里。 小结Android程序设计讲究逻辑和视图分离，所以逻辑代码写在MainActivity.java中，视图界面写在activity_main.xml中。在逻辑代码中的活动，需要先到AndroidManifest.xml进行注册。 方便的是，当我们创建一个新的 Activity，Android Studio会自动帮我们注册。如果你用的是 Eclipse 或其他IDE，可能要手动进行注册。 build.gradleGradle是一个先进的项目构建工具，它使用一种基于Groovy的领域特定语言（DSL）来声明项目设置，摒弃了传统基于XML（如Ant和Maven）的各种繁琐设置。 Android Project 会首先经过gradle构建，gradle会将你的代码构建成字节码和资源，打包成APK，然后经过jar签名，最后通过adb安装到虚拟或真实的Android设备上。 在Android Studio中，有多种项目构造目录，其中默认的Android方式是IDE自动调整的，方便我们查看文件。而只有project目录结构是真实存放在我们硬盘里的组织结构。 切换到project目录结构，可以看到 Helloworld项目有两个 build.gradle 文件。 外层build.gradle1234567891011121314151617buildscript { repositories { google() jcenter() } dependencies { classpath 'com.android.tools.build:gradle:3.0.1' }}allprojects { repositories { google() jcenter() }} jcenter是一个代码托管仓库，声明了jcenter()后我们可以轻松引用任何jcenter上的开源项目。google()同理。 classpath声明了一个 Gradle插件。用于构建 Android 项目。 内层build.gradle12345678910111213141516171819202122232425262728apply plugin: 'com.android.application'android { compileSdkVersion 26 defaultConfig { applicationId &quot;com.jerrysheh.hello&quot; minSdkVersion 15 targetSdkVersion 26 versionCode 1 versionName &quot;1.0&quot; testInstrumentationRunner &quot;android.support.test.runner.AndroidJUnitRunner&quot; } buildTypes { release { minifyEnabled false proguardFiles getDefaultProguardFile('proguard-android.txt'), 'proguard-rules.pro' } }}dependencies { implementation fileTree(dir: 'libs', include: ['*.jar']) implementation 'com.android.support:appcompat-v7:26.1.0' implementation 'com.android.support.constraint:constraint-layout:1.0.2' testImplementation 'junit:junit:4.12' androidTestImplementation 'com.android.support.test:runner:1.0.1' androidTestImplementation 'com.android.support.test.espresso:espresso-core:3.0.1'} 第一行com.android.application表示这是一个应用程序模块，如果是com.android.library表示这是一个库模块。应用程序模块可以直接运行，库模块需要依附别的应用程序模块。 android闭包配置了项目构建的属性。 buildTypes闭包用于指定生成安装文件的相关配置。 dependencies闭包指定当前项目的所有依赖关系。Android Studio有3种依赖方式：本地依赖、库依赖、远程依赖。 Android Debug Bridge （ADB）ADB 是 Android 的 SDK 包含的命令行工具。用于调试。 要从命令行中启动 Android 应用，你可以输入： 1adb shell am start -n com.package.name/com.package.name.ActivityName","link":"/post/4afa9fc3.html"},{"title":"Android笔记（三） Intent 和 Activity的生命周期、启动模式","text":"IntentIntent 是一个消息传递对象。它是 Android 程序中各组件之间进行交互的一种重要方式，它不仅可以指明当前组件想要执行的动作，还可以在不同组件之间传递数据。 关键词： 指明要执行的动作，传递数据 Intent 的基本使用场景 启动 Activity：Activity 表示应用中的一个屏幕。通过将 Intent 传递给 startActivity()，您可以启动新的 Activity 实例。Intent 描述了要启动的 Activity，并携带了任何必要的数据。 如果希望在 Activity 完成后收到结果，请调用 startActivityForResult()。在 Activity 的 onActivityResult() 回调中，您的 Activity 将结果作为单独的 Intent 对象接收。 启动服务：Service 是一个不使用用户界面而在后台执行操作的组件。通过将 Intent 传递给 startService()，您可以启动服务执行一次性操作（例如，下载文件）。Intent 描述了要启动的服务，并携带了任何必要的数据。 如果服务旨在使用客户端-服务器接口，则通过将 Intent 传递给 bindService()，您可以从其他组件绑定到此服务。 传递广播：广播是任何应用均可接收的消息。系统将针对系统事件（例如：系统启动或设备开始充电时）传递各种广播。通过将 Intent 传递给 sendBroadcast()、sendOrderedBroadcast() 或 sendStickyBroadcast()，您可以将广播传递给其他应用。 参阅：官方文档 - Intent 和 Intent 过滤器 使用显式Intent显式 Intent 指的是明确地按名称（完全限定类名）指定要启动的组件。比如说，如果我们想在FirstActivity这个活动中打开SecondActivity，我们可以在FirstActivity中的一个按钮点击中调用StartActivity，传入intent对象。 12345678Button buttonIntent = (Button) findViewById(R.id.button_intent);buttonIntent.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { Intent intent = new Intent(MainActivity.this,SecondActivity.class); startActivity(intent); }}); 定义一个按钮 在按钮点击事件中 new 一个 intent 对象 调用 startActivity，传入 intent 对象 使用隐式Intent隐式 Intent 不会指定特定的组件，而是声明要执行的常规操作，从而允许其他应用中的组件来处理它。 例如，如需在地图上向用户显示位置，则可以使用隐式 Intent，请求另一具有此功能的应用在地图上显示指定的位置。 创建隐式 Intent 时，Android 系统通过将 Intent 的内容与在设备上其他应用的清单文件中声明的 Intent 过滤器进行比较，从而找到要启动的相应组件。 如果 Intent 与 Intent 过滤器匹配，则系统将启动该组件，并向其传递 Intent 对象。 如果多个 Intent 过滤器兼容，则系统会显示一个对话框，支持用户选取要使用的应用。 在AndroidManifest.xml中，把SecondActivity段修改如下 1234567&lt;activity android:name=\".SecondActivity\"&gt; &lt;intent-filter&gt; &lt;action android:name=\"com.jerrysheh.hello.ACTION_START\" /&gt; &lt;category android:name=\"android.intent.category.DEFAULT\"/&gt; &lt;category android:name=\"com.jerrysheh.hello.MY_CATEGORY\"/&gt; &lt;/intent-filter&gt;&lt;/activity&gt; 在&lt;intent-filter&gt;中增添了action和category段，只有 action 和 category 同时匹配才能响应该Intent。每个Intent中只能指定一个action，但能指定多个category。 action：声明接受的 Intent 操作。 category：声明接受的 Intent 类别。 除了action和category外，还有一个data，请参考官方文档 修改按钮点击事件， new Intent对象，因为我们想启动能到响应为com.jerrysheh.hello.ACTION_START这个action的活动，因此参数填入com.jerrysheh.hello.ACTION_START。 123456789Button buttonIntent = (Button) findViewById(R.id.button_intent);buttonIntent.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { Intent intent = new Intent(\"com.jerrysheh.hello.ACTION_START\"); intent.addCategory(\"com.jerrysheh.hello.MY_CATEGORY\"); startActivity(intent); }}); 或者，可以这样写,利用intent.setAction方法。 12345678910Button buttonIntent = (Button) findViewById(R.id.button_intent);buttonIntent.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { Intent intent = new Intent(); intent.setAction(\"com.jerrysheh.hello.ACTION_START\"); intent.addCategory(\"com.jerrysheh.hello.MY_CATEGORY\"); startActivity(intent); }}); 如果intent.addCategory指定的Category没有一个活动能够匹配，那么程序会抛出异常。稍作修改，用resolveActivity()方法来判断是否有应用能响应。假设没有活动匹配，就不启动startActivity(); 12345678910111213Button buttonIntent = (Button) findViewById(R.id.button_intent);buttonIntent.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { Intent intent = new Intent(\"com.jerrysheh.hello.ACTION_START\"); intent.addCategory(\"com.jerrysheh.hello.MY_CATEGORY\"); if (intent.resolveActivity(getPackageManager()) != null) { startActivity(intent); } }}); Intent的更多用法调用浏览器和拨号new 一个 Intnet 对象后， 用 intent.setData(uri) 方法可以调用其他程序 比如调用浏览器打开 github 123Intent intent = new Intent(\"com.jerrysheh.hello.ACTION_START\");intent.setData(Uri.parse(\"https://www.github.com\"));startActivity(intent); 调用系统拨号拨打10010 123Intent intent = new Intent(Intent.ACTION_DIAL);intent.setData(Uri.parse(\"tel:10010\"));startActivity(intent); 可以在 AndroidManifest 的 &lt;intent - filter&gt;标签中配置 标签， 指定当前活动可以响应什么类型的数据。这样其他app响应这种数据的时候，Android系统会弹出选项，你的app会在可选列表里面 12345678&lt;activity android:name=\".SecondActivity\"&gt; &lt;intent-filter&gt; &lt;action android:name=\"com.jerrysheh.hello.ACTION_START\" /&gt; &lt;category android:name=\"android.intent.category.DEFAULT\"/&gt; &lt;data android:schme=\"https\" /&gt; &lt;data android:host=\"www.zhihu.com\" /&gt; &lt;/intent-filter&gt;&lt;/activity&gt; 这样, 你的app可以响应知乎网站的浏览器调用 使用Intent传递数据向下一个活动传递数据可以用 intent 的 putExtra 方法向下一个活动传递数据。核心思想是，把数据存在String里，通过intent参数传递给下一个活动，下一个活动启动后从intent取出。 存放 (MainActivity.java) 1234String data = \"this is data\"Intent intent = new Intent(\"com.jerrysheh.hello.ACTION_START\");intent.putExtra(Intent.EXTRA_TEXT, data);startActivity(intent); 取出 (SecondActivity.java) 12Intent intent = getIntent();String data = intent.getStringExtra(Intent.EXTRA_TEXT); 返回数据给上一个活动Activity中有一个StartActivityForResult()方法用于启动一个活动，但期望活动销毁后（通常是按下返回键或调用finish()方法）返回一个结果给上一个活动。 MainActivity.java 12Intent intent = new Intent(MainActivity.this,SecondActivity.class);StartActivityForResult(intent, 1); SecondActivity.java 1234Intent intent = new Intent();intent.putExtra(\"data_return\", \"this is back data\");setResult(RESULT_OK, intent);finish(); 当然，返回数据后，会回调MainActivity的onActivityResult()方法，因此我们还需要重写这个方法拿到SecondActivity返回来的数据。 1234567891011@Overrideprotected void onActivityResult(int requestCode, int resultCode, Intent data) { switch(requestCode) { case 1: if (requestCode == RESULT_OK) { String returnData = data.getStringExtra(\"data_return\"); ... } break; }} 使用 intent 传递对象上面的 intent 只能传 String， 如果我们有一个 javabean 对象需要传递，怎么做呢？ 首先将实体类（bean）实现 Serializable 接口。注意: 如果 bean 里面嵌套了 bean，内部类也要声明为实现 Serializable 接口。 123456789public class bean implements Serializable { int a; int b; String c; Heybean d; public static class Heybean implements Serializable { ... }} 传递 activity 123Intent intent = new Intent(context, DetailActivity.class);intent.putExtra(\"name\",detailbean);context.startActivity(intent); 接收 activity 1Bean detailBean = (Bean) getIntent().getSerializableExtra(\"name\"); Activity的生命周期Android 用 任务（Task）来管理活动，一个Task就是一组存放在返回栈（Back Stack）里的活动的集合。系统总是会显示处于栈顶的活动给用户。 Activity的四种状态 运行状态 暂停状态（弹出式卡片，背景活动就是暂停状态） 停止状态 销毁状态 Activity的生存期 完整生存期活动在onCraete()和onDestroy()之间经历的，就是一个完整生存期。 可见生存期活动在onStart()和onStop()之间经历的，就是一个可见生存期。onStart()方法在活动从不可见变为可见时调用，onStop()反之。 前台生存期活动在onResume()和onPause()之间经历的，就是一个前台生存期。onResume()方法在活动准备好和用户交互时调用。当系统准备去启动或恢复另一个活动时，onPause()将当前活动一些消耗CPU的资源释放，同时保存关键数据。 此外，还有一个onRestart()，用于活动从停止状态变为运行状态之前调用，也就是活动被重新启动。 当系统内存不足时，用户按下back键返回到上一个Activity，有可能上一个Activity已经被系统回收，这时不会执行onRestart()，而是执行onCreate()。遇到这种情况，如果上一个Activity有数据，那这些数据都丢失了，这是很影响用户体验的。解决办法是调用onSaveInstantState()回调方法。具体参见《第一行代码》第二版p62，以及Activity Google官方文档（推荐） Activity的启动模式Activity有四种启动模式，可以在 AndroidManifest.xml 的 标签中修改 12345678&lt;activity android:name=\".SecondActivity\" android:launchMode=\"singleTop\"&gt; &lt;intent-filter&gt; &lt;action android:name=\"com.jerrysheh.hello.ACTION_START\" /&gt; &lt;category android:name=\"android.intent.category.DEFAULT\"/&gt; &lt;/intent-filter&gt;&lt;/activity&gt; android:launchMode可填以下四种模式 standard 标准模式，在MainActivity中启动MainActivity，会重复创建MainActivity的新实例。如创建了3个MainActivity的实例，需要按3次返回键才能完全退出。 singleTop 如果MainActivity已经在栈顶，启动MainActivity则不会重复创建新实例。但MainActivity不在栈顶，还是会创建新实例。 singleTask 无论MainActivity是否在栈顶，在整个应用程序上下文中只存在一个MainActivity实例。 singleInstance 单独创建一个返回栈存放该实例。解决不同应用共享一个返回栈的问题。 参考：Google官方文档","link":"/post/986c4cb5.html"},{"title":"Android笔记（二） Activity和布局","text":"ActivityActivity 是用户可以执行的单一任务。负责创建新的窗口，供应用绘制和从系统中接收事件。 Activity 是用 Java 编写的，扩展自 Activity 类。 Activity 会创建视图来向用户显示信息，并使用户与 Activity 互动。视图是 Android UI 框架中的类。它们占据了屏幕上的方形区域，负责绘制并处理事件。Activity 通过读取 XML 布局文件确定要创建哪些视图（并放在何处）。这些 XML 文件存储在标记为 layouts 的 res 文件夹内。 参阅Activity Google官方文档 布局 XMLAndroid 项目中的布局在 res/layouts 目录下的 XML 文件编写。 示例1234567891011&lt;TextView android:id=\"@+id/hello\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"Hello World!\" /&gt;&lt;Button android:id=\"@+id/button\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"确定\"/&gt; 常用控件 属性 定义 TextView 显示文本信息 Button 按钮 EditText 文本编辑框 ImageView 图片 ProgressBar 进度条 AlertDialog 弹出对话框 ProgressDialog 弹出带进度条的对话框 常用控件属性 属性 定义 android:id ID值 android:layout_width 控件宽度 android:layout_height 控件高度 android:text 控件显示的文字 android:gravity 文字对齐方式 android:textSize 文字大小 android:textColor 文字颜色 android:src 引用资源 android:padding 内边距 android:margin 外边距 更多控件请查阅：官方文档 关于颜色，可以到 Materia Design官网选取颜色 几种基本布局线性布局（LinearLayout）一种依靠线性方向排列的布局。 123456789101112131415161718192021222324252627&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:orientation=\"vertical\" android:padding=\"16dp\" tools:context=\"com.example.android.exampleapp.MainActivity\"&gt; &lt;EditText android:id=\"@+id/edit_text_name_input\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:background=\"@color/colorAccent\" android:hint=\"Enter your name\" android:padding=\"4dp\" android:textSize=\"24sp\" /&gt; &lt;TextView android:id=\"@+id/text_view_name_display\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:layout_gravity=\"center\" android:layout_marginTop=\"8dp\" android:text=\"Your name appears here\" android:textSize=\"30sp\" /&gt;&lt;/LinearLayout&gt; 相对布局（RelativeLayout）一种依靠相对关系排列的布局。 控件可以用android:layout_above=&quot;@id/other_widget&quot;之类的语句来定位。 相对布局属性： 相对控件属性 描述 android:layout_above 位于给定DI控件之上 android:layout_below 位于给定DI控件之下 android:layout_toLeftOf 位于给定控件左边 android:layout_toRightOf 位于给定控件右边 android:layout_alignLeft 左边与给定ID控件的左边对齐 android:layout_alignRight 右边与给定ID控件的右边对齐 android:layout_alignTop 上边与给定ID控件的上边对齐 android:layout_alignBottom 底边与给定ID控件的底边对齐 android:layout_alignBaseline 对齐到控件基准线 相对父容器属性 描述 android:layout_alignParentLeft 相对于父靠左 android:layout_alignParentTop 相对于父靠上 android:layout_alignParentRight 相对于父靠右 android:layout_alignParentBottom 相对于父靠下 android:layout_centerInParent 相对于父即垂直又水平居中 android:layout_centerHorizontal 相对于父即水平居中 android:layout_centerVertical 相对于父即处置居中 版本4.2以上相对布局新属性 描述 android:layout_alignStart 将控件对齐给定ID控件的头部 android:layout_alignEnd 将控件对齐给定ID控件的尾部 android:layout_alignParentStart 将控件对齐到父控件的头部 android:layout_alignParentEnd 将控件对齐到父控件的尾部 官方 guide ： https://developer.android.com/guide/topics/ui/layout/relative 官方 doc： https://developer.android.com/reference/android/widget/RelativeLayout 帧布局（FrameLayout）默认摆放在左上角的布局。 在下面的例子中， FrameLayout嵌套了ScrollView 12345678910111213141516&lt;FrameLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\"&gt; &lt;ScrollView android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\"&gt; &lt;TextView android:id=\"@+id/tv_toy_names\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:padding=\"16dp\" android:textSize=\"20sp\" /&gt; &lt;/ScrollView&gt;&lt;/FrameLayout&gt; 约束布局（ConstraintLayout）Android Project默认采用的布局。功能强大。 12345678910111213141516171819202122232425&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;android.support.constraint.ConstraintLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:app=\"http://schemas.android.com/apk/res-auto\" xmlns:tools=\"http://schemas.android.com/tools\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" tools:context=\"com.jerrysheh.sunshine.MainActivity\"&gt; &lt;TextView android:id=\"@+id/hello\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"Hello World!\" app:layout_constraintBottom_toBottomOf=\"parent\" app:layout_constraintLeft_toLeftOf=\"parent\" app:layout_constraintRight_toRightOf=\"parent\" app:layout_constraintTop_toTopOf=\"parent\" /&gt; &lt;Button android:id=\"@+id/button\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"确定\"/&gt;&lt;/android.support.constraint.ConstraintLayout&gt; 注意，ConstraintLayout定义在support库中，需要在 app/build.gradle 中的 dependencies 闭包中添加implementation 'com.android.support.constraint:constraint-layout:1.0.2' 更多ConstrainLayout的内容可以参阅郭霖的博客文章 更多布局相关请查阅： - 官方文档1 - 官方文档2 自定义布局如果系统自带的布局和控件不够用，我们可以自定义布局。 先在 res/layout 下面新建一个布局文件，如 title.xml， 然后编写我们的布局。再然后在main_activity.xml中加入&lt;include layout=&quot;@layout/title&quot; /&gt;，就能把我们的布局引进来。 XML 布局与 Java Activity 的关系创建 XML 布局后，你需要将其与你的 Activity 相关联。 你可以在 Activity 的 onCreate 方法中使用 setContentView 方法进行关联。你可以以 R.layout.name_of_layout 的形式引用布局文件。例如，如果你的布局名称为 activity_main.xml，则如下所示： 123456789public class MainActivity extends AppCompatActivity { @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); // other code to setup the activity } // other code} 什么是 R.layout ？当你的应用被编译时，系统会生成 R 类。它会创建常量，使你能够动态地确定 res 文件夹的各种内容，包括布局。 详细可参阅资源的文档。 setContentView 是干什么的 setContentView 它会扩展布局。本质上是 Android 会读取你的 XML 文件并为你的布局文件中的每个标记生成 Java 对象。然后，你可以在 Java 代码中通过对 Java 对象调用方法修改这些对象。 资源每个 Android 项目都包含一个 res 目录。这是放置图片、字符串和布局等的地方。 在 XML 和 Java 中使用资源在上一篇中提到，setContentView(R.layout.activity_main)表示 java 引用了 activity_main.xml 这个xml资源。 可以在 res/value/string 中声明一些资源文件，如 123&lt;resources&gt; &lt;string name=\"app_name\"&gt;Github Query&lt;/string&gt;&lt;/resources&gt; 然后在java中 12// myString 的值为 app_nameString myString = getString(R.string.app_name); 在Activity中使用Toast和Menu使用ToastToast是一种显示在屏幕下方的提示，我们经常可以看到有时候app会提醒你没有联网，或者再按一次返回键退出应用之类，这些提醒在短时间内消失，不会打扰用户。 假设我们已经在 xml 里添加了一个 button 然后转到MainActivity.java，重写onCreate方法 123456789101112@Overrideprotected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); Button buttonOK = (Button) findViewById(R.id.toast_button); buttonOK.setOnClickListener(new View.OnClickListener() { @Override public void onClick(View view) { Toast.makeText(MainActivity.this, \"yeah, you click it\", Toast.LENGTH_SHORT).show(); } });} 先实例化一个Button类型的变量 buttonOK，用findViewById指向button的ID 调用buttonOK的setOnClickListener，传入一个点击事件监听器 重写监听器的onClick方法为调用Toast.makeText Toast.makeText有3个参数，第一个是活动本身，第二个是提示内容，第三个是Toast的长度 最后.show() 让Toast显示出来 Toast单例如果点击很多次按钮，会创建很多个 Toast 重叠在一起，可以封装成工具类，使之只有一个实例 123456789101112131415161718192021222324252627public class ToastUtil { private static Toast toast; /** * 显示Toast * @param context 上下文 * @param content 要显示的内容 */ public static void showToast(Context context, String content) { if (toast == null) { toast = Toast.makeText(context, content, Toast.LENGTH_SHORT); } else { toast.setText(content); } toast.show(); } /** * 显示Toast * @param context 上下文 * @param resId 要显示的资源id */ public static void showToast(Context context, int resId) { showToast(context, (String) context.getResources().getText(resId)); }} 使用Menu在 res 新建文件夹 menu ， 在 menu里面新建 MenuResource file， 命名为 menu.xml，内容如下 1234567891011&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;menu xmlns:android=\"http://schemas.android.com/apk/res/android\"&gt; &lt;item android:orderInCategory=\"1\" android:id=\"@+id/add_item\" android:title=\"Add\" /&gt; &lt;item android:id=\"@+id/remove_item\" android:title=\"Remove\"/&gt;&lt;/menu&gt; 使用 android:orderInCategory=&quot;1&quot; 来对菜单项进行排序 使用 app:showAsAction=&quot;ifRoom&quot; 固定到顶栏而不是右上角三个点里面 如果顶栏空间不够，这个item依然会显示到三个点里面进去。使用 app: 而不是 android: 的原因是兼容低版本Android 这样我们就布局了两个按钮，一个 add ， 一个 remove 然后在 MainActivity.java 里 重写onCreateOptionsmenu方法和onOptionItemSelected方法，如下 123456789101112131415161718192021@Overridepublic boolean onCreateOptionsMenu(Menu menu) { getMenuInflater().inflate(R.menu.main, menu); return true;}@Overridepublic boolean onOptionsItemSelected(MenuItem item) { switch (item.getItemId()) { case R.id.add_item: Toast.makeText(this, \"added\", Toast.LENGTH_SHORT).show(); break; case R.id.remove_item: Toast.makeText(this,\"removed\",Toast.LENGTH_SHORT).show(); break; default: Toast.makeText(this,\"nothing\", Toast.LENGTH_SHORT).show(); } return true;} onCreateOptionsmenu方法根据R.menu.main找到我们的布局 onOptionsItemSelected方法根据id定义了每个按键按下后的动作 实践：从界面到逻辑现在我们有很多个String，我们想把这些 String 放到一个activity里，然后在 Android 设备上显示出来。由于 String 很多，一屏不够显示，因此需要实现可以滑动屏幕上下滚动的功能。 1. 编辑布局首先我们在 activity_main.xml 中编辑好界面布局 123456789101112131415161718&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;FrameLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\"&gt; &lt;ScrollView android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\"&gt; &lt;TextView android:id=\"@+id/tv_toy_names\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:padding=\"16dp\" android:textSize=\"20sp\" /&gt; &lt;/ScrollView&gt;&lt;/FrameLayout&gt; 这个界面有一个ScrollView，用于滚动显示内容。ScrollView里面是一个TextView，用于显示文字。 如果用到了一些 support 库的界面，记得去 app/build.gradle 中的 dependencies 闭包中添加支持。 2. ToyBox.java现在我们在 app/src/main/java/[包名]/ 里创建一个类，这是一个String数组，里面有很多String。 方法getToyNames返回了这个String数组。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public final class ToyBox { /** * This method returns a list of popular toy names from the 20th and early 21st centuries. * I don't know about you guys, but this definitely brings me back to my childhood... * * @return A list of popular toys */ public static String[] getToyNames() { return new String[] { \"Red Toy Wagon\", \"Chemistry Set\", \"Yo-Yo\", \"Pop-Up Book\", \"Generic Uncopyrighted Mouse\", \"Finger Paint\", \"Sock Monkey\", \"Microscope Set\", \"Beach Ball\", \"BB Gun\", \"Green Soldiers\", \"Bubbles\", \"Spring Toy\", \"Fortune Telling Ball\", \"Plastic Connecting Blocks\", \"Water Balloon\", \"Paint-by-Numbers Kit\", \"Tuber Head\", \"Cool Ball with Holes in It\", \"Toy Truck\", \"Flying Disc\", \"Two-Handed Pogo Stick\", \"Toy Hoop\", \"Dysmorphia Doll\", \"Toy Train\", \"Fake Vomit\", \"Toy Telephone\", \"Barrel of Primates\", \"Remote Control Car\", \"Square Puzzle Cube\", \"Football\", \"Intergalactic Electronic Phasers\", \"Baby Horse Dolls\", \"Machines that turn into other Machines\", \"Teddy Bears\", \"Shaved Ice Maker\", \"Glow Stick\", \"Squirt Guns\", \"Miniature Replica Animals Stuffed with Beads that you swore to your parents would be worth lots of money one day\", \"Creepy Gremlin Doll\", \"Neodymium-Magnet Toy\" }; }} 3. MainActivity.java一开始这个MainActivity.java只有初始化代码： 12345678910111213package com.example.android.favoritetoys;import android.os.Bundle;import android.support.v7.app.AppCompatActivity;public class MainActivity extends AppCompatActivity { @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); }} 修改如下 导入android.widget.TextView;包，Android Studio会自动为我们做。 声明一个TextView类型的变量mToysListTextView。 用findViewById方法，让mToysListTextView指向ID为tv_toy_names的TextView。 声明一个 String[] ，存放上面提到的很多String 一个eachfor循环，分别存放每一个String 123456789101112131415161718192021222324package com.example.android.favoritetoys;import android.os.Bundle;import android.support.v7.app.AppCompatActivity;import android.widget.TextView;public class MainActivity extends AppCompatActivity { private TextView mToysListTextView; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); mToysListTextView = (TextView) findViewById(R.id.tv_toy_names); String[] toyNames = ToyBox.getToyNames(); for (String toyName : toyNames) { mToysListTextView.append(toyName + \"\\n\\n\\n\"); } }} 最终效果如下：","link":"/post/7b1dcae5.html"},{"title":"Android笔记（五）持久化技术","text":"什么是持久化技术持久化技术指的是将内存中产生的瞬时数据保存到存储设备中，这样，当手机关机再重启，这些数据不会丢失。Android的持久化技术提供了一套机制，让数据在瞬时状态和持久状态之间进行转换。 Android 主要提供了 3 种数据持久化功能，分别是： 文件存储：顾名思义，用于保存文本或二进制数据等文件 SharedPreference存储：保存相对较小的键值集合 数据库存储：将数据保存到数据库 文件存储File 对象适合按照从开始到结束的顺序不跳过地读取或写入大量数据。 例如，它适合于图片文件或通过网络交换的任何内容。 早期的Android设备，由于内置存储空间非常有限（2011年买的Samung Galaxy S+只有 8 G 存储空间），因此通常都会外置SD卡。所以，Android的存储分为内部和外部。也有一些设备，虽然不支持SD卡，但依然人为地把存储空间分为外部和内部。一般来说，我们推荐把文件保存在内置存储当中，因为它始终可用，且只有自己的应用才能访问此处保存的文件，当自己的应用被卸载时，这些文件也会被移除。 如果要将文件写入外部存储中，请参考官方文档 将文件保存在内部存储中无需任何权限，即可在内部存储中保存文件。 可以用 getFilesDir() 方法返回表示应用的内部目录的 File 。 用getCacheDir()方法返回表示应用临时缓存文件的内部目录的 File。 关于写入文件和写入缓存，请参考官方文档 保存文本示例首先定义一个 EditText activity_main.xml 1234567891011121314151617&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" xmlns:tools=\"http://schemas.android.com/tools\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:orientation=\"vertical\" android:padding=\"16dp\"&gt; &lt;EditText android:id=\"@+id/edit_text_name_input\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:hint=\"input your name\" android:padding=\"4dp\" android:textSize=\"24sp\" /&gt;&lt;/LinearLayout&gt; 然后重写onCreate方法和onDestroy方法 Context类提供了一个 FileOutputStream 类型的 openFileOutput()方法，用于输出数据到文件。 MainActivity.java 1234567891011121314151617181920212223242526272829303132333435public class MainActivity extends AppCompatActivity { private EditText edit; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); // edit 实例 edit = findViewById(R.id.edit_text_name_input); } @Override protected void onDestroy(){ super.onDestroy(); // 获取 edit 的内容 String inputText = edit.getText().toString(); save(inputText); } public void save(String inputText){ FileOutputStream outputStream; try { // 输出流 outputStream = openFileOutput(\"myName\", Context.MODE_PRIVATE); outputStream.write(inputText.getBytes()); outputStream.close(); } catch (Exception e) { e.printStackTrace(); } }} 这样当我们退出app，edittext的文本就会被自动保存起来。 从保存的文件中读取数据类似于输出流，Context类也提供了一个 FileinputStream 类型的 openFileinput()方法，用于输出数据到文件。 openFileinput(filename)的参数是文件名，一旦指定，系统会自动从 /data/data//files/ 目录下加载这个文件，并返回一个 FileinputStream 对象。 一个完整的示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758public class MainActivity extends AppCompatActivity { private EditText dataEditText; private String inputText; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); dataEditText = findViewById(R.id.editText); inputText = load(); // TextUtils.isEmpty方法：当 inputText 为 null 或 空 时返回 true if (!TextUtils.isEmpty(inputText)){ dataEditText.setText(inputText); dataEditText.setSelection(inputText.length()); Toast.makeText(this, &quot;恢复数据成功&quot;, Toast.LENGTH_SHORT).show(); } } // 从文件加载数据 private String load() { StringBuilder content = new StringBuilder(); String line; try ( FileInputStream fileInputStream = openFileInput(&quot;data&quot;); BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(fileInputStream)) ){ while( (line = bufferedReader.readLine()) != null ){ content.append(line); } } catch (IOException IOe){ IOe.printStackTrace(); } return content.toString(); } @Override protected void onDestroy() { super.onDestroy(); String inputText = dataEditText.getText().toString(); saveText(inputText); } //保存数据到文件 private void saveText(String inputText) { try( FileOutputStream outputStream = openFileOutput(&quot;data&quot;,Context.MODE_PRIVATE); BufferedWriter bufferedWriter = new BufferedWriter(new OutputStreamWriter(outputStream)) ){ bufferedWriter.write(inputText); } catch ( IOException e){ e.printStackTrace(); } }} 思路： 在 onCreate()方法中调用 load() 来读取文件中的数据 在 onDestroy()方法中调用 saveText() 来保存数据到文件 SharedPreference存储文件存储还是比较麻烦的，SharedPreference可以用键值对的方式来存储数据。 保存数据时，给数据提供一个键 读取数据时，根据键找到值 在 Android 中，有三种方法得到 SharedPreference 对象: Context 类中的 getSharePreference(filename, mode)方法 参数1是存储的文件名，目录在/data/data/&lt;package name&gt;/share_prefs/ ，参数2是模式，默认 MODE_PRIVATE Activity 类中的 getPreferences(mode) 方法 只有一个mode参数，因为这个方法会把当前类名作为 filename PreferenceManager 类中的 static getDefaultSharedPreferences(Context)方法","link":"/post/1d084fbe.html"},{"title":"Android笔记（九）使用ViewPager","text":"使用 RecyclerView 可以实现动态加载数据。但如果我们有很多个页面，需要通过左右滑动来切换，就可以使用 ViewPager。 需要实现的效果： FragmentFragment，可以称为碎片，或者片段。可以理解成就是小的 Activity， 我们可以在 Fragment 里编写布局，然后在一个 Activity 里面使用多个 Fragment，构成比较复杂的应用界面。 Fragment 同样有自己的生命周期。 创建一个 Fragment 布局比如，如下布局是一个 recyclerView + SwipeRefreshLayout (下拉刷新) recycler_view.xml 123456789101112131415161718192021222324&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;RelativeLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:layout_width=\"match_parent\" android:orientation=\"vertical\" android:layout_height=\"wrap_content\"&gt; &lt;android.support.v4.widget.SwipeRefreshLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:orientation=\"vertical\" android:id=\"@+id/swipeLayout\" &gt; &lt;android.support.v7.widget.RecyclerView android:id=\"@+id/news_recycler_view\" android:scrollbars=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" /&gt; &lt;/android.support.v4.widget.SwipeRefreshLayout&gt;&lt;/RelativeLayout&gt; 继承 Fragment 类创建一个java类，继承 android.support.v4.app.Fragment，重写onCreate()和onCreateView()方法。 onCreate()是在该Fragment被实例化的时候，比如gsmhFragment = new MHFragment()的时候调用。 onCreateView()是创建该fragment对应的视图。在onCreateView()里，用inflater.inflate将上面的 xml 映射成 View 12345678910111213141516171819202122public class MHFragment extends android.support.v4.app.Fragment { // 按需定义一些变量 // 重写onCreate @Override public void onCreate(@Nullable Bundle savedInstanceState) { super.onCreate(savedInstanceState); context = this.getActivity(); } //重写 onCreateView @Nullable @Override public View onCreateView(LayoutInflater inflater, @Nullable ViewGroup container, Bundle savedInstanceState) { View view = inflater.inflate(R.layout.recycler_view, container, false); recyclerView = view.findViewById(R.id.news_recycler_view); mSwipeRefreshLayout = view.findViewById(R.id.swipeLayout); // 其他逻辑，比如mSwipeRefreshLayout的监听 return view; }} 扩展：如果Activity需要传参数给Fragment可以在MHFragment类里用静态工厂方法： 12345678public static MHFragment newInstance(String Comicstype){ MHFragment fragment = new MHFragment(); Bundle bundle = new Bundle(); bundle.putString(\"Comicstype\", Comicstype); fragment.setArguments(bundle); return fragment ;} 然后在 Activity 里调用 12345// Activity类中MHFragment gsmhFragment;// onCreate方法中gsmhFragment = MHFragment.newInstance(ComicTypeEnum.GSMH.getID()); 使用 ViewPagerViewPager的使用也不难，先在Activity里布局 ViewPager，然后创建一个适配器，最后在 Activity 里设置。 Activity布局将 ViewPager 放在 LinearLayout 里面 123456&lt;android.support.v4.view.ViewPager android:id=\"@+id/vp_content\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\"&gt;&lt;/android.support.v4.view.ViewPager&gt; 继承 FragmentPagerAdapter自定义个一个MyViewPagerAdapter类，继承FragmentPagerAdapter类。在构造方法中传入参数（一个 MHFragment 类型的 List 和一个 String 数组用作标题） 之所以要标题，是因为要配合下面的 TabLayout 使用 重写getItem()、getCount()、getPageTitle()方法 123456789101112131415161718192021222324252627public class MyViewPagerAdapter extends FragmentPagerAdapter { private List&lt;MHFragment&gt; fragments; private String[] titleList; public MyViewPagerAdapter(FragmentManager fm, List&lt;MHFragment&gt; fragments, String[] titleList) { super(fm); this.fragments = fragments; this.titleList = titleList; } @Override public Fragment getItem(int arg0) { return fragments.get(arg0); } @Override public int getCount() { return fragments.size(); } @Nullable @Override public CharSequence getPageTitle(int position) { //return titleList.get(position); return titleList[position]; }} 在Activity中首先要有一个 List， 里面放了几个 Fragment 实例 12345678MHFragment gxmhFragment ,gsmhFragment, qqmhFragment;private List&lt;MHFragment&gt; fragments = new ArrayList&lt;&gt;();gsmhFragment = MHFragment.newInstance(ComicTypeEnum.GSMH.getID());gxmhFragment = MHFragment.newInstance(ComicTypeEnum.GXMH.getID());qqmhFragment = MHFragment.newInstance(ComicTypeEnum.QQMH.getID());fragments.add(gsmhFragment);fragments.add(gxmhFragment);fragments.add(qqmhFragment); 然后创建ViewPager和MyViewPagerAdapter实例 12345678910111213// 类中ViewPager mViewPager;MyViewPagerAdapter mViewPagerAdapter;// onCreate方法中FragmentManager fragmentManager = getSupportFragmentManager();// 参数1：Manager// 参数2：Fragments类型的List// 参数3：标题数组mViewPagerAdapter = new MyViewPagerAdapter(fragmentManager, fragments, tabTitles);mViewPager.setAdapter(mViewPagerAdapter); 这样就可以了。 使用 TabLayout有时候我们滑动的时候，还希望上面有一个类似于 Tab 的标签，可以用 TabLayout 布局在 LinearLayout 里面， ViewPager 之上，添加 TabLayout 的布局代码 1234567891011121314151617181920212223242526272829&lt;android.support.design.widget.TabLayout android:id=\"@+id/title_tab\" android:layout_height=\"wrap_content\" android:layout_width=\"match_parent\" android:scrollbars=\"horizontal\" xmlns:android=\"http://schemas.android.com/apk/res/android\"&gt; &lt;android.support.design.widget.TabItem android:id=\"@+id/tab_GXMH\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"@string/tab_GXMH\"/&gt; &lt;android.support.design.widget.TabItem android:id=\"@+id/tab_KBMH\" android:layout_width=\"wrap_content\" android:layout_height=\"wrap_content\" android:text=\"@string/tab_KBMH\"/&gt; &lt;!-- 有几个 TabItem 就写几个 --&gt;&lt;/android.support.design.widget.TabLayout&gt;&lt;android.support.v4.view.ViewPager android:id=\"@+id/vp_content\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\"&gt;&lt;/android.support.v4.view.ViewPager&gt; Activity 中12345// 类中TabLayout mTabLayout;// onCreate()方法中mTabLayout.setupWithViewPager(mViewPager); 搞定。","link":"/post/c60f0455.html"},{"title":"Android笔记（七）连接网络","text":"当我们在知乎上面搜索“Android”的时候，可以看到地址栏的链接变化为： https://www.zhihu.com/search?type=content&amp;q=Android 其中，https://www.zhihu.com/search是 BASE_URL， 问号?后面的是参数。 这里的参数就是 type 为 content， q 为 Android 。 现在，我们要打造一个功能，用户在 EditText 上输入 Android ， 我们的app 可以构造出 https://www.zhihu.com/search?type=content&amp;q=Android 这样的 URL 出来。 并对该地址进行 HTTP 访问，然后获取 Response 结果。 以下将以 Github 的 API 为例 构建URL访问 https://api.github.com/ ，可以看到如果我们要搜索 github 仓库，需要构造的链接是 https://api.github.com/search/repositories?q={query}{&amp;page,per_page,sort,order} 假如搜索 hello，以 stars 数目排序，那么构造的链接是 https://api.github.com/search/repositories?q=Hello&amp;sort=stars 创建一个工具类 NetworkUtils.java， 写一个 buildUrl 方法用来生成URL 1234567891011121314151617181920212223242526public class NetworkUtils { final static String GITHUB_BASE_URL = \"https://api.github.com/search/repositories\"; final static String PARAM_QUERY = \"q\"; final static String PARAM_SORT = \"sort\"; final static String sortBy = \"stars\"; public static URL buildUrl(String githubSearchQuery) { // TODO (1) Fill in this method to build the proper Github query URL Uri builtUri = Uri.parse(GITHUB_BASE_URL).buildUpon() .appendQueryParameter(PARAM_QUERY,githubSearchQuery) .appendQueryParameter(PARAM_SORT,sortBy) .build(); URL url = null; try { url = new URL(builtUri.toString()); } catch (MalformedURLException e) { e.printStackTrace(); } return url; }} 用 Uri 来生成 Uri ，再转换为 URL 然后在 MainActivity.java 中调用 12345// 将 EditText 转为 StringString githubQuery = mSearchBoxEditText.getText().toString();//构造 URLURL githubSearchUrl = NetworkUtils.buildUrl(githubQuery); 获取 Response 内容实际上从 Http 响应中获取数据，就是一个输入流。将输入流转换为 String 可以用 Scanner。或者IOUtils。 使用 Scanner在上面的工具类 NetworkUtils.java 中添加一个静态方法，用于获取Http响应的内容 12345678910111213141516171819202122public static String getResponseFromHttpUrl(URL url) throws IOException { // 建立一个 HTTP 连接 HttpURLConnection urlConnection = (HttpURLConnection) url.openConnection(); try { // 从 HTTP 连接中获取输入流 InputStream in = urlConnection.getInputStream(); // 以 \\\\A 为分隔符 Scanner scanner = new Scanner(in); scanner.useDelimiter(\"\\\\A\"); boolean hasInput = scanner.hasNext(); if (hasInput) { return scanner.next(); } else { return null; } } finally { urlConnection.disconnect(); }} 扩展:使用 IOUtils 工具类除了 Scanner 之外，还可以用IOUtils 123StringWriter writer = new StringWriter();IOUtils.copy(inputStream, writer, encoding);String theString = writer.toString(); 或许还有其他的方法，参考：read-convert-an-inputstream-to-a-string 发起 HTTP 请求在 MainActivity 中， 使用以下语句来发起 HTTP 请求并得到结果 这个方法写在按钮点击事件里，点击时，将发生： 根据EditText的内容构建URL getResponseFromHttpUrl建立一个HTTP连接并返回String类型的结果 在TextView把 response 的结果显示出来 1234567891011121314151617181920private void makeGithubSearchQuery() { // 将 EditText 的内容转为 String String githubQuery = mSearchBoxEditText.getText().toString(); // 用上面的NetworkUtils工具类的buildUrl方法，构建URL URL githubSearchUrl = NetworkUtils.buildUrl(githubQuery); //将构建好的 URL 显示在 TextView 上，作为直观测试 mUrlDisplayTextView.setText(githubSearchUrl.toString()); //用上面的NetworkUtils工具类的getResponseFromHttpUrl方法 //获取 HTTP response 的内容，并显示在 TextView 上 String githubSearchResults = null; try { githubSearchResults = NetworkUtils.getResponseFromHttpUrl(githubSearchUrl); mSearchResultsTextView.setText(githubSearchResults); } catch (IOException e) { e.printStackTrace(); }} 理论上这样做没问题，但如果真的运行，会发现抛出NetworkOnMainThreadException，应用程序强退。 原因是对于需要一定时间的任务（比如网络请求），需要开独立的线程来执行，不能在主线程执行。否则会阻塞UI绘制，导致app假死。 所以我们应该把获取 HTTP 请求写在后台线程里。 后台线程AsyncTask是在 Android 上的线程之间进行线程和消息传递的抽象类。 使用AsyncTask，可以把网络请求在后台线程运行，然后把结果送到UI线程。 AsyncTask的使用方法是： 第一步：继承AsyncTask抽象类，指定3个泛型参数： Params:执行AsyncTask时传入的参数 Progress：后台任务传给前台的进度条单位（如果不需要为Void） Result：后台任务执行完毕后返回给前台的返回值类型 第二步：重写AsyncTask类的以下（部分）方法 onPreExcute()：前台执行。在后台任务开始前调用。 doInBackground(Params ...)：后台执行。后台线程运行的具体内容。 onProgressUpdate(Progress ...)： 前台执行。当后台线程调用publicProgress(Progress ...)后，在前台中该方法随即被调用。用于对UI进行操作（比如改变进度百分比数字） onPostExecute(Result)：前台执行。后台return的时候该方法被调用，返回的结果就是Result参数 具体例子 创建一个类（可以是内部类）继承AsyncTask，泛型参数为URL, Void, String 重写doInBackground()方法，传入一个URL对象，以及它的参数，处理并返回结果集（该方法在后台线程运行） 重写onPostExecute()方法，传入结果集（该方法在主线程运行），将结果集显示在 TextView 上面 123456789101112131415161718192021public class GithubQueryTask extends AsyncTask&lt;URL, Void, String&gt;{ @Override protected String doInBackground(URL... params) { URL searchUrl = params[0]; String githubSearchResults = null; try { githubSearchResults = NetworkUtils.getResponseFromHttpUrl(searchUrl); } catch (IOException e) { e.printStackTrace(); } return githubSearchResults; } @Override protected void onPostExecute(String githubSearchResults) { if (githubSearchResults != null &amp;&amp; !githubSearchResults.equals(\"\")) { mSearchResultsTextView.setText(githubSearchResults); } }} 添加网络访问权限在 AndroidManifest.xml 中需要添加访问权限 1&lt;uses-permission android:name=\"android.permission.INTERNET\" /&gt; 否则会报SecurityException异常 在onCreate()中调用因为GithubQueryTask是一个继承于AsyncTask的类，使用 new 语句来启动后台 1new GithubQueryTask().execute(githubSearchUrl); 效果： 源码：优达学城 扩展：使用 okhttp 框架：http://square.github.io/okhttp/","link":"/post/329b893e.html"},{"title":"Android开发中的一些坑","text":"Gradle 加载慢的问题第一次加载项目很慢一直显示Building “XXXX” Gradle project info 解决办法： 打开{your project}/gradle/wrapper/gradle-wrapper.properties 查看distributionUrl中 gradle 版本 去 https://services.gradle.org/distributions/ 下载相应版本的Gradle（官网地址：https://gradle.org/install） 放到以下目录即可 Linux：~/.gradle/wrapper/dists Windows：C:\\users\\{user name}\\.gradle\\wrapper\\dists 运行时权限在部分Android手机上无效问题按照 Google 文档的开发模型，写的运行时权限模型代码，在一加手机5T上，点击拒绝后没有任何提示，也就是说依然返回了有权限的STATUE_CODE，但是什么都没发生。 1234567891011121314151617181920212223242526if (ContextCompat.checkSelfPermission(this, Manifest.permission.READ_CONTACTS) != PackageManager.PERMISSION_GRANTED) { // 没有权限。 if (ActivityCompat.shouldShowRequestPermissionRationale(this, Manifest.permission.READ_CONTACTS)) { // 用户拒绝过这个权限了，应该提示用户，为什么需要这个权限。 } else { // 申请授权。 ActivityCompat.requestPermissions(thisActivity, new String[]{Manifest.permission.READ_CONTACTS}, MMM); }}...@Overridepublic void onRequestPermissionsResult(int requestCode, String permissions[], int[] grantResults) { switch (requestCode) { case MMM: { if (grantResults.length &gt; 0 &amp;&amp; grantResults[0] == PackageManager.PERMISSION_GRANTED) { // 权限被用户同意，可以去放肆了。 } else { // 权限被用户拒绝了，洗洗睡吧。 } return; } }} 解决办法很多国产ROM都有这个坑。因此不要用上面的开发模型，推荐开源库：AndPermission 项目地址： https://github.com/yanzhenjie/AndPermission 使用方法可参考：Android 6.0 运行时权限管理最佳实践 Android Device Monitor 打不开的问题 查看Log：C:\\Users\\Jerrysheh\\AppData\\Local\\Android\\Sdk\\tools\\lib\\monitor-x86_64\\configuration\\1520661867795.log 关键报错 123456789101112131415161718192021222324252627282930313233343536!ENTRY org.eclipse.osgi 4 0 2018-03-10 14:04:28.224!MESSAGE Bundle reference:file:org.apache.ant_1.8.3.v201301120609/@4 not found.!ENTRY org.eclipse.osgi 4 0 2018-03-10 14:04:28.255!MESSAGE Bundle reference:file:org.apache.jasper.glassfish_2.2.2.v201205150955.jar@4 not found.!ENTRY org.eclipse.osgi 4 0 2018-03-10 14:04:28.255!MESSAGE Bundle reference:file:org.apache.lucene.core_2.9.1.v201101211721.jar@4 not found.!ENTRY org.eclipse.osgi 4 0 2018-03-10 14:04:28.458!MESSAGE Bundle reference:file:org.eclipse.help.base_3.6.101.v201302041200.jar@4 not found.!ENTRY org.eclipse.osgi 4 0 2018-03-10 14:04:28.474!MESSAGE Bundle reference:file:org.eclipse.help.ui_3.5.201.v20130108-092756.jar@4 not found.!ENTRY org.eclipse.osgi 4 0 2018-03-10 14:04:28.474!MESSAGE Bundle reference:file:org.eclipse.help.webapp_3.6.101.v20130116-182509.jar@4 not found.!ENTRY org.eclipse.osgi 4 0 2018-03-10 14:04:28.474!MESSAGE Bundle reference:file:org.eclipse.jetty.server_8.1.3.v20120522.jar@4 not found.!ENTRY org.eclipse.osgi 4 0 2018-03-10 14:04:28.521!MESSAGE Bundle reference:file:org.eclipse.ui.intro_3.4.200.v20120521-2344.jar@4 not found.java.lang.IllegalStateException: Unable to acquire application service. Ensure that the org.eclipse.core.runtime bundle is resolved and started (see config.ini). at org.eclipse.core.runtime.internal.adaptor.EclipseAppLauncher.start(EclipseAppLauncher.java:74) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:353) at org.eclipse.core.runtime.adaptor.EclipseStarter.run(EclipseStarter.java:180) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(Unknown Source) at java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(Unknown Source) at java.base/java.lang.reflect.Method.invoke(Unknown Source) at org.eclipse.equinox.launcher.Main.invokeFramework(Main.java:629) at org.eclipse.equinox.launcher.Main.basicRun(Main.java:584) at org.eclipse.equinox.launcher.Main.run(Main.java:1438) at org.eclipse.equinox.launcher.Main.main(Main.java:1414) 解决办法卸载 JRE 9。 （JDK 9 可以不用卸载） ， 然后装 JDK 8 。 然后启动 Android Studio 时，使用管理员权限打开。","link":"/post/cc537ae4.html"},{"title":"Android笔记（四） Broadcast","text":"什么是 Broadcast Receiver广播接收器（Broadcast Receiver）允许你的应用接收来自各处的广播消息，比如开机广播，电池电量变化广播，时间或地区变化广播，以及来自电话、短信和其他app发出的广播消息等等。同样，我们的应用也可以向外发出广播消息。 Android中的广播可以分为以下两种： 标准广播（Normal Broadcast），一种完全异步执行的广播，当广播发出后，所有的广播接收器几乎同一时刻接收到这条广播信息，没有先后顺序之分。这种广播效率高，但无法截断。 有序广播（Ordered Broadcast），一种同步执行的广播，当广播发出后，同一时刻只有一个广播接收器收到这条广播，当这个广播接收器的逻辑执行完毕后，广播才会继续传递。这样一来，优先级高的广播接收器可以先收到广播，并且前面的广播接收器可以截断正在传递的广播。 接收系统广播我们可以对有需要的广播进行注册，这样，当有响应的广播发出时，广播接收器就能收到并处理。 注册广播的方法有动态和静态两种。 动态注册即在逻辑代码中注册（动态注册的一定要记得手动取消注册），动态注册的广播接收器需要在程序运行后才能接收广播 动态注册创建一个广播接收器的方法： 新建一个类，继承自BroadcastReceiver Override 父类的 onReceive() 方法 实际例子，收到网络状态信息改变广播时，发出Toast 新建一个继承自BroadcastReceiverd的 NetworkChangeReceiver 类 Override 父类的 onReceive() 方法，发出Toast 分别定义一个IntentFilter类型和NetworkChangeReceiver类型的变量 new 一个 IntentFilter 的实例，该实例的addAction方法让intent过滤android.net.conn.CONNECTIVITY_CHANGE广播 new 一个 NetworkChangeReceiver 的实例 registerReceiver方法，传入networkChangeReceiver和intentFilter 1234567891011121314151617181920212223242526272829public class MainActivity extends AppCompatActivity { private IntentFilter intentFilter; private NetworkChangeReceiver networkChangeReceiver; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); intentFilter = new IntentFilter(); intentFilter.addAction(\"android.net.conn.CONNECTIVITY_CHANGE\"); networkChangeReceiver = new NetworkChangeReceiver(); registerReceiver(networkChangeReceiver, intentFilter); } @Override protected void onDestroy() { super.onDestroy(); unregisterReceiver(networkChangeReceiver); } class NetworkChangeReceiver extends BroadcastReceiver { @Override public void onReceive(Context context, Intent intent) { Toast.makeText(context, \"network change\", Toast.LENGTH_SHORT).show(); } }} 静态注册 即在AndroidManifest.xml中注册，应用程序没有运行也能接收。 静态注册创建一个广播接收器的方法： 在Android Studio中右键package → new → Other → Broadcast Receiver来创建广播接收器，这样Android Studio会自动帮我们在AndroidManfest.xml注册 会自动生成@Override的 onReceive()方法，在该方法中编写接收逻辑 在AndroidManfest.xml中的Receiver标签内再建intent-filiter标签 12345678&lt;Receiver android:name=\".BootReceiver\" android:enable=\"true\" android:exported=\"true\"&gt; &lt;intent-filiter&gt; &lt;action android:name=\"android.intent.action.BOOT_COMPLETED\" /&gt; &lt;/intent-filiter&gt;&lt;/Receiver&gt; android:exported用于控制是否接收本程序以外的广播 Android中对敏感的操作必须在AndroidManifest.xml配置文件中声明权限，否则程序会崩溃。 比如，访问系统的网络状态和监听手机开机，需要在AndroidManifest.xml中注明： 12&lt;uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\" /&gt;&lt;uses-permission android:name=\"android.permission.RECEIVE_BOOT_COMPLETED\" /&gt; Broadcast Receiver通常扮演打开程序其他组件的角色，比如创建一条状态栏通知，或者启动一个服务等。不要在 onReceive()方法中写太多逻辑代码或耗时的操作，Broadcast Receiver中不允许开线程，onReceive()方法运行较长时间没有结束时，程序会报错。 发送广播发送自定义标准广播可以在按钮点击事件中加入发送自定义广播的逻辑。 构建一个 Intent 对象 传入要发送的广播的值 调用Context的sendBroadcast(intent)方法，将广播发送出去 发送有序广播发送有序广播只需要把sendBroadcast()方法改成sendOrderedBroadcast(intent, null)。 第二个参数是权限相关字符串。 我们可以在Broadcast Receiver的AndroidManifest.xml中，加入 1&lt;intent-filter android:priority=\"100\"&gt; 把这个Broadcast Receiver的优先级设为100 然后在这个Broadcast Receiver的onReceive()方法中，加入abortBoradcast();语句来截断这条广播，这样，这个有序广播不会被优先级更低的Broadcast Receiver收到。 本地广播有时候，我们只希望我们的广播在自己的应用程序内部可以接收到，不希望被系统和其他app接收，这时候可以用本地广播。 本地广播使用方法： 接收首先我们要定义一个Broadcast Receiver，用来接收我们的本地广播 1234567class LocalReceiver extends BroadcastReceiver { @Override public void onReceive(Context context, Intent intent) { // when recived, do something }} 发送首先在onCreate()方法中获取一个本地广播的实例 1localBroadcastManager = LocalBroadcastManager.getInstance(this); 然后可以在按钮点击事件中使用Intent,并注册本地广播监听器 123456789public void onClick(View v) { Intent intent = new Intent(\"com.jerrysheh.hello.LOCAL_BROADCAST\"); localBroadcastManager.sendBroadcast(intnet);}intentFiliter = new intentFiliter();intentFiliter.addAction(\"com.jerrysheh.hello.LOCAL_BROADCAST\");localReceiver = new localReceiver();localBroadcastManager.rigisterReceiver(localReceiver, intentFilter); 别忘记在onDestroy()方法中取消注册 1localBroadcastManager.unrigisterReceiver(localReceiver);","link":"/post/9e4d7c93.html"},{"title":"Android笔记（八）使用RecyclerView","text":"在 Android笔记（二） Activity和布局 中，使用一个 String[] 模拟了一些数据，然后写入到一个 TextView 或者 ScrollView 中。 但这样有两个弊端： ScrollView是一次性将内容绘制完毕，如果数据量很大，会导致内存消耗。 无法通过点击 String[] 里面的某一个 String 进入详细页面 于是我们引入了 RecyclerView 。想象一下，我们平时刷微博、刷知乎，随着我们不断地向下刷，数据是动态加载出来的。 这就是RecyclerView。 当然，如果在 RecyclerView 里面嵌套 CardView 就能显示很丰富的内容了。 RecyclerView原理RecyclerView 有一个适配器 Adapter Adapter 用于在必要时将某些数据源与 View 绑定，同时向 RecyclerView 提供新的 View。 那它如何提供呢？ Adapter 是通过一个叫 ViewHolder 的对象来提供。 ViewHolder 包含了那些 View 的 Root View 。并且，ViewHolder 缓存了一些 View， 以降低请求更新的成本。 最后，Layout Manager 会告诉 RecyclerView 如何布局所有得到的这些 View ， 例如，是垂直排列，还是水平、网格之类。 知道了以上原理之后，开发步骤就很明朗了： 添加 recyclerView 的依赖 在 layout 中创建一个 RecyclerView 创建单个 item 的layout resource file 创建 Adapter 类，实现内部类AdapterHolder 重写 Adapter 的三个方法 添加 Layout Manager 添加依赖在 app/build.gradle 里面的 dependencies 添加依赖 123dependencies { implementation 'com.android.support:recyclerview-v7:27.1.1'} 注意: 在新版本的 Gradle 中， compile 命令已经变更为 implementation ，或者 API Layout添加 recyclerView123456789101112131415&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;FrameLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\"&gt; &lt;!-- A RecyclerView with some commonly used attributes --&gt; &lt;android.support.v7.widget.RecyclerView android:id=\"@+id/news_recycler_view\" android:scrollbars=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"match_parent\"/&gt;&lt;/FrameLayout&gt; 为每个子项添加布局在 res/layout 创建一个新的 layout resource file number_list_item.xml 12345678910111213141516171819202122232425262728293031323334353637383940&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;LinearLayout xmlns:android=\"http://schemas.android.com/apk/res/android\" android:orientation=\"vertical\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\"&gt; &lt;android.support.v7.widget.CardView xmlns:card_view=\"http://schemas.android.com/apk/res-auto\" android:id=\"@+id/card_view\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" card_view:cardBackgroundColor=\"#FFFFFF\" card_view:cardCornerRadius=\"8dp\" card_view:cardUseCompatPadding=\"true\" android:layout_gravity=\"center\"&gt; &lt;RelativeLayout android:layout_width=\"match_parent\" android:layout_height=\"match_parent\" android:orientation=\"vertical\"&gt; &lt;ImageView android:id=\"@+id/news_photo\" android:layout_width=\"match_parent\" android:layout_height=\"240dp\" android:layout_alignParentTop=\"true\" android:scaleType=\"centerCrop\" /&gt; &lt;TextView android:id=\"@+id/news_title\" android:layout_width=\"match_parent\" android:layout_height=\"wrap_content\" android:layout_below=\"@id/news_photo\" android:gravity=\"center\" android:maxLines=\"1\" android:padding=\"5dp\" android:textColor=\"#ffffff\" android:textSize=\"20sp\" /&gt; &lt;/RelativeLayout&gt; &lt;/android.support.v7.widget.CardView&gt;&lt;/LinearLayout&gt; 以上布局为一个 CardView 里面有一个 ImageView 和 TextView 创建 Adapter 类当 RecyclerView 需要显示内容的时候，它首先会去找 Adapter 问应该显示哪些 items ，然后 RecyclerView 要求 Adapter 创建 ViewHolder 对象。 具体来说，Adapter主要做以下几件事: 为每个 RecyclerView 项目创建 ViewHolder 对象。 将数据来源的数据与每个项目绑定 返回数据来源中的项目数量 扩展将显示的每个项目视图 Adapter 类需要我们重写三个方法： onCreateViewHolder()：ViewHolder将被创建的时候调用，负责从xml中映射并创建View，并返回一个 ViewHolder 对象。 onBindViewHolder()：数据源与View进行绑定的时候调用 getItemCount()：返回计数器表示第几个 item 在写这三个方法前，我们先定义一个内部类作为 ViewHolder： ViewHolder 的作用是将 xml 中的内容映射成 View 对象，它决定如何显示单个item。 ViewHolder 将在 onCreateViewHolder()方法中被实例化。之后，在 onBindViewHolder() 方法中填充每个项的数据。 1234567891011121314151617// 自定义 ViewHolder 类static class NewsViewHolder extends RecyclerView.ViewHolder{ CardView cardView; ImageView newsImage; TextView newsTitle; // 构造器 NewsViewHolder(final View itemView){ super(itemView); cardView = itemView.findViewById(R.id.card_view); newsImage = itemView.findViewById(R.id.news_photo); newsTitle = itemView.findViewById(R.id.news_title); // 设置标题背景为半透明 newsTitle.setBackgroundColor(Color.argb(20, 0, 0, 0)); }} 然后重写 Adapter 的三个方法 1234567891011121314151617181920212223242526272829303132333435public class NewsAdapter extends RecyclerView.Adapter&lt;NewsAdapter.NewsViewHolder&gt; { private List&lt;News&gt; newsList; private Context context; // 构造器 NewsAdapter(List&lt;News&gt; newsList, Context context) { this.newsList = newsList; this.context = context; } // 自定义 ViewHolder 类 // 代码在上面 // 此处省略 @NonNull @Override public NewsViewHolder onCreateViewHolder(@NonNull ViewGroup parent, int viewType) { View v = LayoutInflater.from(context).inflate(R.layout.news_item, parent, false); return new NewsViewHolder(v); } @Override public void onBindViewHolder(@NonNull NewsViewHolder holder, int position) { News oneNews = newsList.get(position); holder.newsTitle.setText(oneNews.getTitle()); Glide.with(context).load(\"https://jerrysheh.github.io/images/Learn_Android/Android.jpg\").into(holder.newsImage); } @Override public int getItemCount() { return newsList.size(); }} LayoutManagerViewHolder 决定如何显示单个 item， 而 LayoutManager 则决定如何显示一堆 item。包括以下三种方式： LayoutManager 同时负责回收不再需要的 view。 MainActivity.java 1234567891011121314151617181920212223242526272829303132public class MainActivity extends AppCompatActivity { NewsAdapter mAdapter; RecyclerView mRecyclerView; List&lt;News&gt; newsList; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); newsList = new ArrayList&lt;&gt;(); String url = \"https://jerrysheh.github.io/images/Learn_Android/Android.jpg\"; for (int i = 1; i &lt; 11; i++) { newsList.add(new News(String.valueOf(i), url)); } mRecyclerView = findViewById(R.id.news_recycler_view); // 实例化一个 LinearLayoutManager LinearLayoutManager layoutManager = new LinearLayoutManager(this); // 实例化一个 Adapter mAdapter = new NewsAdapter(newsList, this); mRecyclerView.setLayoutManager(layoutManager); mRecyclerView.setHasFixedSize(true); mRecyclerView.setAdapter(mAdapter); }} 实现点击事件 其实可以在 RecyclerView 里嵌套 CardView， CardView 自带点击事件，就可以不用自己实现了。 Adapter类添加点击监听接口在我们的 Adapter 中加入一个内部接口，然后定义一个 ListItemClickListener 点击监听器 12345final private ListItemClickListener mOnClickListener;public interface ListItemClickListener { void onListItemClick(int clickedItemIndex);} 修改Adapter构造函数修改 Adapter 类的构造函数，添加第二个参数（ListItemClickListener类型的监听器listener） 12345public GreenAdapter(int numberOfItems, ListItemClickListener listener) { mNumberItems = numberOfItems; mOnClickListener = listener; viewHolderCount = 0;} ViewHolder内部类实现点击监听接口 用 implements OnClickListener 语句实现接口 重写点击方法 ViewHolder的构造函数中调用点击方法 123456789101112131415161718192021222324252627//implements 监听接口class NumberViewHolder extends RecyclerView.ViewHolder implements OnClickListener { TextView listItemNumberView; TextView viewHolderIndex; public NumberViewHolder(View itemView) { super(itemView); listItemNumberView = (TextView) itemView.findViewById(R.id.tv_item_number); viewHolderIndex = (TextView) itemView.findViewById(R.id.tv_view_holder_instance); //调用点击方法 itemView.setOnClickListener(this); } void bind(int listIndex) { listItemNumberView.setText(String.valueOf(listIndex)); } //重写点击方法 @Override public void onClick(View v) { int clickedPosition = getAdapterPosition(); mOnClickListener.onListItemClick(clickedPosition); }} MainActivity.java implements GreenAdapter.ListItemClickListener 重写按钮监听方法 实例化 Adapter 的时候传入 this 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class MainActivity extends AppCompatActivity implements GreenAdapter.ListItemClickListener { private static final int NUM_LIST_ITEMS = 100; private GreenAdapter mAdapter; private RecyclerView mNumbersList; private Toast mToast; @Override protected void onCreate(Bundle savedInstanceState) { super.onCreate(savedInstanceState); setContentView(R.layout.activity_main); mNumbersList = (RecyclerView) findViewById(R.id.rv_numbers); LinearLayoutManager layoutManager = new LinearLayoutManager(this); mNumbersList.setLayoutManager(layoutManager); mNumbersList.setHasFixedSize(true); // 用this传入监听器 mAdapter = new GreenAdapter(NUM_LIST_ITEMS, this); mNumbersList.setAdapter(mAdapter); } @Override public boolean onCreateOptionsMenu(Menu menu) { getMenuInflater().inflate(R.menu.main, menu); return true; } @Override public boolean onOptionsItemSelected(MenuItem item) { int itemId = item.getItemId(); switch (itemId) { case R.id.action_refresh: mAdapter = new GreenAdapter(NUM_LIST_ITEMS, this); mNumbersList.setAdapter(mAdapter); return true; } return super.onOptionsItemSelected(item); } // 重写按钮监听方法 @Override public void onListItemClick(int clickedItemIndex) { if (mToast != null) { mToast.cancel(); } String toastMessage = \"Item #\" + clickedItemIndex + \" clicked.\"; mToast = Toast.makeText(this, toastMessage, Toast.LENGTH_LONG); mToast.show(); }","link":"/post/37cb0c4f.html"},{"title":"推荐系统漫游","text":"参考教程： Part I: Building the recommender Part II: Building and running the web service 厦门大学数据库实验室 参考书籍： 大数据技术原理与应用 林子雨（人民邮电出版社） 参考链接： Spark 官方文档- Collaborative Filtering Github项目 - An on-line movie recommender using Spark, Python Flask, and the MovieLens dataset 在线图书推荐系统的实现（协同过滤） Github项目 - spark-book-recommender-system 常用的推荐算法基于人口统计学的推荐(Demographic-Based Recommendation) 基本假设（underlying assumption）：一个用户有可能会喜欢与其相似的用户所喜欢的Item 当我们需要对一个User进行个性化推荐时，利用User Profile计算其它用户与其之间的相似度，然后挑选出与其最相似的前K个用户，之后利用这些用户的购买和打分信息进行推荐。 基于内容的推荐(Content-Based Recommendation) 基本假设：一个用户可能会喜欢和他曾经喜欢过的Item相似的Item 比如你看了哈利波特I，基于内容的推荐算法发现哈利波特II-VI与你以前观看的在内容上面（共有很多关键词）有很大关联性，就把后者推荐给你。 基于内容的推荐引入了关于item的内容信息，来计算item与item之间的相似度。但跟用户历史行为无关。 优点：可以避免Item的冷启动问题 缺点：缺点一：推荐的Item可能会重复。典型例子：新闻。如果你看了一则关于MH370的新闻，很可能推荐的新闻和你浏览过的内容一致。缺点二：多媒体的推荐（音乐、电影、图片等)由于很难提内容特征，则很难进行推荐，一种解决方式则是人工给这些Item打标签。但是费时费力。 冷启动：如果一个Item从没有被关注过，其他推荐算法则很少会去推荐，但是基于内容的推荐算法可以分析Item之间的关系，实现推荐。 协同过滤的推荐（Collaborative Filtering Recommendation） 基本假设：用户A 和 用户B 如果对某些商品持有相同的观点，那么 用户A 跟 用户B 对 另一些商品 的观点会更接近。 协同过滤是指收集用户过去的行为以获得其对产品的显式或隐式信息。根据用户对物品或者信息的偏好，发现物品或者内容本身的相关性、或者 用户的相关性，然后再基于这些关联性进行推荐。 基于协同过滤的推荐可以分为以下几个子类： 基于用户的协同过滤推荐（User-based Recommendation）通过用户的行为信息，计算用户与用户之间的相似度。比如你跟你的朋友喜好类似，系统认为你们相似度高，如果你的朋友喜欢电影哈利波特I，那么就会推荐给你，这是最简单的基于用户的协同过滤算法。 基于物品的协同过滤推荐（Item-based Recommendation）喜欢Item A 的用户，其可能也会喜欢与Item A相似的Item B。 相似度的计算是基于历史行为信息，计算每两个item之间的相似度（比如有多少人喜欢A，有多少人喜欢B，有多少人既喜欢A又喜欢B，A和B的相似度，就可以计算为共同喜欢A和B的用户个数除以喜欢A或喜欢B的总用户数） 我们可以简单比较下基于用户的协同过滤和基于项目的协同过滤：基于用户的协同过滤需要在线找用户和用户之间的相似度关系，计算复杂度肯定会比基于基于项目的协同过滤高。但是可以帮助用户找到新类别的有惊喜的物品。而基于项目的协同过滤，由于考虑的物品的相似性一段时间不会改变，因此可以很容易的离线计算，准确度一般也可以接受，但是推荐的多样性来说，就很难带给用户惊喜了。一般对于小型的推荐系统来说，基于项目的协同过滤肯定是主流。但是如果是大型的推荐系统来说，则可以考虑基于用户的协同过滤,当然更加可以考虑第三种类型，基于模型的协同过滤。 协同过滤和基于人口统计、基于内容推荐的区别 基于模型的协同过滤推荐（Model-based Recommendation）基于模型的协同过滤推荐就是基于样本的用户喜好信息，训练一个推荐模型，然后根据实时的用户喜好的信息进行预测，计算推荐。 比如说，有m个物品，n个用户的数据，只有部分用户和部分数据之间是有评分数据的，其它部分评分是空白，此时我们要用已有的部分稀疏数据来预测那些空白的物品和数据之间的评分关系，找到最高评分的物品推荐给用户。 对于这个问题，用机器学习的思想来建模解决，主流的方法可以分为：用关联算法，聚类算法，分类算法，回归算法，矩阵分解，神经网络,图模型以及隐语义模型来解决。这种方法训练过程比较长，但是训练完成后，推荐过程比较快。 基于模型协同过滤的推荐机制是现今应用最为广泛的推荐机制。 优点： 它不需要对物品或者用户进行严格的建模，而且不要求物品的描述是机器可理解的，所以这种方法也是领域无关的。 这种方法计算出来的推荐是开放的，可以共用他人的经验，很好的支持用户发现潜在的兴趣偏好 缺点： 方法的核心是基于历史数据，所以对新物品和新用户都有“冷启动”的问题。 推荐的效果依赖于用户历史偏好数据的多少和准确性。 在大部分的实现中，用户历史偏好是用稀疏矩阵进行存储的，而稀疏矩阵上的计算有些明显的问题，包括可能少部分人的错误偏好会对推荐的准确度有很大的影响等等。 对于一些特殊品味的用户不能给予很好的推荐。 由于以历史数据为基础，抓取和建模用户的偏好后，很难修改或者根据用户的使用演变，从而导致这个方法不够灵活。 补充协同过滤的本质是对用户喜好进行预测，其思想是根据邻居用户(与目标用户兴趣相似的用户)的偏好信息，计算出某用户对某商品的感兴趣度。 如果我们用一个用户-产品矩阵来描述用户对产品的喜好程度，那么协同过滤算法的目标就是填充缺失的元素，如下图所示。（These techniques aim to fill in the missing entries of a user-item association matrix） Spark.ml库中的推荐算法spark.ml 库支持基于模型的协同过滤推荐推荐算法，其中用户和商品通过一小组隐语义因子(latent factors)进行表达，并且这些因子也用于预测缺失的元素。spark.ml库使用 ALS算法来学习这些隐性语义因子。 交替最小二乘法（ALS）交替最小二乘法 (Alternating Least Squares，ALS)常用于基于矩阵分解的推荐系统中。 例如：将用户(user)对商品(item)的评分矩阵分解为两个矩阵： 一个是用户对商品隐含特征的偏好矩阵 另一个是商品所包含的隐含特征的矩阵。 在这个矩阵分解的过程中，评分缺失项得到了填充，也就是说我们可以基于这个填充的评分来给用户做商品推荐了。 隐性反馈（implicit feedback）和显性反馈（explicit feedback）基于矩阵分解的协同过滤的标准方法一般将用户商品矩阵中的元素作为用户对商品的显性偏好。在许多的现实生活中的很多场景中，我们常常只能接触到隐性的反馈（例如游览，点击，购买，喜欢，分享等等） 在 MLlib 中所用到的处理这种数据的方法来源于文献： Collaborative Filtering for Implicit Feedback Datasets。 本质上，这个方法将数据作为二元偏好值和偏好强度的一个结合，而不是对评分矩阵直接进行建模。因此，评价就不是与用户对商品的显性评分而是和所观察到的用户偏好强度关联了起来。然后，这个模型将尝试找到隐语义因子来预估一个用户对一个商品的偏好。 使用关联规则做预测在 Spark.ml 中，还有一种 Frequent Pattern Mining （FPM） 算法，这种算法用来计算物品之间的关联性。称为关联规则（Association Rule）。 参考：Spark官方文档 - Frequent Pattern Mining","link":"/post/8bda90b5.html"},{"title":"C&#x2F;C++语言中的指针","text":"这几天在接触一些C语言的项目，发现自己对C语言，包括C++的知识理解不透彻，尤其是指针。导致项目完全看不懂。因此这一篇就来补补C/C++中指针的知识。 参考书籍《C++ Primer》 指针简单比喻什么是指针，假如你住5楼503号房间。那么有一张纸条，纸条上写着5楼503。那么，我们就说这张纸条就是指向你房间的一个指针。 定义指针（Pointer）是指向（Point to）另外一种类型的复合类型。 指针有两个特点： 本身是一个对象，允许对指针进行赋值和拷贝，而且在指针的生命周期内可以先后指向几个不同的对象。 无须在定义时赋初始值 一个简单例子12345678910#include &lt;stdio.h&gt;int main() { int ival = 42; int *p = &amp;ival; printf(&quot;p是一个指针，P为%p\\n&quot;,p); printf(&quot;*p是指针指向的变量，*p为%d\\n&quot;,*p); return 0;} 输出 12p是一个指针，P为0x7ffe09031b1c*p是指针指向的变量，*p为42 在这个例子中，我们用 int *p来定义指针，这时候p是一个指针。&amp;ival的意思是取int型变量ival的地址。 而在输出的时候，*p是指针指向的变量，也就是说，*号在这里成了解引用符号。仅在指针确实指向了某个对象，即指针确实有效的情况下，*p才适用。 理解的关键：在定义阶段， 用int *p用来定义指针。在操作阶段，*p是解引用。 空指针123int *p1 = nullptr; // only C++11int *p2 = 0; // okint *p3 = NULL; // include cstdlib 第一种方法仅在C++11中可用，也是C++编程中最推荐的；第二种是最常见的，直接给指针赋值0，即是空指针；第三种 NULL 在 cstdlib 中定义，其实 NULL 的值就是0； 假设p是一个指针，那么以下做法是错误的，即使zero等于0： 12int zero = 0;p = zero; 一个编程建议是，指针一定要初始化，最好是先有对象（变量），然后再去定义指向这个对象的指针。假设真的要在定义对象前定义指针，不知道让它指向哪里，那就初始化为0或者nullptr。不要让它悬空。 赋值有时候我们会搞混究竟是改变了指针本身，还是改变了指针指向的对象。一个好方法是，改变的永远是等号左边的。 12pi = &amp;val; // 指针指向了val的地址*pi = 0; // 指针没变，但是指针指向的对象值变为0了 void* 指针1234567double mynum = 3.66;double *pd = &amp;mynum; // pa指向mynumint mynum2 = 9;void *pv = &amp;mynum2; // pv指向mynum2pv = &amp;mynum1; // pv现在又指向mynum1了 从上面的例子可以看到， void *型指针跟普通指针也没什么区别。但是，void *指针可以指向任何类型。当然，它不能用于操作指针所指的对象，因为我们不知道这个对象的类型（void *一会儿可指向int型变量的地址，一会儿可以指向double型） 指向指针的指针12345678910111213#include &lt;stdio.h&gt;int main() { int val = 1024; // 一个int int *pi = &amp;val; // 一个指向val的指针 int **ppi = &amp;pi; // 一个指向pi的指针 printf(&quot;1) val是一个int，值为%d\\n\\n&quot;, val); printf(&quot;2) pi是一个指向int的指针，pi为%p\\n\\n&quot;,pi); printf(&quot;3) ppi是一个指向指针的指针，ppi为%p\\n&quot;,ppi); printf(&quot;4) *ppi其实就是 2) 中的pi,*ppi为%p&quot;,*ppi); return 0;} 不要被**ppi 吓到了，其实它就是指向了pi这个对象。只不过恰好pi这个对象也是一个指针罢了。 输出： 1234561) val是一个int，值为10242) pi是一个指向int的指针，pi为0x7ffc86a9d6b43) ppi是一个指向指针的指针，ppi为0x7ffc86a9d6b84) *ppi其实就是 2) 中的pi,*ppi为0x7ffc86a9d6b4 可以看到， *ppi其实就是pi，他们都是0x7ffc86a9d6b4 指向常量的指针C语言中的const限定了对象不能被改变，一把用来表示常量。相当于 java 的 final。 而指向常量的指针（point to const），不能用于改变其所指对象的值。point to const一般用来存放常量的地址。 有一点值得注意，允许一个指向常量的指针指向非常量，但是却不能通过这个指针操作这个非常量。 12345const double d = 3.33;const double *pd = &amp;d;double x = 6.66;pd = &amp;x; // ok，但是不能通过pd去改变 x 的值 常量指针指针是对象，跟int、double等一样，所以可以用 const int来表示常量， 那当然也可以用 *const int来表示常量指针啦。 只是，一旦定义了*const int，那这个指针必须初始化，且只能指向初始化的这个地方，不能再改变了。 注意下面的定义 123int i = 6;int *const p1 = &amp;i; //常量指针，不能改变p1所指的对象const int *p2 = &amp;i p-&gt;mem 是什么意思有时候我们会看到 p-&gt;mem 这种用法，实际上它等价于 (*p).mem。 123456789101112131415161718192021#include &lt;stdio.h&gt;int main() { typedef struct { int x; int y; } Point; Point pos; pos.x = 10; pos.y = 5; printf(&quot;answer1:%d\\n&quot;, pos.x * pos.y); Point* pPos = &amp;pos; (*pPos).x = 15; pPos-&gt;y = 20; printf(&quot;answer2:%d\\n&quot;, pos.x * pos.y);} 输出 12answer1:50answer2:300 首先定义了一个Point结构体，包含 int 类型的 x, y。然后实例化· 我们当然可以用pos.x = 10，pos.y = 5这样的方式来给结构体的每个变量赋值。 但有时候我们要用指针操作对象，我们可以先定义一个Point *类型的指针pPos。 然后查看两种用指针间接给结构体赋值的方法： (*pPos).x = 15; pPos-&gt;y = 20; 第一种是先将指针 pPos 解引用，让它变成指向的对象（pos）， 然后用 对象.成员 的方式来赋值。第二种直接在指针pPos上操作，也就是用-&gt;来表示，对指针指向的结构体对象（pos）的某个成员(y)进行操作。 换言之， . 直接成员访问操作符，但操作前需对指针解引用 -&gt; 间接成员访问操作符 实质上两种方式是等价的。 结构体和指针定义结构体在C语言中，我们可以这样定义结构体： 1234567891011121314151617//方法一：struct student{ short age; char name[MAXNAME]; long phoneNumber;};struct student s1; // s1是student类型的一个实例//方法二：typedef struct student{ short age; char name[MAXNAME]; long phoneNumber;}STUDENT;STUDENT s2; // s2是student类型的一个实例 可见，用方法二比较方便一点。 用指针访问结构体成员1234567891011typedef struct{ short age; char name[MAXNAME]; long phoneNumber;}STUDENT;STUDENT s2; // s2是student类型的一个实例student *ps = &amp;s2;ps-&gt;age = 6;printf(&quot;%d\\n&quot;,s2.age); 如果要给结构体的 name[MAXNAME] 赋值，下面的做法是错误的 1ps-&gt;name = \"jerry\"; 应该用strcpy函数。 123char *name = &quot;jerry&quot;;strcpy(ps-&gt;name, name);printf(&quot;%s\\n&quot;,stu1.name); 结构体偏移量问题假设现在有一个结构体 12345struct fun{ int a; int b; char c;}; 我们已知道结构体成员 c 的地址，如何求结构体的起始地址呢？ 答案就是：(char *) &amp; ((struct fun*)0)-&gt;c 123456789101112131415int main(){ //实例化一个结构体变量 struct fun domain; //结构体起始地址 printf(&quot;iic:%u\\n&quot;,&amp;domain); //结构体成员 c 的地址 printf(&quot;char c:%u\\n&quot;, &amp;(domain.c)); //偏移量 printf(&quot;sub: %d\\n\\n&quot;, (char *) &amp; ((struct fun*)0)-&gt;c); return 0;} 输出： 1234jerrysheh@ubuntu:~$ ./funfun:-1838605600char c:-1838605592sub: 8 链表和指针定义一个链表 12345//定义链表中的节点 typedef struct node{ int data; //链表中的数据 struct node * p_next;//指向下一节点的指针 }Node,*pNode; 顺序遍历链表 1234567void TraverseList(pNode h){ pNode p = h-&gt;p_next; while(p!=NULL){ printf(\"%d\\n\",p-&gt;data); p = p-&gt;p_next; } }","link":"/post/82d9a37c.html"},{"title":"Crash Course Computer Science（11-20）","text":"P11 编程语言发展史一条计算机指令，00101110，前四位是操作码，表示 LOAD_A（把值从内存复制到寄存器A），后四位是内存地址14，简写为 LOAD_A 14，意思是，读内存地址14，复制到寄存器A。计算机只认识二进制数，用二进制指令编写的程序称为 机器语言。早期人们编程的方式，是先在纸上写英文版的程序，再根据操作码表制作成二进制码的纸带，丢到计算机去处理。像这样，对计算机程序进行高层次的描述称为 伪代码。 与其用机器码编写程序，为什么我们不直接写 LOAD_A 14 来表示 00101110，而中间翻译的部分交给机器去做呢？于是程序员发明了一种能将像 LOAD_A 14 这样的文字指令翻译成 00101110 这样的二进制指令的程序，叫做 汇编器（assembler）。用像 LOAD_A 14 这样的文字指令编写的程序，叫做 汇编语言。 1940-1950年代，一名美国海军军官，也是哈佛1号计算机的设计者 Hopper，她想到能否把一条自然语句翻译成多条汇编指令或机器指令，于是设计了一种机器叫做 编译器（compiler），专门把高级语言转换成低级语言。在高级语言里，我们用 变量 来抽象内存地址和值，程序员不必了解底层细节，从此，编程开始变得简单起来。 Hopper 一开始发明了一种 A-0 高级语言，但没有流行开来，反倒是1957年IBM发明的 FORTRAN 主宰了早期的计算机编程，但只能运行在IBM的机器上，再后来出现了所有机器都可运行的 COBLE，再后来出现了我们熟悉的C、C++、Objective-C、Python、Java、Golang等高级语言。 FORTRAN 项目总监 John Backus： 我做的大部分工作是因为懒，我不喜欢写程序，所以我写这门语言，让编程更容易。 P12 编程原理 - 语句和函数a = 5 这是高级语言 Python 中的语句，意思是把值5赋给变量a，这叫做 赋值语句，也是初始化语句。if 、while 和 for 是常见的 控制流语句，表示条件判断和循环。高级编程语言都是通过特定的语句和语法组织起来的，跟英语、中文等自然语言没有本质不同。 当程序中有一部分代码在很多地方都要重复使用时，我们可以把它抽出来作为 函数。函数有参数和返回值，任何调用它的地方都能执行这段代码。下面是 Python 计算一个数的平方的函数： 12def pow(x): return x*x; 函数有助于模块化编程，帮助团队协作写出大型的程序。现代编程语言中，很多语言已经提前写好了一些常用的函数集合，叫做 库(libraries)。 P13 算法入门解决问题的步骤，称为 算法。不同的算法可能得出相同的结果，但有些效率更高。 排序和算法的复杂度排序 是一种常见的算法需求，选择排序 是一种最简单的排序算法。其思想是，从第一个数开始，找到数组中最小的一个数，跟第一个数交换，然后从第二个数开始，找到数组剩下的数字中最小的一个，跟第二个数交换，以此类推。下面是 Python 选择排序的实现： 1234567def select_sort(arr): for i in range(0, len(arr)): min = i for j in range(i, len(arr)): if arr[j] &lt; arr[min]: min = j arr[min], arr[i] = arr[i], arr[min] 可以看到，选择排序用了两个 for 循环，如果循环一次需要 n 个步骤，那么两个 for 循环大概需要 n * n 个步骤。 算法的输入大小和运行步骤之间的关系，叫做算法的复杂度。计算机科学家把算法复杂度描述为 大O表示法。需要 n * n 个步骤的算法，记为 O(n*n)。如果一个步骤需要1秒，当 n 为 8，这个算法需要 8 * 8 = 64 秒，当 n 为 80 ，这个算法需要 80 * 80 = 6400 秒，n增大了10倍，时间却增加了100倍，可见 O(n*n) 是呈指数级增长的，是一种效率很低的算法。 一种效率比较高的排序算法是 归并排序。它通过分治的思想，把一个大数组一分为二，分开的两个小数组又分别再一分为二，一直分到每个小数组都只有两个元素，排完序，再向上归并起来。这种算法的复杂度为 O(n*logn)，n是需要比较的次数，logn是合并步骤的次数，例如，在有8个元素的数组中，有8个数需要比较，所以n是8，从2合并到4再合并到8，需要3次，也就是 log8=3。 O(n*logn) 呈对数级增长，效率比较高。 图搜索图搜索是另一种算法，图是一种用线连起来的一堆节点，从一个节点到另一个节点有不同的成本，称为 权重。如何用最少的成本，从一个节点到达另一个不相邻的节点呢？最简单粗暴的方法是把所有可能的走法都列出来，但这样的复杂度是 O(n!)，比 O(n*n) 还糟糕。解决这个问题的一个经典算法是一位理论计算机科学家 Edsger Dijkstra 发明的，因此称为 Dijkstra 算法，他会从开始节点向相邻节点走，并记录每个节点的成本，到达下一个节点后，再继续向相邻的节点走，记录第一步跟第二步的成本和，一直到目标节点，找出成本最小的一条路径。 P14 数据结构算法处理的是数据，然而在内存中，数据有多种存法。数据结构化存储的方式，称为 数据结构。 数组一种简单的数据结构是 数组（array），或者叫向量（vecror）、列表（list）。定义数组时，需要先申请固定的内存空间，数据在内存中是连续存储的，通过下标（index）来获取对应的值。字符串本质上是字符数组，其最后一位是 zero，表示字符串结束。如果数组里面的每一个元素也都是数组，这样的数组称为 二维数组 或 矩阵（matrix）。因为数组在内存中连续存储，所以遍历很快，但从中间插入元素需要把后面的元素都相应地往后移动，因此插入效率不高，而且，数组的容量是事先定义好的，不能动态扩容。 结构体把不同的数据类型打包在一起，叫做一个 结构体(struct)，例如要表示坐标，需要 x 和 y，就可以把它定义成一个 Point 结构体： 1234typedef struct { int x; int y;} Point; 链表一种很有用的结构体叫做 节点（node），节点包含一个变量值，以及指向下一个值的指针。 1234struct node{ var i; pointer next;} 一个节点有一个指针指向另一个节点，这样的数据结构叫做 链表（linked list），链表在内存中是不连续的，通过指针来指向下一个元素的位置，所以插入很快，但遍历比较慢，跟数组相反。链表理论上可以存无限节点，无需事先申请一片固定的内存区域。 栈和队列栈(stack)和队列(queue)通常用链表来实现，当然也可以用数组。栈是一种后进先出（LIFO）的数据结构，而队列是先进先出（FIFO）的，跟栈相反。 树和图链表只指向下一个节点（双向链表除外），如果我们在节点中再加多一个指针，像这样一个节点指向两个子节点的数据结构，叫做 二叉树。当然，我们也可以指向多个子节点，但前提是节点之间有固定方向，这叫做 树。树是一种很有用的数据结构，可以用在文件系统中，或者大规模数据的索引。著名的开源数据库MySQL的默认引擎InnoDB就是用二叉搜索树（B+树）作为索引的。 12345struct node{ var i; pointer left_child; pointer right_child;} 如果节点可以有任意个指向其他节点的指针，且方向不受约束，那这个数据结构叫做 图。上面提到的图搜索算法就需要用到图结构。 P15 艾伦·图灵艾伦·图灵被誉为计算机科学之父，1912年出生于英国伦敦。他在剑桥读硕士期间，开始解决一个“可判定性问题”——是否存在一种算法，输入正式逻辑语句，输出准确的是或否。1935年美国数学家丘奇发明了 lambda算子 的数学表达系统，证明了这样的算法不存在，但其中的数学技巧太过于难理解。与此同时，图灵自己想了一种方法来解决这个问题，他提出了一种我们现在叫 图灵机 的假想计算机。包含了读写端、规则、状态和处理。他证明了这种计算机如果有足够的时间和内存，就可以执行任何的计算，这种强大之处称为 图灵完备。他利用图灵机模拟了 停机问题，证明了并不是所有的问题都可以用计算来解决。 丘奇和图灵证明了计算是有极限的，不是所有的问题都可以通过计算机来解决。1936-1938年，图灵在丘奇的指导下完成了博士学习，后来回到英国，1939年英国卷入第二次世界大战，图灵一直致力于破译德军密码的工作。战后，图灵回到学术界为许多早期计算机工作做出贡献，包括人工智能。1950年，图灵设想未来的计算机会跟人类难以区分，如果计算机能欺骗人类让人类以为计算机是人类，那才叫智能。这种测试，现在叫做 图灵测试，一个例子就是网页上的验证码。 1952年，图灵因性取向问题被当局认定为态度不端，强制他接受激素压制性欲，然而激素影响了他的性格和情绪，1954年图灵服毒自杀，年仅41岁。后人为了纪念他，很多东西以他的名字命名，包括计算机科学的“诺贝尔奖”——图灵奖。 P16 软件工程面向对象微软的 Office 软件大约有4000万行代码，20多万个函数，需要一整个部门合作完成。如何高效协作完成大型软件即是 软件工程（Software Engineering） 要考虑的问题。我们知道，代码块可以封装成函数，事实上，若干相关的函数还可以封装成 对象（Object），对象也是可以复用的。对象与对象之间可以有父子继承关系。像这样，将函数和变量打包成对象的思想，叫做 面向对象编程（Object-Oriented Programming）。 API在软件工程中，不同的模块由不同的团队完成，他们需要约定相同的接口，叫做 程序编程接口（API）。API控制哪些函数让外部使用，哪些只能内部使用。在面向对象编程中，函数可以指定 private、public 等访问权限。 IDE无论大型还是小型的软件，在编译前都只是一堆文字而已，你当然可以用记事本来写这些代码。然而，现代程序员基本上都会用专门的开发工具，封装了编辑器、调试、运行等等工具集的软件，叫做 集成开发环境（IDE）。 文档软件还需要写文档来说明软件的用途和用法，一般文档都会写在一个叫做 README.MD 的文件里。当然，也可以直接写在源代码里，大部分语言用 // 或 /**/ 作为注释标记。 版本控制合作开发的项目，会把代码放在代码仓库里，程序员想改其中的一段，需要先 checkout ，然后进行修改、测试，改完之后，再提交（ commit）回代码仓库。源代码管理软件还会记录是谁改动了代码，如果有bug还可以回滚到之前的版本。 测试编码与测试密不可分，测试可以统称为 质量保证测试（QA），主要是找 bugs。测试对确保软件质量至关重要。beta版本的软件意思是软件接近完成，但没有100%完全测试，而alpha版本的软件通常未经测试，可能存在较多 bugs。而 release 版，即是稳定发布版本了。 P17 集成电路&amp;摩尔定律软件的快速发展依赖于硬件的进步。早期计算机都是把独立元件用电线连接起来（想象一堆晶体管和成千上万条电线），随着复杂性的提高，计算机变得越来越庞大。与其如此，为何不把多个组件封装在一起，成为一个新的组件呢？于是，集成电路（Integrated Circuits, CI） 诞生了。1959年仙童半导体公司的 Noyce 使用硅来做集成电路，开创了电子时代，创造了 硅谷。之后，工程师们又发明了 印刷电路板(PCB)，器件变得更小、更便宜、更可靠。然而在微小的器件上连接电路是一件很难的事情，于是又有了 光刻 技术，光刻操作简单，又能制作出复杂的电路。 光刻的发展使晶体管变小，密度变高，1965年，戈登·摩尔看到了趋势：每18个月集成电路里面同样的空间能塞下的晶体管数量就会翻一倍。这就是 摩尔定律。1968年，诺伊斯和摩尔成立了一家新公司—— Intel（英特尔），如今已经成为世界上最大的芯片制造商。 50多年来，摩尔定律一直没有被打破，然而集成电路的精度已经快到达极限了，加上晶体管非常小，电极之间可能出现量子隧穿效应，这对集成电路的发展又提出了新的挑战。 P18 操作系统操作系统（Operating System，OS） 也是一种程序，它具有操作硬件的权限，并且可以运行和管理其他程序。最开始，计算机一次只能运行一个软件，有了操作系统之后，可以让计算机一个接一个地运行软件，不用手工处理，这叫 批处理。早期的程序直接运行在硬件上，需要适配不同的机器，有了操作系统以后，操作系统提供统一的硬件抽象，叫 设备驱动程序，上层应用直接跟驱动打交道即可，屏蔽了底层硬件细节。 1962年，英国曼切斯特大学研发了一台超级计算机Atlas，拥有具备调度功能的操作系统。因为他们发现，程序的时间都耗费在IO上了，例如打印一份文档要5分钟，CPU可能1秒就执行完了，剩下的时间都只是在等待打印机结果，这段时间里，操作系统可以休眠这个程序，转而去运行其他程序，当打印机打印结束，再唤醒这个程序，继续后面的步骤。这样，多个任务共享单一的CPU，由操作系统来调度，这种能力叫 多任务处理。 有了多任务后，多个程序共享内存，操作系统会给每个程序分配独立的内存空间，但这样会带来碎片化的问题，解决办法是 虚拟内存。操作系统会在物理内存和虚拟内存之间做映射，好让程序以为它申请的内存是连续的。这种机制使得程序的内存可以动态增减，叫做 动态内存分配，同时也可以做 内存保护。 1970年代，计算机不仅可以多任务，还可以多用户，每个用户通过 终端 连接到计算机，为了防止某个用户占满计算机资源，每个用户只能使用小百分比的计算机资源，这叫 分时操作系统。早期分时操作系统中，最有影响力的是 Multics，但它被过度设计，系统本身占了一半以上的内存，于是，Multics 的开发者 Dennis 和 Ken Thompson 联手又打造了一个新的操作系统——Unix，Unix把系统分成了内核和工具两部分，使得核心功能大大精简，受到了很多人的欢迎，在80年代的PC中也逐渐流行开来。 后来操作系统逐渐发展，出现了像 Windows、Mac、Android、iOS 等我们熟悉的现代操作系统。 P19 内存&amp;存储介质内存(memory) 是易失性(volatile)的，断电数据即丢，存储(storage) 是非易失性(non-volatile)的，断电数据还在。 最早是用纸带和纸卡来存储临时数据，然而纸带打孔无法复原。工程师建造 ENIAC 时发明了延迟线存储器来存储数据。原理是在水银管一头接扬声器，声波在水银管中变成压力波，有波表示1，否则表示0，另一头接麦克风把声波转回电信号，再用电线首尾相连形成闭环。延迟线存储器一次只能读取一位，而且是顺序读取的，所以又叫 顺序存储器。 然而我们想要的是可以随时访问任意位置的存储器，即 随机存取存储器（random access memory，RAM）。1950年代，磁芯存储器 被发明，通过控制电流方向来反转磁性，从而存储1和0，很多磁芯圈串起来形成阵列，即可存储很多位，而且能随时访问任意位置。 后来又出现了更便宜、占空间更小的磁带，以及磁盘。磁盘由于很薄，可以把多个磁盘堆叠，磁头会上下滑动找到正确的盘再伸进去读数据。磁头找到正确的数据所用的时间叫做 寻道时间。软件和硬盘都是基于磁盘的原理制造出来的，在此就不再展开。值得一提的是，还有一种叫做光盘，也就是我们熟悉的CD、DVD，它的原理则不是磁性，而是通过挖坑造成光的反射不同来读取数据。 进入现代，内存和存储正朝着 固态（solid） 发展，固态是集成电路，而非机械结构，速度更快，体积更小，性能更好。 P20 文件系统数据在内存或硬盘中是按一定格式存储的。最简单的文件格式是 .txt 文本格式，本质上是一堆二进制数，翻译成十进制数就是ASCII编码，ASCII编码映射成英文字符，呈现在屏幕上。.wav是存储音频格式的文件，也叫波形（wave）文件，文件开头会有一些 元数据，叫做文件头，记录了声音的码率、单声道或立体声等内容。存储图片（位图（bitmap））的文件格式是 .bmp，它也有元数据记录图像宽度、高度、颜色深度等，数据部分每3个字节记录RGB值，表示一个像素点。 为了存储多个文件，我们用 目录(directory) 来装载其他文件，目录本身也是一种特殊的文件。不仅仅存数据文件，还存了他们的元信息（创建时间、文件大小、长度等）。把文件目录化，以及管理所有目录和文件，就是 文件系统（file system）。现在的文件系统会把文件分成多个块，每个块预留一定空间以防文件增大，如果预留的也不够了，会在其它块里划分空间继续存这个文件。长此以往导致的结果是 文件碎片，可以用文件系统的碎片整理功能来解决。 文件删除只需要删除目录记录的元信息即可，数据本身不会被删除，直至被其他文件的数据覆盖。而文件移动，也只是在一个目录下删除元信息，在另一个目录下添加该元信息，数据本身并没有移动。","link":"/post/20575023.html"},{"title":"Android笔记（六） 运行时权限和内容提供器","text":"什么是Content Provider ?内容提供器（Content Provider）主要用于在不同的应用程序之间实现数据共享。它提供一套机制，允许在数据安全的条件下，让一个程序访问另一个程序的共享数据。比如，读取联系人app的电话号码数据等。 Content Provider可选择只对哪一部分数据进行共享，从而保证隐私。 但是在谈Content Provider之前，先来谈谈 Android 的运行时权限（Runtime permissions）。 运行时权限（Runtime permissions）Android 6.0 之后，Android 系统的权限分为两类： 普通权限 危险权限 普通权限在 AndroidManifest.xml 文件里直接声明，如下： 123456&lt;manifest xmlns:android=\"http://schemas.android.com/apk/res/android\" package=\"com.jerrysheh.englishquickchecker\"&gt; &lt;uses-permission android:name=\"android.permission.ACCESS_NETWORK_STATE\"/&gt; &lt;uses-permission android:name=\"android.permission.ACCESS_WIFI_STATE\"/&gt; ...&lt;/manifest&gt; 危险权限则需要使用运行时权限（runtime permssions）。Android 6.0 引入了这个概念，简单地说，就是在应用程序运行的时候，由用户手动授权是否调用手机的某些数据（比如，麦克风、相机、电话）。 关于普通权限和危险权限的区别，以及分别有哪些权限，可以参考 Google 官方文档 申请运行时权限可以调用ContextCompat.checkSelfPermission()方法来检查是否有相应的权限，如果有返回 PackageManager.PERMISSION_GRANTED，并且应用可以继续操作。如果没有，返回 PERMISSION_DENIED，且应用必须明确向用户要求权限。 可以调用shouldShowRequestPermissionRationale()方法来向用户解释需要某些权限。如果用户第一次拒绝了权限，第二个需要这个权限的时候，该方法返回true。 可以调用requestPermissions()来申请权限。（此时系统会显示标准对话框让用户选择是否授权，我们无法更改） 可以重写onRequestPermissionsResult()方法来了解用户选择的结果。 开发模型： 1234567891011121314151617181920212223242526if (ContextCompat.checkSelfPermission(this, Manifest.permission.READ_CONTACTS) != PackageManager.PERMISSION_GRANTED) { // 没有权限。 if (ActivityCompat.shouldShowRequestPermissionRationale(this, Manifest.permission.READ_CONTACTS)) { // 用户拒绝过这个权限了，应该提示用户，为什么需要这个权限。 } else { // 申请授权。 ActivityCompat.requestPermissions(thisActivity, new String[]{Manifest.permission.READ_CONTACTS}, MMM); }}...@Overridepublic void onRequestPermissionsResult(int requestCode, String permissions[], int[] grantResults) { switch (requestCode) { case MMM: { if (grantResults.length &gt; 0 &amp;&amp; grantResults[0] == PackageManager.PERMISSION_GRANTED) { // 权限被用户同意，可以去放肆了。 } else { // 权限被用户拒绝了，洗洗睡吧。 } return; } }} 上述代码详细参考 Google 官方文档 可以看到，上面的逻辑还是比较复杂的。而且，由于OEM厂商会在定制ROM上各种改，导致权限获取不正常，以致出现各种各样的 bug。我本人就因为在一加5T上测试上面的代码时，点击了拒绝权限，但没有任何的 Toast 提示，白白浪费了4个小时的时间研究。后来用 AOSP 测试通过了，才发现是一加改了系统的权限通知框。 解决上述问题，推荐开源库：AndPermission 项目地址： https://github.com/yanzhenjie/AndPermission 使用方法可参考：Android 6.0 运行时权限管理最佳实践 访问其他程序中的数据未完待续 创建内容提供器未完待续","link":"/post/f85eb43b.html"},{"title":"Crash Course Computer Science（21-30）","text":"P21 压缩前面提到，位图文件存储的是RGB数据，有时候一张图片很大，而我们想更快地把它发给朋友，这时候就需要用到 压缩（compression），一种简单的压缩方法是游程编码，例如连续7个像素点都是黄色，与其用7个一样的RGB数据，不如在前面加个7代表7个，再接1个RGB数据即可。这种压缩方法适合经常出现相同值的文件，并且可以轻易地复原，叫做 无损压缩。1950年代，麻省理工学院学生哈夫曼发明了一种高效编码方式，叫做 哈夫曼树（Huffman Tree），将出现频率高的块用短编码，频率低的用长编码，用树结构和字典来映射。 可以看到，上面两种方法的思路分别是消除冗余和用更紧凑的表示方法。几乎所有的无损压缩都用了这两种方法，如 gif、png、pdf、zip 然而，并不是所有的数据都需要无损。像音频文件，有些超声波部分完全可以抛弃，因为人类听不到，图像和视频也是，有时候我们并不追求超清画质，只要能看到图片是什么就够了。这时候太过细致的细节会被模糊化处理，这就是 有损压缩 。著名的例子是 mp3 和 jpeg 。 P22 命令行界面早期计算机都是通过纸带和插线板一次性获取输入数据，计算完成后一次性输出到纸带。到了1950年代开始，小型机开始出现，大型机也慢慢有了多任务和分时系统的概念，于是 交互式 产生了。当时人们就借助了键盘来输入数据，通过电传，计算机能很快接收到键盘的输入然后显示，再根据输入的内容做出文字反馈，这种人类与计算机交流的方式叫做 命令行，用于交互的键盘和屏幕叫做 终端。 虽然命令行只能显示文字，十分原始，但由于其性能高，即便是在今天，也有很多程序员喜欢用命令行，尤其是访问远程计算机时。 P23 屏幕&amp;2D 图形显示屏幕显示技术最早最有影响力的是 阴极射线管（CRT），原理是把带电粒子发射到涂层上，通过磁场来控制方向。在屏幕上显示清晰的点叫做 像素（pixel），液晶显示器就是通过改变每个像素的颜色来显示图像的。 前面提到 ASCII 码通过把二进制数字映射成英文符号显示在屏幕上，映射的过程是由 字符生成器 来完成的，基本上算是第一代显卡。为了让屏幕可以显示任意画面，而不仅仅是字符，同时为了节省内存，人们用矢量画图的方式来绘制图形，屏幕上所有的一切都是由线组成。 1960年代，出现了真正内存中的一个位对应一个像素的图形界面，叫 位图显示。图形就是一个巨大的像素值矩阵，计算机把像素数据存在特殊的区域，叫做 帧缓冲区，一开始缓冲区在内存里，后来存在 高速视频缓冲（VRAM） 里，VRAM在显卡里面，而不是内存，这样访问更快。程序员预先写好了一些例如画直线、画圆、文字等函数，然后再在此基础上调用，从而绘制出丰富的图形界面。 P24 冷战和消费主义1940年代，美国和苏联开始冷战，科技成了不可小觑的力量，而计算机是科技的中流砥柱，但由于其高成本，只有政府才负担得起。当时两个美苏都在争第一，所以在计算机研发上投入了大量的资金和人力，这促进了计算机科学的发展。之后，由于苏联宇航员抢先登上太空，不甘落后的美国发起了“阿波罗登月计划”，阿波罗的导航是首次使用集成电路的典例，且这个计划投入了40万人力，计算机技术借此得以飞跃发展。1950年代美国成立了国家科学基金会，该机构至今都在给美国科学研究提供政府资金，美国的科技之所以领先，主要原因之一就是这个机构。 1950年代，消费者开始购买晶体管设备。此时战后的日本开始寻找新的工业机会，日本公司很快取得了晶体管的授权，开始振兴日本的半导体和电子行业，其中就包括收音机，日本设备以低利润为特点开始大量售出，而美国企业一开始就是跟政府签订高利润的合同，忽略了消费者市场，因此在消费者领域人们更愿意购买便宜好用的日本产品。 到了1970年代，冷战和太空竞赛褪去，美国企业失去了高利润的政府合同，变得更难竞争了，这导致了美国公司规模的缩小、裁员，甚至倒闭，其中就包括英特尔1974年大裁员，1979年仙童半导体濒临倒闭而被收购。美国公司的无力最终导致了日本公司如夏普、卡西欧等的崛起，以至于1970年代随处可见日本的电子产品。 在消费的刺激下，集成电路的成本越来越低，出现了各种各样的产品，电视、街机、手持计算器，最终催生了家用个人计算机。 P25 个人计算机革命计算机成本的下降和性能的提升，让个人计算机成为可能。第一台取得成功的商业个人计算机是 MITS 公司的 Altair 8800 ，需要自己组装，而且编写的是机器码。彼时19岁的比尔盖茨和22岁的艾伦保罗向 MITS 公司提议在 8800 上运行 BASIC 程序，并答应为其编写 BASIC 的 解释器(Interpreter)，解释器是一种将 BASIC 语言转换成机器码的程序，解释器跟编译器的区别是，前者是在程序运行时转换，而后者是在运行前。后来他们真的做出来了，于是 Altair BASIC 成了微软公司的第一款产品。 Altair 8800的问世聚集了很多计算机爱好者的聚会，一次聚会上24岁的斯蒂夫·沃兹尼亚克突发奇想说要设计自己的计算机，它的设想是把计算机连接到电视显示并提供文本界面，沃兹的大学朋友斯蒂夫·乔布斯建议说不如直接出售组装好的主板，于是，Apple-I 问世了。 个人计算机的发展引起了行业大佬IBM的注意，IBM让十二名精干的工程师从零设计了 IBM PC，立马获得了成功。它提供了开放式架构，叫做 IBM Compatible （IBM兼容），使得第三方可以提供硬件或外设，包括显卡、声卡、硬盘等。很快，康柏和戴尔也开始卖PC了，而且采用的就是 IBM 兼容的架构，微软也很乐意给他们提供 MS-DOS 操作系统，IBM硬件+微软软件 的生态很快建立起来。 然而，苹果还是坚持采用封闭式架构，自己做机器，自己做系统，甚至卖得还不错。为了在IBM+微软的夹攻中体现竞争力，1984年，Macintosh 问世了，这是第一款采用了图形界面的个人计算机！ P26 图形用户界面尽管第一台消费者可以购买到的图形界面个人计算机 Macintosh 是 1984 年才发布的，但图形界面的研究1960年代就开始了。恩格尔巴特算是对图形界面贡献比较大的人，尽管他的尝试在商业上失败了，但还是获得1997年的图灵奖。他在施乐公司工作，他们的研发团队将2D屏幕当作桌面，就像今天我们在用的一样，每一个程序都有一个窗口，窗口和窗口之间可以堆叠。然后用鼠标操作指针移动，用键盘输入内容。程序窗口有许多可复用的元素，文本框、按钮、滑动条、标签页等，GUI程序就是由这些小组件构成，而且是 事件响应驱动 的，并非顺序执行。 1979年，乔布斯参访了施乐公司，看到了他们如此酷的设计，决定跟施乐合作，后来他说，就像拨开了眼前的一层迷纱，我可以看到计算机产业的未来。之后，乔布斯回到苹果，开始图形界面的开发，并在1984年的 Macintosh 上大获成功。但没过多久，其他个人计算机的图形界面也赶了上来，加上当时苹果公司内部的混乱，乔布斯被赶出了苹果公司，给微软有机可乘，微软随即发布了 Windows 1.0，并在10年的时间里吃掉了95%的个人计算机的操作系统份额，其中就包括微软的第一个图形操作系统 Windows 95。 P27 3D图形投影和多边形将 3D 的物体通过投射的方式，显示在 2D 的屏幕上，就是 3D 投影。如果正方体各个边在投影中也互相平行，叫做 正交投影，如果会在远处收敛于一点，则叫做 透视投影。在复杂的场景中，通常用三角形来绘制图案，三角形在图形学中称为 多边形，一堆多边形的集合叫做 网格。网格数量和精细度呈正比。 渲染线框绘制好后需要填充，经典的填充算法是 扫描性渲染，它会找到三角形最大和最小的Y值，然后从上往下逐行填充颜色，如果像素不高，就会产生很多锯齿。一种解决办法是 抗锯齿，原理很简单，即边缘部分用较浅的颜色来渲染。 在 3D 场景中，经常有画面堆叠的情况。这叫 遮挡。常用 画家算法 来计算遮挡。先画远的，再画近的。再用扫描性渲染来填充。但是这种算法需要先对多边形的远近进行排序。 还有一种算法叫 深度缓冲（Z-buffering），是通过数值来记录多边形的远近，如果更远的部分被更近的遮挡，就不渲染。这种算法因为不用排序，所以会更快。但是这种算法有个有趣的现象，如果两个多边形距离一样，谁画在上面？而且浮点数计算往往不够准确，导致结果不可预测，因此在一些 3D 游戏中，经常出现 Z-Fighting 现象，同一个地方画面颜色变来变去。此外，在一些 3D 游戏中，往往会忽略多边形背面的渲染，来加快渲染速度，但坏处是如果遇到bug进入了多边形内部，会看到消失的画面。 在 3D 场景中，同样也需要明暗处理，最简单的是用 平面着色 照明算法，后来又开发了其他优化算法。此外，3D 中还需要 纹理化 让网格得到特殊外观。此处就不展开讲了。 GPU总而言之，在 3D 渲染中需要用到大量的计算，CPU不是专门为此设计的，因此工程师们做了专门的处理器—— GPU ，图形处理单元，放在显卡上面，能够进行大规模并行计算，现代GPU每秒能处理上亿个多边形！ P28 计算机网络局域网计算机网络的诞生是为了方便信息交换和共享物理资源。计算机近距离构成的小型网络称为 局域网（LAN），最广泛使用的局域网技术是 以太网，用一条电缆连接多台电脑，用电信号传输，由于以太网不会区分信号是要传给谁的，大家都能接收到相同的信号，所以需要每台计算机都有一个物理地址（mac），只监控传给自己的电信号。像共享电缆这样，多台电脑共享一个传输媒介，称为 载波侦听多路访问（CSMA），以太网的载体是铜线，Wi-Fi的载体是空气。载体传输数据的速度叫做 带宽（bandwidth）。共享载体带来的一个弊端是容易冲突，大家都有数据要发，产生信号混乱，解决办法是 指数退避，当有冲突时按指数时间递增延迟发送。即便如此，在较大的局域网中还是很容易产生冲突，于是人们使用 交换机 来减少冲突域。 路由和IP协议在大型局域网中，计算机之间的通路可能有多条，这就产生了 路由（routing）。两台相隔较远的计算机通信，最开始是使用专用电路线路，叫做 电路交换，缺点是价格昂贵且不灵活。另一种方法是 报文交换，途中会经过好几个站点，就像邮局送信一样，好处是可以使用不同的路由，提升容错且更可靠，坏处是如果报文过大会阻塞路由。于是人们把将大的报文分成多个小块，叫做 数据包（packets），这种方法称为 分组交换。报文和分组的格式由互联网协议（Internet Protocol，IP）定义，每台联网的计算机都需要一个 IP 地址。路由器 会平衡与其他路由器的负载，叫做 拥塞控制。同一个报文的不同数据包，可能会经过不同的路由线路，最后到达目的地后再按顺序拼接起来，顺序问题由 TCP/IP 协议来解决。分组交换的好处是它是去中心化的，没有中心权威机构，也没有单点失败问题。 如今，不仅仅是PC、手机接入计算机网络世界，形成互联网，一些智能家电也有了网络功能，构成了 物联网。 P29 互联网UDP互联网是一个巨型分布式网络，大数据会被拆分成一个一个数据包传输。数据包的格式遵循IP协议，即在数据包的头部加上元数据注明要发给谁，但如果只有IP协议，对方不知道这是哪个应用程序需要的数据，于是人们在IP协议之上开发了更高级的协议。例如 用户数据报协议（UDP） 在数据前加UDP头，指明了端口号，端口号是应用程序访问网络时，需要向操作系统申请的识别号。总而言之，IP协议负责把数据包发给正确的计算机，UDP协议负责发给正确的应用。 TCPUDP头里还有 checksum 检验和，用来检查数据是否正确，如果不正确，UDP通常会把数据包丢弃，加之UDP并不能确认对方已经收到数据包，所以它其实并不太可靠。但是由于其简单性，一些应用并不在乎丢失数据，例如视频通话最多也就是丢帧，影响不大，所以UDP的使用还是非常广泛的。不过到了邮件发送，文件传输等场景，要求所有数据必须准确无误地送达，就不得不使用 传输控制协议（TCP） 了，其原理跟UDP一样，但提供了更高级的功能，如数据包排序、确认码（ACK）、超时重传、滑窗、拥塞控制，从而保证数据完整无误地传输。 DNS应用程序想从网络上的另一台计算机上的应用程序获取数据，需要知道对方的IP地址和端口号，事实上，因为 172.217.7.238 是谷歌服务的ip地址，而80是其端口号，我们在浏览器上输入 http://172.217.7.238:80 即可直接访问谷歌。但记下一串数字总归是很烦的，我们还是喜欢输入 www.google.com 的方式，这叫做域名。互联网上有一种专门的服务，负责把域名和ip地址对应起来，这种服务就是 域名系统（Domain Name System，DNS）。 OSI七层模型线路里的电信号或者Wi-Fi里的无线信号，这些是物理层。mac地址，碰撞检测，指数退避等用来操控物理层的方法叫做数据链路层，IP协议等负责各种报文交换和路由转发的叫做网络层，TCP和UDP负责如何点到点传输的叫做传输层，操纵TCP、UDP进行连接、传递信息、关闭连接的叫做会话层，例如socket，最后像浏览器、Skype、微信等具体的应用程序如何展现数据，就是展示层和应用层了。 P30 万维网（world wide web）万维网建立在互联网之上，通常我们用浏览器访问一个页面，会输入如 www.bilibili.com/video/av21376839 这样的链接，前缀www就是万维网的缩写。其最基本的单位是单个页面，页面上会有跳转到其他页面的链接，叫做 超链接，每个页面都需要一个唯一的地址，叫做 统一资源定位符（URL）。当我们输入一个 URL，DNS首先会找到域名 www.bilibili.com 对应的ip地址，然后我们的计算机会向对方（通常是web服务器，默认80端口）发起一个 tcp 连接，连接建立后，会继续向服务器请求对应的页面 /video/av21376839，这里面用到的协议是 超文本传输协议（HTTP）。服务器返回的内容为了更好地展示，如标题、内容、列表，通常会用 超文本标记语言（HTML） 来显示，如今最新的 HTML5 标准，加上 CSS、JavaScript 可以做出丰富多彩的网页效果。 如果我们知道一个域名，可以直接输入，但如果我们事先不知道呢？最开始网页服务还比较少的时候，人们可以维护一个黄页目录，有专门提供这种服务的网站，例如 Yahoo，后来随着万维网的网站越来越多，人工维护变得困难起来，于是又出现了搜索引擎，如Google。","link":"/post/231feaa1.html"},{"title":"Crash Course Computer Science（31-40）","text":"P31 计算机安全并不是所有人都在互联网和万维网上规规矩矩，计算机安全即是保护计算机的保密性、完整性和可用性。保密性 是指只有有权限的人才能读取计算机系统和数据，黑客盗取信用卡即是破坏保密性，完整性 是指只有有权限的人才能使用和修改系统和数据，黑客盗取邮箱密码冒充你就是破坏完整性，可用性 是指有权限的人应该随时可以访问系统和数据，拒绝服务攻击（DDOS） 是黑客发送大量虚假请求让网站崩溃，这破坏了可用性。 很多安全问题都可以归纳为2个问题：你是谁，你可以访问什么。为了区分谁是谁，我们用 身份认证（Authorization），常见的身份认证是用户名和密码，或密钥和令牌，以及生物识别（指纹、刷脸），这几种方式各有优缺点。认证之后，我们还需要对用户进行 访问控制，也叫 鉴权（Authentication），不同的用户在系统中拥有不同的权限，通常用权限控制列表来实现，常见的权限有读、写、执行，有一种权限控制原则叫 no read up、no write down。 即便做了最严谨的安全措施，还是不可避免地有被攻破的可能性。从另一角度出发，开发者应该用最少的代码、最少的权限实现功能，以防潜在的漏洞，除此之外，操作系统还会对程序进行隔离，程序只能访问操作系统分配给它的内存块，无法访问其他内存，一台计算机可以运行多个虚拟机，虚拟机之间也是互相隔离的。这样能一定程度防范安全攻击。 P32 黑客&amp;攻击黑客攻击最常见的方式不是通过技术，而是通过欺骗，这叫 社会工程学。一种常见的方法是钓鱼网站，使用假官网诱导你输入真实的账号密码，或者假装IT人员给你打电话诱导你泄露计算机信息。还有一种方法是植入木马，木马会伪装成人畜无害的软件，实际上是会窃取个人信息的有害软件。如果能物理接触计算机，有些黑客会用复制内存的方式，让输入错误等待机制失效。而如果只能通过互联网，早期黑客会使用缓冲区溢出的漏洞，覆盖掉重要的内存值，如 IS_ADMIN = TRUE，但现代的操作系统和程序已经让这种方式很难命中了。另一种经典的手段叫代码注入， 如 SQL 注入，在 SQL 语句中插入恶意语句。 如果有足够多的电脑被黑客控制，那么这些电脑叫做 蠕虫，可能会被用来做恶意的事，如群发垃圾邮件，挖矿，或发起DDOS攻击， P33 加密安全专家知道，不可能有 100% 安全的系统。所以计算机系统通常会部署多层防御。而 加密 就是极其重要的一层。把明文通过算法转成密文就叫加密（encryption），反之叫解密（decryption）。密码学早在计算机出现之前就有了，如战时德军的英格玛。在计算机出现后，早期应用最广泛的加密是1977年 IBM 和 NSA 开发的数据加密标准（DES），采用56位二进制，有大约72千万亿个不同的密钥，到了1999年计算机能力提升，有计算机两天内就能穷举所有可能的密钥，所以DES不再安全。2001年，出现了更高级的 AES 算法，有128位/192位/256位，128位的密钥哪怕用如今所有的计算机，也要算个上万亿年。 加密和解密依赖于相同的密钥，但我们要如何让对方知道密钥呢？解决办法是 密钥交换，密钥交换是一种不发送密钥，但依然让两台计算机在密钥上达成共识的算法，就像把多种颜色混在一起很容易，但看一种颜色很难知道是哪几种颜色混合而成的。在数学上，可以用单向函数来实现。如果双方用一样的密钥加密和解密信息，就叫 对称加密，DES、AES都是对称加密的。 还有一种加密叫做 非对称加密，一个公钥，一个私钥，用公钥加密信息，只有私钥才能解密。换句话说，知道公钥只能加密而不能解密。或者反过来，用私钥加密，只有公钥才能解密，这种方法通常用来做签名，例如服务器做了加密，客户端如果能解密，说明数据来自正确的服务器。如今，最流行的非对称加密技术是RSA。 P34 机器学习&amp;人工智能决策树 &amp; 支持向量机计算机很擅长收集数据，处理数据，但如果我们想根据数据来做决定怎么办？我们希望计算机从数据中学习，然后自行做出预测和决定，这就是 机器学习 的本质，机器学习是实现人工智能的技术之一。在一系列数据中做出区分和判断，称为 分类，分类的算法称为 分类器，很多算法会把数据简化成 特征，特征是用来帮助分类的值。我们会给计算机提供一些已知的标记数据，记录了特征值和种类，特征的边界点叫做 决策边界，我们会用一个混淆矩阵来记录正确的分类和错误的分类，机器学习算法的目标就是最大化正确分类，最小化错误分类。当我们遇到一个未知的数据，我们可以测量它的特征，根据决策边界判定它属于哪一种数据。把决策空间划分成一块一块的简单方法，叫做 决策树。生成决策树的机器学习算法，需要选择用什么特征来分类，每个特征用什么值。如今，有些机器学习算法会用到多个决策树，叫做 决策森林。 也有一种不用决策树的算法，叫做 支持向量机，它是用任意曲线来划分决策空间。只有两个特征的二维划分的可能比较简单，但特征一多，就不是一件容易的事情了。这也正是机器学习的价值所在。 人工神经网络决策树和支持向量机都是基于统计学的，但也有不是统计学的算法，其中最值得一提的是 人工神经网络，就像大脑里的神经元一样。神经网络的输入层接收多个输入，然后经过隐藏层，里面有多个神经元，每一个神经元经过加权、求和、偏置、激活函数等数学转换，最后输出层输出结果。其中，隐藏层可能有很多层，因此得名 深度学习。 深度学习算法非常复杂，但还不够“聪明”，因为一个算法只能做一件事情——分辨飞蛾种类、识别人脸、翻译、自动驾驶，这类人工智能称为 弱AI，而能够让计算机在空闲时创作音乐、找出美食食谱，就像人类一样聪明的，叫做 强AI，目前还很难实现。 AI不仅可以吸收大量信息，还可以不断自我学习，速度比人类还快得多，IBM的沃森吸收了2亿个网页的知识，在知识竞赛中碾压全人类，Google的 AlphaGo 不断跟自己的克隆版下围棋，发现成功的路径，最终战胜人类最强选手。这叫做 强化学习。 P35 计算机视觉 抽象是构建复杂系统的关键。 计算机科学家一直致力于让计算机“看懂”图像和视频，因此诞生了 计算机视觉 学科。 像素的颜色是由RGB值决定的，最简单的视觉定位方法是找到特定RGB值，然后逐层扫描图像，在视频的每一帧都跑这个算法，就可以追踪图像的移动。但是这种简单粗暴的方法并不适用于受光线、阴影等影响的现实场景，而且多个物体同种颜色会干扰算法。更进一步的算法是将图像分成一块块进行处理，例如9个像素为一块。物体边缘的颜色块往往跟背景有一定差异，专门识别这些边缘的算法叫做 核 或者 过滤器。将过滤器应用于一个块，计算出新像素值，这种操作叫做 卷积（convolution）。识别物体垂直边缘的过滤器如果应用在图片的所有像素，图片将会发生如下图的变化。 如果我们再叠加识别水平边缘的过滤器，就有了水平的白线。这样物体的边缘就出来了。不同的过滤器能识别不同的边缘，锐化、模糊、匹配特征。多个过滤器组装在一起成为窗口，早期人脸识别算法就是基于此开发出来的。时至今日，热门的算法是 卷积神经网络，通过神经网络深度学习的方式来做人脸识别，本质上是一堆过滤器卷积再卷积。 识别出人脸后，计算机会再用其他进一步的算法，来判断情感，是哭是笑，然后做出不同的响应。除人脸识别外，如今，计算机视觉被广泛用在商品条码扫描，无人驾驶汽车，照片滤镜。 P36 自然语言处理（NLP）计算机科学家的目标不仅仅是让计算机看懂图像，还要听懂人话。于是有了计算机学科+语言学科的 自然语言处理（NLP）。 编程语言通常语法固定，稍有错误都会编译报错。但人类语言不确定因素很多，如语序、发音、口音等，只要不是很严重的错误，对方一般都能理解，这对计算机来说却很难。早期NPL研究怎么把句子分成一块块更容易处理，例如 冠词+名词+动词 等等各种组合，形成 分析树。语音搜索一般都是这样做出来的。 短语结构规则把语言结构化，用来生成句子。构造句子的成分如果放在信息网络上，就形成了知识图谱。计算机会根据既定事实处理、分析、生成文字，然后跟你聊天。早期聊天机器人用的是专家系统，即把可能的问题和对应的答案存在字典里，但这很难维护而且不适用于复杂的对话场景。如今，聊天机器人使用机器学习，用大量真人聊天数据来训练机器人，应用在智能客服上面。 计算机如何从声音中提取词汇？这属于 语音识别。以前都是用特定规则来做，如今大都切换到深度神经网络了。其中用到将波形转频率的算法，叫做 快速傅里叶变换（FFT）。频率里会有各种元音、音素的特征，当遇到相似单词，语音模型会根据语法规则和统计学方法，找到可能性最高的单词。 P37 机器人机器人是由计算机控制，可以自动执行一系列动作的机器。第一台计算机控制的机器出现在1940年代，可以执行一连串指定的程序。精细的控制能让我们生产出之前很难做的物品。机器中用来判断位置的控制回路叫 负反馈回路，包含传感器、控制器、系统组件（泵、电机、加热元件）。在实际情况中，还要考虑外界环境影响，如摩擦力，风力，上下坡等，因此一般都用 PID控制器 来算误差和比例值，在汽车巡航控制，无人机等都被广泛应用。更高级的机器人一般有多个控制回路，用来保持各个数值的稳定，从而配合做出不同的动作。 机器人可以轻易做到精细的动作，但对人类来说很基础的动作，如双脚走路、摸狗等，对机器人却很难。如今，像 Google 等技术公司已经开始在用机器学习的方式训练机器人做人类动作，所以机器人早晚也能做到。最近几年，机器人最大的突破是无人驾驶汽车，汽车的输入其实很简单，转弯、加减速、刹车，难的是让汽车看懂路标和信号灯，指示牌，车流和行人等，因此得结合计算机视觉技术。 近年来又出现了一些类人类机器人，模仿人类的外观和行为，也是通过 机器人+计算机视觉+自然语言处理 实现的，只是目前还不够成熟。 P38 计算机心理学计算机终究只是人类的工具，为了让人类使用得更愉快，设计者们甚至都运用了心理学的原理。 人类很擅长给颜色的深度排序，而不擅长给不同颜色排序。所以好的界面通常用颜色深浅度来排序连续的数据，用不同的颜色来区分不同的数据； 人类的短期记忆能记住5-9个物体，因此把信息分成小于5的块更容易理解，例如电话号码通常用 137-1111-1111 的方式； 程序的 直观功能 很重要，例如，平板用来推、旋钮用来转、插槽用来插，用户一眼就看懂怎么使用； 好找好记固然重要，但熟练使用之后人类会建立心理模型，因此好的界面应该提供多种方式来实现目标，例如复制可以在菜单栏找到，也可以直接 Ctrl+C 心理学研究表明，比起面对面，人们更愿意在互联网上透露自己的个人信息，因此问卷调查最好是用聊天机器人，而非虚拟真人助手。 说服、讲课或引起注意，需要用到眼神交流，这有助于加强参与感。但视频通话时摄像头往往不在眼睛注视的前方，因此有专门的软件算法来纠正偏差。 人机交互被用来感知人类的情绪，让计算机更好地应答。 计算机心理学带来的好处很多，但也会带来一些坏处，例如使用计算机利用人类心理诱导人类行为。但总而言之，计算机+心理学还有很多值得去挖掘的地方，这个方向也一直在发展。 P39 教育科技计算机带来的改变之一是信息的创造和传播能力。互联网上大部分的信息是教育型信息，正如这门课的视频一样。但是网络视频带来的问题是，几百万人同时学一门视频课程，老师如何给几百万人打分？而且缺少学习互动和反馈。因此计算机教育科学家研究了智能辅导系统，通过建立模型来针对性辅导学习，通常是使用贝叶斯知识追踪让学习练习技能，直至掌握。甚至运用上百万学生学习、做题时的数据来做 教育数据挖掘。虚拟现实和增强现实技术也应用在教育科技上，帮助学生直观体验学习。 人们甚至幻想，能不能通过教育科技，直接把知识下载到大脑呢？可谓脑洞大开。 P40 计算机的未来说到计算机的未来，很多人想到的是 人工智能，科技无处不在，如影随形。有一句话叫最好的科技是让你感受不到科技的存在。然而，就像有了灯泡之后，蜡烛也依然存在，并不是所有的地方都会用到AI，或需要AI，最可能的情况是AI成为人类科学家的好工具。 真正让人担忧的是，人工智能是否会超越人类智能？按照AI现在的发展速度，几十年内计算机的能力就会超过人类。智能科技的失控性发展叫做 奇点。一旦奇点到来，首先AI会替代掉大部分重复性劳动的工作，许多人将会失业，其次也可能会影响人的身体（例如脑电接口）…… 总之，未来是不可预测的，但也不必太过悲观。许多的新技术正在诞生，至少目前来看，人类的生活因为计算机正变得越来越好，不是吗？","link":"/post/5d95362f.html"},{"title":"Crash Course Computer Science（1-10）","text":"在 B站 发现了一门好课《Crash Course Computer Science》（计算机科学速成课），虽然讲“速成”有点急功近利的意思，但这门课从计算机的历史开始讲起，几乎涵盖了从布尔逻辑到二进制、从硬件到软件、从编译原理到操作系统、从计算机网络到信息安全等等计算机科学的知识，作为一种科普，扩充知识面还是相当不错的。 课程地址：https://www.bilibili.com/video/av21376839/ P1 计算机的早期历史计算机起源于人们计算的需求，最早被发明的是算盘，用来计算大数字，后来又出现了很多变种应用于各行各业，比如星盘让船可以在海上计算纬度，计算尺帮助计算乘除法，各种时钟用于计算日出、潮汐、天体位置等。而 Computer 一词，最初是指以计算为职业的人，后来才慢慢代指机器，其中以 1694 年发明的“步进计算器”最出名，它通过转动齿轮，带动数字加减过程的进位。1822年，Charles Babbage 提出了一种“差分机”，用于解决同一个公式下不同参数的计算，但这个项目最终失败了。在研究差分机期间，Charles Babbage 还构想了一种“分析机”可以做不同的运算，由于这个思想太超前，所以同样没有建成。但是分析机的思想奠定了 计算机可以自动完成一系列操作 这个基础。英国数学家 Ada 根据分析机的理念，设计了假想的程序，所以 Ada 被认为是世界上第一个程序员。 1880年，美国人口快速增长，人口普查局找到 Herman Hollerith 制造一款打孔卡片制表机，用传统机械来计数，用电动结构连接其他组件，大大提升了统计的数据。企业开始意识到计算的价值，之后 Hollerith 成立了制表机器公司，在1924年跟其他机械公司合并后，成为 国际商业机器公司（International Business Machines），即 IBM 。 步进计算器发明者 Gottfried Leibniz： 让优秀的人浪费时间算数简直是侮辱尊严，农民用机器能算得一样准。 P2 电子计算机IBM 在 1944年 建造了哈佛马克一号机电计算机，它的基本组件是 继电器（一种用电控制的机械开关）。但继电器是机械结构，本身有重量，而且频繁开闭容易坏，所以效果不是很理想。早在 1904年，英国物理学家就发明了真空管（二级管），1906年美国发明家往真空管加入了控制电路，变成 三极管，达到了跟继电器一样的效果，从此计算机从机械走向了电子。世界上第一台通用，可编程的电子计算机是ENIAC，每秒能进行5000次加法运算。 三极管是其他电子器件的基础，但也不是完美的，经常烧坏，1947年，贝尔实验室发明了 晶体管，晶体管涉及的原理十分复杂，简单地说，就是两个电极之间有一种材料隔开，这种材料有时导电，有时不导电，这叫做 半导体。晶体管通过改变导电性让电荷流动或不流动，达到跟继电器和三极管一样的效果。自那以后，IBM 建造了很多纯晶体管的计算机，计算机的体积也越来越小，最终让计算机从实验室走向办公室，再走向普通家庭。 有趣的是，晶体管的主要材料是硅，而彼时晶体管和半导体的开发集中在美国的加州，所以那个地方被称为硅谷。连晶体管发明者之一 William Shockley 都搬了过去，成立了肖克利半导体，里面的员工后来成立了仙童半导体，里面的员工后来又成立了英特尔。 从继电器到三极管再到晶体管，我们只做了一件事，那就是让开关开闭得更快，而且更不容易损坏，仅此而已。 P3 布尔逻辑和逻辑门用两种状态表示信息叫做「二进制」，二进制可以用 true 和 false ，或者 1 和 0 来表示。计算机二进制的理论来自于布尔代数，在布尔代数中，变量的值只有 true 和 false 两种，运算法则有与、或、非、异或（AND、OR、NOT、XOR） 等。晶体管的控制信号表示输入，结果表示输出。用不同的晶体管组合来实现不同的布尔逻辑运算，这就是逻辑门。 与（AND）：两个值都为true，结果才为true 或（OR）：两个值只要有一个为true，结果才为true 非（NOT）：取反 异或（XOR）：两个值相同时，结果为 false ，否则为 true P4 二进制在十进制中，只有 0-9 十个数字，想表示更大的数字，加位数就行了，比如51，5在十位表示5个10。在二进制中只有 0 和 1 两个数，想表示更大的数字，也是加位数，这样一个位，我们称之为 比特（bit），比如 101，表示 1个1 + 0个2 + 1个4 = 5。二进制逢二进一，需要比十进制更多的进位，在计算机里，大部分操作都是八位八位这样子计算的，比如 11011010，所以我们把八个位称为一个 字节（byte），8位能表示256种不同的状态，在8位的游戏里，只有256种颜色，而16位是65536种。 就跟 1000克 = 1千克 一样，1000 byte = 1 kilobyte（千字节） = 1KB = 8000 bits ，以此类推， MB是百万字节（Mega）， GB是十亿字节（Giga）。可是在计算机中，还有另外一种计算方式，那就是1千字节 = 2^10 byte = 1024 byte ，在 Linux 系统中为了加以区分，常用 1 KiB 这样的写法跟 1KB 区分开来，前者是 1024 byte，后者是 1000 byte。 为了表示负数，我们把第一位作为符号位，1表示负，0表示正。类似于科学计数法，在32位系统中，为了表示小数（浮点数），我们会取第2-9位作为指数，剩下23位作为有效位数。 除了数字，我们也要在计算机中表示文字。最简单的方法就是编码，ASCII（美国信息交换标准代码）发明于1963年，采用7位编码，可以表示128个不同的值，我们的每一个英文字母、数字和常用符号都对应一个值，比如 a 的编码是 97，当计算机遇到二进制97的编码时，就在显示器上显示 a 。随着计算机在全世界的流行，各个国家都推出了自己的字符编码，比如中国的 GBK，后来由于实在是太混乱了，Unicode 就诞生了————统一了所有编码的标准。Unicode是16位的，足以解决所有国家的编码问题。 就像用二进制编码来表示不同的字符一样，其他格式的二进制编码，如 .mp3 / .jpg / .avi 等等都是特定的二进制编码，用来编码音乐、图片和视频。所以，在计算机中，归根结底都是一长串的 0 和 1 罢了。 P5 算术逻辑单元（ALU）我们用二进制表示数字，但真正重要的是有意义地处理数字。 算术逻辑单元（ALU） 是计算机负责运算的组件，ALU包含一个算术单元（Arithmetic）和一个逻辑单元（Logic）。算术单元我们可以用一个 XOR 和 一个 AND 组装成一个半加器，两个半加器组装一个全加器，再由全加器组装8位加法器。在8位加法器中，如果两个数相加超过了11111111，那么我们就称 溢出(overflow) 了。逻辑单元是负责逻辑运算的组件，比如 AND、OR、NOT、XOR，以及一些简单的数值测试（如一个数是否负数）。 在8位的ALU中，我们有两个8位的输入 A 和 B，以及一个4位的操作码告诉ALU应该执行什么操作，例如用操作码1000表示做加法，用1100表示做减法。ALU有一个8位的输出，以及一些标志输出，例如是否溢出标志，是否为零标志。 P6 寄存器和内存算术逻辑单元可以对数字进行运算，而 寄存器和内存负责对结果进行保存。断电后丢失的存储称为随机存储（RAM），而断电后永久保存的称为持续存储（ROM）。用一个 AND 门，一个 OR 门，一个 NOT 门能制作一个 AND-OR 锁存器，可以存储一位。锁存器加一些额外的逻辑门，可以实现允许写入和允许读取，用这个来控制该位是否允许被读写。将8个一位锁存器并排，就可以存储8位的二进制数了，一组这样的锁存器称为 8位寄存器，当然，也有16位、32位或64位的寄存器。 在64位的寄存器中，每个锁存器都要有线来控制读写显得很麻烦，可以用矩阵来级联，矩阵一横一竖的交叉点即是特定位置的锁存器。这样，对于256位的寄存器，只需要35条线（1条数据线、1条允许写入线、1条允许修改线、16行+16列矩阵线用于选择锁存器）。例如，要选择第12行第8列的锁存器，可以启用对应的矩阵线，其交点就是目标，对应的矩阵线用二进制标记就是 1100 1000，这就是内存地址概念的由来。内存的一个重要特性是，可以随时访问任何位置，因此叫 随机访问存储器（RAM）。 如今，无论是 SRAM，DRAM 或其他 RAM，从根本上都是矩阵层层嵌套，来存储大量信息罢了。 P7 中央处理器（CPU）CPU负责执行程序。程序由一个个操作组成，这些操作称为 指令（instruction），如果是计算指令，CPU 会与 ALU 通信进行计算操作，如果是内存指令，CPU 会与内存通信，然后读写值。 程序可以放在内存里，指令也一样可以放在内存里。在内存里放一系列8位二进制数，前4位表示 操作码，即 CPU 应该执行的指令，后4位表示数据来自哪里（内存地址或某个寄存器ID），此外，我们还需要两个寄存器来组建我们的 CPU，一个负责追踪程序运行到哪里了，称为 指令地址寄存器，存储着当前指令的内存地址，另一个负责存当前指令，称为 指令寄存器。 CPU 启动时，第一个步骤是 取地址，CPU会往指令地址寄存器上的地址去取需要的指令，例如在0地址取到00101110，这个数会被存入指令寄存器中。第二个步骤是 解码（decode），取到的00101110指令表示什么意思？需要由 控制单元 进行解码，控制单元本质上也是一些逻辑门的组合，它可以解释例如前4位0010是存储操作，后4位1110是应该存入的地方。知道该做什么操作和往哪里存储后，第三个步骤就可以 执行 了。CPU会有一些线连接到内存，打开内存对应地址的允许写入线，然后往里面写值。 执行完毕后，指令地址寄存器的值自动加一，一个CPU操作就完成了。像这样，CPU 取指令 → 解码 → 执行 → +1 这样一个周期称为 时钟周期。现代PC或手机一秒能达到10亿次时钟周期。所谓 超频 或 降频，就是让 CPU 周期更快或更慢的技术。 P8 指令和程序CPU的强大之处在于可编程，写入不同的指令就会执行不同的任务。 假设在内存地址0的地方，存放着00101100，前四位是操作码表示 LOAD_A ，后四位表示内存地址14，写成人类容易理解的内容是 LOAD_A 14，意思是，从内存地址14的位置取数放到寄存器A，内存地址14假设存放着数字3，那么数字3就会被放到寄存器A。同样的，内存地址1的地方，存放着 LOAD_B 15，CPU就会从内存地址15的地方取数放到寄存器B，最后，当 CPU 遇到 ADD B A，表示把寄存器B的值加到寄存器A上，遇到 STORE_A 13，表示把当前寄存器A的值存入内存地址13。这样就完成了一次加法。 除了 LOAD、ADD 和 STORE，CPU还有其他一些指令，SUB减法、JUMP跳转（用于实现循环和分支）、JUMP_NEGATIVE条件跳转、HALT停止（没有这个指令程序会一直执行下去）， P9 高级CPU设计1.特殊指令早期CPU是没有除法指令的，除法用减法来实现，例如16÷4，相当于16-4-4-4-4，这要花费很多个时钟周期。现代CPU设计中，从硬件层面上加了除法的指令，这样只要一个时钟周期就能搞定。此外，现代处理器有一些专门的电路来处理图像操作，解码压缩视频，加密等复杂运算，这些用标准操作要很多时钟周期，但一旦在硬件层面搞定，速度便大大提升。 2.Cache缓存CPU的设计越来越巧妙和强大，以至于RAM读写的速度跟不上，RAM读写的这段时间，CPU白白空等完全就是浪费。于是人们在CPU和RAM之间加了个中间层——Cache缓存，CPU 从 RAM 拿数据时，不用一个个拿，而是一批批拿，即将用到的指令直接存在Cache缓存里，这样大大提高了读写效率。但这样带来了Cache和RAM数据不一致的问题，于是Cache会专门设计一个脏位，Cache存满后会检查脏位，把内容写回RAM后再清空缓存。 3.指令流水线CPU有一种提升性能的方式，并行处理。我们知道，CPU一次完整的操作包含 取指 → 解码 → 执行。我们可以在执行一条指令的时候，先解码下一条待执行的指令，以及做取下下条指令的操作。这种方式叫 指令流水线。但这种方式会带来两个问题： 第一，依赖性的问题，比如你在读某个数据，而正在执行的指令会修改这个数据，因此，我们要弄清楚指令之间的依赖关系，必要时暂停指令流水线，避免出错。现代CPU会动态排序有依赖关系的指令，在学习Java volatile时，你可能听说过”重排序”的问题，就来源于CPU的指令依赖关系。第二，JUMP跳转问题。一般的CPU会再JUMP前等待观察，一旦JUMP的结果出来，便往正确的分支塞指令。更高级的CPU会猜测JUMP到哪个分支的概率更大，叫 分支预测，提前用流水线塞指令，如果猜对了直接按流水线执行，否则就要先清空流水线，再重新塞正确的指令了。现代CPU分支预测的正确率能达到90%，所以效率棒棒哒。 4.多核处理器现代CPU往往有多个核心，可以同时处理多个指令流。多核可以同时共同参与运算，提升效率也是很明显的。当多核也不够时，为啥不考虑下多CPU呢？中国国家超算中心的超威·太湖之光超级计算机就有 40960 个 CPU，每个 CPU 有 256 个核心，是世界上最快的计算机。 P10 早期的编程方式程序需要加载进内存。可能你已经知道，早期的编程都是通过纸带打孔的方式，这种方式其实最早来源于纺织业。后来在19世纪美国人口普查中穿孔纸卡被用于记录汇总数据。但这只是数据，还不是程序。为了达到可编程的目的，程序员需要某种控制面板用于输入数据，最早被发明的控制面板是“插线板”，世界上第一台计算机ENIAC就用到了大量的插线板，其缺点是连线复杂，换程序十分不方便。还有一种是用大量的开关代替插线，叫做面板编程（panel programming）。 1940-1950年代，内存开始出现，使用了内存的计算机称为“存储程序计算机”，如果内存足够，不仅仅可以存程序，还可以存需要的数据，包括程序运行时产生的新数据。程序和数据存储在同一个地方，这种结构称为 冯诺依曼结构。冯诺依曼计算机的标志是：算术逻辑单元 + 数据寄存器 + 指令寄存器 + 指令地址寄存器 + 内存。 早期的编程方式都是专家活，我们亟需一种简单的方式告诉计算机我们要做什么，于是，编程语言诞生了！请看下篇。","link":"/post/7a4edbf1.html"},{"title":"漫谈五大常用算法","text":"五大常用算法： 分治 动态规划 贪心 回溯 分支界定 分治算法概念分治，就是“分而治之”，把一个问题分成两个或多个相同或相似的子问题，再把子问题分成更小的子问题……最后子问题可以直接求解，原问题的解即子问题的解的合并。 分治法常常跟递归一起使用，借助递归，我们可以方便地将问题分解再将结果合并。 分治法的基本步骤 分解：将原问题分解为若干个规模较小，相互独立，与原问题形式相同的子问题； 递归：若子问题规模较小而容易被解决则直接解，否则递归地解各个子问题 合并：将各个子问题的解合并为原问题的解。 可使用分治法求解的经典问题 二分搜索 大整数除法 Strassen矩阵乘法 棋盘覆盖 归并排序 快速排序 线性时间选择 最接近点对问题 循环赛日程表 汉诺塔 动态规划概念将一个问题分解成若干个子问题（阶段），按顺序求解子阶段，前一子问题的解，为后一子问题的求解提供了有用的信息。在求解任一子问题时，列出各种可能的局部解，通过决策保留那些有可能达到最优的局部解，丢弃其他局部解。依次解决各子问题，最后一个子问题就是初始问题的解。 与分治法的差别适合于用动态规划法求解的问题，经分解后得到的子问题往往不是互相独立的（即下一个子阶段的求解是建立在上一个子阶段的解的基础上，进行进一步的求解）。 动态规划的基本步骤动态规划过程如下： 初始状态 → │决策１│ → │决策２│ → ……… → │决策ｎ│ → 结束状态 划分阶段：按照问题的时间或空间特征，把问题分为若干个阶段。在划分阶段时，注意划分后的阶段一定要是有序的或者是可排序的，否则问题就无法求解。 确定状态和状态变量：将问题发展到各个阶段时所处于的各种客观情况用不同的状态表示出来。当然，状态的选择要满足无后效性。 确定决策并写出状态转移方程：根据相邻两个阶段的状态之间的关系来确定决策方法和状态转移方程。 寻找边界条件：给出的状态转移方程是一个递推式，需要一个递推的终止条件或边界条件。 使用动态规划求解问题，最重要的就是确定动态规划三要素： 问题的阶段 每个阶段的状态 从前一个阶段转化到后一个阶段之间的递推关系。 贪心算法基本概念在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的仅是在某种意义上的局部最优解。 贪心算法不是对所有问题都能得到整体最优解，选择的贪心策略必须具备无后效性，即某个状态以后的过程不会影响以前的状态，只与当前状态有关。 适用前提局部最优策略能导致产生全局最优解。 贪心算法基本步骤 建立数学模型来描述问题。 把求解的问题分成若干个子问题。 对每一子问题求解，得到子问题的局部最优解。 把子问题的解局部最优解合成原来解问题的一个解。 回溯法概念在搜索尝试过程中寻找问题的解，当发现已不满足求解条件时，就“回溯”返回，尝试别的路径。 回溯法是一种选优搜索法，按选优条件向前搜索，以达到目标。但当探索到某一步时，发现原先选择并不优或达不到目标，就退回一步重新选择，这种走不通就退回再走的技术为回溯法，而满足回溯条件的某个状态的点称为“回溯点”。 基本思想在包含问题的所有解的解空间树中，按照深度优先搜索的策略，从根结点出发深度探索解空间树。当探索到某一结点时，要先判断该结点是否包含问题的解，如果包含，就从该结点出发继续探索下去，如果该结点不包含问题的解，则逐层向其祖先结点回溯。（其实回溯法就是对隐式图的深度优先搜索算法）。 若用回溯法求问题的所有解时，要回溯到根，且根结点的所有可行的子树都要已被搜索遍才结束。 而若使用回溯法求任一个解时，只要搜索到问题的一个解就可以结束。 回溯基本步骤 针对所给问题，确定问题的解空间:首先应明确定义问题的解空间，问题的解空间应至少包含问题的一个（最优）解； 确定结点的扩展搜索规则； 以 深度优先 方式搜索解空间，并在搜索过程中用剪枝函数避免无效搜索。 分支限界法回溯法的求解目标是找出T中满足约束条件的所有解，而分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出使某一目标函数值达到极大或极小的解，即在某种意义下的最优解。 分支搜索所谓“分支”就是采用 广度优先 的策略，依次搜索E-结点的所有分支，也就是所有相邻结点，抛弃不满足约束条件的结点，其余结点加入活结点表。然后从表中选择一个结点作为下一个E-结点，继续搜索。","link":"/post/b054556.html"},{"title":"漫谈递归和迭代","text":"兔子问题今天看到一个题目 有一对兔子，从出生后第3个月起每个月都生一对兔子，小兔子长到第三个月后每个月又生一对兔子，假如兔子都不死，问每个月的兔子对数为多少？ 我一开始的解法是这样的： 123456789101112public static void rabbit2(){ int last_month_num = 0; int current_month_num = 1; int next_month_num = last_month_num + current_month_num; for (int months = 1; months &lt;= 12; months++) { current_month_num = next_month_num; System.out.printf(\"第 %d 个月兔子的对数为 %d\\n\",months,current_month_num); next_month_num = current_month_num + last_month_num; last_month_num = current_month_num; }} 我的想法是，根据题意，可以得出规律: 1、1、2、3、5、8、13… 总结规律：前两个月的数量和等于下个月 起始条件：当前月兔子对数为1的话，前一个月可以认为是0，那么下一个月就是0+1=1； 然后下一个月的值赋给当前月，当前月的值赋给上一个月 当前月兔子对数为1，前一个月为1，下一个月就是1+1=2； 当前月兔子对数为2，前一个月为1，下一个月就是2+1=3； 当前月兔子对数为3，前一个月为2，下一个月就是3+2=5； 以此类推… 程序输出： 123456789101112第 1 个月兔子的对数为 1第 2 个月兔子的对数为 1第 3 个月兔子的对数为 2第 4 个月兔子的对数为 3第 5 个月兔子的对数为 5第 6 个月兔子的对数为 8第 7 个月兔子的对数为 13第 8 个月兔子的对数为 21第 9 个月兔子的对数为 34第 10 个月兔子的对数为 55第 11 个月兔子的对数为 89第 12 个月兔子的对数为 144 到这里本来就结束了。但后来在网上看到另一种解法： 12345678910public static void rabbit() { for (int months = 1; months &lt;= 12; months++) { System.out.printf(\"第 %d 个月兔子的对数为 %d\\n\",months,getRabbits(months)); }}private static int getRabbits(int months){ if (months == 1 || months == 2) return 1; else return getRabbits(months-1) + getRabbits(months-2);} 基本思想是：根据规律，如果月数是1或2，就返回1，如果是3或者以上，就返回前一个月和前两个月的和 然后要知道前一个月的数量，就又要去算前两个月和前三个月的和 要知道前两个月的数量，就又要去算前三个月和前四个月的和 一直往前算到第一个月和第二个月，得出具体的数字，然后逐步加回去 以此类推 程序输出： 123456789101112第 1 个月兔子的对数为 1第 2 个月兔子的对数为 1第 3 个月兔子的对数为 2第 4 个月兔子的对数为 3第 5 个月兔子的对数为 5第 6 个月兔子的对数为 8第 7 个月兔子的对数为 13第 8 个月兔子的对数为 21第 9 个月兔子的对数为 34第 10 个月兔子的对数为 55第 11 个月兔子的对数为 89第 12 个月兔子的对数为 144 两种解法，第一种可以认为是迭代的思想，而第二种则是递归的思想。 递归和迭代的区别 迭代：迭代是将输出做为输入,再次进行处理。 递归：递归是函数自己调用自己。 那么，使用递归和迭代求 1+2+3…+n 的过程是怎样的呢？ 使用迭代 123450+1=11+2=33+3=66+4=1010+5=15 使用递归 123456789101112sum(5)5+sum(4)5+4+sum(3)5+4+3+sum(2)5+4+3+2+sum(1)5+4+3+2+1+sum(0)5+4+3+2+1+05+4+3+2+15+4+3+35+4+65+1015 到这里基本能看出迭代和递归的区别，由于时间关系，暂不展开深入探讨。 延伸阅读： 深究递归和迭代的区别、联系、优缺点及实例对比 漫谈递归和迭代","link":"/post/2f95bdb5.html"},{"title":"数据结构（二）算法的复杂度、简单排序算法","text":"前言：算法的复杂度在讨论数据结构和算法时，我们通常用算法的复杂度来描述一个算法的好坏，复杂度包括：时间复杂度 和 空间复杂度。计算机本质上是一个状态机，内存里的数据构成了当前的状态，CPU利用当前的状态计算出下一个状态。所谓的空间复杂度就是为了支持你的计算所必需存储的状态最多有多少，所谓时间复杂度就是从初始状态到达最终状态中间需要多少步！ 时间复杂度算法的时间复杂度，也就是算法的时间量度，记作：T(n) = O(f(n))。它表示随问题规模 n 的增大，算法执行时间的增长率和 f(n) 的增长率相同，称为算法的渐近时间复杂度，简称为时间复杂度。其中 f(n) 是规模 n 的某个函数。 如何推导时间复杂度 用常数 1 取代运行时间中的所有加法常数。 在修改后的运行次数函数中，只保留最高阶项。 如果最高阶项存在，且不是 1 ，则去除与这个项相乘的常数。 例如: 123int sum = 0, n = 100; // 执行 1 次sum = (1 + n) * n / 2; // 执行 1 次printf(\"%d\", sum); // 执行 1 次 这个算法的运行次数函数是 f(n) = 3。根据推导规则，第一步把常数项 3 改为 1。第二步保留最高阶项，它没有最高阶项，所以这个算法的时间复杂度为 T(n) = O(1)。 常数阶当 n = 1 时，算法执行次数为 3， 当 n = 100 时，算法的执行次数还是 3，所以我们可以看出这个算法的执行次数与 n 的规模没关系。我们把这种与问题的大小（n 的大小）无关，执行时间恒定的算法，叫作常数阶。 线性阶下面这段代码的时间复杂度为 T(n) = O(n)，因为循环体中的代码必须要执行 n 次。 123for (i = 0; i &lt; n; i++) { /* 时间复杂度为 O(1) 的程序步骤序列 */} 对数阶12345int count = 1;while (count &lt; n) { count = count * 2; /* 时间复杂度为 O(1) 的程序步骤序列 */} 由于每次 count 乘以 2 以后，就越来越接近于 n，也就是说有多少个 2 相乘后大于 n，则会退出循环。由2^x = n 得到 x = log2n。所以这个算法的时间复杂度为 T(n) = O(logn)。 平方阶123456789101112131415// 例1int i, j;for (i = 0; i &lt; n; i++) { for (j = 0; j &lt; n; j++) { /* 时间复杂度为 O(1) 的程序步骤序列 */ }}// 例2int i, j， m;for (i = 0; i &lt; m; i++) { for (j = 0; j &lt; n; j++) { /* 时间复杂度为 O(1) 的程序步骤序列 */ }} 在 例1 中内循环时间复杂度为O(n)，而对于外层的循环，不过是这个内循环再循环 n 次。所以这段代码的时间复杂度为 O(n^2)。 在 例2 中，时间复杂度就变为 O(m^n) 常见的时间复杂度耗费时间从小到大依次是： O(1) &lt; O(logn) &lt; O(n) &lt; O(nlogn) &lt; O(n^2) &lt; O(n^3) &lt; O(2^n) &lt; O(n!) &lt; O(n^n) 空间复杂度算法的空间复杂度通过计算算法所需的存储空间实现，算法空间复杂度的计算公式： 1S(n) = O(f(n)) 其中 n 为问题的规模，f(n)为语句关于 n 所占存储空间的函数。 参考：程序猿必修课之数据结构（二）算法和算法的复杂度 复杂度分析的主要方法 迭代：级数求和 递归：递归跟踪 + 递推方程 猜测 + 验证 一、选择排序（Selection Sort）选择排序介绍选择排序是一种最简单的排序算法，它的算法步骤如下： 找到数组中最小的元素 将它和数组的第一个元素交换位置（如果相同，也交换） 在剩下的元素中找到最小的元素 将它和数组的第二个元素交换位置 重复。。 选择排序交换的总次数为N，算法的效率取决于比较的次数。 特点： 运行时间和输入无关、移动数据是最少的 选择排序是不稳定的排序方法 对于长度为 N 的数组，选择排序需要大约 N²/2次比较和 N 次交换 时间复杂度 O(n^2) 算法2.1 选择排序1234567891011121314public static void selectSort(int[] arr){ int size = arr.length; for (int i = 0; i &lt; size; i++) { int min = i; // 第二个for循环找出最小元素 for (int j = i; j &lt; size; j++) { if (arr[j] &lt; arr[min]) min = j; } Swap.swap(arr, min, i); }} 二、插入排序（Insertion Sort）插入排序介绍插入排序，将数插入到其他已经有序的数中的适当位置。为了给要插入的数腾出空间，我们需要将其余所有元素在插入之前都向右移动一位。 插入排序所需的时间取决于输入中元素的初始顺序。(原始数据越接近有序，越快) 命题：对于随机排列的长度为 N 且主键不重复的数组，平均情况下插入排序需要约 N²/4 次比较以及 N²/4 次交换。最坏情况下需要 约 N²/2 次比较以及 N²/2 次交换，最好情况下需要 N-1 次比较 和 0 次交换。 时间复杂度：O(n^2) 算法2.2 插入排序123456789101112131415/** * 原理：插入排序，将数插入到其他已经有序的数中的适当位置 * 思路：从 a[0] 开始，a[0] 已经是第一个，所以不用动 * a[1] 与 a[0] 比较 -&gt; 得出顺序 * a[2] 与 a[1] a[0] 比较 -&gt; a[2] 先与 a[1] 比较 ，如果 a[2] 比 a[1] 小，则交换， 然后 a[1] 与 a[0] 比较 * a[3] 与 a[2] a[1] a[0] 比较 -&gt; 插入适当位置 * ... */private static void insertSort(int[] arr){ for (int i = 1; i &lt; arr.length; i++) { for (int j = i; j &gt; 0 &amp;&amp; arr[j] &lt; arr[j-1]; j--) { Swap.swap(arr, j, j-1); } }} 三、希尔排序（Shell Sort）希尔排序介绍在插入排序和选择排序中，由于它们只能交换相邻的元素，如果有位于数组起始的大元素，则需要多次遍历才能交换到队尾，很不划算。希尔排序以更大的间隔来比较和交换元素，这样，大元素在交换的时候，可以向右移动不止一个位置。 希尔排序只需要在插入排序的代码中将移动的元素距离由1改为h即可。 希尔排序依赖于间隔(step)的选取。 算法2.3 希尔排序123456789101112131415161718public class Shell { public static void sort(Comparable[] a){ int N = a.length; int h = 1; while(h &lt; N/3) h = 3*h + 1; // 1,4,13,40,121,364,1093... //将数组变为h有序 while (h &gt;= 1){ //将a[i] 插入到 a[i-h]、a[i-2h]、a[i-3h]...之中 for (int i = h; i &lt; N ; i++) { for (int j = i; j &gt; h &amp;&amp; less(a[j],a[j-h]); j-=h) { exch(a, j, j-h); } } h = h/3; } }} 四、冒泡排序比较相邻元素，大的放右边 要点：第一躺结束后，最右元素一定是最大的，因此第二趟最右元素不参与，即 size - i - 1 时间复杂度：O(n^2) 1234567891011public static void bubbleSort(int[] arr){ int size = arr.length; for (int i = 0; i &lt; size; i++) { // 第一躺结束后，最右元素一定是最大的，因此第二趟最右元素不参与，即 size - i - 1 for (int j = 0; j &lt; size - i - 1; j++) { if (arr[j] &gt; arr[j+1]) Swap.swap(arr, j, j+1); } }}","link":"/post/7c5cf5e1.html"},{"title":"数据结构（一）数据抽象、数组、链表","text":"数据抽象在开始谈数据结构之前，先聊一聊什么是数据抽象和抽象数据类型（ADT）。 数据类型是指 一组值 和 一组对这些值的操作 的集合，Java中有多种 原始数据类型，如int。int是 -2^31 到 2^31 - 1 之间的这些整数值，以及加、减、乘、除等这些操作的集合。理论上所有程序只需要使用这些原始数据类型(int double char等)即可，但如果我们能把原始数据类型抽象成更高级的数据类型（string queue stack等），无疑会更加方便程序的编写。 我们把定义和使用我们自己的数据类型的这个过程，叫做数据抽象。 抽象数据类型（ADT） 是一种能够对使用者隐藏数据表示的数据类型。它将数据和函数的实现关联，并将数据的表示方式隐藏起来。我们在使用抽象数据类型时，主要关注如何操作而不关心数据本身是怎么表示的。也就是说，使用一个抽象数据类型，并不需要了解其实现细节。 三种简单的集合类数据类型背包背包是一种不支持从中删除元素的集合数据类型。它主要用于帮助用例收集元素，然后遍历这些的元素。这些元素没有顺序。 队列队列是一种先进先出（FIFO）策略的集合类型。 栈栈是一种后进先出（LIFO）策略的集合类型。栈的应用非常广泛，例如几乎每个编辑器都有的Undo操作（撤销）、操作系统中的程序调用栈、括号/符号匹配等等。 栈的典型应用 逆序输出（十进制转其他进制） 括号匹配 Dijkstra双栈算式表达式求值法，将操作数和运算符分别放入两个栈中，遇到左括号“（” 则忽略，遇到操作数则将操作数压入栈1中，遇到运算符将它压入栈2中，遇到右括号，则弹出运算符和操作数，计算结果后重新压入栈中。 如何用两个栈实现一个队列？添加时往A栈添加。删除时，先判断B栈是否为空，如果非空，直接从B栈取出最顶元素删除，如果为空，先把A栈里的元素全部倒入B栈中，然后删除最顶元素。 什么是对象的游离在一个栈中，当我们使用pop()弹栈的时候，被弹出的元素我们再也不需要用到它了。但它的引用还存在于数组中。这种情况就称为游离。在 Java 中，避免对象游离很容易，只需将其设为 null 即可。这样系统（Java垃圾回收策略）就可以在使用完后将其回收。 数组背包、队列和栈是三种简单的数据类型。那么我们如何去组织上述的数据类型呢？这时候就要用到数组和链表了。这里先介绍数组： 数组，简单来说就是将所有的数据排成一排存放在系统分配的一个内存块上，通过使用特定元素的索引作为数组的下标，可以在常数时间内访问数组元素的这么一个结构。 数组的优点 简单、易用 访问元素快（常数时间） 数组的缺点 大小固定：数组在使用前必须先制定固定的大小，可能会造成浪费或者不够用溢出 连续空间块：数组初始分配空间时，有时候无法分配能存储整个数组的内存空间（当数组规模太大时） 插入操作实现复杂：往一个大数组中间插入数据，插入索引后面的数据都要相应地往后移动，这会造成很大的开销 算法1.1 下压（LIFO）栈的数组实现（能够动态调整数组大小的实现）1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859import java.util.Iterator;public class ResizingArrayStack&lt;Item&gt; implements Iterable&lt;Item&gt; { //栈元素 private Item[] a = (Item[]) new Object[1]; //元素数量 private int N = 0; //判断是否为空 public boolean isEmpty(){ return N == 0; } //栈的大小 public int size(){ return N; } //将栈移动到一个大小为max的新数组 private void resize(int max){ Item[] temp = (Item[]) new Object[max]; for (int i = 0; i &lt; N; i++) { temp[i] = a[i]; } a = temp; } //将元素添加到栈顶 public void push(Item item){ if (N==a.length) resize(2*a.length); a[N++] = item; } // 弹栈 public Item pop(){ Item item = a[--N]; //避免对象游离 a[N] = null; if ( N &gt;0 &amp;&amp; N == a.length/4) resize(a.length/2); return item; } @Override public Iterator&lt;Item&gt; iterator() { return new ReverseArrayIterator(); } public class ReverseArrayIterator implements Iterator&lt;Item&gt; { private int i = N; public boolean hasNext() { return i &gt; 0; } public Item next() { return a[--i]; } public void remove() { } }} 四、什么是链表链表是一种递归的数据结构。它或者为空（null），或者是指向一个结点（node）的引用，该结点含有一个泛型元素和一个指向另一条链表的引用。对于链表来说，初始时仅需要分配一个元素的存储空间。添加新的元素也很容易，不需要做任何内存复制和重新分配的操作。 链表的优点 动态，大小不固定 离散，在内存空间里存储不必连续 链表的缺点 没有随机访问的能力，访问一个元素必须先访问它的上一个元素 链表中的额外指针引用需要浪费内存 链表操作1. 定义结点1234private class Node{ Item item; Node next;} 2. 访问链表如果有一个链表的对象实例 first，那么我们可以用 first.item 和 first.next 访问它的实例变量。 3. 构造链表12345678910111213//创建三个链表对象实例Node first = new Node();Node second = new Node();Node third = new Node();//每个实例的值first.item = \"to\";second.item = \"be\";third.item = \"or\";//指向下一个实例first.next = second;second.next = third; 我们先 new 了三个链表对象实例，然后给他们的Item赋值，并让他们的next指向下一个链表的引用。（链表是递归的数据结构） 在这里，third.next是null，也就是third.next指向了一个空链表。 链表表示的是一列元素。 4. 在表头插入结点123456789//步骤一：保存原来的表头Node oldfirst = first;//步骤二：创建新的首结点first = new Node();//步骤三：设置新结点的实例变量first.item = \"not\";first.next = oldfirst; 5. 删除头结点1first = first.next; 6. 在表尾插入结点123456789//步骤一：保存指向尾结点的链接Node oldlast = last;//步骤二：创建新的尾结点last = new Node();last.item = \"not\";//步骤三：将尾链接指向新结点oldlast.next = last; 算法1.2 下压堆栈（链表实现）123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051import java.util.Iterator;public class Stack&lt;Item&gt; implements Iterable&lt;Item&gt;{ //栈顶 private Node first; // 元素数量 private int N; //定义结点 private class Node{ Item item; Node next; } // 判断栈是否为空 public boolean isEmpty(){ return N == 0;} // 栈的大小 public int size(){ return N;} //向栈顶添加元素 public void push(Item item){ Node oldfirst = first; first = new Node(); first.item = item; first.next = oldfirst; N++; } //从栈顶删除元素 public Item pop(){ Item item = first.item; first = first.next; N--; return item; } //实现迭代 public Iterator&lt;Item&gt; iterator(){ return new ListIterator(); } private class ListIterator implements Iterator&lt;Item&gt;{ private Node current = first; public boolean hasNext(){ return current != null; } public void remove(){ } public Item next(){ Item item = current.item; current = current.next; return item; } }} 算法1.3 先进先出队列(链表实现)123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657import java.util.Iterator;public class Queue&lt;Item&gt; { //指向最早添加的结点的链接 private Node first; //指向最近添加的结点的链接 private Node last; // 元素数量 private int N; //定义结点 private class Node{ Item item; Node next; } // 判断队列是否为空 public boolean isEmpty(){ return first == null;} // 队列的大小 public int size(){return N;} //向表尾添加元素 public void enqueue(Item item){ Node oldlast = last; last = new Node(); last.item = item; last.next = null; if (isEmpty()) first = last; else oldlast.next = last; N++; } //从表头删除元素 public Item dequeue(){ Item item = first.item; first = first.next; if (isEmpty()) last = null; N--; return item; } //实现迭代 public Iterator&lt;Item&gt; iterator(){ return new ListIterator(); } private class ListIterator implements Iterator&lt;Item&gt;{ private Node current = first; public boolean hasNext(){ return current != null; } public void remove(){ } public Item next(){ Item item = current.item; current = current.next; return item; } }}","link":"/post/a7047cb5.html"},{"title":"数据结构（六）查找算法","text":"什么是查找有时候我们需要搜索信息，例如，在数组中找出某个元素，或者找出某个集中是否有某个对象。我们把寻找目标信息的过程，叫做查找。 顺序查找 和 二分查找 是查找的基本方法。 当我们需要高效查找时，我们可以用 符号表（或者叫字典、索引） 来表示一张抽象的表格。符号表（symbol table）是一种存储键值对的数据结构。目的是将一个键和一个值联系起来，使我们可以通过键找到值。这种数据结构包括两种操作： 插入（put）：将一组新的键值对存入表中 查找（get）：根据给定的键，找到相应的值 生活中不乏符号表的例子： 字典：通过单词找到释义 网络搜索：通过关键字找到网页 账户管理：通过账号找到交易详情 在计算机科学中，有三种经典的高效符号表： 二叉查找树（或者叫二叉搜索树，Binary Search Tree, BST） 红黑树（基于平衡查找树, AVL） 哈希表（或者叫散列表） 顺序查找和二分查找顺序查找顺序查找，简单地说，就是遍历。从顺序表中逐个与目标值进行比对，直到找到匹配元素。 123456789public static int SequenceSearch(int[] arr, int key){ for (int i = 0; i &lt; arr.Length; i++){ if (arr[i] == key){ return i; } } return -1;} 二分查找先把一个序列 从小到大排序，取中间元素与目标值进行比对，如果中间元素比目标值大，就在中间点左半边继续取中间点，否则在右半边取中间点。 1234567891011121314151617181920212223242526272829303132333435363738import java.util.Arrays; public static int binarySearch(int[] arr, int target){ int low = 0; int high = arr.length -1; int mid; while (low &lt;= high){ // 每次调整后，中间值重新计算 mid = (low + high) / 2; // 如果目标值大于中间值，将 low 调整到中间+1（下一次将查找右半边） if (target &gt; arr[mid]) low = mid + 1; // 如果目标值小于中间值，将 high 调整到中间-1（下一次将查找左半边） else if (target &lt; arr[mid]) high = mid - 1; // 如果目标值等于中间值，返回 else return mid; } // 没有找到，返回 -1 return -1; } public static void main(String[] args) { // 前提：数组一定要是有序 int[] testArr = {3,4,8,10,11, 66, 80, 128}; System.out.println(Arrays.toString(testArr)); int result = binarySearch(testArr, 128); if ( result == -1 ) System.out.println(\"没有找到目标\"); else System.out.println(\"在数组下标 \" + result + \" 处找到目标\"); }} 哈希什么是哈希（Hash）？Hash就是把任意长度的输入通过散列算法，变换成固定长度的输出，该输出就是散列值（哈希值）。 这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，所以不可能从散列值来唯一地确定输入值。简单的说，哈希就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。 所有散列函数都有如下一个基本特性：根据同一散列函数计算出的散列值如果不同，那么输入值肯定也不同。但是，根据同一散列函数计算出的散列值如果相同，输入值不一定相同。 哈希函数哈希函数（散列函数）就是把键转换为数组的下标的过程。对于不同数据类型的键，有不同的哈希函数方法，例如： 正整数：除留余数法（选择大小为素数M的数组，对于任意正整数k，计算k除以M的余数。简单地说，就是 k % M） 浮点数：乘以M并四舍五入得到一个 [0,M-1] 之间的索引值。（但是这样做会让高位作用大，低位作用小，解决办法是将建转换成二进制然后用除留余数法） 字符串：除留余数法 组合键：组合除留余数 当然，除了除留余数法之外，还有直接定址法、数字分析法、平方取中法等来构造哈希函数，这里不展开讲。 在 Java 中，所有数据类型都继承了一个能够返回一个 32 Bits 整数的 hashCode() 方法。每种数据类型的 hashCode() 方法和 equal()方法必须一致。也就是说，a.equal(b)返回 true，那 a.hashCode() 和 b.hashCode() 必然一致。但是反过来却不一定。 哈希表（散列表）哈希表是算法在时间和空间上作出权衡的经典例子。 我们知道，连续的存储结构——数组，在数据的查找和修改上具有很好的优点，很方便，时间复杂度很小。但是在数据的增添和删除上则显得很麻烦，空间复杂度很大。而非连续，非顺序的存储结构——链表，恰和数组相反，数据的增添和删除容易，空间复杂度很小，查找和修改复杂，时间复杂度很大。 而哈希表，既满足了数据的查找和修改很容易，同时又不占用很多空间的特点。 使用哈希的查找算法分为两步： 用哈希函数将被查找的键转化为数组的一个下标值 处理碰撞冲突 为什么会碰撞冲突？因为不同的键通过哈希函数计算出来的值可能一样，比如，17%7=3，24%7=3，那对于键17和键24来说，他们的哈希结果都是3。也就是说，我们把键是17和键是24的数据都存储在了数组下标为3的地方，也就导致了碰撞冲突。 解决碰撞冲突的两种经典方法分别是：拉链法 和 线性探测法。 基于拉链法的哈希表拉链法的处理方式是，将大小为 M 的数组中的每一个元素指向一条链表，链表中的每个节点都存储了哈希值为该元素索引的键值对。 查找分两步： 根据哈希值找到链表； 沿着链表顺序查找相应的键 可以拿我们生活的中的字典做比喻，比如我们要查找 “哈” 这个字，我们先去目录找到“哈”在 351 页。然后我们翻开第 351 页，发现这一页还有其他的比如”蛤”、“铪”等字，我们要在这一页中找到“哈”字所在的位置。 Java 实现 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051public class SeparateChainingHashST&lt;Key, Value&gt;{ private int N; //键值对总数 private int M; //哈希表的大小 // 存放链表对象的数组 // SequentialSearchST是基于无序链表的顺序查找，实现见下面 private SequentialSearchST&lt;Key, Value&gt;[] st; //无参构造函数 public SeparateChainingHashST(){ this(997); // 无参构造函数调用有参构造函数 } //有参构造函数 public SeparateChainingHashST(int M){ //创建M条链表 this.M = M; // Java不支持泛型数组，所以需要强制类型转换 st = (SequentialSearchST&lt;Key, Value&gt;[]) new SequentialSearchST[M]; for (int i=0; i&lt;M ;i++ ) { st[i] = new SequentialSearchST(); } } // 哈希函数：计算哈希值 private int hash(Key key){ return (key.hashCode() &amp; 0x7ffffffff) % M; } //通过键获取值 public Value get(Key key){ return (Value) st[hash(key)].get(key); } //修改某个键对应的内容 public void put(Key key, Value val){ st[hash(key)].put(key, val); } //哈希表中所有键的集合 public Iterable&lt;Key&gt; keys() { Queue&lt;Key&gt; queue = new Queue&lt;Key&gt;(); for (int i = 0; i &lt; m; i++) { for (Key key : st[i].keys()) queue.enqueue(key); } return queue; }} 基于拉链法的哈希表完整实现: SeparateChainingHashST.java 线性探测法（开放定址法）当冲突发生时，使用某种探查(亦称探测)技术在散列表中形成一个探查(测)序列。沿此序列逐个单元地查找，直到找到给定的关键字，或者碰到一个开放的地址(即该地址单元为空)为止（若要插入，若探查到开放的地址，则可将待插入的新结点存人该地址单元）。查找时探查到开放的地址则表明表中无待查的关键字，即查找失败。 引申：hashcode的作用hashCode用于返回对象的散列值，用于在散列函数中确定放置的桶的位置。 hashCode的存在主要是用于查找的快捷性，如Hashtable，HashMap等，hashCode是用来在散列存储结构中确定对象的存储地址的； 如果两个对象相同是 equals 的，那么这两个对象的 hashCode 一定要相同； 如果对象的 equals方法 被重写，那么对象的 hashCode 也尽量重写，并且产生 hashCode 使用的对象，一定要和equals方法中使用的一致，否则就会违反上面提到的第2点； 两个对象的hashCode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object) 方法，只能够说明这两个对象在散列存储结构中，如Hashtable，他们“存放在同一个篮子里”。 二叉查找树（二叉搜索树，BST）二叉搜索树，又称二叉查找树（Binary Search Tree, BST），是一种所有左子树结点的元素小于根节点的数据，所有右子树结点的元素大于根节点数据的二叉树。 注意：在 BST 中，没有键值相等的节点（no duplicate nodes）。 BST 的查找查找方式有点类型二分查找方法，知识这里采用的树结构进行存储。首先与根结点进行判断: 如果当前结点为 null，则直接返回 null 如果当前结点值与查找值相同则返回当前结点 如果当前结点值 &lt; 查找值，则递归地到当前结点的 右孩子 查找 如果当前结点值 &gt; 查找值，则递归地到当前结点的 左孩子 查找 12345678910111213141516171819202122public Tree search(Tree root, int val) { // 1. 如果当前结点为 null，则直接返回 null if(root == null) { return null; } // 2. 如果当前结点值与查找值相同则返回当前结点 if(root.val == val) { return root; } // 3. 当前结点值 &lt; 查找值，则递归地到当前结点的 右孩子 查找 else if (root.val &gt; val) { return search(root.left, val); } // 4. 当前结点值 &gt; 查找值，则递归地到当前结点的 左孩子 查找 else { return search(root.right, val); }} AVL查找树二叉树查找树在插入时没有对二叉树的深度和结构做一个调整，使得叶子结点深度不一，在查找时深度越深的结点时间复杂度越高。最坏情况下退化成为链表。 为了改进查找的时间复杂度，可以使用 平衡二叉树(AVL)，平衡二叉树使得每个结点的左结点和右结点的深度差不超过1。 平衡二叉树通过左旋和右旋，一步步调整二叉搜索树，直至平衡。 多路查找树(B树、B+树)多路查找树包括 B-树 和 B+ 树。 和二叉搜索树每个结点只能存储一个元素，每个结点的孩子数不多于两个的性质不一样，多路查找树每一个结点的孩子数可以多于两个，每一个结点处都可以存储多个元素。B+树在数据库索引技术中用得较多。 B-Tree查找数据时，先在根节点二分查找，命中则直接返回数据，否则对相应区间的指针指向的节点递归进行查找。查找的时间复杂度为O(logN)。由于插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质 B树 和 B+树 的区别B树每个结点都可以存放数据，而B+树只在叶子结点存放数据。 为什么B树（B+树）适合做数据库索引？一般来说，索引本身也很大，很难将索引一次全部载入内存中，通常都是用索引文件。这样索引查找的时候也是需要I/O开销的，评价一个数据结构作为索引的优劣最重要的指标就是在查找过程中磁盘I/O操作次数的渐进复杂度。B-Tree检索一次最多需要访问h个节点。数据库系统的设计者巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。 参考：MySQL索引背后的数据结构及算法原理 红黑树红黑树是一棵二叉搜索树，它在每个结点上增加了一个存储位来表示结点的颜色，可以是RED或BLACK。通过对任一条从根到叶子的简单路径上各个结点的颜色进行约束，红黑树确保没有一条路径会比其它路径长2倍，因此是近乎平衡的。 红黑树的性质： 每个结点的颜色只能是红色或黑色的。 根结点是黑色的。 每个叶子结点（NIL）是黑色的。 如果一个结点是红色的，那么它的两个子结点都是黑色的。 对每个结点，从该结点到其所有后代叶子简单的简单路径上，均包含相同数目的黑色结点。","link":"/post/c61c7436.html"},{"title":"数据结构（三）归并排序算法","text":"一、归并排序简介要将一个有16个元素的数组排序，可以先将它分成两半，每一半8个元素，分别排序，然后将排序好的两个8元素的结果归并起来。 要将一个有8个元素的数组排序，可以先将它分成两半，每一半4个元素，分别排序，然后将排序好的两个4元素的结果归并起来。 要将一个有4个元素的数组排序，可以先将它分成两半，每一半2个元素…… 基于这种思想的排序，就是归并排序。 二、实现思路从上面的图可以看到，归并排序的两个步骤： 第一步：分治即不断地把长数组拆分成两半，直到只有2个了，再排大小。 实现分治非常简单，用递归调用自己，大数组自然会被划分到最小： 123456789101112131415public static void mergeSort(int[] arr, int low, int high){ if (high &lt;= low ) return; // 找到中间点 int mid = (low + high) / 2; // 排序左半边 mergeSort(arr, low, mid); // 排序右半边 mergeSort(arr, mid+1, high); // 左右两边归并 merge(arr, low, mid, high);} 第二步：归并把很多个排好的两半，重新拼接起来，拼到最后，就把所有元素排序好了。 如何实现呢？ 假设原来要排序的数组为a[]，可以先将a[] 全部复制到辅助数组 aux[] 中。然后依次判断： 左半边是否用尽，如果用尽，取右半边的元素，否则2 右半边是否用尽，如果用尽，取左半边的元素，否则3 右半边的当前元素是否小于左半边的当前元素，如果是，取右半边的元素，否则取左半边的元素 12345678910111213141516171819202122232425public static void merge(int[] arr, int low, int mid, int high){ int left = low; int right = mid + 1; // 将数组复制到一个新的临时数组中 int[] tempArr = new int[high+1]; for (int i = low; i &lt;= high; i++) { tempArr[i] = arr[i]; } for (int i = low; i &lt;= high; i++) { // 左半边是否用尽，如果用尽，取右半边的元素 if ( left &gt; mid ) arr[i] = tempArr[right++]; // 右半边是否用尽，如果用尽，取左半边的元素 else if ( right &gt; high ) arr[i] = tempArr[left++]; // 右半边的当前元素是否小于左半边的当前元素，如果是，取右半边的元素 else if ( tempArr[right] &lt; tempArr[left]) arr[i] = tempArr[right++]; // 否则取左半边的元素 else arr[i] = tempArr[left++]; }} 算法2.4 自顶向下的归并排序123456789101112131415161718192021222324public static void mergeSort(int[] arr, int low, int high){ if (high &lt;= low ) return; // 找到中间点 int mid = (low + high) / 2; // 排序左半边 mergeSort(arr, low, mid); // 排序右半边 mergeSort(arr, mid+1, high); // 左右两边归并 merge(arr, low, mid, high);}public static void main(String[] args) { int[] testArr = {3,7,42,8,0,5, 66, 3, 80, 11, 2}; System.out.println(Arrays.toString(testArr)); mergeSort(testArr,0, testArr.length - 1); System.out.println(Arrays.toString(testArr));}","link":"/post/4e99e3ae.html"},{"title":"数据结构（五）优先队列和堆排序","text":"有时候我们会收集一些元素，然后处理当前键值最大的元素。然后再收集更多，再处理。例如，在手机来电、短信、游戏三个程序中，来电的优先级是最高的，我们总希望先处理来电请求。 满足这种场景的数据结构，需要支持两种操作：删除最大（或最小）元素、插入元素。这种数据类型，就叫优先队列。优先队列也是一种队列，但是跟前面提到的先进先出队列不同，优先队列的“出”，是根据优先级来的（最大或最小的先出）。 优先队列在很多地方有应用，例如： 数据压缩：哈夫曼编码算法 最短路径算法：Dijkstra算法 最小生成树算法：Prim算法 事件驱动仿真：顾客排队算法 选择问题：查找第k个最小元素 初级实现数组（无序）我们可以用 前面提到的 下压栈的方式来实现优先队列。 只是在其中加入一段内循环代码，将最大元素和栈顶元素交换，然后弹栈删除它。 数组（有序）在插入操作中添加代码，将较大的元素往右边移动一格，以保证数组有序。这样，栈顶的元素永远是最大的，弹栈删除即可。 链表实现可以用 前面提到的 基于链表的下压栈。 修改 pop() 找到并返回最大的元素， 或者修改 push() 保证所有元素逆序，并用 pop() 删除并返回链表的首元素（最大元素）。 不同实现的比较 实现 插入 删除 寻找最小值 无序数组 1 n n 无序链表 1 n n 有序数组 n 1 1 有序链表 n 1 1 二叉搜索树 logn(平均) logn(平均) logn(平均) 平衡二叉搜索树 logn logn logn 二叉堆 logn logn 1 完全二叉树在讨论堆之前，得先了解一下什么是 完全二叉树（Complete Binary Tree）。在一颗二叉树中，每一个结点都与深度为K的满二叉树中编号从 1 至 n 的结点一一对应，这样的二叉树称为完全二叉树。 堆什么是堆所谓堆，就是利用树的结构来维护一组数据。我们平时说的堆，一般都是指 二叉堆 。如果在一颗完全二叉树中，每个结点都 大于等于 它的两个子节点，那么我们就说这个完全二叉树是 堆有序 的。一组能以堆有序的完全二叉树排序、并在数组中按层级存储的元素，我们就称为二叉堆。二叉堆能够比初级实现更好地实现优先队列。 要点: 完全二叉树 堆有序（父节点 &gt;= 两个子节点） 堆的性质在一个基于完全二叉树的堆中，如果下标从 1 开始，那么 k 的两个子节点分别为 2k 和 2k+1。如果下标从 0 开始，那么 k 的两个子节点分别为 2k+1 和 2(k+1) 通过这个性质，我们可以轻易计算出某个节点的父节点以及子节点的下标。这也就是为什么可以直接用数组来存储堆的原因。 堆有序化上浮法实现堆有序化123456private void swim(int k){ while( k&gt;1 &amp;&amp; less(k/2, k)){ exch(k/2, k); k = k/2; }} 下沉法实现堆有序化 12345678910111213141516171819202122private void sink(int k){ // k 是参考结点， 2*k 是左子结点， &lt;= N 确保子结点有元素 while (2*k &lt;= N){ // j 是子结点，我们要把参考结点跟比较大的子结点做比较 //由于不知道左子结点比较大还是右子结点比较大 // 默认为 左子结点 int j = 2*k; // 左右子节点比较，如果 左子 &lt; 右子，j改为右子 if ( j&lt;N &amp;&amp; less(j,j+1)) j++; // 参考结点跟比较大的子结点比较，如果子结点比较小，直接退出 if ( !less(k,j)) break; // 如果子结点比较大，把比较小的参考结点沉下去 exch(k,j); // 把子结点作为参考结点，继续循环 k = j; }} 基于堆的优先队列算法 2.6 1234567891011121314151617181920212223242526272829public class MapPQ&lt;key extends Comparable&lt;key&gt;&gt;{ private key[] pq; private int N = 0; public MapPQ(int MaxN){ pq = (key[]) new Comparable[maxN+1]; } public boolean isEmpty(){ return N == 0; } public int size(){ return N; } public void insert(Key v){ pq[++N] = v; swim(N); } public Key delMax(){ Key max = pq[1]; //从根节点得到最大元素 exch(1, N--); //将其和最后一个结点交换 pq[N+1] = null; //防止对象游离 sink(1); //恢复堆有序 return max; }} 堆排序基于优先队列的排序方法：将所有元素插入一个查找最小元素的优先队列，然后重复调用删除最小元素的操作，将他们按顺序删去。 堆排序就是一种这样的方法。分为两个阶段： 构造堆：将数组以堆的形式安排 下沉排序：按递减顺序取出所有元素，得到排序结果 算法2.7 123456789public static void sort(Comparable[] a){ int N = a.length; for (int k=N/2; k&gt;=1 ;k-- ) sink(a, k, N); while(N&gt;1){ exch(a, 1, N--); sink(a, 1, N); }} 排序算法总结 算法 稳定性 原地 时间复杂度 空间复杂度 备注 选择排序 不稳定 是 N² 1 插入排序 稳定 是 (N,N²) 1 取决于输入元素的排列情况 希尔排序 不稳定 是 NlogN ? 1 快速排序 不稳定 是 NlogN lgN 效率由概率提供保证 三向快速排序 不稳定 是 (N,NlogN) lgN 归并排序 稳定 否 NlogN N 堆排序 不稳定 是 NlogN 1 快速排序是最快的通用排序算法。Java系统库中 java.util.Arrays.sort() 根据不同的类型参数使用了不同的排序方法。对于原始数据类型，Java选择了三向快速排序，而对于引用类型，则是用归并排序。这些选择实际上是用速度和空间来换取稳定性。 本文部分内容参考自： 数据结构与算法(4)——优先队列和堆","link":"/post/18ede324.html"},{"title":"数据结构（七）树和二叉树","text":"什么是树我们知道，链表是一种线性递归的数据结构。前一个结点指向后一个结点，线性地链接起来。树跟链表类似，只不过树的结点与结点之间，不再是单个线性地链接，而是一个结点可以指向多个其他结点。 树的相关术语 根节点：根节点是一个没有双亲结点的结点，一棵树中最多有一个根节点 边：双亲结点到孩子结点的链接 叶子结点：没有孩子结点的结点 兄弟结点：拥有相同双亲结点的所有孩子结点 祖先结点：如果存在一条从根节点到结点q的路径，其结点p出现在这条路径上，那么就可以吧结点p叫作结点q的祖先结点，结点q也叫做p的子孙结点 结点的大小：结点的大小是指子孙的个数，包括其自身 树的层：位于相同深度的所有结点的集合叫作树的层 结点的深度：是指从根节点到该节点的路径长度（上图G点的深度为2，A—C—G） 结点的高度：结点到树中最深结点的路径长度，只含有根节点的树的高度为0。（B的高度为2，B—F—J） 二叉树如果一棵树中所有的结点都只有0，1 或者 2个孩子结点，那么这棵树就是二叉树。 二叉树的应用 编译器中的表达式树 用于数据压缩算法中的赫夫曼编码树 支持在集合中查找、插入和删除，其平均时间复杂度为O(lognn)的二叉搜索树（BST） 优先队列（PQ），它支持以对数时间（最坏情况下）对集合中的最小（或最大）数据元素进行搜索和删除 遍历二叉树访问树中所有结点的过程叫作树的遍历。如果用递归的思想去进行遍历就不难理解了。 前序遍历前序遍历的规则如下： 访问根节点； 按前序遍历方式遍历左子树； 按前序遍历方式遍历右子树. 上图使用前序遍历的结果为： 1 2 4 5 3 6 7 1234567void preOrder(BinaryTreeNode root) { if (null != root) { System.out.println(root.getData()); preOrder(root.getLeft()); preOrder(root.getRight()); }} 中序遍历中序遍历的规则如下： 按中序遍历方式遍历左子树； 访问根节点； 按中序遍历方式遍历右子树. 上图使用中序遍历的结果为：4 2 5 1 6 3 7 1234567void inOrder(BinaryTreeNode root) { if (null != root) { inOrder(root.getLeft()); System.out.println(root.getData()); inOrder(root.getRight()); }} 后序遍历后序遍历的规则如下： 按后序遍历方式遍历左子树； 按后序遍历方式遍历右子树； 访问根节点. 上图使用后序遍历的结果为：4 5 2 6 7 3 1 1234567void postOrder(BinaryTreeNode root) { if (null != root) { postOrder(root.getLeft()); postOrder(root.getRight()); System.out.println(root.getData()); }} 二叉搜索树(BST)二叉搜索树，又称二叉查找树（Binary Search Tree, BST），是一种所有左子树结点的元素小于根节点的数据，所有右子树结点的元素大于根节点数据的二叉树。","link":"/post/f65fff79.html"},{"title":"数据库（二）存储引擎、事务、锁","text":"存储引擎存储引擎是数据库的底层软件组织。不同的存储引擎提供不同的存储机制、索引技巧、锁定水平等功能，使用不同的存储引擎，可以获得其各自特定的功能。 InnoDBInnoDB 是 MySQL 默认的存储引擎，它是面向在线事务处理(OLTP)的应用，被设计用来处理大量的短期（short-lived）事务。 特点： 采用 MVCC（多版本并发控制）来支持高并发 支持事务，实现了 4 个事务隔离级别，默认级别是可重复读 通过间隙锁（next-key locking）防止幻读，间隙锁使得 InnoDB 不仅仅锁定查询涉及的行，还会对索引中的间隙进行锁定，防止幻影行的插入 聚簇索引，主键查询性能高，但二级索引（非主键索引）必须包含主键列，如果主键列很大，其他索引都会很大 存储格式平台独立 行锁设计 支持外键 支持一致性非锁定读（默认情况下读取操作不会产生锁） 提供了插入缓冲，二次写，内存自适应哈希索引，预读等高性能和高可用的功能 支持真正的热备份 一句话概括：InnoDB的优势在于提供了良好的事务处理、崩溃修复能力和并发控制。缺点是读写效率较差，占用的数据空间相对较大。 MyISAMMyISAM 存储引擎表由 .MYD 和 .MYI 组成，.MYD用来存放数据文件，.MYI用来存放索引文件，特点： 不支持事务 表锁设计，读取共享锁，写入排他锁。但是在读取查询的同时也能插入记录（并发插入） 支持全文索引 压缩 空间函数（GIS） 它的缓冲池只缓冲索引文件，而不缓冲数据文件 崩溃后无法安全修复 一句话概括：MyISAM的优势在于占用空间小，处理速度快。缺点是不支持事务的完整性和并发性。如果表经常读取，且不需要事务，MyISAM是合适的选择。 MEMORY将表中的数据存放在内存中，如果数据库重启或发生崩溃，表中的数据库都将消失，它非常适合存储临时数据的临时表．默认采用哈希索引。 三种存储引擎的比较 事务什么是事务？事务就是由一组SQL语句组成的逻辑处理单元，一个事务中的SQL语句组，要么全部执行，要么全部不执行。 12345START transaction;SELECT ... FROM ...UPDATE checking SET ...DELETE savings FROM ...COMMIT; 事务的自动提交（AUTOCOMMIT）如果不显式开始一个事务，则每个查询都被当作一个事务执行提交操作。 12SHOW VARIABLES LIKE 'AUTOCOMMIT';SET AUTOCOMMIT = 1; // 1 或 ON 表示启用，0 或 OFF 表示禁用 事务的并发问题 脏读：事务A读取了事务B更新的数据，然后B回滚操作，那么A读取到的数据是脏数据 不可重复读：事务 A 多次读取同一数据，事务 B 在事务A多次读取的过程中，对数据作了更新并提交，导致事务A多次读取同一数据时，结果不一致。 幻读：事务A在读取某个范围内的记录时，事务B又在该范围内插入新的记录，事务A再次读取该范围的记录时会产生幻行。（两次不一致） 不可重复读侧重于记录被修改，幻读侧重于新增或删除了记录。解决不可重复读的问题只需锁住满足条件的行，解决幻读需要锁表。 事务的四大特征事务的四个基本特征：ACID 原子性（Atomicity）：一个事务必须被视为不可分割的最小工作单元。一个事务中的所有操作，要么全部成功提交，要么全部失败回滚。不可能只执行其中的一部分操作。 一致性（Consistent）：在事务开始和完成时，数据都必须保持一致状态，或者说从一个一致性状态转换到另一个一致性状态。不会出现查询开始时的数据跟查询到一半的数据不一样的情况。 隔离性（Isolation）：数据库系统提供一定的隔离机制，保证事务在不受外部并发操作影响的独立环境执行。这意味着 事务处理过程中的中间状态对外部是不可见的，反之亦然。事务隔离分为不同级别，包括未提交读（Read uncommitted）、提交读（read committed）、可重复读（repeatable read）和串行化（Serializable）。 持久性（Durability）: 事务完成之后，它对于数据的修改是永久性的，即使出现系统故障也能够保持。 事务的ACID特性可以确保银行不会弄丢你的钱，因此很重要。 事务的四种隔离级别（Isolation level）事务的隔离级别规定了哪些修改在事务内和事务间是可见的，哪些是不可见的。较低级别的隔离并发程度高，开销低。 未提交读(read uncommitted)事务中的修改，即使未提交，对其他事务也都是可见的。事务可以读取未提交的数据，这也称为脏读（Dirty Read）。该级别性能不必其他级别好太多，带来的问题却不少，不建议使用。 提交读(read committed)只有提交了，其他事务才能读到。即一个事务从开始到提交之前，所做的任何修改对其他事务都是不可见的。这个级别有时候叫做不可重复读，因为同一事务自己两次执行同样的查询，期间可能有其他事务修改并提交了数据，因此两次查询可能会得到不一样的结果。 可重复读(repeatable read)解决了脏读问题，该级别保证了在同一个事务中多次读同样记录的结果是一致的，理论上无法解决幻读问题。(MySQL InnoDB通过 MVCC 解决幻读问题)。 该级别是 MySQL 的默认隔离级别。 可串行化(serializable)它通过强制事务串行执行，避免了前面说的幻读的问题。该级别用得较少。 改变事务的隔离级别1SET TRANSACTION ISOLATION LEVEL READ COMMITTED; 如何修改 MySQL 隔离级别 查看当前会话隔离级别 1select @@tx_isolation; 查看系统当前隔离级别 1select @@global.tx_isolation; 设置当前会话隔离级别 1set session transaction isolatin level repeatable read; 设置系统当前隔离级别 1set global transaction isolation level repeatable read; 锁（并发控制）当数据库表同时被多个事务读写时，一个事务正在读取，另一个事务将记录删除了，将会导致不可预期的结果。因此，引入锁的概念来解决并发控制问题。 锁的分类共享锁和排他锁共享锁（shared lock）也叫做读锁，如果一个事务对数据对象A加了共享锁，其他事务只能读而不能写，直至当前事务释放该锁。 排他锁（exclusive lock）也叫做写锁，如果一个事务对数据对象A加了排他锁，其他事务不能再对A加锁，包括读和写，直至当前事务释放该锁。 乐观锁和悲观锁悲观锁假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。而乐观锁假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。 乐观锁 不能 解决脏读的问题。所谓脏读，就是一个事务读取了另一个事务未提交的数据。例如，事务T1更新了一行记录内容，但并没有提交修改。事务T2读取更新后的行，然后T1执行回滚操作。T2读取的行就无效了。 锁的粒度加锁也需要消耗资源，数据库的目标是存取数据，而不是花费大量的时间来管理锁。很多商业数据库通常都是在表上加行锁，但 MySQL 不同的存储引擎实现了不同的锁策略和锁粒度,提供了多种选择。 在 MySQL 中， MySQL有三种级别的锁定： 表锁（table lock）实现逻辑简单，带来的系统负面影响最小。获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所以可以很好的避免死锁问题。当然，锁定颗粒度大所带来最大的负面影响就是出现锁定资源争用的概率也会最高，致使并发程度大打折扣。 页锁（page lock）锁定颗粒度介于行级锁定与表级锁之间。页级锁定和行级锁定一样，会发生死锁。 行级锁（row lock）锁定颗粒度很小，发生锁定资源争用的概率也最小。能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能。但由于锁定资源的颗粒度很小，所以每次获取锁和释放锁需要做的事情也更多，带来的消耗自然也就更大了。最容易发送死锁。 在 MySQL 中，行级锁只在存储引擎层实现，服务器层并不了解存储引擎中的锁是如何实现的。不同的存储引擎有不同的行锁实现。 死锁问题 解决一：InnoDB 存储引擎一旦检测到死锁的循环依赖，就会立即返回一个错误。具体做法是，将持有最少行级排他锁的事务进行回滚。 解决二：当查询超时自动放弃锁请求，这种方式不太友好。 锁的行为是存储引擎相关的，有些死锁是真正的数据冲突，而有些是存储引擎的实现导致的。 数据库三大范式第一范式（1NF）属性不可分。当关系模式R的所有属性都不能再分解为更基本的数据单位时，称R是满足第一范式的。 例如，某些数据库系统中需要用到“地址”这个属性，本来直接将“地址”属性设计成一个数据库表的字段就行。但是如果系统经常会访问“地址”属性中的“城市”部分，那么就有必要要将“地址”这个属性重新拆分为省份、城市、详细地址等多个部分进行存储，这样在对地址中某一部分操作的时候将非常方便。而“省份”、“城市”这些属性就是不可再分的了。 符合1NF的表 第二范式（2NF）符合1NF，并且表中的每列都和主键相关。也就是说，在一个数据库表中，一个表中只能保存一种数据，不可以把多种数据保存在同一张数据库表中。 符合2NF的表 第三范式（3NF）符合2NF，并且，消除传递依赖。即每一列数据都和主键直接相关，而不能间接相关。 符合3NF的表 参考： https://www.cnblogs.com/linjiqin/archive/2012/04/01/2428695.html https://www.zhihu.com/question/24696366/answer/29189700 范式化的优缺点 优点：更新操作快，没有冗余数据（意味着更少的GROUP BY和 DISTINCT），表数据通常较少可以更好地放进内存因此执行操作更快 缺点：需要关联，同时可能使某些索引失效 《高性能MySQL》中提到，实际中经常需要混用范式化和反范式化，不要极端地完全去范式化。 事务日志事务日志用于提高事务效率。 存储引擎修改表数据时，只需修改内存拷贝，然后把修改记录持久在硬盘的事务日志中，而不用每次都把修改的数据本身持久到硬盘中。之后把再内存修改的数据再慢慢刷回磁盘中。 多版本并发控制（MVCC）MVCC 是行锁的变种，使用非阻塞读操作避免加锁，写操作也只锁定必要的行，因而开销更低。 MVCC 是通过保存数据在某个时间点的快照来实现的。不管事务执行多少时间，每个事务看到的数据都是一致的。 InnoDB 的 MVCC 实现在每行记录后面保存两个隐藏列。一个保存行的创建时间，一个保存行的过期时间（删除时间）。这里的时间，指的是系统版本号，不是真正的时间。每开始一个事务，系统版本号都会递增。 SELECT：只查找早于当前版本的数据行，删除时间要么未定义，要么大于当前版本号。 INSERT：为插入的行保存当前版本号。 DELETE：为删除的行保存当前版本号，作为删除标志。 UPDATE：先插入一行新记录作为新版本号，再保存当前版本号到原来的行作为行删除标志。 MVCC的好处是读操作简单，性能好，不足是需要额外的存储空间和行检查、维护工作。 MVCC 只在提交读（READ COMMITTED）和可重复读（REPEATABLE READ）两个隔离级别下工作。 MySQL 的大小写敏感MySQL 使用文件系统的目录和文件来保存数据库和表的定义，因此大小写敏感与平台相关。在 Windows 下大小写不敏感，而类Unix系统则是敏感的。","link":"/post/4c81d70.html"},{"title":"数据结构（四）快速排序算法","text":"快速排序简介在归并排序中，我们将一个数组分为两半，每一半又再分为两半，分到最后再一步步归并。 快速排序和归并排序是互补的：快速排序先选定一个元素，比这个元素小的放在左边，比这个元素大的放在右边，每一半，也都选一个元素，比它小的放左边，比它大的放右边。不断地选、分下去。 如何切分假设我们选取数组的第一个元素为切分（partition）元素，如何把小于它的元素放在左边，大于它的元素放在右边呢？ 选取第一个元素 arr[low] 为参考元素 从左边向右，每一个元素都跟参考元素做比较，直到找到比参考元素大的 从右边向左，每一个元素都跟参考元素做比较，直到找到比参考元素小的 交换第 2，3 步 的两个元素（也就是把大的放右边、小的放左边） 重复 2、3、4，直到扫描完 将参考元素arr[low]放到中间位置 12345678910111213141516171819202122232425262728293031323334private static int partition(int[] arr, int low, int high) { // 1.选取第一个元素为参考元素 int refer = arr[low]; int left = low; int right = high + 1 ; // 这里要加一 // 重复 2.3.4 while (true){ // 2.从左边向右，每一个元素都跟参考元素做比较，直到找到比参考元素大的 while ( arr[++left] &lt; refer ){ // 如果到达最右了，不再向右 if (left == high) break; } // 3.从右边向左，每一个元素都跟参考元素做比较，直到找到比参考元素小的 while ( arr[--right] &gt; refer ){ // 如果到达最左了，不再向左 if (right == low) break; } // 5. 检查是否扫描完 if (left &gt;= right) break; // 4. 交换刚刚两个元素 Swap.swap(arr, left, right); } // 6. 将参考元素`arr[low]`放到中间位置 Swap.swap(arr, low, right); return right; } 算法2.5 快速排序 先切分，再排序左半边，排序右半边 排序左半边的时候，又会切分，排序左半边右半边，排序右半边的时候，也会切分，排序左半边右半边 递归下去 12345678910111213141516171819202122232425262728293031323334353637383940package sort;import Jutils.Swap;import java.util.Arrays;/** * 快速排序 * * 思路：先选定一个元素，比这个元素小的放在左边，比这个元素大的放在右边 * 挑出来的每一半，也都选一个元素，比它小的放左边，比它大的放右边。 * 不断地选、分下去。 */public class QuickSort { public static void quickSort(int[] arr, int low, int high){ if (high &lt;= low) return; // 切分，refer 是参考元素 int refer = partition(arr, low, high); // 将切分的左半部分快排 quickSort(arr, low, refer - 1); // 将切分的右半部分快排 quickSort(arr, refer + 1, high); } public static void main(String[] args) { int[] testArr = {3,7,4,8,0,1}; System.out.println(Arrays.toString(testArr)); quickSort(testArr, 0, 5); System.out.println(Arrays.toString(testArr)); }}","link":"/post/a4803490.html"},{"title":"数据库（五）Oracle 和 MySQL 的一些区别","text":"团队最近正在计划将项目从 Oracle 数据库迁移到 MySQL，特此整理一份 Oracle 字段、函数、建表语句的差异。 字段差异整数在 Oracle 中，数字统一使用 NUMBER(m) ，NUMBER(6) 最大值为 999999 ，NUMBER(6,2) 最大值为 9999.99，如果不指定m值，直接写 NUMBER，则默认为浮点数，精度根据实际情况。 在 MySQL 中，整数分为 tinyint、smallint、mediumint、int 和 bigint 五种，区别如下： 整数类型 字节数 比特数 取值范围 tinytint 1字节 8 bit (2^8) -128 到 127 smallint 2字节 16 bit (2^16) -32768 到 32767 mediumint 3字节 24 bit (2^24) -8388608 到 8388607 int 4字节 32 bit (2^32) -2147483648 到 2147483647 bigint 8字节 64 bit (2^64) -9223372036854775808 到 9223372036854775807 在 MySQL 中，int(4) 表示 zerofill 为 4，实际上是可以插入大于 4 位的数值比如 12345，只不过，当不足 4 位的时候，在左边会填充 0 ，例如对于 int(4)， 插入 123，显示的是 0123， 对于 int(5)，插入 123，显示的是 00123。 小数MySQL的小数不建议用 FLOAT 或 DOUBLE，会损失精度，推荐用 DECIMAL 。DECIMAL(6,2) 最大值为 9999.99 Oracle NUMBER(6,2) 最大值为 9999.99 时间在 Oracle 中，DATE 精确到秒，获取当前时间用 sysdate 在 MySQL 中，DATETIME 精确到秒，而 DATE 只精确到天，获取当前时间用 CURRENT_TIMESTAMP 或 NOW() 或 sysdate() 虽然差异很小，但是 CURRENT_TIMESTAMP 和 NOW() 取的是本次查询开始的时间，而 sysdate() 取的是执行到 sysdate() 语句时动态的实时时间。 结果字符集在 Oracle 中，用 ROWNUM 筛选结果集。但 ROWNUM 是一个伪列，即先有结果集，然后再筛选。在一个20行记录的表中，当我们想查询表的第11-20行记录，输入select rownum,c1 from t1 where rownum &gt; 10，我们会得不到任何结果，因为 Oracle 会先筛选出第一条，发现 不满足 &gt; 10，于是排除，将第二条记录放到 1 的位置，发现还是 不满足 &gt; 10，以此类推，20条记录都被推到第一的位置，都不满足 &gt; 10 的条件。简而言之，rownum 条件要包含到 1，否则永远查不到结果。 在 MySQL 中，用 LIMIT 筛选结果集， LIMIT(10)筛选前 10 条，LIMIT(30,10)，从第 31 条开始，取 10 条（即31-40行记录）。 字符串在 Oracle 中，字符串有 VARCHAR2，且只可以用单引号包起字符串。 在 MySQL 中，只有 VARCHAR， MySQL里可以用双引号包起字符串。 NULL和空字符在 Oracle 中，只有 NULL 的概念，没有空字符。 在 MySQL 中，有 NULL，也有空字符。 default创建表结构时，Oracle 允许 default+函数 MySQL 不允许 default+函数（时间函数除外），因此 default user() 是会报错的，解决这一问题只能用触发器，但在开发规范里面触发器是禁止使用的，只能在应用层添加。 函数差异连接字符串在 Oracle 中，连接字符串用 ||。 如 '%'||'es'||'%'，表示任意字符串连接 es 再连接任意字符串。 在 MySQL 中，连接字符串用 concat 函数。如 concat('%', 'es','%')。 子串函数在 Oracle 中，子串用 SUBSTR('abcd', 2, 2) 在 MySQL 中，子串用 substring('abcd',2, 2) 注意：mysql的 start 从 1 开始，如果 start 为 0 ，那么返回空 Oracle 12substr('shit', 0, 1) -- 返回 ssubstr('shit', 1, 1) -- 返回 s MySQL 12substring('shit',0, 1) -- 返回空串substring('shit',1, 1) -- 返回 s 时间转char在 Oracle 中，用 to_char(time, format)： 12SELECT to_char(sysdate, 'yyyy-mm-dd') from dual;SELECT to_char(sysdate, 'hh24-mi-ss') from dual; 在 MySQL 中，用 date_format(time, format)（可表示年月日时分秒多种格式） 或 time_format(time, format)（只可表示时分秒） 12SELECT date_format(now(), '%Y-%m-%d %H:%i:%S');SELECT time_format(now(), '%H:%i:%S'); char 转时间在 Oracle 中，用 to_date(str,format)： 1SELECT to_date(`2019-3-6`, 'yyyy-mm-dd') 在 MySQL 中， 用 str_to_date(str,format)： 1SELECT str_to_date('2019-3-6 16:53:58', '%Y-%m-%d %H:%i:%S') YYYYMM 注意点Oracle 1to_date('201907', 'YYYYMM') -- 返回 2019-7-1 MySQL` 12str_to_date('201907', '%Y%m') -- 返回空串str_to_date('20190701', '%Y%m%d') -- 返回 2019-07-01 所以，遇到 201907 这样的 char 要转成日期，只能用 concat('201907', '01') 时间截取在 Oracle 中，sysdate在当天的零时零分零秒等于 trunc(sysdate) ， trunc 函数用来截取时间。 1234567891011# 当年的第一天trunc(sysdate, 'yy')# 当月的第一天trunc(sysdate, 'mm')# 本周的第一天（周日）trunc(sysdate, 'd')# 当天（零时零分零秒）trunc(sysdate) 在 MySQL 中，只能用 DATE_FORMAT 函数来格式化时间。 12345678# 自定义日期格式SELECT date_format(now(), '%Y-%m-%d');# 当月的第一天SELECT date_format(now(), '%Y-%m-01');# 下个月的第一天SELECT date_add(date_format(now(), '%Y-%m-01'), INTERVAL 1 MONTH) 不过，如果要取当天，Oracle 里的 trunc(sysdate) 在 MySQL 可以直接写成 CURDATE() 日期相加在 Oracle 中，当前时间的三个月后，写法为： 1add_months(sysdate, 3) 在 MySQL 中，写法为： 1date_add(now(), INTERVAL 3 montn) 相差月数在 Oracle 中，用 months_between(日期1，日期2) 计算日期相差的月数 在 MySQL 中，用 timestampdiff(month, 日期1，日期2) nvlnvl(a, b) 如果 a 为 null，则函数结果为b，否则函数结果为a 在 MySQL 中，用 ifnull(a, b) ，注意 ifnull 不能判空串 nvl2在 Oracle 中，nvl2(a,b,c) 的逻辑是： 如果 a 为 null ，则c，否则 b 在 MySQL 中写法为： 1IF ( ISNULL(a), c, b ); 注意 b 和 c 的位置 decode()在 Oracle 中，decode(条件，值1，返回值1，值2，返回值2, ……) 用来选择数据 在 MySQL 中，用 case when 代替 1234case 条件 when '值1' then '返回值1' when '值2' then '返回值2' when ... then ... END 保留两位小数在 Oracle 中，用 to_char(123.345, '0.99') 保留两位小数并转换成字符串 在 MySQL 中，用 convert(123.345, decimal(10,2)) 来保留两位小数 位数不够补空格Oracle，用 to_char(num, '999') ， 会补齐到四位 如： 12[空格]100[空格][空格]83 MySQL，用 LPAD(char, 4, ' ')，第一个参数是传入的字符串，第二个是要补齐到多少位，第三个是补什么。 Oracle 也有 LPAD 函数。 其他获取当前用户在 Oracle 中，用 USER 获取当前数据库连接用户 在 MySQL 中，用 user() 获取当前数据库连接用户 常量在 Oracle 中，有 CONSTANT 关键字，声明一个常量 在 MySQL 中，没有常量的概念 约束在 Oracle 中，可以使用 check 约束某些值的范围，如 Y N 在 MySQL 中，可以使用 check 约束，但没有任何效果，因为 MySQL 底层没有实现。一般这种检查在应用层做。 计列在 Oracle 中，有时候用 1SELECT rownum num FROM table 这样的语法来增加一行辅助列，并在后面 WHERE 用于限制结果集和分页。但在 MySQL 中，直接用 LIMIT 即可。 当 MySQL 确实需要辅助计数列时，可以用以下语法 12SELECT @rownum := @rownum +1 numFROM table t, (SELECT @rownum:=0) tt 左右连接在 Oracle 中，有时候会遇到 123FROM table_a a, table_b b,WHERE a.series = b.code(+) 实际上这是左右连接的特殊写法 (+)符号放在非主表，上面的例子是左连接，在 MySQL 中只能用 JOIN 123FROM table_a aLEFT JOIN table_b bON a.series = b.code 更新或插入某些列值存在时则更新，不存在时则插入一条新记录。在 Oracle 中，用 MERGE INTO 语法。 1234567MERGE INTO tableUSING dualON ( .. = ..)WHEN MATCHED THEN...WHEN NOT MATCHED THEN... 在 MySQL 中，可以用 REPLACE INTO，但主键冲突或唯一索引冲突时，会删除原有数据，再插入。 或者用 INSERT INTO ON DUPLICATE KEY UPDATE ，在主键冲突或唯一索引冲突时更新原数据，否则插入。 12345678910111213INSERT INTO table( ..., ...,)VALUES( ..., ...,)ON DUPLICATE KEY UPDATEcolumn1 = v1,column2 = v2 别名mysql delete语句不支持别名，Oracle可以","link":"/post/65a27c74.html"},{"title":"数据库（三）索引","text":"什么是索引？概念索引是一个单独存储在磁盘上的数据结构，包含着对数据表里所有记录的引用指针。 作用使用索引可以 提高数据库特定数据的查询速度。 实现位置在存储引擎中实现。 结构类型BTree 和 Hash table，具体哪种和表的存储引擎有关。MyISAM 和 InnoDB 只支持 BTree ，MEMORY 同时支持 BTree 和 Hash table。 为什么要用索引？优点： 唯一索引可以保证数据库表中每行数据的唯一性 减少服务器需要扫描的数据量，加快数据的查询速度 加速表和表之间的连接 在使用分组和排序子句进行数据检索时，同样可以显著减少查询中分组和排序的时间 使用索引，可以在查询中使用优化隐藏器，提高系统的性能 将随机IO变为顺序IO 缺点： 创建索引和维护索引要耗费时间，并且随着数据量的增加耗费时间也增加 索引需要占空间内存 在对表中数据进行增、删、改的时候，索引也需要动态维护，这样降低了数据维护速度 索引的分类按逻辑存储结构划分按逻辑存储结构划分，索引可以分为： B Tree索引 Hash索引 空间(Spatial)索引 全文(Fulltext)索引 1. BTree 索引 InnoDB 和 MyISAM 底层都是基于 B+Tree 索引的。适用于 BTree 索引的情况有： 全值匹配：索引可能有多个列，全值匹配就是匹配所有的列。例如，查找姓名列为 Allen，年龄列为 18 的人。 匹配最左前缀：匹配所有姓 Allen 的人。即只使用索引的第一列。 匹配列前缀：匹配某一列的值的开头部分。例如姓以 Al 开头的人。也只使用了索引的第一列。 匹配范围值：匹配查找姓在 Allen 和 Barrymore 之间的人。也只使用索引的第一列。 精确匹配某一列并范围匹配另外一列：查找所有姓为 Allen，并且名字是 K 开头的人。即第一列 last_name 全匹配，第二列 first_name 范围匹配。 只访问索引的查询：查询只需要访问索引，而无需访问数据行。（覆盖索引） 不适用于 B Tree 索引的情况： 非最左：不是按照索引的最左列开始查找，就无法使用索引。例如无法查找姓氏（姓氏是索引的第一列）不知道，但名字（名字是索引第二列）为 Bill 的人。也无法查找姓氏最后以 n 结尾的人，因为姓氏虽然是第一列，但最左值不知道。 跳过列：不能按索引查找姓氏为 “Smith”（第一列），名字（第二列）不知道，年龄为 18 （第三列）的人。如果非要这样查找，那MySQL只会用到第一列姓氏的索引。 某个列存在范围：例如，姓氏为“Smith”，名字以“J”开头，年龄为18的SQL语句... WHERE last_name = 'Smith' AND first_name like 'J%' AND age = 18;，这时索引只有第一列姓氏起作用。 2.Hash索引 Hash在理论上平均时间复杂度能达到O(1)，非常快，经常用在内存中。在数据库领域，数据更多的是放在磁盘中，Hash索引 跟 B tree索引 相比还是有一定的局限性，主要体现在： Hash索引的无序性导致无法范围查找，像 &gt;、&lt;=、between 等是无能为力的 需要对完整的key计算Hash，因此不支持部分匹配。像 like 'jerr%' 这样的前缀匹配无能为力 无法实现索引覆盖 Hash碰撞冲突代价高 3.全文索引简单地说，全文索引就是在一堆文字中，通过其中的某个关键字等信息，就能找到该字段所属的记录行。 注意：全文索引只有在 MyISAM 引擎上才能使用，且只能在CHAR,VARCHAR,TEXT类型字段上使用。 4.空间索引空间索引是对空间数据类型的字段建立的索引。 传统的索引不能很好的索引空间数据，我们需要一种方法能对空间数据进行索引，例如专门对地图上景点数据的索引，这就是空间索引。 MySQL中的空间数据类型有四种： GEOMETRY （几何体） POINT （点） LINESTRING （线） POLYGON （多边形） 在创建空间索引时，使用SPATIAL关键字。当引擎为MyISAM，创建空间索引的列，必须将其声明为 NOT NULL。 按功能或约束划分普通（单列）索引1CREATE INDEX indexName ON mytable(username(length)); 如果是CHAR，VARCHAR类型，length可以小于字段实际长度；如果是BLOB和TEXT类型，必须指定 length。 唯一索引索引列的值必须唯一，但允许有空值。如果要禁止空值，则成为主键索引。 1CREATE UNIQUE INDEX indexName ON mytable(username(length)) 主键索引主键索引是一种特殊的唯一索引，作用于主键。 特别注意： 主键索引的叶子节点存的是整行数据。在InnoDB里，主键索引也被称为聚簇索引（clustered index）。 非主键索引的叶子节点内容是主键的值。在InnoDB里，非主键索引也被称为二级索引（secondary index）。 聚簇索引和二级索引的区别假设有数据行： ID name age 500 Jerry 18 age 列有普通索引，ID 列有主键索引 执行以下语句： 1select * from T where age = 18; 首先会在 age 列索引找到 18，普通索引存储的是主键值，得到 ID 为 500，在根据 ID = 500 找到这一数据行的全部数据，这个过程叫回表。 而直接执行： 1select * from T where ID = 500; 直接通过聚簇索引找到 500 处，直接得到行数据。 组合索引（多列索引）在表中的多个字段组合上创建的索引，只有在查询条件中使用了这些字段的左边字段时，索引才会被使用，使用组合索引时遵循最左前缀集合。 MySql会一直向右匹配直到遇到范围查询(&gt;、&lt;、between、like)就停止匹配，比如a = 1 and b = 2 and c &gt; 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。 什么时候该创建索引？ 主键：对于主键，会自动建立一个唯一索引，以保证值唯一 频繁查询：对于频繁查询的表或字段，建立索引无疑会提高查询效率 查询中需要排序的字段：使用索引去访问排序字段将大大提高排序速度 查询中需要统计或者分组字段 什么时候不该使用索引？ 表记录太少 经常增删改的字段（因为修改字段的同时还要动态维护索引） WHERE 条件用不到的字段不需要索引 过滤性（选择性）不好的字段不适合使用索引，例如0/1，男/女 索引的底层实现MyISAM 索引实现MyISAM 索引使用了 B+Tree 作为索引结构，叶子结点的 data 域存放的是数据记录的地址。MyISAM中索引检索的算法为首先按照 B+Tree 搜索算法搜索索引，如果指定的Key存在，则取出其data域的值，然后以data域的值为地址，读取相应数据记录。主索引和辅助索引的存储结构没有任何区别。 InnoDB 索引实现虽然InnoDB也使用B+Tree作为索引结构，但具体实现方式却与MyISAM截然不同。 MyISAM索引文件和数据文件是分离的，索引文件仅保存数据记录的地址。而在InnoDB中，表数据文件本身就是按 B+Tree 组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。 与 MyISAM 不同之处（聚簇索引）第一个与 MyISAM 不同的是 InnoDB 的数据文件本身就是索引文件。数据行放在索引的叶子叶，这种索引叫做聚簇索引。“聚簇”的意思是，数据行和相邻的键值紧凑地存储在一起。 第二个与 MyISAM 的不同是 InnoDB 的二级索引 data 域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。 因为 InnoDB 的数据文件本身要按主键聚集，所以 InnoDB 要求表必须有主键（MyISAM可以没有）。通常，InnoDB 被索引的列是主键列，因为 InnoDB 通过主键来聚集数据。如果没有定义主键，InnoDB会选择一个唯一的非空索引替代，如果表中没有这样的列，InnoDB 会隐式出定义一个主键来作为聚簇索引。 为什么聚簇索引要用 B+ 树，而不是B树？ B+树由于只在叶子节点有 data，单一节点比B树可以存储更多的元素，树更“矮胖”，查询的IO次数更少。 所有叶子节点形成有序链表，便于范围查询。 参考：MySQL性能优化[理论篇]-B树索引与hash索引 选择合适的主键由于聚簇索引底层由B+树组织，建议使用连续递增的数值作为主键（AUTO_INCREMENT是最好的）。相反，如果用无序的 UUID 作为主键，性能将非常糟糕。 在分布式情况下，常用 Twitter 开源的 Snowflake 雪花算法，在应用层生成主键。 什么时候索引会失效？索引可以包含多个列的值，但是列的顺序十分重要，MySQL只能高效地使用索引的最左前缀列。 WHERE 条件有 不等于号 WHERE 条件使用了表达式或函数，如SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5; JOIN中，MySQL只有在 主键和外键的数据类型相同 时才能使用索引，否则无效 LIKE ‘abc%’，MYSQL将使用索引；但 LIKE ‘%abc’，MySQL将不使用索引。 使用 OR 一般会使索引失效 如果列类型是字符串，那一定要在条件中将数据使用引号引用起来，否则不使用索引。","link":"/post/a7354b8d.html"},{"title":"数据库（一）给自己的SQL基础知识备忘","text":"SQL简介SQL （Structured Query Language，结构化查询语言）是一种大小写不敏感的标准语言，用于帮助我们访问数据库。 SQL 包含两大部分 DML 和 DDL 两部分。 DML（data manipulation language，数据操作语言）DML包括： SELECT：从数据库表中获取数据 UPDATE： 更新数据库表中的数据 DELETE：从数据库表中删除数据 INSERT INTO：向数据库表中插入数据 … DDL（data definition language，数据定义语言）。DDL包括： CREATE DATABASE：创建新数据库 ALTER DATABASE：修改数据库 CREATE TABLE：创建新表 ALTER TABLE：变更数据库表 DROP TABLE：删除数据库表 CREATE INDEX：创建索引 DROP INDEX：删除索引 TRUNCATE TABLE：清空表 RDBMSRDBMS（Relational Database Management System，关系型数据库管理系统）是将数据组织为相关的行和列的系统，其数据存储在被称为表（tables）的数据库对象中。表是相关的数据项的集合，由列和行组成。常见的RDBMS有 MS SQL Server、MySQL、Oracle 等。 Ubuntu 18.04 安装 Mysql 5.7注：如果要安装 Mysql 8.0 ，可以参考 官方文档 卸载和安装干净卸载后安装 12sudo apt-get --purge remove mysql-server mysql-common mysql-clientsudo apt-get install mysql-server 设置 root 密码 12mysqladmin -u root password your-new-passwordsudo /etc/init.d/mysql restart 或者，直接运行安全脚本配置 1sudo mysql_secure_installation 安装完毕后发现没有登录权限12ERROR 1045: Access denied for user: 'root@localhost' (Usingpassword: YES) 首先无密码登录 1sudo mysql -u root 然后查看当前用户，删除后重新创建 ROOT 账户，并授权 123456789mysql&gt; SELECT User,Host FROM mysql.user;mysql&gt; DROP USER 'root'@'localhost';mysql&gt; CREATE USER 'root'@'%' IDENTIFIED BY '123456';mysql&gt; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;mysql&gt; FLUSH PRIVILEGES; 允许远程访问123mysql&gt; GRANT ALL PRIVILEGES ON *.* TO 'root'@'%' WITH GRANT OPTION;mysql&gt; FLUSH PRIVILEGES; 打开 /etc/mysql/mysql.conf.d/mysqld.cnf 文件 1sudo vim /etc/mysql/mysql.conf.d/mysqld.cnf 把 bind-address 改为 0.0.0.0 12#bind-address = 127.0.0.1bind-address = 0.0.0.0 修改ROOT密码方法1： 用SET PASSWORD命令12MySQL -u rootmysql&gt; SET PASSWORD FOR 'root'@'localhost' = PASSWORD('newpass'); 方法2：用mysqladmin1mysqladmin -u root password &quot;newpass&quot; 如果root已经设置过密码，采用如下方法 1mysqladmin -u root password oldpass &quot;newpass&quot; 如何导入数据库文件假设我们已经有了一个数据库脚本， projectDB.sql，如何导入到MySQL？ 方法一：直接通过 mysql 命令运行 1mysql -u root -p123456 --port 3306 &lt; /home/jerrysheh/projectDB.sql 方法二：登录 mysql 后使用 source 命令 123mysql&gt;create database &lt;database-name&gt;;mysql&gt;use &lt;database-name&gt;;mysql&gt;source /home/jerrysheh/projectDB.sql; 解决导入慢的问题当数据库非常大（&gt;100M）时，导入时间可能要花费几小时，优化方式如下： 假设要讲A数据库的数据导入到B数据库 1、首先确定目标库(B)的参数值，登录数据库B，执行以下命令 12mysql&gt;show variables like 'max_allowed_packet';mysql&gt;show variables like 'net_buffer_length'; 2、根据参数值，在A数据库中使用 mysqldump 命令，如： 1C:\\Program Files\\MySQL\\MySQL Server 8.0\\bin&gt;mysqldump.exe -uroot -p mall -e --max_allowed_packet=67108864 --net_buffer_length=16384 &gt; mall.sql 各个参数的意思： -e： 使用包括几个VALUES列表的多行INSERT语法; –max_allowed_packet=XXX：客户端/服务器之间通信的缓存区的最大大小; –net_buffer_length=XXX：TCP/IP和套接字通信缓冲区大小,创建长度达net_buffer_length的行。 注意：max_allowed_packet和net_buffer_length不能比目标数据库的设定数值大，否则可能出错。 3、登录数据库B，执行 source 命令导入 修改默认字符集123ALTER DATABASE db_name CHARACTER SET utf8mb4;ALTER TABLE db_name DEFAULT CHARACTER SET utf8mb4;ALTER TABLE db_name CONVERT TO CHARACTER SET utf8mb4; SQL的单表操作SELECT从表里选择列 123SELECT column FROM tableSELECT LastName,Address FROM Persons DISTINCT从表里选择列（不出现重复值） 1SELECT DISTINCT column FROM table 多列 DISTINCT 1SELECT DISTINCT column1, column2, column3 FROM table 这里的 DISTINCT 是 column1, column2, column3 组合起来的去重，相当于： 1SELECT column1, column2, column3 FROM table group by column1, column2, column3 WHERE从表里中选择 city 列等于 Beijing 的所有行 1SELECT * FROM Persons WHERE city = 'Beijing' WHERE 语句中，&lt;&gt;或!=都可表示不等于，除了=、&gt;、&lt;、&gt;=、&lt;=之外，还可以用 BETWEEN（表示某个范围） 和 LIKE（搜索某种模式）。 注意：这里是使用 单引号，但是大部分数据库也接受双引号。如果是数值类型，不要加引号！ AND、OR从表里中选择 FirstName 是’Thomas’ 并且 LastName 是 ‘Carter’ 的行 1SELECT * FROM Persons WHERE FirstName = 'Thomas' AND LastName='Carter' 注意：当既有 AND 又有 OR 的时候，SQL 默认先执行 AND，如果要让 OR 先执行，用括号括起来即可。 1SELECT * FROM product WHERE (id &gt; 3000 OR id &lt; 1000 ) AND price &gt; 50; ORDER BY 排列 ASC 升序（小→大）（默认） DESC 降序（大→小） 例1： 优先以 Company 升序排列，然后以 OrderNumber 升序排列 1SELECT Company, OrderNumber FROM Orders ORDER BY Company,OrderNumber 假设这是一个记录公司订购了多少数量的物品的表，Google公司订购了两次，先以 A - G - I 升序排列，然后在相同值Google的两次订购中以数字升序排列 Company OrderNumber A pple 4698 G oogle 2356 G oogle 6953 I BM 3552 例2： 从商品表中根据id倒序取出前2个 1SELECT * FROM product ORDER BY id DESC LIMIT 2 MySql 是没有 top 关键字的，用 LIMIT 来完成相同功能。 INSERT INTO顺序依次插入往 Person 表的1、2、3、4列依次填入值 1INSERT INTO Persons VALUES('Jerry',\"Sheh\",\"Guangdong\",\"China\") 那么在 Persons 表的最后一行会新增如下 Firstname LastName Province Country Jerry Sheh Guangdong China 指定列插入往 Person 表的 LastName 列插入 Wilson，Age列插入 18 1INSERT INTO Persons(LastName, Age) VALUES ('Wilson', 18) Firstname|LastName|Province|Country|Age—|—|—|—|—|— | |Wilson| | |18 UPDATE修改 Persons表 中 LastName 是 Wilson 的 Address列 和 City列 123UPDATE PersonsSET Address='Xueyuan Road',City='Zhongshan'WHERE LastName='Wilson' INSERT INTO … ON DUPLICATE KEY UPDATE尝试插入，如果有冲突（唯一键冲突、主键冲突）则更新。 1234INSERT INTO Persons(LastName, Age)VALUES ('Wilson', 18)ON DUPLICATE KEY UPDATE Address='Xueyuan Road', City='Zhongshan' DELETE删除某行 12DELETE FROM PersonsWHERE LastName='Wilson' 删除所有行（表并没有被删除，结构、属性、索引都是完整的） 1DELETE * FROM table; 清空 1TRUNCATE TABLE t; TOP / LIMIT显示前多少条 12345# 显示前 2 条SELECT TOP 2 * FROM Persons# 显示前50%，PERCENT表示百分比SELECT TOP 50 PERCENT * FROM Persons SQL Server 可用 TOP ，但 MySQL 不行，用 limit 代替。 1234567891011# 显示前 2 条SELECT * FROM PersonsLIMIT 2# 从第 6+1 行开始，显示 2 条SELECT * FROM PersonsLIMIT 6,2# 从第 6+1 行开始，显示 2 条SELECT * FROM PersonsLIMIT 2 offset 6 注意：LIMIT 用 逗号 和 用 offset 是相反的。 LIKE在 WHERE 子句中搜索列中的指定模式 123SELECT * FROM PersonsWHERE cityLIKE '%N' 同理，NOT LIKE是不包含 符号 % 定义了通配符：N%表示以N开头， %g表示以g结尾，%lon%表示包含lon 模糊查询例子： 选出商品表中，标签包含 “爱情” 的 123SELECT * FROM productWHERE tagslike '%爱情%' SQL 通配符 % ：代替一个或多个字符 _ ：代替一个字符 [charlist] ：字符列中的任何单一字符 [^charlist] 或 [!charlist] ：非字符列中的任何单一字符 选取 c 开头，然后一个任意字符，然后 r，然后任意字符，最后 er 123SELECT * FROM PersonsWhere LastNameLIKE `c_r_er` 选取以 A 或者 L 或者 N 开头 123SELECT * FROM PersonsWhere LastNameLIKE `[ALN]%` IN在 Persons 表中选取姓氏为 Adams 和 Carter 的人 123SELECT * FROM PersonsWhere LastNameIN ('Adams','Carter') BETWEEN选取介于两个值之间的数据范围 （数值、文本、日期） 123SELECT * FROM PersonsWhere LastNameBETWEEN 'Adams' AND 'Carter' NOT BETWEEN，不在某范围内 不同数据库 BETWEEN…AND… 包括的范围可能不一样。在 MySQL 中包含两边边界值。 多表操作ALIAS （AS）ALIAS 用于给列名或表名指定“别名”，方便阅读。 1234SELECT o.OrderId, p.LastNameFROM Persons AS p, Orders AS oWHERE p.LastName = \"Adams\" JOIN将 Persons表 和 Orders表 的 Id_p 列关联起来 12345SELECT Persons.LastName, Persons.FirstName, Orders.OrderNoFROM PersonsINNER JOIN OrdersON Person.Id_p = Orders.Id_pORDER BY Person.LastName 1234SELECT p.FirstName, p.LastName, a.City, a.StateFROM Person as pLEFT JOIN Address as aON p.PersonId = a.PersonId JOIN 或 INNER JOIN：有匹配时才显示 LEFT JOIN：即使右表没有匹配，也从左表返回所有行 RIGHT JOIN：即使左表没有匹配，也从右表返回所有行 FULL JOIN ：返回左右表中所有的行，即使另一边没有匹配 注意：MySQL不支持 FULL JOIN，可以用 UNION 联合 LEFT JOIN 和 RIGHT JOIN，如果需要重复行，用 UNION ALL 123456789SELECT p.FirstName, p.LastName, o.OrderNoFROM persons AS pLEFT JOIN Orders AS oON p.Id_p = o.Id_pUNIONSELECT p.FirstName, p.LastName, o.OrderNoFROM persons AS pRIGHT JOIN Orders AS oON p.Id_p = o.Id_p UNION合并两个或多个 SELECT 语句的结果集 合并两个表的员工名字，如果名字一样，只出现一次（UNION有去重功能，不想去重，可以用 UNION ALL） 123SELECT E_Name FROM Employees_ChinaUNIONSELECT E_Name FROM Employees_USA GROUP BY根据一个或多个列对结果集进行分组 12SELECT Customer,SUM(OrderPrice) FROM OrdersGROUP BY Customer 有了 GROUP BY 之后 ，SUM 是以 Customer 分组，对每一组的OrderPrice记录进行计算，而不是表中全部的OrderPrice记录。 HAVINGHAVING 通常与 GROUP BY 和 函数 一起使用。 找出成绩全部大于80分的学生学号 123SELECT number FROM gradeGROUP BY numberHAVING MIN(grade.grade &gt; 80) SELECT INTO等从一张表选择数据，然后插入到另一张表里（常用于创建表的备份附件，或者用于对记录进行存档） 1SELECT * INTO new_table FROM old_table 可结合 WHERE 或者 JOIN 使用 MySQL 常用数据类型 类型 释义 integer(size) 整数 int(size) 整数 smallint(size) 整数 tinyint(size) 整数 decimal(size,d) 小数，d=小数点右侧最大位数 numeric(size,d) 小数 char(size) 固定字符串 varchar(size) 可变长字符串 date(yyyymmdd) 日期 date(yyymmddHHiiss) 时间 MySQL 函数Concat用来拼接字段 123SELECT Concat( name, '(', age ,\")\")FROM PeopleWHERE age &gt; 18 输出： 123小明（18）小白（20）Jerry（23） Upper &amp;&amp; Lower转换成大写、小写 数据库操作CREATE DATABASE创建数据库 1CREATE DATABASE mydb 在 MYSQL 中， 也可以用 CREATE SCHEMA mydb 摘自MYSQL 5.0官方文档： CREATE DATABASE creates a database with the given name.To use this statement, you need the CREATE privilege for the database.CREATE SCHEMA is a synonym for CREATE DATABASE as of MySQL 5.0.2. CREATE TABLE创建表 123456789CREATE TABLE Persons( id_p int NOT NULL AUTO_INCREMENT, last_name varchar(255), first_name varchar(255), address Varchar(255), primary key(id_p) UNIQUE INDEX ix_first_name(first_name)) DEFAULT CHARSET=utf8; NOT NULL: 不接受NULL值 UNIQUE:为列或者列集合提供唯一性保证 PRIMARY KEY：主键 创建/删除索引创建 12ALTER TABLE table_name ADD INDEX index_name (column_list);ALTER TABLE table_name ADD UNIQUE (column_list); 删除 1ALTER TABLE table_name DROP INDEX index_name; ALTER 在已有表 添加/修改/删除 列1ALTER TABLE table_name ADD column_name datatype; 实战一有两张表，学生表和成绩表。 找出所有科目成绩都大于 80 分的学生名字 方法一：用 HAVING + 函数 先用 join 把两张表连起来 用 group by 分组，分组条件是 分数大于 8012345SELECT s.nameFROM student AS sJOIN grade AS g ON s.number = g.numberGROUP BY s.`name`HAVING MIN(grade) &gt; 80 方法二：用 WHERE + NOT IN 123456789SELECT DISTINCT s.nameFROM student AS sJOIN grade AS gON s.number = g.numberWHERE s.numberNOT IN(SELECT g.numberFROM grade AS gWHERE g.grade &lt; 80) 求所有人成绩的平均分 12345SELECT s.name AS name, AVG(g.grade) AS avgFROM student AS sJOIN grade AS gON s.number = g.numberGROUP BY s.name 实战二查找表中多余的重复记录，重复记录是根据单个字段（peopleId）来判断 123SELECT * FROM peopleWHERE peopleId IN (SELECT peopleId FROM people GROUP BY peopleId HAVING count(peopleId) &gt; 1) 实战三JOIN 两张表，右表只取一条记录 1234SELECT a.name b.numFROM lefttable as aJOIN (SELECT num FROM righttable GROUP BY num) as bON a.name = b.num","link":"/post/f95479c9.html"},{"title":"html5插入视频空白问题","text":"今天想在我的博客文章一些想法中插入一段视频。 本来把视频上传到我的apache服务器中，然后在 Hexo 的 Markdown语法中插入以下语句即可 12&lt;video src='链接地址' type='video/mp4' controls='controls' width='100%' height='100%'&gt;&lt;/video&gt; 但是在 Chrome 中播放的时候，一直显示空白，但是有声音。琢磨了半天不知道问题出在哪。 后来发现是 html5 嵌入视频的时候，对视频编码是有要求的 MP4有3种编码，mpg4(xdiv),mpg4(xvid)，avc(h264) 转换成H264编码就可以网页正常播放了，好像H264才是公认的MP4标准编码 用 PotPlayer 重新录制新的编码视频重新上传，搞定了。","link":"/post/5e11ed5b.html"},{"title":"数据库（四）MySQL优化","text":"这一篇主要从以下三个角度谈谈MySQL的优化： 使用恰当的数据类型 高效索引 高效查询 大表优化（含分库分表） explain SQL执行过程想要优化，先得了解一条SQL查询语句的执行过程。 MySQL 大致架构为： 客户端 –&gt; Server层 –&gt; 存储引擎 客户端发起一次SQL请求，会依次经过以下Server层组件： 连接器：连接器负责跟客户端建立连接、获取权限、维持和管理连接 查询缓存：之前执行过的语句，会先放在缓存里 分析器：词法分析、语法分析 优化器：优化语句，决定如何使用索引 执行器：判断权限，开始执行语句 最后到达存储引擎进行数据的存储和提取。 MySQL是插件式架构，支持InnoDB、MyISAM、Memory等多个存储引擎。 Schema与数据类型优化基本原则： 更小：如果只要存0-200，tinyint unsigned 比 int 好 简单：用内建类型表示时间而不是varchar 避免NULL：有 NULL 的列使得索引、索引统计和值比较更加复杂。虽然调优时把NULL改NOT NULL性能提升较小，但是如果要在列上建索引，就应该避免 NULL 整数类型整数类型包括 TINYINT（8位）、SMALLINT（16位）、MEDIUINT（24位）、INT（32位）、BIGINT（64位）。无符号数和有符号数使用相同的存储空间，具有相同的性能。整数计算一般用 64位的 BIGINT 整数，但一些聚合函数用 DECIMAL 或 DOUBLE。 MySQL 可以为整数指定宽度，如 INT(11)，但这不会限制值的合法范围。仅仅是在客户端中显示字符的个数而已。 实数（小数）类型实数不仅仅存储小数，也可以用 DECIMAL 存储比 BIGINT 大的整数。DECIMAL 一般用来做精确计算，但是需要的额外空间和开销也大。因此，如果不需要精确计算，4字节的FLOAT或8字节的DOUBLE已经足够。 但是，在《阿里巴巴开发手册》里面，规范小数一律用 DECIMAL ，可以避免潜在问题。 【强制】小数类型为 decimal ，禁止使用 float 和 double 。说明： float 和 double 在存储的时候，存在精度损失的问题，很可能在值的比较时，得到不正确的结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数分开存储。 CHAR 和 VARCHAR存储引擎存储 CHAR 或 VARCHAR 的方式，在内存和在磁盘中可能不一样。 CHAR：定长字符串。会截断末尾的空格。适合存储较短的字符串或所有值长度接近。 VARCHAR：可变长字符串。需要用1或2个额外字节记录字符串的长度（列的最大长度超过255字节，用2个额外字节记录长度信息）。VARCHAR虽然节省空间性能较好，但 UPDATE 时由于长度的改变，需要额外的工作。适用场景：字符串的最大长度比平均长度大很多，列很少更新。 需要注意的是，VARCHAR(5)和VARCHAR(200)存储hello的空间开销是一样的，但是更长的列会消耗更多的内存，所以最好根据需要来分配。 同理，有 BINARY 和 VARBINARY，存储的是二进制值，二进制的比较比字符比较要快。 BLOB 和 TEXTBLOB 和 TEXT 都是设计用来存储很大的字符串数据的，但 BLOB 采用二进制存储，TEXT采用字符方式存储。 跟其他类型不一样的是，当 BLOB 或 TEXT 值太大时，InnoDB会用专门的“外部”存储区来存储。每个值只需要在行内用1-4个字节存储指针，然后指向外部真正存储的区域。 BLOB：二进制数据，没有排序规则和字符集 TEXT：字符数据，有排序规则和字符集 MEMORY 存储引擎不支持 BLOB 和 TEXT，如果使用到了，将不得不转换成 MyISAM 磁盘临时表，这将带来很大的开销。MEMORY中最好避免使用 BLOB 和 TEXT。 枚举类代替字符串有时候可以用枚举类代替不重复的字符串。其内部是用整数实际存储的，而不是字符串。因此最好不要往里面插入常量（如’1’,’2’）以避免混乱。但是也有缺点，添加或删除字符串需要用 ALTER TABLE，因此对于一些未来可能会改变的字符串，使用枚举是不明智的。 1234CREATE TABLE enum_test( e ENUM('fish','apple','dog') NOT NULL);INSERT INTO enum_test(e) VALUES ('fish', 'dog', 'apple'); DATETIME 和 TIMESTAMP DATETIME：能保存1001年-9999年，精度为秒。将日期和时间封装到 YYYYMMDDHHMMSS 格式的整数中，与时区无关。使用8个字节的存储空间。 TIMESTAMP：能保存1970-2038年，只使用4个字节，存储的是1970年1月1日到现在的秒数，时区相关。 其他 MySQL 把 bit 当作字符串，而不是数字 MySQL 内部使用整数存储 ENUM 和 SET 类型，比较时再转换成字符串 应该用无符号整数（unsigned int）存储IP地址，MySQL提供 INET_ATON()（字符串转整数） 和 INET_NTOA()（整数转字符串） MySQL 高效索引单列索引对于独立的列来说，要创建高效索引，必须满足：索引列不能是表达式的一部分，也不能是函数的参数。例如： 1234// 使用了表达式，索引失效SELECT actor_id FROM sakila.actor WHERE actor_id + 1 = 5;SELECT ... WHERE TO_DAYS(CURRENT_DATE) - TO_DAYS(DATE_COL) &lt;= 10; 应该养成简化 WHERE 条件的习惯，始终将索引列放在比较符号的一侧。 前缀索引有时候要索引很长的字符列，这会让索引变得很大且慢。一种解决办法是在索引上再建哈希索引。但还可以用 前缀索引 来解决。 前缀索引，顾名思义，只索引字符串的前面一部分，例如，对于数据University，我们可以建立索引Uni。但这样会降低索引的选择性，索引选择性是指不重复的索引值 和 表记录数的比值。选择性越高，说明索引越多。唯一索引的选择性是1，因此性能最高。 在 MySQL 里面，BLOB、TEXT 和 很长的 VARCHAR 必须使用前缀索引。 查看前缀为3的情况 1234SELECT COUNT(*) AS cnt, LEFT(city, 3) AS prefFROM city_demoGROUP BY prefORDER BY cnt DESC LIMIT 10; 那索引前缀多长比较合适呢？诀窍是，前缀应该足够长，使得选择性接近于整个列，但不能太长（以便节约空间）。 计算完整列的选择性方法： 1SELECT COUNT(DISTINCT city) / COUNT(*) FROM city_demo; 假如计算出来结果是 0.0312，那么选择性接近 0.0312 的前缀就差不多了。 测试各个前缀的选择性： 1234SELECT COUNT(DISTINCT LEFT(city, 3)) AS sel3, COUNT(DISTINCT LEFT(city, 4)) AS sel4, COUNT(DISTINCT LEFT(city, 5)) AS sel5FROM city_demo; 当我们找到一个合适的前缀，比如是5，用下面的方式来创建前缀为5的前缀索引： 1ALTER TABLE city_demo ADD KEY (city(5)); 前缀索引的缺点是无法使用前缀索引做 GROUP BY 和 ORDER BY 和 覆盖扫描。 多列索引常见多列索引的错误有：为每一列创建独立的索引，或者按照错误的顺序创建索引。那什么是正确的顺序呢？一个经验法则是：当不需要考虑排序和分组时，将选择性最高的列放在最前面。 一个简单的例子 1SELECT * FROM payment WHERE staff_id = 2 AND customer_id = 584; 创建索引时，是应该创建 (staff_id, customer_id) 还是 (customer_id,staff_id) ？这取决于哪一列的选择性更高。但这也不是绝对的，还要考虑WHERE 子句中的排序、分组、范围条件等其他因素。 聚簇索引聚簇的意思是：数据行和相邻的键值紧凑地存储在一起。当表有聚簇索引时，数据行本身存放在索引的叶子页。InnoDB的实现是，通过主键聚集数据，被索引的列就是主键列。如果没有主键，InnoDB会选择一个非空索引代替，如果没有这样的索引，就隐式创建一个。 InnoDB支持聚簇索引，而MyISAM不支持，使用了聚簇索引和非聚簇索引的存储方式区别可参考 数据库（二）MySQL必知必会概念 聚簇索引优点： 把相关数据保存在一起 数据访问更快 使用覆盖索引扫描的查询可以直接使用页节点中的主键值 聚簇索引缺点： 聚簇索引提高了I/O密集型应用的性能，但如果数据全部在内存中，那就没有优势 插入速度严重依赖于插入顺序 更新列代价高 页分裂问题，占用更多磁盘空间 全表扫描更慢 二级索引较大，访问要2次 覆盖索引正如聚簇索引中你看到的，索引本身是可以包含数据本身的，这样我们就不必回表查询，直接在索引拿到数据就行了。想象一下，如果一本书需要知道第 11 章是什么标题，你会翻开第 11 章对应的那一页吗？目录浏览一下就好，这个目录就是起到覆盖索引的作用。 如果一个索引包含（覆盖）所有需要查询的字段的值，我们就称之为覆盖索引。覆盖索引也不一定是聚簇索引，在MySQL中，只有 BTree 索引能做覆盖索引。 MySQL 查询优化查询慢的原因 查询了不需要的记录。一个典型的错误是先 SELECT 查出所有结果集，然后获取前面的 N 行后关闭结果。这样 N 行后面的数据就是不需要的数据，MySQL会把时间浪费在这上面。最好的解决办法是用 limit N，这样MySQL只会去找 N 行而不是所有。 多表关联时返回全部列。比如 SELECT * FROM xxx join yyy ON ...，其实可以用 SELECT sakila.actor.* FROM sakila join yyy ON ...，只取关键的列。 总是取出全部列。SELECT *的做法在数据库的角度是不考虑周全的，但是有时候从开发的角度看却能简化开发，因为能提高相同代码片段的复用性。 重复查询相同的数据。需要多次重复查询的数据，最好第一次查询后缓存起来，可以使用 redis 等。 重构查询的两种方法1.切分查询一次大查询（例如删除旧的数据）可能需要一次锁住很多数据，占满整个事务日志、耗尽系统资源、阻塞很多其他重要的查询。可以把大查询切分成很多个小查询。 12345678910// 原始 大查询DELETE FROM messages WHERE created &lt; DATE_SUB(NOW(), INTERVEL 3 MONTH);// 切分 小查询rows_affected = 0;do { rows_affected = do_query( \"DELETE FROM messages WHERE created &lt; DATE_SUB(NOW(), INTERVEL 3 LIMIT 10000\" )} while rows_affected &gt; 0; 2.分解关联查询高性能应用都会对关联查询进行分解，先对每一个表进行单表查询，再将结果在应用程序进行关联。 12345678910// 分解前SELECT * FROM tag JOIN tag_post ON tag_post.tag_id = tag.id JOIN post ON tag_post.post_id = post.idWHERE tag.tag = 'mysql';//分解后SELECT * FROM tag WHERE tag = 'mysql';SELECT * FROM tag_post WHERE tag_id = 1234;SELECT * FROM post WHERE post.id in (123,456,7897,9090) 优化特定类型的查询优化COUNT() 如果要统计所有行，用 COUNT(*) 而不是 COUNT(col) 。 COUNT(col)统计的是不为NULL的行 COUNT(distinct col)统计不为NULL且不重复的行 COUNT(distinct col 1, col 2) 如果其中一列全为 NULL ，那么即使另一列有不同的值，也返回为 0 12345// 统计行数，假如该表有100行，返回100count(*);// 统计 last_name 这一列不为NULL的数量count(last_name); MyISAM中，不带 WHERE 的 COUNT(*) 速度非常快，因为可以直接利用存储引擎的特征获取这个值。但是带 WHERE 的跟其他存储引擎没区别 如果某列col不可能为NULL，那 COUNT(col) 将被自动优化成 COUNT(*) 借助 MyISAM COUNT(*) 非常快的特性，我们可以优化如下： 123456// 原语句，求大于5SELECT COUNT(*) FROM city WHERE id &gt; 5;// 优化后，总数 - 小于等于5SELECT (SELECT COUNT(*) FROM city) - COUNT(*)FROM city WHERE id &lt;= 5; 优化关联查询 确保 ON 或 USING 子句的列上有索引。也就是说，表A和表B用列c关联时，如果优化器的关联顺序是B、A，那只需要在 第二张表（A表） 的相应列上创建索引。 确保 GROUP BY 和 ORDER BY 中的表达式 只涉及到一个表中的列，这样MySQL才有可能使用索引来优化这个过程。 优化 GROUP BYMySQL在无法使用索引时，GROUP BY会用临时表或文件排序来做分组。在 GROUP BY 的时候，如果标识列（如用户id）和查找列（如用户名）是对应的，那用标识列做分组，效率会比查找列高，GROUP BY右表标识列比GROUP BY左表标识列高。 如果不关心结果集的顺序，但GROUP BY默认会按分组的字段排序从而使用了文件排序功能，不需要的时候可以ORDER BY NULL。 优化 LIMIT 分页MySQL limit接收一个或两个参数，如 12345// 取出前18条记录SELECT ... limit 18;// 取出第51-53条记录SELECT ... limit 50,3 但有两个参数的时候，且第一个参数（偏移量）非常大，如 limit 10000,30，那MySQL需要查询 10030 条记录，然后抛弃前面 10000 条，返回最后30条。这样的代价是非常高的。 一个优化思路是：尽可能使用索引覆盖扫描，而不是查询所有的列，然后根据需要做一次关联操作再返回所需的列。考虑下面的例子： 1234567891011121314151617# 改写前SELECT film_id, description FROM sakila.filmORDER BY titleLIMIT 50000,5;# 改写后SELECT film.film_id, film.description FROM sakila.film INNER JOIN ( SELECT film_id FROM sakila.film ORDER BY title LIMIT 50000,5; ) AS lim USING(film_id);# 另一种改写SELECT film_id, description FROM sakila.filmWHERE film_id &gt; 50000LIMIT 5 先快速定位需要获取的 id 段，然后再关联。 12SELECT a.* FROM 表 1 a, (select id from 表 1 where 条件 LIMIT 100000,20 ) bwhere a.id=b.id 优化 UNIONMySQL 总是通过创建并填充临时表的方式来执行 UNION。除非确实需要消除重复的行，否则一定要使用 UNION ALL，没有 ALL 时 MySQL 会给临时表加 IDSTINCT 对数据做唯一性检查，这样做的代价非常高。 大表优化MySQL单表数据量超过500万时，性能就开始急剧下降。 限定数据的范围禁止不带任何限制数据范围条件的查询语句。比如：查询订单历史，我们可以控制在一个月的范围内。 读/写分离经典的数据库拆分方案：主库负责写，从库负责读 垂直拆分数据表列的拆分，把一张列比较多的表拆分为多张表 优点： 可以使得列数据变小，在查询时减少读取的Block数，减少I/O次数。此外，垂直分区可以简化表的结构，易于维护。 缺点： 主键会出现冗余，需要管理冗余列，并会引起Join操作，可以通过在应用层进行Join来解决。此外，垂直分区会让事务变得更加复杂。 水平拆分数据表行的拆分，把一张表复制多份，存到不同的库上。 分表仅仅是解决了单一表数据过大的问题，但由于表的数据还是在同一台机器上，其实对于提升MySQL并发能力没有什么意义，所以水平拆分最好分库 。 目前流行的分片方案： 客户端代理：分片逻辑在应用端，封装在jar包中，通过修改或者封装JDBC层来实现。 如 Sharding-JDBC 中间件代理：在应用和数据中间加了一个代理层。分片逻辑统一维护在中间件服务中。如 Mycat explain在一条 SQL 前面加上 explain 执行，即可查看执行计划。 id select_type table type possible_key key key_len ref rows Extra 1 SIMPLE s ALL NULL NULL NULL NULL 17022 Using where select typeSELECT 语句的类型，如 SIMPLE（简单查询）、 PRIMARY（最外层查询）、UNION（UNION里的查询）、SUBQUERY（子查询）、DERIVED（派生表） 。 table指明了是哪张表，包括别名和中间表。 partitions非分区表显示 NULL， 分区表显示该查询在哪个分区。 typejoin type，指出这张表是用何种方式 JOIN 的： system：系统表或该表只有一行数据（const的特例） const：常数级，表示该表最多有一个匹配行，这是最快的。通常情况下，查询条件带主键或唯一索引就是 const eq_ref：两张表互相一次匹配，通常在两张表主键或唯一索引 = 操作查询一条记录时 ref：两张表按某一列关联 range：范围查找 index：全扫描覆盖索引，或全表扫描 all：全表扫描 还有几种不常见的可参阅 MySQL官方文档，讲得非常详细了。 possible_keys可能的索引 key 和 key_len实际使用的索引，及其长度 ref跟实际使用的索引（即key列）进行比较的列 或 常数，如果是 func，说明比较的是某个函数的结果 rows执行这条语句 MySQL 需要扫描多少行数据 filtered过滤百分比，例如 rows 是 1000， filtered 是 50.00（50%），那么会有 1000 × 50% = 500 条数据会被 JOIN Extra其他信息，如 Using Where、Using Index 参考： 《高性能MySQL》 《阿里巴巴Java开发手册》 MySQL官方文档 https://github.com/Snailclimb/JavaGuide/blob/master/docs/database/MySQL.md","link":"/post/2bb1b1ab.html"},{"title":"使用 ajax 和 Vue 进行前后端交互","text":"在传统的 Web 应用开发中，浏览器的请求首先会发送到 Controller， 由 Controller 交由相应的 Model 进行业务逻辑处理，处理完毕后将结果交由 View 进行渲染，动态输出完整的 HTML 返回给浏览器。这么做有两个缺点，一是需要在 HTML 中嵌入后端模板引擎，如 JSP、Thymeleaf 等。JSP饱受诟病，在HTML中写大量的java代码，显然让程序显得很混乱，无法很好地解耦。而 Thylemeaf 虽然是纯 HTML 的后端模板引擎，但这样前后端的关联性还是比较强。二是使用后端模板引擎的坏处是，HTML页面需要完全渲染完毕后，才返回给浏览器展示。这样一来，如果页面元素非常多，页面加载时间就很长了，影响用户体验不说，还会给服务器造成很大的处理压力。 如果后端仅提供数据，而把渲染页面这种事交给前端来做，因为前端是在浏览器执行的，这样就能够减缓服务器的压力了。从另一个角度，随着移动互联网的兴起，客户端不再仅仅是浏览器，还可能是手机，例如Android客户端、iOS客户端、微信小程序。如果一套互联网服务需要同时有Web端、手机端，那么传统的后端包办一切的开发模式显然是行不通的。 在这种大环境下，于是催生了前后端分离。简单地说，就是把传统网络应用的 Controller 层，交给了客户端来掌控。后端只负责业务逻辑处理。当然，这里的 Controller 不是指 Spring MVC 中的 Controller，而是前端对一个页面中什么时间点应该展示什么内容，有自己的控制权。 具体到 Spring Boot 中的前后端分离，就是利用 @RestController 注解，让后端仅仅提供 json 格式的纯数据。前端（包括Web端和移动端）拿到数据之后，该怎么渲染，怎么展示，那是前端的事情。例如，Android客户端拿到数据，将数据显示到 RecyclerView 上， Web前端拿到数据，将数据显示在网页表格里。 如何提供一套好的规范，可以参考之前写过的 Spring（四）使用 RESTful 风格。 RESTful 风格就是一种很好前后端数据交互的的规范。 那么我们的问题是，后端通过 RESTful 风格的设计， 向前端提供纯 json 数据，对于Web前端来说，我们该如何“拿取”这些数据，并进行展示呢？这就需要用到 Ajax 和 Vue 技术了。 AjaxAjax 的全称是 Asynchronous JavaScript and XML （异步的 JavaScript 和 XML） Ajax 不是新的编程语言，而是一种使用现有标准的新方法。其最大的优点是提供了异步请求的能力，即在不重新加载整个页面的情况下，可以与服务器交换数据并更新部分网页内容。想象一下，如果有一个验证注册用户名是否可用的服务，按照传统的方法，前端向后端请求数据后需要刷新页面才能看到。而使用 Ajax，可以直接在当前页面更新数据内容。 使用原生 Ajax原生 Ajax 的语法大概如下： 1234567891011121314151617181920212223var xmlhttp;function check(){ // 创建一个 http请求 xmlhttp =new XMLHttpRequest(); //响应函数 xmlhttp.onreadystatechange=checkResult; //设置访问的页面 xmlhttp.open(\"GET\", url, true); //执行访问 xmlhttp.send(null); }function checkResult(){ if (xmlhttp.readyState==4 &amp;&amp; xmlhttp.status==200){ // 更新页面数据 document.getElementById('checkResult').innerHTML=xmlhttp.responseText; }} 使用 jQuery现在几乎没有人用原生 Ajax 去发起 HTTP 请求，因为语法太啰嗦了，都是用一些js框架简化请求过程。使用 jQuery 发起 Ajax 大概如下： 发起 GET 请求123456789$.get( url, //参数1，url success: function (data) { //参数，返回处理函数 // data 就是服务器返回的数据 }, error : function() { alert(\"服务器发生错误！请稍后再试\"); }); 发起 POST 请求12345678910111213141516171819202122// 提供一个 jsonvar loginjson = { \"username\": username, \"password\": password};// 将 json 变成字符串var jsonData = JSON.stringify(loginjson);$.ajax({ type: \"POST\", //请求方法 contentType: \"application/json;charset=UTF-8\", // 要发送的数据类型 dataType: \"text\", //预期服务器返回的数据类型 json text html url: \"/api/user/login\" , //url data: jsonData, success: function (data) { console.log(data); //打印服务端返回的数据(调试用) }, error : function() { alert(\"服务器发生错误！请稍后再试\"); }}); javascript 中 json对象 和 字符串 的转换 JSON.parse(data)：字符串 → json对象 JSON.stringify(data)：json对象 → 字符串 例子： 123456//定义一个字符串var data='{\"name\":\"goatling\"}'//变成对象​​JSON.parse(data) // ​name:\"goatling\" 12345// 定义一个 json对象var data={name:'goatling'}// 变成字符串JSON.stringify(data) //'{\"name\":\"goatling\"}' 使用 axiosaxios 是一个基于 promise 的 HTTP 库，可以用在浏览器和 node.js 中。关于 promise 的内容，可以参考 廖雪峰的javascript教程 axios 的特点是： 从浏览器中创建 XMLHttpRequests 从 node.js 创建 http 请求 支持 Promise API 拦截请求和响应 转换请求数据和响应数据 取消请求 自动转换 JSON 数据 客户端支持防御 XSRF 要使用 axios ，首先需要在 html 中引入axios.min.js 1&lt;script src=\"https://unpkg.com/axios/dist/axios.min.js\"&gt;&lt;/script&gt; 发起 GET 请求1234567891011121314151617181920212223// 为给定 ID 的 user 创建请求axios.get('/user?name=jerry&amp;age=18') .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); });// 可选地，上面的请求可以这样做// param 就是 url 问号后面的参数axios.get('/user', { params: { name: \"jerry\", age: 18 } }) .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); }); 发起 POST 请求12345678910axios.post('/user', { firstName: 'Fred', lastName: 'Flintstone' }) .then(function (response) { console.log(response); }) .catch(function (error) { console.log(error); }); 执行多个并发请求123456789101112function getUserAccount() { return axios.get('/user/12345');}function getUserPermissions() { return axios.get('/user/12345/permissions');}axios.all([getUserAccount(), getUserPermissions()]) .then(axios.spread(function (acct, perms) { // 两个请求现在都执行完成 })); 更多关于 axios 的内容，请参考 Axios 中文说明 Vue.jsVue.js是一款优秀的渐进式 JavaScript 框架。 Vue.js要系统学习起来需要花费比较大的学习成本，作为一个定位并非专业前端工程师的开发者来说，先暂且达到会用的水平就足够了。因此下面只是简要说一下我在项目中是如何使用 Vue 的。 想象一个场景，在基本页面加载完毕后，我需要异步去获取一份购买订单数据，并显示在 HTML 上。如果使用 JavaScript 或者 jQuery，我们一般是用操作 HTML DOM 的方式，把数据显示上去。例如document.getElementById(&quot;some_id&quot;).innerHTML = data。但如果使用Vue, 只需提供数据，以及数据要绑定到的元素的id就行了,不再需要显式地操作HTML DOM。这正是 Vue 的优势所在。 要使用 Vue.js，首先需要在 HTML 中引入： 1234567&lt;!-- 开发环境版本，包含了有帮助的命令行警告 --&gt;&lt;!-- 开发的时候用这个 --&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;!-- 生产环境版本，优化了尺寸和速度 --&gt;&lt;!-- 上线的时候换成这个 --&gt;&lt;script src=\"https://cdn.jsdelivr.net/npm/vue\"&gt;&lt;/script&gt; order.js 12345678910111213141516171819202122232425262728293031323334// 首先 new 一个 Vue 对象var buy_v = new Vue({ // 绑定 HTML 的某个div el:'#IBuy_pageinfo_div', // 即将从服务器获取的数据，这里暂时为空 data:{ pageinfo: [] }, // 这个 VUE 对象拥有的方法，可以在 HTML 中调用 methods:{ getDate:function (strDate) { var d = new Date(strDate); return d.getFullYear() + '-' + (d.getMonth() + 1) + '-' + d.getDate(); }, getData(self, u){ axios.get(u).then(function (response) { // 将服务器返回的结果赋值给VUE数据 self.pageinfo = response.data; // ... 其他逻辑处理 }) } }});// 获取我的订单（购买）function getMyBuy() { const url = \"/api/exchange\" // 调用 VUE 对象的方法 buy_v.getData(buy_v._self, url);} order.html 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;!--购买订单 --&gt;&lt;div class=\"tab-pane \" id=\"panel-3\"&gt; &lt;div class=\"myOrder\"&gt; &lt;div class=\"container\" style=\"margin-top: 20px\"&gt; &lt;div class=\"card\" style=\"border-radius: 20px\"&gt; &lt;div class=\"card-header\"&gt;我的订单&lt;/div&gt; &lt;div class=\"card-body\"&gt; &lt;!-- 这里的 id 跟上面 VUE 的el 绑定起来 --&gt; &lt;div class=\"container\" id=\"IBuy_pageinfo_div\"&gt; &lt;table class=\"\"&gt; &lt;!-- pageinfo是服务器返回的json数据对象，list是pageinfo下的某个对象 --&gt; &lt;tr v-for=\"exchange in pageinfo.list\"&gt; &lt;td&gt; &lt;div style=\"width: 260px;height: 240px;background-color: white\" class=\"container\"&gt; &lt;a :href=\"/product/ + exchange.product.id\"&gt; &lt;img :src=\"exchange.product.images[0]\" style=\"width: 240px;height: 220px\"/&gt; &lt;/a&gt; &lt;/div&gt; &lt;/td&gt; &lt;td&gt; &lt;div class=\"container\"&gt; &lt;p&gt; 商品名字：{{exchange.product.name}}&lt;/p&gt; &lt;p&gt; 商品单价：{{exchange.product.price}}元&lt;/p&gt; &lt;p&gt; 交易金额：{{exchange.trade_number}}件，共{{exchange.total}}元&lt;/p&gt; &lt;p&gt; 成交时间：{{getDate(exchange.trade_time)}}&lt;/p&gt; &lt;p&gt; 商品状态： &lt;span style=\"color: green\"&gt;{{exchange.status}}&lt;/span&gt;&lt;/p&gt; &lt;/div&gt; &lt;/td&gt; &lt;/tr&gt; &lt;!-- 循环结束 --&gt; &lt;/table&gt; &lt;!-- 加载更多 --&gt; &lt;div align=\"center\"&gt; &lt;!-- 调用方法也是没问题的 --&gt; &lt;button id=\"IBuy_loadmore_btn\" style=\"color: #787878;\" class=\"btn btn-default btn-lg\" role=\"button\" onclick=\"getMyBuy()\"&gt;加载更多 &lt;/button&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 关于 Vue 的更多内容，参考： 官方文档 how2j - VUE.JS 系列教程","link":"/post/a24bf899.html"},{"title":"Golang 快速入门","text":"这几天闲来无事，想试着玩下 Golang。对于 Go 的认知，最开始是在知乎上看到一些相关的讨论，大概知道这是一门2009年由谷歌工程师捣鼓出来的新语言，其最大的特点是在语言层面支持并发（goroutine），因此天生适合用来做服务端开发。 学 Golang 只是为了好玩！ 参考教程 Go 语言指引 官方文档 标准库手册 基本语法Hello World 不需要分号 已导出的方法调用以大写字母开头（Println） hello.go 123456789package mainimport ( \"fmt\")func main() { fmt.Println(\"hello world!\")} 编译执行 12C:\\Users\\Gopher\\go\\src\\hello&gt; go buildC:\\Users\\Gopher\\go\\src\\hello&gt; hello 参考：https://golang.google.cn/doc/install 声明变量、常量跟C++这类语言不同，Go的类型放在变量名后面。之所以这么写，Go官方在 一篇博客 中说是为了更加简洁清晰，特别是加入指针后不那么容易混淆。 12345678910111213package mainimport \"fmt\"// 声明全局变量var status boolvar j float64var i = 4func main() { var a = 2 // 声明函数变量 b := 1 // 简洁方式} 函数 函数支持多值返回。 返回值可以命名，相当于在函数首行声明了这个变量。 1234567891011121314151617181920212223// 函数func add(x, y int) int{ return x + y}// 支持多值返回func swap(x, y int) (int, int){ return y, x}// 返回值可以命名func splitNum(num int) (x, y int){ x = num + 5 y = num - 5 return}func main() { a := 1 b := 2 a, b = swap(a, b) a, b = splitNum(50)} 类型转换简单粗暴 123456// 类型转换func cast(){ var x int = 1 y := float64(x) fmt.Println(\"the type of y is: \", reflect.TypeOf(y) )} for循环C 语言中的 while 在 Go 里面叫做 for 1234567891011121314151617func forLoop(){ sum := 0 for i := 1; i &lt; 100; i++ { // 普通for循环 sum = sum + i } num := 1 for num &lt; 2000 { // 省略前置后置 num++ } v := 0 for{ // 无限循环 v++ }} if 语句if语句可以简短声明表达式 1234567func ifStatement(a, b int){ if v:=a * b; v &lt; 20 { fmt.Println(v) } else { fmt.Println(\"wrong\") }} defer defer语法，推迟到外层函数结束后执行 defer会立即求值，但推迟调用，多个 defer 以压栈的方式后进先出 以下程序输出： three two one 12345func deferStament(){ defer fmt.Println(\"one\") defer fmt.Println(\"two\") fmt.Println(\"three\")} 指针跟C++一样，&amp;是取地址符号 123456func pointer() { var i = 66 // 一个 int var p *int // 一个指针 p = &amp;i // 指针指向 int fmt.Println(p)} 输出：0xc000054080，即变量 i 所在内存中的地址 在指针变量前加 * 可以获得原变量 123456func pointer2() { var i int p := &amp;i *p = 6 // 通过指针设置 i 的值 fmt.Println(i)} 与 C++ 不同的是，Go 的指针不能用于运算。 struct跟 C 好像没啥区别 12345678910type rectangle struct { long int width int}func main() { rec := rectangle{3,4} rec.long = 5 fmt.Println(rec.long, rec.width)} struct pointer在 C++ 中，p是指向结构体的指针，可以用 (*p).X 来访问结构体中的变量。在 Go 中也可以这么干，但 Go 也允许我们直接用 p.X 来访问。 12p := &amp;recp.width = 4 // 相当于 rec.width = 4 如果不指定结构体变量的值，会给默认值 123456var ( v1 = Vertex{1, 2} // 创建一个 Vertex 类型的结构体 v2 = Vertex{X: 1} // Y:0 被隐式地赋予 v3 = Vertex{} // X:0 Y:0 p = &amp;Vertex{1, 2} // 创建一个 *Vertex 类型的结构体（指针）) 稍微高级一点的语法数组(array)和切片(slice)在 Go 中，数组是不可变的。声明数组时必须指定长度，[3]int{}和[2]int{}是两种不同的类型。不声明长度则叫做切片，可以把切片理解为数组的一段（有时是全部）。通常用切片操作数组。 123456789101112131415var names = [4]string{ \"John\", \"Paul\", \"George\", \"Ringo\",} // 声明数组的一种方法func main() { primes := [...]int{2, 3, 5, 7, 11, 13} // 也可以用 ... 让编译器帮你计算长度 fmt.Println(primes) primes[2] = 1 // 修改数组第 3 个元素值 sub := primes[1:4] // 切片，获取数组的第 1-3 个元素} 来自官方文档： 切片是数组的片段，它并不存储任何数据，更改切片的元素会修改其底层数组中对应的元素。共享同一数组的切片都会看到这些修改。 切片下界的默认值为 0，上界则是该切片的长度。 切片的长度就是它所包含的元素个数。切片的容量是从它的第一个元素开始数，到其底层数组元素末尾的个数。 对于数组var a [10]int来说，以下切片是等价的： 1234a[0:10]a[:10]a[0:]a[:] 使用 make 创建切片make 传入两个或三个参数，底层数组类型，长度，容量（可选） 1234func cut() { b := make([]string, 2) c := make([]int, 3, 5)} 使用 append 为切片添加元素12345a := []int{1,2,3}fmt.Println(a) // [1 2 3]a= append(a, 6,7,8)fmt.Println(a) // [1 2 3 6 7 8] 当 s 的底层数组太小，不足以容纳所有给定的值时，它就会分配一个更大的数组。返回的切片会指向这个新分配的数组。 使用 for range 遍历切片for range 输出两个值，一个当前元素的下标，一个当前元素的值。 123456func cut() { s := []int{1,2,4,8,16} for i, v:=range s{ fmt.Printf(\"切片的第 %d 个元素为 %d \\n\", i, v) }} 输出： 12345切片的第 0 个元素为 1切片的第 1 个元素为 2切片的第 2 个元素为 4切片的第 3 个元素为 8切片的第 4 个元素为 16 如果不需要下标，或不需要值，用 _ 代替 i 或 v 即可忽略。 1234567for _, v:=range s{}for i, _:=range s{} 映射使用 map[string]int 这样的语法来创建一个 map 键值对，[]括号里面是 key 的类型，后面是 value 的类型。 12345678910func test() { m := make(map[string]int) m[\"a\"] = 42 m[\"b\"] = 43 fmt.Println(m[\"b\"]) // 43 elem := m[\"a\"] fmt.Println(elem) // 42} 用双赋值检测某个键是否存在。如果存在，第一个值为键值对的value，第二个值为 true ，如果不存在，第一个值为 value 的零值，第二个值为 false。 12345e, ok := m[\"a\"]fmt.Println(e, ok) // 42 truee, ok := m[\"d\"]fmt.Println(e, ok) // 0 false 用 delete 删除元素 1delete(m, \"a\") 一个 wordcount 小程序 1234567func WordCount(s string) map[string]int { m := make(map[string]int) for _, key:=range strings.Fields(s){ m[key]++ } return m} 闭包Go 支持闭包，即函数可以作为值，函数也可以返回一个函数。 用闭包实现斐波那契数列（0,1,1,2,3,5,8,13,21,34…） 1234567891011121314151617// 返回一个“返回int的函数”func fibonacci() func() int { first := 0 second := 1 return func() int { result := first first, second = second, first+second return result }}func main() { f := fibonacci() for i := 0; i &lt; 10; i++ { fmt.Println(f()) }} f 是一个“返回int的函数”，f() 是 f 的调用，即一个 int 值。闭包的作用在于“内部封闭外部”，即变量在外部作用域结束之后，还保留一份在内部。 方法和接口方法在 Golang 中，没有类，但结构体是一样的。Java的类里面可以定义方法，Go可以为结构体定义方法。例如： 一个长方形结构体 1234type Rectangle struct { long float64 width float64} 为其定义求面积的方法， 12345678func (r Rectangle) Area() float64 { return r.long * r.width}func main() { r := Rectangle{3.5, 1.8} area := r.Area()} 事实上，方法跟函数是一样的。上面的方法可以改写成函数。 12345678func getArea(r Rectangle) float64 { return r.long * r.width}func main() { r := Rectangle{3.5, 1.8} area := getArea(r)} 当然，也可以直接操作指针(通常的做法) 12345678910// 将长方形的长和宽扩大两倍func (r *Rectangle) scala() { r.width = 2 * r.width r.long = 2 * r.long}func main() { r := Rectangle{3.4,2.1} r.scala()} 接口如果一个类型，实现了一个接口所定义的所有方法，那就说这个类型实现了这个接口，并不用显式去声明。 123456789101112131415161718192021// 一个图形接口type shape interface { Area() float64 Perimeter() float64}// 长方形type Rectangle struct { long float64 width float64}// 长方形求面积func (r Rectangle) Area() float64 { return r.long * r.width}// 长方形求周长func (r Rectangle) Perimeter() float64 { return r.long * 2 + r.width * 2} 在 Go 中，接口也是可以作为参数或者返回值的。 错误Go 使用 error 表示错误。error 本质上是个接口： 123type error interface { Error() string} 通常一个方法会返回一个错误，如果这个错误不为空，则说明它发生了错误。 12345678910// 一个 http 请求http.HandleFunc(\"/\", sayHello)// 错误err := http.ListenAndServe(\":9090\", nil)// 如果检测到错误，执行对应的动作if err != nil { log.Fatal(\"ListenAndServe: \", err)} 并发Go 语言最大的特点就是 goroutine 了 1234567891011func say(s string) { for i := 0; i &lt; 5; i++ { time.Sleep(100 * time.Millisecond) fmt.Println(s) }}func main() { go say(\"world\") say(\"hello\")} go say(&quot;world&quot;) 会发起一个新的协程执行，而say(&quot;hello&quot;) 在 main 主程里执行，所以是并发执行的。 信道（channal）信道非常适合在各个 Go 协程间进行通信。箭头就是数据流动的方向。 12345// 创建一个接收或发送 int 型的信道ch := make(chan int)ch &lt;- v // 将 v 发送至信道 ch。v := &lt;-ch // 从 ch 接收值并赋予 v。 官方示例 12345678910111213141516171819// 求和func sum(s []int, c chan int) { sum := 0 for _, v := range s { sum += v } c &lt;- sum // 将和送入 channal}func main() { s := []int{7, 2, 8, -9, 4, 0} c := make(chan int) go sum(s[:len(s)/2], c) // 计算前半部分和 go sum(s[len(s)/2:], c) // 计算后半部分和 x, y := &lt;-c, &lt;-c // 从 c 中接收 sum := x + y // 合并} 用 for range 来不断地从信道获取值，用双值检测信道是否被关闭。 123456// 若没有值可以接收且信道已经被关闭，ok会被置为falsev, ok := &lt;-chfor i := range c { fmt.Println(i)} IDE 使用 我使用的是 JetBrain 全家桶的 Goland。有几个注意点： main 函数一定要在 main package 里面 如果同包不同文件互相调用，编译的时候记得在 Configuration 的 Run Kind 选择 Package","link":"/post/dcaae91f.html"},{"title":"《黑客与画家》摘录","text":"《黑客与画家》是我去年读过感觉很棒的一本书，重新温习了一遍，记录了一些很值得分享的句子和观点。 作者paul graham的博客：http://paulgraham.com/articles.html 前言黑客行为必须包含三个特点: 好玩 高智商 探索精神 黑客的追求的是这三种价值，而不是实用性或金钱。 应该把黑客与画家当作同一种人看待。和画家一样，黑客只是怀有一门特殊手艺，有创造天赋的普通人。编程是一种艺术创作，黑客就是艺术家，开发软件与画家作画，雕塑家雕塑，建筑师设计房屋并没有本质不同。 虽然黑客从外表看上去一般都是呆呆的，但是他们的大脑内部却是一个有趣得让你吃惊的地方。 第一章 为什么书呆子不受欢迎他们的心思在别的地方。 因为我在这个世界中过得并不好，我觉得一定是自己什么地方做错了。我没有意识到，作为书呆子，我不适应周围环境，某种程度上正说明我领先了一步。书呆子已经在思考的东西，正是世界看重的东西。他们与别人不一样，不把所有的时间用来玩一种耗尽全力但又毫无意义的游戏。 意识到学校并非全部的人生，也是很重要的事情。学校是一个很奇怪的，人为设计出来的体系，一半像是无菌室，一半像是野蛮洪荒之地。它就像人生一样，里面无所不包，但又不是事物的真实样子。 你告诉一个人，他的脚天生就是坏的，并不能阻止他去怀疑他可能穿错了鞋子。 第二章 黑客与画家黑客与画家一样，都是从事创造性的工作。 黑客搞懂“计算理论”的必要性，和画家搞懂颜料化学成分的必要性差不多大。 编程不应该是先打草稿然后把头脑中的程序一步步写出来，确保大体是正确的，最后再调试；而应该是一股脑不管对错，先把代码堆上去，再慢慢修改（编程和调试同步）。绘画的创作过程就很值得学习，你不能盼望先有一个完美的规格设计，然后再去动手编程，这样想是不现实的。 在大公司看来，黑客的工作就是用软件实现某个功能，而不是设计软件。在那里，程序员被当作技工，职责就是将产品经理的“构想”翻译成代码。当然这也不能说是错的，大公司本该如此（减少设计结果的标准差）。 开发优秀软件的方法之一就是自己创业，但是会遇到许多与开发软件无关的事情，而且赚钱的软件和好玩的软件重叠度不高。 黑客解决生计的办法就是找一份白天工作，然后在其余时间设计优美的软件。 黑客就像画家，工作起来是有心理周期的。有时候你有了一个令人兴奋的新项目，你会愿意为它一天工作16个小时。等过了这一阵，你又会觉得百无聊赖，对所有事情都提不起兴趣。为了做出优秀的工作，你必须把这种心理周期考虑在内。 “程序写出来是给人看的，附带能在机器上运行。”——《计算机程序的结构与解释》 第四章 良好的坏习惯良好的坏习惯，那就是不服从管教。 第五章 另一条路几年前，我妈妈收到苹果公司的一封来信，上面说她可以优惠购买新版的操作系统。老太太被这些术语吓坏了。一个65岁的妇女，只用电脑收发邮件和记账，却被迫要和操作系统打交道，搞清楚要不要安装一个新版本，这真是太过分了。 ——普通用户根本没必要知道“操作系统”这个词，更不要说“驱动程序”和“补丁”了。 “你的电脑”这个概念正慢慢成为过去，取而代之的是“你的数据”。你应该可以从任何电脑上获取你的数据。或者更准确地说，在任何终端设备上获取你的数据，终端设备不一定是你的电脑。 第六章 如何创造财富金钱并不等于财富。 哥白尼不认同托勒密的体系，一个极其重要的原因是，她觉得托勒密提出的偏心等距点（equant）毫无美感。 ——托马斯·库恩《哥白尼革命》 我们所有人都受到凯利·约翰逊的影响，狂热地相信外观优美的飞机一定会飞得同样漂亮。——本·里奇《臭鼬计划》 美感是第一道关卡。丑陋的数学在世界上无法生存。——G.H 哈代《一个数学家的辩白》 第九章 设计者的品味确实存在比其他设计更好的杰出设计。众多不同学科对“美”的认识有着惊人的相似度。优秀设计的原则是许多学科的共同原则，一再反复地出现。 好设计是简单的设计； 好设计是永不过时的设计； 好设计是解决主要问题的设计； 好设计通常是有点趣味性的设计； 好设计是艰苦的设计； 好设计是看似容易的设计； 好设计是对称的设计； 好设计是模仿大自然的设计； 好设计是一种再设计； 好设计是能够复制的设计； 好设计通常是奇特的设计； 好设计是成批出现的；（如果你远离这些中心，几乎不可能单靠自己就取得伟大成果，趋势决定你，不是你决定趋势） 好设计常常是大胆的设计。 单单是无法容忍丑陋的东西还不够，只有对这个领域非常熟悉，你才可能发现哪些地方可以动手改进。 你必须锻炼自己。只有在成为某个领域的专家之后，你才会听到心里有一个细微的声音说：“这样解决太糟糕了！一定有更好的选择。“不要忽视这种声音，要培育他们。优秀作品的秘诀就是：非常严格的品味，再加上实现这些品味的能力。 第十章 编程语言解析对于一些编程语言，内核设计并非很好，但却有着无数强大的函数库。你可以想象一辆本身性能很差的小汽车，车顶却绑着一个飞机发动机。 然而，车顶上绑着飞机发动机的小车也许真能开，只要你不尝试拐弯，可能就不会出问题。 第十一章 一百年后的编程语言当你设计语言的时候，心里牢牢记住这个目标是有好处的。学习开车的时候，一个需要记住的原则就是要把车开直，不是通过将车身对齐画在地上的分隔线，而是通过瞄准远处的某个点。即使你的目标只在几米开外，这样做也是正确的。 第十二章 拒绝平庸语言只是工具。如果有更好的工具，为什么不用呢？ 第十五章 设计与研究设计意味着做出符合人类特点和需要的产品。 设计与研究的区别看来就在于，前者追求“好”，后者追求“新”。优秀的设计不一定很“新”，但必须是“好”的。 优秀设计的前提是你自己必须喜欢这种产品，否则你不可能对设计有兴趣，更不要说士气高昂了。为了把产品设计好，你必须对自己说：“哇，这个产品太棒了，我一定要设计好！” 而不是心想：“这种垃圾玩意，只有傻瓜才会喜欢，随便设计一下就好了。”","link":"/post/2f71447d.html"},{"title":"silver lining","text":"每个人都有半面，一半乌云、一半幸福。在别人看来，你是一个疯狂的精神病人，可是当你遇到一个跟你一样独特的人，你乌云背后的阳光才能拥有初霁。我所理解的《乌云背后的幸福线》，正是遇见那个跟你一样 crazy 的人。 Crazy帕特因为妻子的背叛而精神崩溃。他逃避，假装乐观，用自以为的积极理性骗自己事情在好转。蒂芙尼目睹了丈夫的死，从此变得浪荡不羁，做出了一系列疯狂的举动，但是她承认并喜欢自己疯狂糟糕的经历。 都是 crazy 的人。 电影中让我印象比较深刻的是，在餐厅里蒂芙尼夺门而出，狠狠地骂了帕特： 你的精神病比较高级，对不对？ 你是没做过，但倒是挺爱听的，不是吗？ 你没胆子活出自我，没胆子做自己，你是个伪君子！只敢随大流，你是个骗子。我对你敞开心扉，你却瞧不起我。 当帕特听到那首刺激的歌发了疯差点被警察带走的瞬间，蒂芙尼主动帮他解围。尽管有着冲突，但本质上他们是一类人，他所经历的她都理解。也因此，才有了后来帕特答应陪蒂芙尼练舞。最后彼此看懂对方。 By the way，站在跟帕特类似性格的角度的我来说，有时候我也觉得，我们活得很假。自以为积极、理性，实际上心里阴暗得很。像蒂芙尼那样疯狂自我一点，也是一种享受和自在。 Response借用豆瓣的一句影评： 你知道生活的真谛是什么吗？就是让人大吼what the fuck。 你知道健康生活的真谛是什么吗？就是半夜打破窗子把那本你不喜欢结局的破书扔出去。 你知道人际交往的真谛是什么吗？就是大家彼此都是精神病，却互相都觉得自己的精神病更高级一点。 你知道爱情的真谛是什么吗？就是两个精神病在同一条小道上你追我赶，从互相揭伤疤到可以共跳一支舞。 你知道人生的真谛是什么吗？就是明知道这是精心策划的一场骗局，可你还是愿意参与其中，豪赌一把。 这世界上看着你疯的人很多，但是愿意陪着你一起疯的人很少。 The only way you could meet my craziness was by doing something crazy yourself. The world will break your heart tenways to Sunday, that’s guaranteed. And I can’t begin to explain that… Or the craziness inside myself and everybody else, but guess what ? Sunday is my favorite day again. I think of everything everyone did or me and I feel like … a very lucky guy. 生活会将你的心彻底击碎，这是肯定的。我无法解释这一点，也无法解释在我和其他所有人内心的疯狂。但你猜怎么着？星期天又成了我最爱的一天。我想到每个人为我做的一切，我觉得很幸运。","link":"/post/745782bb.html"},{"title":"《挪威的森林》摘录","text":"第二章 何以夜间非降旗不可、其缘由我无从得知。其实，纵然夜间，国家也照样存在，工作之人也照样不少。巡路工、出租车司机、酒吧女招待、值夜班的消防队、大楼警卫等等——这些夜间工作的人享受不到国家的庇护，我觉得委实有欠公道。不过，这也许不足为怪，谁也不至于对此耿耿于怀。介意的大概舍我别无他人。 但不管我怎么努力忘却，仍有一团恍若薄雾状的东西残留不走，并且随着时间的推移，雾状的东西开始以清楚而简洁的轮廓呈现出来。 死并非生的对立面，而作为生的一部分永存。 第三章 …但不知何故，就是不曾为之倾心。或许我的心包有一层硬壳，能破壳而入的东西是极其有限的。 若问自己现在所做何事，将来意欲何为，我都如坠雾中。 惟有死者永远十七。 第四章 于是我走到他们跟前，问他们何以前来教室而不继续罢课，他们没有回答，也无法回答。他们害怕因缺课过多而拿不到学分。此等人物居然也高喊什么肢解大学，想来令人喷饭。如此卑劣小人，惟有见风使舵投敌变节之能事。 “喜欢孤独吗？”她手托着脸颊说。“喜欢一个人旅行，一个人吃饭，上课的时候一个人离得远远的孤零零地坐？” “没有人喜欢孤独的。只是不勉强交朋友而已。因为就算那样做也只有失望而已。”我说。 “哪里会有人喜欢孤独，只是讨厌失望而已。” 我不由想，倘若那个五月的星期日不在电车中碰巧遇到直子的话，或许我的人生将与现在大为不同。但又马上推翻了这一想法，觉得即使那时不遇上直子，恐怕也不至于出现第二种结果。说不定那时我们是为相遇而相遇的。纵令那时未能相遇，也会在别的地方相遇。 然而在隔了许久后重新观望这光景的时间里，我蓦然注意到一个事实：每个人无不显得幸福。至于他们是真的幸福还是仅仅表面上看上去如此，就无从得知了。但无论如何，在九月间这个令人心神荡漾的下午，每个人看来都自得其乐，而我则因此而感到了平时所没有感到过的孤寂，觉得惟独我自己与这光景格格不入。 第五章 …不时出现那种情况，亢奋、哭泣。不过不要紧。这样还好，因为可以把感情宣泄出去。可怕的是感情泄不出去，就会憋在心里，越憋越多，各种感情憋成一团，在体内闷死。 任凭怎么解释，世人也稚嫩那个相信自己愿意相信的事情。越是拼命挣扎，我们的处理越是狼狈。 第八章 我不是那样的强者，也并不认为不被任何人理解也无所谓，希望互相理解的对象也是有的。只不过对除此以外的任何人，觉得在某种程度上即使不被理解也无可奈何。 人理解某人是水到渠成的事，并非某人希望对方理解所使然。 第九章 “喂，喂喂，说点什么呀！”绿子把脸埋在我胸前说。 “说什么？” “什么都行，只要我听着心里舒坦。” “可爱极了！” “绿子”，她说，“要加上名字。” “可爱极了，绿子。”我补充道。 “极了是怎么个程度？” “山崩海枯那样可爱。” 绿子扬脸看看我：“你用词倒还不同凡响。” “给你这么一说，我心里也暖融融的。”我笑道。 “来句更棒的。” “最最喜欢你，绿子。” “什么程度？” “像喜欢春天的熊一样。” “春天的熊？”绿子再次扬起脸，“什么春天的熊？” “春天的原野里，你一个人正走着，对面走来一只可爱的小熊，浑身的毛活像天鹅绒，眼睛圆鼓鼓的。它这么对你说道：‘你好，小姐，和我一块儿打滚玩好么？’接着，你就和小熊抱在一起，顺着长满三叶草的山坡咕噜咕噜滚下去，整整玩了一大天。你说棒不棒？” “太棒了。” “我就这么喜欢你。” 第十章 恕我免去客套。这封信是在你去买可乐的时候写的。给凳子邻座的人写信，在我还是初次。但不这样做，似乎很难把我想说的传达给你。因为无论我说什么你几乎都听不进去，是吧？ 嗯，你可知道？今天你做了一件十分使我伤心的事：你甚至没有注意到我发型的变化吧？我辛辛苦苦地一点点把头发留长，好不容易在上周末把发型变得像个女孩儿模样，可你连这点都未察觉吧？我自以为十分可爱，加之久未见面，本想吓你一跳，然而你根本无动于衷，这岂不太跟人过不去？反正你现在恐怕连我穿什么衣服都记不起来了。我也是个女孩儿！你就是再有心事要想，也该多少该正眼看我一下才是。只消说上一句“好可爱的发型”，往下无论你做什么，哪怕再心事重重，我都会原谅你。 所以，我现在向你说谎，什么要同姐姐在银座会面，全是谎话。本来我打算今天住在你那里，睡衣都带在身上。是的，挎包里装有睡衣和牙具。哈哈哈，傻瓜似的。但你偏偏不肯邀我去你住处。不过也好，既然你不把我放在心上而似乎乐得一人孤独，那么就让你孤独去，去绞尽脑汁想各种事情，想个彻底！ 不过这也并非说我对你有多么恼火。我仅仅是感到寂寞。因为你对我没少热情关照，而我却一次也没为你效力。你总是蜷缩在你自己的世界里，而我却一个劲儿“咚咚”敲门，一个劲儿叫你。于是你悄悄抬一下眼皮，又即刻恢复原状。 现在你手拿可乐回来了，一副边走边沉思的样子，我恨不得你跌一跤才解气，可你并未跌跤。你正坐在旁边，“咕嘟咕嘟”喝可乐。买可乐回来时，我还期待你注意到我的发型，说上一句“嗬，发型变了嘛”，结果还是落空了。假如你注意到，我会把这封信撕得粉碎，说：“喂，去你那里好了，给你做一顿香喷喷的晚饭，然后和和气气地一起睡觉。”但你俨然一块铁板似的麻木不仁。再见。 附记：下次在教室见面不要打招呼。","link":"/post/dce17740.html"},{"title":"关于感情","text":"健康最近发生了很多事，博客也将近一个月没有更新。 首先我病了。病了将近半个多月，生病的这段时间里，除了吃药睡觉，就只有吃药睡觉。很难受。每天早上起床的第一件事不是去上课，不是想着该补回已经落下很多的知识，也不是想着去哪里玩，而是躺在床上，直到继续睡过去，再直到中午浑浑噩噩地起床吃个外卖，然后继续午睡。 有一句话说，“赖床是因为没有勇气开始这一天”。尽管在生病期间，理应得到好好的休息，但那段时间，我好像同时也丧失了好好生活的动力，以及勇气。我的脑袋运转不起来，无力去想关于生活的任何方方面面，我只是躺在床上，然后无所事事。 冬至拖着感冒疲惫的身体回了家，好好休整了三天。回到学校正常去上课了一天，晚上又因为肚子痛和胃痛，一下子被打回原样。终于又没有去上课了，而这学期，也再没有课可以上了。 好似是感冒好很多了，这两天精神状态才又恢复了一点。 我这才又重新振作了一点点。重新开始去思考，去总结，去捡起落下的东西。 总而言之，人心里总要有一些诗和远方，但是健康地活着，包括心理和身体上的健康，才是最重要的。 感情生病的这将近半个多月时间里，我有时也会去想感情的问题。 我在想，经历一段失败的感情，其实也未必一定让人成长。相反，也可能使一个人丧失爱的能力。人的一生当中，是否一定要经历很多分分合合，又是否也有可能，你努力了那么久，也不一定会找到对的那个人，或者找到了却错过了。如果上面的问题的答案是“Yes”的话，那简直太令人难过了。 但是，无论如何，还是得相信爱，不是吗？本身就不相信爱情的人，即使拥有，也会因为自己的不相信而再次失去。 “胆小鬼连幸福都会害怕，碰到棉花都会受伤，有时还被幸福所伤”。 我想，我还是相信爱的。 昨天发现了一部电影——《Love actually》，中文翻译是《真爱至上》。晚上11点钟看完竟然深深地被治愈。 Whenever I get gloomy with the state of the world, I think about the arrival’s gate at Heathrow airport. General opinion start to make out that we live in a world of hatred and greed. But I don’t see that, seems to me that love is everywhere. Often it’s not particularly dignified or newsworthy, but it’s always there, fathers and sons, mothers and daughters, husbands and wives, boyfriend, girlfriend, old friends. When the plane hit the Twin Tower, as far as I know, none of the phone calls from people on board were messages of hate or revenge. They are all messages of love. If you look for it, I’ve got a sneaky feeling that love actually is all around. 每当我为世界的现状感到沮丧时，我就会想到伦敦希思罗机场的接机大厅。很多人都开始觉得，我们生活在一个充满贪婪与憎恨的世界里，但我却不这么认为。对我来说，真爱无处不在。它可能并不起眼，也上不了报纸头条，但它的的确确存在着。它存在于父子、母女、夫妻、 男朋友、女朋友、还有老朋友之间。飞机撞上双子楼的那一刻，据我所知，没有一通来自航班上的通话传递的是仇恨或复仇，它们全部是爱的留言。如果你用心去看，我确信你会发现，真爱其实无处不在。 即使没有和你手牵手漫步街头开怀大笑的那天，即使只能在四下无人的夜里想你想到独自哭泣，即使永远只能守望着你和另外一个人相守白头； 我荒废的心也会爱你直到天荒地老。 That’s enough. 明年的圣诞节，我想不出意外我一定会重温《真爱至上》这部电影。到时候又会对爱有怎样的感悟呢？ 今天又看了同类电影，《其实他没有那么喜欢你》(《其实你不懂他的心》)。再一次对寻找爱和幸福有了新的感悟。 女孩在成长的过程中会学到很多东西： Girls are taught a lot of stiff growing up: 如果一个男孩欺负你，是因为他喜欢你。 If a guy pinches you, he likes you. 千万不要试着自己修剪刘海。 Never try to trim your own bangs. 然后有一天，你会遇到非常棒的男人，从此过着幸福生活。 And someday you will meet a wonderful guy and get your very own happy ending. 我们看的每场电影，听过的每个故事都告诉我们要耐心等待。 Every movie we see, every story we’re told implores is to wait for it. 而第三类情况是：无法预知的爱情宣言，游离于规则之外。 The third act twist: The inexpected declaration of love.the exception to the rule. 但有时我们太专注于寻找幸福。 But sometimes we’re so focused on finding our happy ending. 我们没有学会如何读懂别人的暗示。 We don’t learn how to read the signs. 如何分辨谁是真正爱我们的人。 How to tell the ones who want us from the ones who don’t. 如何分辨这个人是不是只是生命中的过客。 The ones who will stay from the ones who will leave. 或许这个幸福的结局中并没有一个很棒的男人。 And maybe this happy ending doesn’t include a wonderful guy. 或许是你，你一个人，收拾好心情，然后重新开始。 Maybe it’s you, on your own, picking up the pieces and starting over. 释放自己，为了更好的未来。 Freeing yourself up for something better in the future. 或许这个幸福的结局只是继续生活。 Maybe the happy ending is just moving on. 或者可能幸福的结局是这个： Or maybe the happy ending is this: 我们明白，即使你曾因男人不回电话而伤心欲绝。 Knowning that through all the inreturned phone calls and broken hearts. 即使你曾像无头苍蝇一样四处碰壁，自作多情… throgh all the blinders and misread signals… 即使你曾经受伤或者出糗… through all of the pain and embarrassment… 你也决不能放弃希望。 you never, ever gave up hope. 好朋友小静静跟我说：“正确的恋爱观也应该是这样的吧：尽力地去等一个人、尽力地去爱一个人，在每一次恋爱中全心投入，失恋分手了，可以伤心难过，但也要再认真地做回自己，不要失去去爱的勇气！” 感情也好，生活的其他方面也好，愿你不放弃。 最后，在我心里，其实一直有个疑问：那么一段成熟、稳定、可持续的感情到底应该是什么样的呢？ 所有的爱情电影，似乎都只会告诉你爱情的美好，告诉你真爱存世，告诉你不要放弃追寻爱的希望……但是好像却少有人告诉你，如何在感情中长久地相处。如果知道答案的话，就不会有那么多的分手了吧。 我也会，试图去寻找这个答案的。","link":"/post/c3c12d05.html"},{"title":"关于2018","text":"窗外是阵阵建筑工地的金属切割声，虚掩的房门时而传来妈妈和她的朋友们新年首聚欢谈的言笑。抬头倒也是蓝天白云，安溥的《蓝天白云》自然在我心里单曲循环。这太像是我会想的内容，也太像是我会做的事情。 当我意识到我可能该为去年写些什么东西的时候，却无论如何回忆不起来这一年的任何一个细节，那些人、事、喜欢的和不喜欢、以及自我统统四散无寻。于是开始翻阅这一年我在互联网上留下的痕迹，试图找寻一个代表性的事件，但答案跟这蓝天白云一样转眼间即逝。就像上个月准备离校时整理出来的很多书、电影、歌和物品，愈是想通过回忆抓住，愈是很快地溜走了。 上半年的项目和下半年的秋招充实了我的整个2018，但我并不想为此再写些什么总结性的东西。因为它们太像是正常而会发生之事，在大学生涯或者往大了说在人生道路上总会或者循规蹈矩或者坎坷般地出现。对此我没有任何的意外。 而在让自己更舒心的探索上（尽管有时候会变成更糟心），一开始是人和联结（4月28日的句子：Rarely can a response make somthing better, what makes something better is connection），尤其是跟一些人的往来中得到了新的启发曾经是让我见到那么些阳光，让我开心过有那么一段时间我拥有过友谊、感情、理解或者在现在看来是比较虚无缥缈的快乐一类的事物，Whatever，时光沉淀终究清晰了画面，他人并不解救自己。好在在 2018 的最后一段精彩时光里在安溥的歌和词中获得一些共鸣性的东西，因而也能够心生宽慰而不太过于在意和纠结。2019 我更想遵循内心地走过，不再刻意为了联结而联结。人、事、喜欢和不喜欢以及自我都自然而然地发酵发生。可贵的是，能够去相信的人和事越来越少，可仍然倾向于去相信。 应该是在很久以前就认识到读书的重要性，但这一年完整读过的非技术书籍却寥寥无几，以至于四散窜出而又无处安放的想法和思维得不到补充和表达。这种感觉在每个每天深夜思考的自己的灵魂中尤为强烈，写下这篇文字的同时亦有同感。这是在我写了四年的代码后发现自己对文字情有独钟的那一刻最后悔莫及之事。 从写下这篇文字的第一个字至此，我终于明白 2018 年对我最重要的内容依然无法透过文字表达。除此之外，便没有什么再值得回忆或者记录的东西了。我想留一些信条在2019： 一切事情以让自己开心为导向； 把自己的情绪寄托在他人身上是愚蠢的； 不再刻意去追求一些本该无所谓的东西，倒是保持本性自在； 保持阅读和学习英语。 附上 2018 年看过并且喜欢的电影，电影依旧是我喜欢的艺术： 《大佛普拉斯》 - 虽然现在已经是太空时代了，人类可以搭乘太空船到达月球，但却没办法看穿每个人心里的宇宙 《向阳处的她》 - 是你吃掉了布莱恩吧？ 《敦刻尔克》 - 1 hour, 1 day, 1 week 《控方证人》 - 一个不同寻常的女人 《面纱》 - 我只恨我自己曾经深爱过你 《饮食男女》 - 人生不能像下厨，等所有材料准备好了才下锅 《小偷家族》 - 如果说爱你，还打你，那一定是说谎；如果爱你，就会像我这样紧紧抱住你。 《我不是药神》 - 我只是想活 《三块广告牌》 - 愤怒不得宣泄只会酝酿出更深的愤怒 《真爱至上》 - Love is actually all around 《无问西东》 - 愿你在被打击时，记起你的珍贵 《影》 《灵异第六感》 《Unnatural》（日剧） - 一个懂得规则的人的坚持是尤为可贵的","link":"/post/9484ec75.html"},{"title":"快递","text":"晚上9点，接到京东小哥的电话，说我快递到了，在出入口体温检测点等我，我说放那吧，我稍后就出去取，小哥说我快件比较多，他不太放心，还是在这等我出来吧。听他这么说，我便即刻起身出门，一路快走，3分钟就从家里赶到了出入口。 小哥正在接另一位客户的电话，我只听到了几句「很快就给你送」之类的话。挂了电话，他从车上翻出四个包裹，磊得整整齐齐，看我一只手握着手机，另一只手捏着出入证，便说你稍等，我给你缠一下。又掏出胶带熟练地把四个包裹缠在一起，上面还留了一截，方便我一只手提。 期间我问小哥这么晚还在派件呢，小哥嘀咕着说这几天快件特别多，送不完。说罢指了指旁边磊好的几小堆快件，说这些都是给他们打过电话，让他们来出入口取，但有些放了两三天都没人来取走，又怕放丢了，像你3分钟就出来的倒是很难得了。 我在想，为啥我会用一路快走这样的下意识动作尽快的到达呢？除了我自小就不喜欢等别人也不喜欢被别人等的性格之外，我想某种层面上我和京东小哥曾经也「共事」过，理解他们的不易。大学的时候我在校园京东派兼职，京东派的负责人是强哥，强哥的性格跟我眼前这位京东小哥实在太相像，友善而认真。那段时间，我跟着强哥见识过很多「奇葩」的客户，其中最令我印象深刻的是一个学生说他出了配送费，就应该给他送到宿舍门口，而不是让他自己到京东派取，要求给他退配送费，还扬言要投诉我们。然而学生宿舍是学校管制地区，快递员又怎么随便能进得去呢？这就成了一个矛盾。 这次疫情，几乎所有小区都是封闭管理状态，快递配送模式跟当年在学校京东派很像。我实在很想说，没有人是容易的，尽量少给别人制造麻烦，也多一些互相理解吧。 回到家，拆了快递，其中一个包裹里面是两个插座。凭借着初中学过还没忘的「左零右火中接地」知识，自己摸索着把出租屋里烧坏的两个插座换掉了。我除了不喜欢等别人或者被别人等之外，也不太乐意有求于人，就像这次联系了维修师傅整整一个星期都没来后，我总感觉像是我做错了什么一样，期待无果最终决定自己动手。 回想起来，毕业后自己独自生活不到一年的时间里，我在租的出租屋里自己换过水龙头，燃气管，水阀，电灯，甚至自己修理衣柜门。在练就一身技能的同时，也是在体验着一次又一次的不容易。慢慢的，我开始不再期待依赖或者麻烦别人。 讲了这么多，我只是想说，少给友善的人添麻烦，也别对没必要的人加以期待( 这不只是对一个预约了一个星期都没上门的维修师傅的控诉 :XD )。","link":"/post/7c07ab5f.html"},{"title":"人月神话","text":"焦油坑编程有它的乐趣，来自于创造事物、创造有用的劳动成果、精妙组织产生的魔术般力量、学习和挑战和自我驾驭等等。然而这份职业也有自己的问题，如必须追求完美，由他人设定目标和供给资源和信息，不可避免的重复劳动，以及更新换代快等等。 而软件工程（尤其是开发大型系统）就像焦油坑，只有非常少数项目能满足目标、时间进度和预算的要求。表面上看，没有一个单独的问题导致了困难，但当它们相互纠缠和积累在一起的时候，麻烦就来了。 人月神话在众多软件项目中，缺乏合理的时间进度是造成项目滞后的最主要原因： 缺乏有效的估算； 假设人和月可以互换，错误地将进度与工作量混淆； 对估算没有信心，而又不愿意持续估算； 对进度缺少跟踪和监督； 进度偏移时，下意识增加人力，火上浇油，适得其反。 乐观主义所有的编程人员都是乐观主义者，“这次一定能运行”你一定听得多吧？编程是一种创造性的活动，而人的构思总是有缺陷的，因此总会有bug。即使单个任务万无一失，在大型项目中，多个任务的组装不一定就那么顺利，使得一切正常的概率变得非常小。 人月在软件工程中，成本的确随开发产品的人数和时间的不同，有着很大的变化，但进度却不是如此。因此用人月作为衡量一项工作的规模是一个危险和带有欺骗性的神话。它暗示着人员数量和时间是可以相互替换的。 当任务由于次序上的限制不能分解时，人手的添加对进度没有帮助。无论多少个母亲，孕育一个生命都需要十个月。而对于可以分解，但子任务之间需要相互沟通和交流的任务，必须在计划工作中考虑沟通的工作量。 沟通的负担来自于两个部分，培训和相互交流。每个成员需要进行技术、项目目标以及总体策略上的培训。一对一交流的情况下，三个人的工作量是两个人的三倍，四个人则是两个人的六倍。而对于需要在三四个人之间召开会议、进行协商、一同解决的问题，情况会更加恶劣。 对于进度安排，一个经验法则是，30%的时间用来做计划，20%的时间用来编码，25%+25%的时间用来做构建测试+系统测试。也就是说，测试至少占一半的时间。 缺乏合理的时间进度是造成项目滞后的主要原因，而向进度落后的项目中增加人手，只会使进度更加落后。","link":"/post/70855dc9.html"},{"title":"我的2019","text":"圣诞节前一晚，阿琳问我重温《真爱至上》了没有，我说资源都找好了，就是没有兴致看，于是临时决定看《小森林》，可是《小森林》也没看完，就把平安夜的时间花费在其他虚无的事情上去了。2018年我看了不少电影，在 去年的总结 里列出来过，但对于我的2019，一瞬间却是完全的空白。直至打开D盘电影清单目录，试图寻找这一年的蛛丝马迹的时候，才赫然看到下载未看电影已经积累到十几二十部。 2019对我来说其实是很好的一年，拿到驾照、提前实习、顺利毕业、到一个新的城市、有一份不错的工作，租房遇到很好的房东、以及，最重要的，盛夏时节跟她重逢。一切都非常顺利，以至于此刻回想起来竟觉得有些不可思议，又或许是我把今年要面对的最困难的事情提前在2018年完成了，比如拿到校招offer和完成我的毕业论文，这些都是2018年提前做完了的。 2018我说要留一些信条在2019，分别是： 一切事情以让自己开心为导向； 把自己的情绪寄托在他人身上是愚蠢的； 不再刻意去追求一些本该无所谓的东西，倒是保持本性自在； 保持阅读和学习英语。 回想起来，除了第4点程度还不够之外，前3点自觉已经达成，发现自己一旦真的这样去做了，就会发自内心的感到舒适和自在。整个2018年最困扰我的是我发现自己没法跟身边的人建立「良好的关系」，鲁迅说，人的悲欢并不相通。我实在是做不到用家乡话叫做「世情」的性格去融入或大或小的群体。2019年，我索性维持了一套简单的人际法则，反而变得舒心，快乐得多。只是这样做的后果是常常要面对一个人的境况，但于我而言这是最好不过的了。 我很喜欢知乎2020给我的这句话： 驾驭得了「光鲜亮丽」，但「与世无争」的时候你会更欢喜。 我大概是少数的喜欢上班甚过上学的人。上学又有什么意思呢？老师上面讲的多半都是我已经会的了内容，回去还是得自学新的东西，而我还得给他们交学费。而上班有时候会遇到很多我不会的挑战，这有时候很刺激，但前提是在一个有完善的人才培养机制的公司里，允许你去花时间弄懂你不会的东西，即使最后实在弄不懂也不会有太严重的后果。而如果工作内容都是我已经会了并且喜欢做的东西，那就更爽了——我在做着这么有意思的事情，而他们竟然还要给我钱。 但是工作带来的一个后果就是愈发觉得时间不够用了起来，除去睡眠和属于工作的时间，我的一天只有4个小时。再除去生活成本，真正属于自己的时间只有两到三个小时（如果多的话），所以花两个小时看一部电影对一天来说其实足够奢侈。因而D盘积攒的那些影单，显然还没好看到我愿意花时间买单。唯一一次例外是8月份的一个晚上，我几乎是熬夜看完了《寄生虫》，所以不妨可以作为我的年度电影。实在要加一部电视剧的话，《毒枭》3部曲也相当不错，我的国庆假期就是在这部剧中度过的。 说回工作和时间，由于近一年的时间我都在跟随团队做数据库迁移的工作，这是一件往大了说很有挑战性，往小了说又足够繁琐有许多细枝末节的事，所以刚参加工作就能参与到这样一件事里面，直接导致了我的SQL能力提升了300%，并且在改前人的屎山代码时深刻体会到前瞻的重要性，于是乎重新捡起了买了两年都没怎么好好读的《Clean Code》。迁移这件事还推动我几乎读完了《高性能MySQL》和《Effective Java》两本书，这一年对 MySQL 和 Java 的理解变得更加透彻，回过头来看以前的知识，有一种恍然大悟之快感。 这一年所处在的环境让我见识到很多很优秀的人，这让我不得不承认自己实在算不上一个聪明的人，只是性格里的肯学多少弥补了一点差距，才让我勉强在此站稳驻足。但接受自己的平凡和普通本身没有什么不好的，重要的是「知不足然后能自反也；知困然后能自强也」。 这篇文字拖拖拉拉从2019写到2020，想了很久，也没有什么值得再能补充和回忆了。寄语2020，希望自己保持19年这种节奏的同时，稳步精进，对时间更加有规划，再然后多读书总是没有错的，最后，更多的是希望自己能多抽出时间陪陪家人和女朋友，我向来是个喜欢独处的人，但却发现只有跟他们在一起的时候，我才感到真正的心安，所谓一个人的幸福感，其实大半是来自于亲近的人，这是再怎么享受独处都无法体会的一种满足。","link":"/post/3e5ce296.html"},{"title":"腾讯创业史中我所看到的","text":"最近在看吴晓波的《腾讯传》，书的封面有三个词——幸存者（Survivor）、挑战者（Challenger）、领跑者（Leader）很是让我感兴趣。想着一边看一边随便写点什么吧，顺便记录我从这本书中思考的一些点。 “大佬”们和他们的创业马化腾说，在创业的那些年，我们从来没有想过未来，都在为明天能活下去而苦恼不已。看到这句话，我想起 ZEALER 的王自如，在 ZEALER 最近一期视频 这几年王自如经历了什么？中也印证了这一点。都说创业维艰，确实创业维艰。 1998-1999年，确实是一个不可错过的互联网时代。国外有网景与微软的浏览器之争、盖茨的Windows 98、乔布斯的 iMac、以色列的ICQ，以及，错过用100万美元收购 Google 搜索核心技术的雅虎杨致远。国内有从搜索+门户网站切入的搜狐张朝阳，从生活咨询切入的新浪王志东，从电子邮箱切入的网易丁磊，从电子商务切入的阿里巴巴马云，从搜索切入的百度李彦宏和3721周鸿祎。以及，砸钱养OICQ的腾讯。 事实上，这些人其实都是当时最聪明的人才，他们的发家绝不仅仅只是因为机遇和时代浪潮。我很喜欢书中的一段话： 这是当代中国的“黄金一代”，他们大多数受过正规的学历教育，有良好的专业背景，不少人拥有硕士或博士学位，甚至毕业于全球最好的大学。 微创新ICQ以及他的中国模仿者们确实有很大的缺陷，例如客户端存储好友。而腾讯OICQ之所以能成功，离不开腾讯的微创新。服务端存储、适应当时中国互联网背景的软件体积（OICQ第一版只有220KB）、UDP传输。可以说，腾讯一开始就是一家注重用户体验的公司。 它们的思考出发点均非技术的革命性突破，而是客户的点滴体验。 而往往，技术的突破来源于为了更好的用户体验。 用户快速增长，性能瓶颈不断出现，为了不让用户失望，逼得团队不断优化性能，不断克服瓶颈。说到底，都是被逼出来的结果。（张志东） 看到这里，我除了佩服腾讯的这种微创新之外，还思考了其背后的东西——为什么是他们能够做到？张志东跟马化腾是大学同学，本科毕业后又到华南理工大学攻读了研究生，他本身就是一个技术天才。没有这种硬实力，我想是开发不出来这样的产品的。所以，你首先得足够优秀，足够有能力，然后再来谈实现，谈创新，谈优化用户体验。这一点，在 Google 的创始人拉里佩奇和谢尔盖布林中也得到印证——他们是在斯坦福大学读计算机博士。 寄人篱下腾讯当时帮别人做软件，把赚到的钱都用来养QQ这一款在当时看来完全没有盈利方式的软件上。在那个年代，投资人也不敢轻举妄动，不敢投资。在濒死之际，MIH 和 IDG 的一笔风险投资救了腾讯一命。后来，腾讯又找到了依托于电信运营商的“移动梦网”业务疯狂吸金，直至2004年上市。 可是上市了，就一帆风顺了吗？事实上，腾讯的业务是寄人篱下的。在腾讯上市前，当时高盛亚洲投资银行部的执行董事刘炽平就说了这么一段话： 这是一种寄人篱下的业务模式，会让投资人觉得腾讯缺乏可塑性，对未来美元信心和想象力。所以应该在公开募股的时候，强调网络效应，发掘即时通信工具的发展潜力。 果不其然，上面一则移动短信业务整顿的通知下来，许多公司（包括网易等）的收入受到了重创，腾讯因此也受到了一定影响。而彼时网易泡泡和微软MSN等同类产品又开始对QQ进行围剿，腾讯可谓危机重重。这让腾讯意识到，寄人篱下的业务模式是不能久远的。一定要有自己的创新点和独特的模式。 PS.《腾讯传》这本书丢在老家了，故没有读完。 o~~","link":"/post/3fc4d13c.html"},{"title":"选择、格局和搭积木","text":"选择考研 or 工作 ? 早上起来看到朋友圈有人五六点钟就起床抢占下一年的考研自习室座位。也看到身边的一些朋友原来都默默下决心要考研了。 感叹时间过得真快。考研还是工作，这个问题从大一就开始想过，现在我自己的答案是：为工作而准备。 每个人的条件和追求都不一样，对我来说，学术和科研似乎不是我所梦想的。自觉本身潜在有 Geek 的性格。因而越早投身于自己喜爱的项目和钻研中，更加合适。而且就我来说，要我看一天高数、组原这些很理论的知识，大抵我是坐不下去的。倒是坐在电脑前思考一整天如何实现XX功能，做点自己觉得酷的事情，却没有问题。 每个人都有自己的选择，定下来了，就往前走。 格局这几天一直在考试，每考完一科就觉得，学了一个学期，也就这样了。似乎每一门课带给我的收获都不及期望的大，权衡时间和精力的投入，结果甚至可能是负值。昨天加了一个华南理工大学毕业的师兄建的微信群，是给大三大四的学生做腾讯等IT公司内推的。深知差距之大，唯有继续努力学习。 不知道为什么，这几天一直想到“格局”这两个字。可能我的格局还是太小了，把自己局限在一个认知的小圈子里面。每次感觉自己很局限的时候，看到和想起一些人，一些事，比如上面提到的微信群，比如考上研究生很激励我的堂姐，比如每次看到同样在努力的好朋友小静静，就会觉得，三五年后，一切都会不一样。 现在越是拘泥自己，往后越难放大眼界。 吴军博士说： 一个人能走多远，在于他的格局有多大。想要格局大，就要广泛地吸收知识和经验，而不是把自己局限在那一点小领域中。 所以还是要多认识这个世界，再把时间线拉长到以年计。放大自己的格局和思维。 很多现在想不开觉得没有意义的事情，也就能想开了。 搭积木期末复习这段时间，偶尔也会写写东西。 因为写一篇博客，我每次都需要在git-bash里输入hexo new &quot;titile&quot;，一开始，我只是想写一个一键创建新博客的脚本，这样只需要输入文章标题，然后点一下就创建好了，然后自动打开atom。岂不很方便？ 用 Python 很快就做出来了： 123456import osname = input(&quot;please enter article name&quot;)new_article = &quot;hexo new \\&quot;%s\\&quot;&quot; % nameos.chdir(r&quot;C:\\Blog\\hexo&quot;)os.system(new_article)os.system(&quot;atom&quot;) 作为一个极致主义者，用了两次觉得黑窗口太丑了吧，我要做一个图形界面！ 于是临时学了 python 的 tkinter，捣鼓了半天，有了下面这个： 嗯，像那么点样子。 后来，觉得既然做出了创建新博客的功能，何不把生成、部署、同步到Github等等功能全部加上去呢。 于是有了下面这个。 就这样，开心地玩耍了一天之后，觉得有些博客写完需要在本地测试一下，需要加入hexo s --debug，然后调用Chrome浏览器打开http://127.0.0.1。 就在实现这个feature的时候，我卡住了。因为按下按钮后无论如何就卡死在那里。后来一想，调试的时候程序的状态是阻塞的，需要手动Ctrl+C才能继续执行下一步，可是Ctrl+C后调试就中止了呀。 于是我想到了用多线程来解决这个问题。。。想着等考试考完有时间了，再慢慢搞下去。 似乎走上了一条远征之路。。。 然而，回想起来，我一开始只是想写一个一键创建新博客的脚本而已。却慢慢搭积木搭着搭着搞出这么多花样，涉及到的知识点也越来越多，从黑窗口到图形界面到调用webbrower到多线程。 不过，这么一折腾，收获好像也是一点点变多了。 之前听北京理工大学金旭亮老师的知乎Live，他提到，你就算只是写一个简简单单的计算器应用，你能把它写好也是一种了不起的成就。从一开始的黑窗口，到带有图形界面的本机应用，再做成一个Web应用，再实现其Android客户端，这一路上涉及的知识点多着呢，你还看不起一个计算器应用吗？ 也许，就是这个道理。 2018年1月23日更新 现在“积木”已经搭成这样了 算是完成了一个功能善可的快捷助手了。当然本地测试还有一些bug，但是懒得修了，就酱紫吧。","link":"/post/5b1e0c36.html"},{"title":"重庆森林——致失去和重生","text":"不知道为什么，最近很享受看感情类电影时那种沉浸其中的感觉。可能以前经历少的时候，也就很难看懂其中的精髓。随着人生经历的增加，渐渐地在一些电影中也更能找到所谓共鸣和感同身受了。 《重庆森林》，作为港片中治疗失恋的经典之作，四个人，两个故事，讲的是我，也是你，是千千万万经历过的人。 连保鲜纸都会过期 “过期的东西没有人要的，人家要买也要买新鲜的” “新鲜新鲜，什么新鲜啊？ 就是你这种人，喜新厌旧。弄一罐凤梨罐头要花多少新鲜你知道吗？又要种，又要摘，又要切，你说不要就不要啊？ 你有没有想过罐头的感受？” “先生，我只是职员，我负责卖东西的。你叫我去想罐头的感受？你有没有想过我的感受？又要抬，又要搬，还要负责扔。我也希望那些罐头永远不会过期，我还省功夫呢。” 在爱我们的人的眼中，我们永远都是新鲜的，他们爱我们，不怕我们过期。就像金城武爱凤梨罐头。 可是，在不爱我们的人眼中，我们和这凤梨罐头没有什么分别。每一个罐头都被印上一个日期，日期一过，就什么都不是了。 之前听说过一句话，说，你给妈妈发消息，妈妈没有回复，你不会感到不安，因为你知道妈妈爱你。你给对象发消息，对象没有回复，你开始不安烦躁，因为你不确定你对象还爱不爱你。 其实了解一个人并不能代表什么，今天他喜欢凤梨，明天他可能喜欢别的 可能在已经不爱你的对方看来，你就是那个过了期的不再喜欢的凤梨罐头，仅此而已。 如果说，凤梨罐头的保质期只有一个月，那我宁愿做一张保鲜纸，可是，竟然连保鲜纸都会过期。 这个世界，还有什么是不会过期的？ 如果记忆是一个罐头，我希望他永远也不会过期 即使失去你，我会记得你。 你没发现的事失恋的时候人的状态是很好玩的。 比如，梁朝伟可以跟香皂说： “你不要自暴自弃嘛，前一阵子看你还好好的，怎麽一下子胖这麽多？！她虽然不在，你还是得见人那，不要再放纵自己了，减肥” 跟毛巾说： “我早就想骂你了，你变了你知不知道，做人要有性格嘛，就算她真的不回来，你也不应该改变你自己呀，自己好好反省。” 看到它哭的时候，我很开心，因为它外表好像改变了，可是它的本质没有变。它仍然是一条感情丰富的毛巾。 对布老虎说： “觉不觉得我开朗了，我突然觉得什麽东西都好看多了。以前我觉得你很笨，现在看起来也蛮可爱的，别把自己弄得那麽脏，以前白白的，多好！现在弄得黄黄的，你看你，还弄那麽多疤，跟别人打架啦？啊？” 对衬衣说： “你怎麽躲在这里呀？知不知道我找你多久了？你躲起来也没有用呀，要面对现实才行嘛。哇噻，你发霉了，明天吧，明天我有空，带你晒太阳。” 不知道是我忘了关水龙头，还是房子越来越有感情。我一直以为它是最坚强的，没想到它哭得最厉害。一个人哭，你只需要给他一包纸巾，可是一个房子哭，你可要做多很多功夫。 不知道是不是因为换季了，我觉得自己变了很多。我的观察力强了，开始注意些我平常不会注意的事情。 失恋的663并没有失去全世界，其实还有人喜欢，反而下一个遇到的人给了他新的毛巾，新的衣服，新的拖鞋，新的床单。 你会遇见更好的自己更好的她。 那些感同 每天你都有机会和很多人擦身而过，而你或者对他们一无所知，不过也许有一天他会变成你的朋友或是知己。 > 她走了之后，家里很多东西都很伤心。每天晚上，我都要安慰他们，才能睡觉。 每个人都有失恋的时候，而每一次我失恋，我都会去跑步，因为跑步可以将你身体里的水分蒸发掉，而让我不那么容易流泪，我怎么可以流泪呢？在阿May心目中，我可是一个很酷的男人。 不知道什么时候开始，我变成一个很小心的人，每次我穿雨衣的时候，我都会戴太阳眼镜，你永远都不会知道什么时候会下雨，什么时候出太阳。 每一架飞机上，一定有一位空中小姐是你想泡的，去年这个时候，我非常成功地在两万五千英尺的高空上泡了一个。我以为会跟她在一起很久，就象一架加满了油的飞机一样，可以飞很远。谁知道飞机中途转站…… 没有，那为什么去跑步呢？比赛？！你神经啊你？跑步这么私人的事情怎么可以随便跑给人家看呢？就这样，白白！","link":"/post/95a8d81.html"},{"title":"改变","text":"一场疫情不知不觉间改变了很多原本我以为一成不变的事情。 春节在家过了个超长假期，又远程办公了两个星期。我原本以为我永远不会期待热闹和人群，但是有一天在家突然一束光影掠过眼角，竟也有几个瞬间想念平日里稀松平实却又吵闹无比的生活。那些往日里平凡得再不能平凡东西，在这一刻变得有意义。 这段时间由于觅食的不便，我也开始自己煮东西吃了。在用煮锅煮粥这件事情上，听爸妈远程讲解多少次，加多少水，放多少米，煮多少分钟，最终成品会是什么样，都不如自己实践一遍。最坏的结果也就是吃一两顿夹生米，或者锅巴粥之类。到最后总能轻车熟路。这让我想起大一刚学编程的时候，令我很不可思议 C++ 课每两个星期理论课才有一次上机实践，我认为像编程这种东西就应该多实践，你不真实去敲一敲，听再多理论又有什么用呢？最好是每次课都是上机实践才对（毕业后听说学院教学改革确实改成这样了）。 然后这给了我一个很大的信心，原来自己煮饭也不是很难，而且确实还省钱了。 这段时间发生的事情给我带来的一个感悟就是，很多时候是外部环境改变而让自己也产生了一些改变，但有时候自己也是可以尝试着主动去改变一些事情的。譬如说，我曾经以为我永远不会骑单车上下班，直到那天尝试过一次，发现也没那么远，于是现在都是骑行了，每个月还省下了不少地铁钱，我也乐此不疲。 所以，多尝试，多改变，生活并非一成不变。 :）","link":"/post/d8c55445.html"},{"title":"最近触动我的几件事","text":"最近瞎想的东西比较多，脑袋开始有点飘。为了静下心来沉淀沉淀，决定复盘自己的博客文章，想着重温一下，温故而知新，同时查漏补缺，也是极好的。补充知识的同时也翻了翻之前带给我许多灵感的大神们的主页（个人网站、知乎、博客网站之类）。 最近几年见识过不少真正有实力的大神，从他们那里学到很多，我有个习惯就是会收藏他们的主页，像在阿里搞Java后端的大闲人柴毛毛、搞Flink的伍翀、在快手搞Android客户端的贾楷阳、以及我很崇拜的前Facebook开发者catchen。 收藏他们的主页，一来查阅技术资料时方便查找，二来不时翻阅一下他们的经历以激励自己。我自认为看他们写的复盘、人生经历、阶段总结的文章得到的收益大过于其技术文章本身。 说说这几天触动我的三件事吧。 weishu第一件，看到 weishu 在知乎问题 你决心离职的引爆点是什么 下的 回答，他说： 从那以后，我每天下班就是维护 VirtualXposed，乐此不疲；而且，下班写的这两三个小时代码，抵得上我一天的快乐……然后我明白：公司不会因为你懂得的这些额外的知识给你支付额外的工资，如果你想把这些东西变现，只能靠你自己。 这段话让我久久不能平静。想起了我高中那会曾经也有一段时间拥有过这种快乐，后来不知道为什么就把这种感觉搞丢了，大学四年和毕业一年，那种感觉却怎么也找不回来。今天早上重新把这篇回答翻出来读了两遍，感觉自己的心中有一团火，但却始终无法用言语表达，直至现在写下这些文字，依然无法描述我触动那个的点。 UtsavizedUtsavized 是昨天晚上刷 Youtube 偶然发现的一个视频博主。 起初是被 A Day In The Life Of A Software Engineer At Microsoft | Expectation vs Reality 这个视频给吸引到，介绍了他在 Microsoft 担任软件工程师的一天的生活。这真的是我理想中的生活，没有996和来自家庭、社会的压力。 而是 work life balancee 和用自己所热爱的编程技能在一个伟大的公司创造 amazing 的事情。可能我把它想得有点太过于理想化了吧，又或者我本身就是一个理想主义者。 之后看 Utsavized 最新的视频才发现他一个月前已经从 Microsoft 离职了。因为他不想循规蹈矩，想尝试一些有挑战性的事情。好吧，生活就像围墙，里面的人想出来，外面的人想进去。 vamei今天在复盘 Linux系统漫游 两篇文章，还记得这两篇是当年看 vamei 的博客 总结而写成的，当时我就感慨 vamei 写的真是太好了，文风幽默，简洁明了，值得好好学习。 后面关注了下 vamei 的最新动态，发现自2018年后就再也没有更新了，在最近的一篇博客下面看到很多 R.I.P 的评论，一时错愕得说不出话来。追到知乎才知道，vamei在2019年因抑郁症去世，实为可惜，当年跟着 vamei 的博客学习协议森林和Linux系统的场景还历历在目。 由此又想起前段时间同样因病去世的前端开发者司徒正美，他开发的 avalon 框架我至今还有在一个项目里在使用，想到这，心里更不是滋味了。 珍惜生命，热爱生活！","link":"/post/d5de69fb.html"},{"title":"Debian 9 安装 Apche2 和 vsftpd","text":"什么是 Apache HTTP ServerApache HTTP Server Project 是致力于为现代操作系统（包括UNIX 和 Windows）提供和维护的一个开源 HTTP 服务项目。该项目发起于 1995 年，至今已有20+年的历史。 借助 Apache HTTP Server，我们可以在我们的计算机或服务器上快速部署一个高效、可用的 HTTP 服务。Apache2 是 Apache HTTP Server 的最新版本。 Apache官网：Link Getting Started安装1sudo apt-get install apache2 访问 127.0.0.1 或者该服务器的公网ip ，即可看到 apache2 的主页面 修改主配置文件1vim /etc/apache2/apache2.conf 在主配置文件里，修改以下内容为文件夹赋予打开的权限 12345678910111213141516171819# 拒绝访问 / 目录&lt;Directory /&gt; Options FollowSymLinks AllowOverride None Require all denied&lt;/Directory&gt;# 不用改或注释掉&lt;Directory /usr/share&gt; AllowOverride None Require all granted&lt;/Directory&gt;# 这里可以修改成自己想更改的目录&lt;Directory /var/www/&gt; Options Indexes FollowSymLinks AllowOverride None Require all granted&lt;/Directory&gt; 修改其他配置文件默认目录1vim /etc/apache2/sites-available/000-default.conf DocumentRoot 对应的值就是默认的目录了，可以任由我们修改。 修改端口号1vim /etc/apache2/sites-available/000-default.conf 第一行 virtualport 记得改（默认80） 1vim /etc/apache2/ports.conf listen 端口号（默认80） 修改完配置文件后重启服务 1sudo service apache2 restart 启动和关闭 apache2 服务启动和关闭apache2服务可以通过执行命令 1sudo /etc/init.d/apache2 start（stop / restart） 或者 1sudo service apache2 start (stop / restart) 注意：这里一定要注意记得！不加root权限可能没有明显的提示。但实际上并没有启动成功。 其他配置 当访问本机的时候，默认进入的页面是/var/www/html/index.html。 配置系统的说明在/usr/share/doc/apache2/README.Debian.gz中。 完整使用手册可以通过安装apache2-doc 进行下载。 主配置文件为/etc/apache2/apache2.conf。 默认情况下apache2拒绝访问除/var/www 和/usr/share文件夹外的其他文件，这种权限是通过apache2.conf文件来控制的. 什么是 vsftpdvsftpd 是 UNIX（包括linux）系统下的一个 FTP 服务。借助 vsftpd，我们可以在 UNIX 服务器上快速部署一个安全、快速、稳定的 FTP 服务。 Getting Started安装12sudo apt-get updatesudo apt-get install vsftpd 配置1sudo vim /etc/vsftpd.conf 在配置文件里几点注意: 12345678910111213141516# listen 和 listen_ipv6 开一个就行；两个都开，vsftpd就报错了listen=YES# listen_ipv6=YES# 本地用户访问local_enable=YES# 可写write_enable=YES# 不允许所有用户访问用户主目录之外的目录chroot_local_user=NO 启动12345# 启动sudo service vsftpd start# 查看状态sudo service vsftpd status 客户端连接 客户端连接推荐使用 FileZilla 官网下载地址：https://filezilla-project.org/ 使用方法在站点管理器里面简单配置连接即可： 提示：用户名和密码是 linux 系统的用户名和密码","link":"/post/d3952d64.html"},{"title":"重温《真爱至上》","text":"现在是2018年12月25日圣诞节晚。去年圣诞节我看了一部电影《真爱至上》，并随手写了一些感想，那时我说，不出意外今年还会重温一遍吧？于是乎，今晚我又把躺在硬盘里一年的真爱至上翻了出来…… 跟去年一样，电影又一次以相同的方式温暖了我。重温最大的收获便是能够发现第一次观看时没发现的细节，更深刻地去理解它。去年观影时，让我印象最深刻的是圣诞夜 Mark 对 Juliet 的白板表白，最后换来 Juliet 的一吻，这一吻虽不能让他们在一起，但对 Mark 来说，一切都已经足够了。这一吻也是 Juliet 对 Mark 的感激。 虽然我不能和你在一起，但是谢谢你的喜欢和爱。 Mark 对 Juliet 的感情，其实在前面已经有铺垫。Juliet 的婚礼上， Mark 一直录制关于她的特写，默默地记录她的美丽。但 Mark 平日里却从不跟她说话，这让 Juliet 以为 Mark 不喜欢她。果然人在真爱面前都是胆小鬼呀。内向的 Mark 只能用这种方式默默爱着她。而现实生活中，又有多少人以友情的名义深爱着一个人呢。每每想到此，都虐心无比，是不是每个人心中都住着一个不可能的人。 让我感动的另外一个剧情是，英格兰作家和葡萄牙女佣的故事。两个语言不通的人，他可以为了她特意学了葡萄牙语，而她更是为了他特意学了英语。她说，Just in case，以防万一，结果真的在一起了。爱，真的是不论国籍也没有语言差异可以阻挡的。所以，又有什么是不可以为你爱的人付出的呢？你看，连10岁的小男孩都可以为了在圣诞晚会上当喜欢的女孩子的鼓手而特地学习一门乐器。 一年前刚从一段感情里走出来的我说，自己还是相信爱的。并提问一年后自己又会对爱有怎样的感悟呢？虽然2018也经历了一些事，对这方面也更加慎重，但终究没有开始一段新的感情。我的感受正如电影里说，没有比受爱情煎熬更惨的事了。 但我还是会选择去相信。","link":"/post/2a19f391.html"},{"title":"Linux内核模块编程 HelloWorld","text":"微内核和宏内核微内核内核中只有最基本的调度、内存管理。其他的比如驱动、文件系统等都是用户态的守护进程去实现的。比如Windows NT、OS X 优点是超级稳定，驱动等的错误只会导致相应进程死掉，不会导致整个系统都崩溃，做驱动开发时，发现错误，只需要kill掉进程，修正后重启进程就行了，比较方便。 缺点是效率低。典型代表QNX，QNX的文件系统是跑在用户态的进程，称为resmgr的东西，是订阅发布机制，文件系统的错误只会导致这个守护进程挂掉。 宏内核简单来说，就是把很多东西都集成进内核，例如Linux内核，除了最基本的进程、线程管理、内存管理外，文件系统，驱动，网络协议等等都在内核里面。优点是效率高。缺点是稳定性差，开发过程中的bug经常会导致整个系统挂掉。做驱动开发的应该经常有按电源键强行关机的经历。 内核模块由于 Linux 内核是宏内核，集成性比较高，随着内核版本的迭代，内核变得非常大（Linux内核约50M），我们想定制自己的内核时，需要整个重新编译，比较繁琐。而且，定制内核时，有些功能我们是不需要的。 因此 Linux 内核采用了模块化的方式。当我们编译内核时，可以只选择我们需要的模块。而且，我们自己编写的模块，可以采用安装/卸载的方式，集成到内核里。 内核模块的优点是：开发效率更高，而且可以在内核运行时动态加载。由于Linux内核模块是动态加载的，所以它也叫可加载内核模块(Loadable Kernel Module, LKM)。Linux内核镜像位于/boot目录下，启动时最先加载，LKM总是在内核启动之后加载。 LKM主要用于：设备驱动、文件系统驱动和系统调用。 注意：LKM是内核空间程序，不是用户空间程序，你可以把它看成是内核的一部分。也就是LKM没有任何保护，一不小心可能就会导致系统崩溃。 编译LKM安装C编译器和Linux内核头文件1sudo apt-get install build-essential linux-headers-$(uname -r) Hello World内核模块代码（hello.c）1234567891011121314151617181920212223242526272829#include &lt;linux/module.h&gt; /* 模块头文件，必不可少 */#include &lt;linux/kernel.h&gt; /* KERN_INFO在这里 */#include &lt;linux/init.h&gt; /* 使用的宏 */// LICENSEMODULE_LICENSE(\"GPL\");// 作者MODULE_AUTHOR(\"blog.topspeedsnail.com\");// 描述MODULE_DESCRIPTION(\"hello world\");// 模块版本MODULE_VERSION(\"3.14\");static int __init hello_start(void){ printk(KERN_INFO \"Hello World\\n\"); return 0;}static void __exit hello_end(void){ printk(KERN_INFO \"Go to Hell\\n\");}module_init(hello_start);module_exit(hello_end); module_init 定义了模块的入口函数，在模块加载 insmoded (插入模块)时执行 module_exit 定义了模块的退出函数，在模块卸载 rmmoded （移除模块）时执行 创建Makefile123456obj-m = hello.oall: make -C /lib/modules/$(shell uname -r)/build/ M=$(PWD) modulesclean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean# make命令前是tab，不是空格 编译make命令 1make 输出 123456789jerrysheh@ubuntu:~/Desktop$ makemake -C /lib/modules/4.13.0-31-generic/build/ M=/home/jerrysheh/Desktop modulesmake[1]: Entering directory '/usr/src/linux-headers-4.13.0-31-generic' CC [M] /home/jerrysheh/Desktop/helloworld.o Building modules, stage 2. MODPOST 1 modules CC /home/jerrysheh/Desktop/helloworld.mod.o LD [M] /home/jerrysheh/Desktop/helloworld.komake[1]: Leaving directory '/usr/src/linux-headers-4.13.0-31-generic' 查看使用modinfo hello.ko来查看模块信息 使用sudo insmod hello.ko来加载模块到内核 使用lsmod来查看已加载的内核（结合管道lsmod | grep hello） 使用sudo rmmod hello来卸载模块 输出使用tail /var/log/kern.log来查看模块的输出 1234567891011jerrysheh@ubuntu:~/Desktop$ tail /var/log/kern.logMar 7 12:53:59 ubuntu NetworkManager[863]: &lt;info&gt; [1520398439.9770] gateway 192.168.224.2Mar 7 12:53:59 ubuntu NetworkManager[863]: &lt;info&gt; [1520398439.9770] server identifier 192.168.224.254Mar 7 12:53:59 ubuntu NetworkManager[863]: &lt;info&gt; [1520398439.9770] lease time 1800Mar 7 12:53:59 ubuntu NetworkManager[863]: &lt;info&gt; [1520398439.9770] nameserver '192.168.224.2'Mar 7 12:53:59 ubuntu NetworkManager[863]: &lt;info&gt; [1520398439.9770] domain name 'localdomain'Mar 7 12:53:59 ubuntu NetworkManager[863]: &lt;info&gt; [1520398439.9770] wins '192.168.224.2'Mar 7 12:53:59 ubuntu NetworkManager[863]: &lt;info&gt; [1520398439.9771] dhcp4 (ens33): state changed bound -&gt; boundMar 7 12:56:41 ubuntu kernel: [ 1170.100050] helloworld: loading out-of-tree module taints kernel.Mar 7 12:56:41 ubuntu kernel: [ 1170.100085] helloworld: module verification failed: signature and/or required key missing - tainting kernelMar 7 12:56:41 ubuntu kernel: [ 1170.100760] Hello World 看到最后一行输出了 Hello World，正是我们编写的 helloworld.ko 模块输出的。 可以使用tail -f /var/log/kern.lo来动态监控内核的输出 作为字符型驱动在 insmod 的时候把设备的主设备号打印出来。 如果要把内核模块作为字符型驱动设备，首先 1tail -f /var/log/messgaes 查看设备的主设备号，比如是 254 然后创建目录和节点 12mkdir /dev/demomknod /dev/demo/newdev c 254 0 这样就创建了一个虚拟的字符型驱动设备。 本文引用的文章： 编写第一个Linux内核模块: Hello World 宏内核与微内核、Linux内核与Unix内核的区别","link":"/post/75b0adbf.html"},{"title":"Linux环境QT编程","text":"由于课程需要，需要在 Linux 环境下开发 QT 程序，因此开一篇文章来记录QT的知识点。 Ubuntu 16.04 QT安装由于实验室和课程安排都是基于 QT4，因此这里安装QT4 12sudo apt install qt4*sudo apt install qtcreator QT 基本操作屏幕自适应先布局一个 layout，然后在全局框里，设置 layout 用以下代码自动全屏 1234QDesktopWidget* desktopWidget = QApplication::desktop();QRect screenRect = desktopWidget-&gt;screenGeometry();resize(screenRect.width(),screenRect.height());this-&gt;showMaximized(); 显示图片 布局一个 label 头文件添加 #include &lt;QPixmap&gt; 构造函数添加 ui-&gt;label-&gt;setPixmap(&quot;0.png&quot;) 定时器 主类声明一个指针 public: 下， QTimer *display_timer; 头文件添加 #include &lt;QTimer&gt; 构造函数添加 12345display_timer = new QTimer(this);//槽函数connect(display_timer,SIGNAL(timeout()), this, SLOT(doChange()));display_timer-&gt;start(10000); 头文件 public slots: 声明 doChange(); 实现doChange();函数 1234void MainWindow::doChange(){ qDebug(\"doChange\"); ui-&gt;label-&gt;setPixmap(QPixmap(QString::number(num) + \".png\"));} 使用display_timer-&gt;start(1000);来开启定时器 使用display_timer-&gt;stop(1000);来关闭定时器 实验室环境QT交叉编译将QT程序编译成实验室开发板 ARM-linux 下能执行的程序。 将工程文件拷贝到编译目录1cp myproject /usr/local/Trolltech/QtEmbedded-4.8.5-arm/examples/ -a 执行 qmake这一步主要是生成 Makefile 实验室里为了区分，把 qmake 命令换成了 qmake-arm 1qmake-arm 执行 make1make make完成后，可执行文件就生成了。通过串口传输到ARM实验箱上。 串口连接过程略。 串口:本地 -&gt; ARM1rx myAPP 选择 传输 -&gt; 发生 Xmodem 解决ARM实验箱的坑 kill掉以下三个进程 123/opt/Qtopia/bin/qpe/opt/Qtopia/bin/qss/opt/Qtioua/bin/quicklauncher 初始化环境变量 1. setqt4env # 不要漏了中间的空格 运行 1./myApp -qws","link":"/post/10e2f7a0.html"},{"title":"Linux系统漫游（一）从开机到架构","text":"用了好久的 Linux 系统了，然而却没有从头开始好好系统地认识过 Linux，这两篇，就从以下几个方面，漫游式地重新梳理一下关于 Linux 的知识。 本篇： Linux简介与版本 从开机到启动 文件系统 文本流 标准输入、标准输出、标准错误、重定向 管道 Linux 架构 下一篇： 进程 进程空间 信号 进程间通信 并发与同步 注：本文提取总结自Vamei的博客 Linux 简介和版本狭义的 Linux 指的是 Linux kernel (内核)，最初由 Linus Torvalds 根据Minix系统的代码，参照UNIX系统的设计写出。kernel 就是负责管理硬件并为上层应用提供接口的底层代码。广义的 Linux 指的是以 Linux kernel 为基础的包括操作系统和各种应用在内的各个Linux版本(distribution)。 上图就是 Linux Kernel 的最初创始人 Linus Torvalds，关于 linus 的介绍，可看Linus，一生只为寻找欢笑，Linus 还出过一本自传《只是为了好玩》，当年在大学图书馆看完这本书心里只有仰望和佩服。 PC平台比较流行的 Linux厂商版本 可以分为两类： Redhat系列：包括面向企业的Red Hat Enterprise、由社区维护的Fedora和CentOS等，该系列 Linux版本 的软件安装包以rpm结尾。 Debian系列：包括完全免费的 Debian 和 继承自 Debian 且界面友好的 Ubuntu ，以及继承自 Ubuntu 但提供了更加丰富的预装应用的Mint，还有预装了许多网络安全、渗透相关工具的kali Linux。 国产做得比较优秀的深度（Deepin）也是属于Debian系列的。这一类 Linux版本 的软件安装包以deb结尾。。 个人用户安装建议 如果只是为了体验一下 Linux 系统，推荐安装有强大的社区支持的 Ubuntu，不想太折腾也可以尝试 Deepin；如果是为了稳定建站等希望有持续的技术支持，但不愿意频繁升级的，可以试试 CentOS ；如果想学习黑客知识、网络安全等，推荐 kali Linux。 此外，还有一些小众的 Linux 发行版就不介绍了。总而言之， Linux 的发行版本非常多。 发一张仅供娱乐的图片。 Linux 开机启动(bootstrap)注：本小节摘自 Vamei 的博客 最初始阶段当我们打开计算机电源，计算机会自动从主板的BIOS(Basic Input/Output System)读取其中所存储的程序。这一程序通常知道一些直接连接在主板上的硬件(硬盘，网络接口，键盘，串口，并口)。现在大部分的BIOS允许你从软盘、光盘或者硬盘中选择一个来启动计算机。 随着计算机的发展，传统的BIOS被新的UEFI BIOS替代。UEFI的全称是Unified Extensible Firmware Interface，意即统一可扩展固件接口。UEFI做了很多对传统BIOS的改进。 下一步，计算机将从你所选择的存储设备中读取起始的512个字节(bytes)。如果我们从光盘启动的话，那么计算机就会读取光盘最开始的512个字节。这512个字节叫做 主引导记录MBR (master boot record)。MBR会告诉电脑从该设备的某一个分区(partition)来装载 引导加载程序(boot loader)。引导加载程序储存有操作系统(OS)的相关信息，比如操作系统名称，操作系统内核所在位置等。常用的引导加载程序有GRUB和LILO。 随着计算机的发展，逐渐出现了GPT来代替MBR。GPT的全称是Globally Unique Identifier Partition Table，意即GUID分区表，它的推出是和UEFI BIOS相辅相成的，鉴于MBR的磁盘容量和分区数量已经不能满足硬件发展的需求，GPT首要的任务就是突破了2.2T分区的限制，最大支持18EB的分区。 随后，引导加载程序会帮助我们加载内核(kernel)。内核实际上是一个用来操作计算机的程序，它是计算机操作系统的内核，主要的任务是管理计算机的硬件资源，充当软件和硬件的接口。操作系统上的任何操作都要通过内核传达给硬件。Windows和Linux各自有自己内核。狭义的操作系统就是指内核，广义的操作系统包括内核以及内核之上的各种应用。 实际上，我们可以在多个分区安装引导加载程序，每个引导加载程序对应不同的操作系统，在读取MBR的时候选择我们想要启动的引导加载程序。这就是多操作系统的原理。 小结：BIOS -&gt; MBR（GPT）-&gt; boot loader -&gt; kernel 内核如果我们加载的是Linux内核，Linux内核开始工作。内核会首先预留自己运行所需的内存空间，然后通过驱动程序(driver)检测计算机硬件。这样，操作系统就可以知道自己有哪些硬件可用。随后，内核会启动一个init进程。它是Linux系统中的1号进程。到此，内核就完成了在计算机启动阶段的工作，交接给init来管理。 小结: kernel -&gt; init process init process(根据boot loader的选项，Linux此时可以进入单用户模式(single user mode)。在此模式下，初始脚本还没有开始执行，我们可以检测并修复计算机可能存在的错误) 随后，init会运行一系列的初始脚本(startup scripts)，这些脚本是Linux中常见的shell scripts。这些脚本执行如下功能： 设置计算机名称，时区，检测文件系统，挂载硬盘，清空临时文件，设置网络…… 当这些初始脚本加载完毕，操作系统就已经完全准备好了，只是，还没有人可以登录。init会给出登录(login)对话框，或者是图形化的登录界面。 输入用户名(比如说vamei)和密码，DONE！ 文件系统在计算机组成原理中我们知道，内存中的数据会随着掉电而消失。为了关机后还能保存我们的数据，我们需要将数据保存在ROM介质中（光盘、硬盘）。我们把每一份保存的数据称为文件。那么当文件多的时候，我们如何去找到我们需要的文件？这就需要用到文件系统(file system)了。 文件系统是就是文件在逻辑上组织形式，它以一种更加清晰的方式来存放各个文件。Linux 的文件系统本质上是二叉树。要找到一个文件，除了要知道该文件的文件名，还需要知道从树根到该文件的所有目录名。从根目录开始的所有途径的目录名和文件名构成一个路径(path)。 值得注意的是，在Linux系统中，目录也是一种文件。Linux中的文件有目录文件、常规文件、软链接文件三种。对于任意一种文件，我们都可以读取(read)，写入(write)和运行(execute)，但首先要有相关操作的权限。 上面提到的软链接，可以理解为类似于 Windows 的快捷方式。 文件权限相关可以看另一篇：给自己的 Linux 备忘 文本流计算机中的数据都是 0 1 这样的二进制，每一个 0 或者 1，称为 1位(bit)。Unix 以 字节（byte） 来作为数据的单位，规定每 8 个位，就等于 1 个字节。8 个位，二进制数范围为00000000 - 11111111，对应的十进制数就是 0 - 255 通过ASCII编码，可以把这一个字节转换成为256个字符中的一个。所以，在Unix中，数据完全可以用字符的形式表示出来，也就是所谓的文本（text）。 Unix/Linux的基本哲学之一就是「万物皆文件」（Everything is a file）。前面提到，目录也是一种文件。对于Unix系统来说，文件可以广义的认为是可以提供或接收数据的对象。既然这样，Unix系统干脆把提供或接收数据的硬件也表示成文件。 但 linus 对「万物皆文件」的说法作出过纠正，改为「万物皆文本流」（Everything is a stream of bytes）系统运行时，数据并不是在一个文件里定居。数据会在CPU的指挥下不断地流动。有时数据需要到办公室上班，因此被读入到内存，有时会去酒店休假，传送到外部设备。有的时候，数据需要搬个家，转移到另一个文件。在这样跑来跑去的过程中，数据像是排着队走路的人流，我们叫它 文本流（text stream，或者byte stream）。 然而，计算机不同设备之间的连接方法差异很大，从内存到文件的连接像是爬山，从内存到外设像是游过一条河。为此，Unix定义了流 (stream)，作为连接操作系统各处的公路标准。有了“流”，无论是从内存到外设，还是从内存到文件，所有的数据公路都是相同的格式。至于公路下面是石头还是土地，就都交给操作系统处理，不劳用户操心了。 标准输入、标准输出、标准错误当Unix执行一个程序的时候，会自动打开三个流，标准输入(standard input)，标准输出(standard output)，标准错误(standard error)。 比如说你打开命令行的时候，默认情况下，命令行的标准输入连接到键盘，标准输出和标准错误都连接到屏幕。对于一个程序来说，尽管它总会打开这三个流，但它会根据需要使用，并不是一定要使用。 想象一下，当我们在 shell 中敲下 ls 命令的时候，键盘作为标准输入，把我们敲下的命令文本流传给shell，shell随后调用/bin/ls去解释这个命令，得到结果a.txt，最后这个输出文本流流向标准输出，也就是屏幕，这才显示出来。 如果我们不想让a.txt流向标准输出（屏幕） ，我们可以用&gt;符号来重定向让它流向别的文件，这样目标文件就会被替代成我们输出的结果a.txt。或者，你用&gt;&gt;符号来追加，在原来文件不变的情况下在后面追加我们的a.txt结果。 我们也可以用&lt;符号来改变标准输入。 Linux中，命令 echo 的作用就是将文本流导向标准输出。 管道(pipe)管道可以将一个命令的输出导向另一个命令的输入，从而让两个(或者更多命令)像流水线一样连续工作，不断地处理文本流。在命令行中，我们用|符号表示管道。 例子： 把 a.txt 作为输入，传给 cat 命令， cat命令解释后的输出通过管道传递给 wc，用于统计字数 1cat &lt; a.txt | wc Linux 架构注：本小节摘自 Vamei 的博客 根据上图，我们从内到外，逐一分析！ 内核由上图，硬件是物质基础，而应用提供服务。但在两者之间，还要经过一番周折。Linux首先启动内核 (kernel)，内核直接管理管理硬件，包括CPU、内存空间、硬盘接口、网络接口等等。同样，所有的计算机操作都要通过内核传递给硬件。 系统调用为了方便调用内核，Linux将内核的功能接口制作成系统调用(system call)。系统调用看起来就像C语言的函数。你可以在程序中直接调用。系统调用是操作系统的最小功能单位。 库函数系统调用提供的功能非常基础，所以使用起来很麻烦。一个简单的给变量分配内存空间的操作，就需要动用多个系统调用。所以，Linux定义一些库函数(library routine)来将系统调用组合成某些常用的功能。 比如，分配内存的操作，可以定义成一个库函数(像malloc()这样的函数)。再比如说，在读取文件的时候，系统调用要求我们设置好所需要的缓冲。我可以使用Standard IO库中的读取函数。这个读取函数既负责设置缓冲，又负责使用读取的系统调用函数。 使用库函数对于机器来说并没有效率上的优势，但可以把程序员从细节中解救出来。 shell那么跟库函数处于同等地位的 shell 又是何方神圣呢？ shell是一个特殊的应用。很多用户将它称为命令行。shell是一个命令解释器(interpreter)，当我们输入“ls -l”的时候，它将此字符串解释为 在默认路径找到该文件(/bin/ls)， 执行该文件，并附带参数”-l”。 shell是可编程的，它可以执行符合shell语法的文本。这样的文本叫做shell脚本(script)。 UNIX的一条哲学是让每个程序尽量独立的做好一个小的功能。而shell充当了这些小功能之间的”胶水”，让不同程序能够以一个清晰的接口(文本流)协同工作，从而增强各个程序的功能。这也是Linux老鸟鼓励新手多用shell，少用图形化界面的原因之一。 应用最后，我们进入一般的应用。应用是一个程序，它可以 直接调用系统函数 调用库函数 运行shell脚本这些应用可以由多种语言开发。最常见的是C语言。 由于篇幅原因，这一篇先介绍到这里，下一篇继续介绍进程、信号、并发等知识。","link":"/post/4f4dc2a9.html"},{"title":"Linux系统漫游（二）从进程到并发","text":"漫游式梳理一下关于 Linux 的知识。 上一篇： Linux简介与版本 从开机到启动 文件系统 文本流 标准输入、标准输出、标准错误、重定向 管道 Linux 架构 本篇： 进程 进程空间 信号 进程间通信 并发与同步 注：本文提取总结自Vamei的博客 Linux 进程程序在计算机组成原理中，我们知道计算机只是在重复做一些简单的指令动作，简单地说，计算机只是从内存中取指令或数据然后执行逻辑运算、移位运算或算术运算。而程序(program)，就是一系列指令对数据进行运算所构成的集合。 进程进程是执行程序的过程。同一个程序可以执行多次，每次都可以在内存中开辟独立的空间来装载，从而产生多个进程。不同的进程还可以拥有各自独立的IO接口。 操作系统的一个重要功能就是为进程提供方便，比如说为进程分配内存空间，管理进程的相关信息等等。 在 Linux 中使用ps命令(Process Status)查看进程，用pstree查看进程树 当计算机开机的时候，内核(kernel)只建立了一个init进程。Linux内核并不提供直接建立新进程的系统调用。剩下的所有进程都是init进程通过fork机制建立的。新的进程要通过老的进程复制自身得到，这就是fork。 fork是一个系统调用。进程存活于内存中。每个进程都在内存中分配有属于自己的一片空间 (address space)。当进程fork的时候，Linux在内存中开辟出一片新的内存空间给新的进程，并将老的进程空间中的内容复制到新的空间中，此后两个进程同时运行。 父/子进程、孤儿进程、僵尸进程在 Linux 中，子进程终结时，会通知父进程并清空自身所占内存，并在内核里留下退出信息（exit code，正常退出为0）。父进程得知子进程结束，会对该子进程使用wait系统调用。这个wait函数能从内核中取出子进程的退出信息，并清空该信息在内核中所占据的空间。 但是，如果父进程早于子进程终结，子进程就会成为一个孤儿(orphand)进程。孤儿进程会被过继给init进程，init进程也就成了该进程的父进程。init进程负责该子进程终结时调用wait函数。 当然，一个糟糕的程序（父进程没有回收子进程、释放子进程占用的资源）也完全可能造成子进程的退出信息滞留在内核中的状况，这样的情况下，子进程成为僵尸（zombie）进程。当大量僵尸进程积累时，内存空间会被挤占。 Linux 中的线程在Linux中，线程只是一种特殊的进程。多个线程之间可以共享内存空间和IO接口。所以，进程是Linux程序的唯一的实现方式。 但是通识上的理解和在高级语言编程中，进程和线程还是有区别的。下面并发一节会讲到。 进程空间当程序文件运行为进程时，进程在内存中获得空间，那么，进程如何使用内存呢？ 如上图，Text区域用来储存指令(instruction)，说明每一步的操作。Global Data用于存放全局变量，栈(Stack)用于存放局部变量，堆(heap)用于存放动态变量 (dynamic variable，程序利用malloc系统调用，直接从内存中为dynamic variable开辟空间)。Text和Global data在进程一开始的时候就确定了，并在整个进程中保持固定大小。 malloc是一个C语言函数，它接收一个 int 参数，表示需要向系统申请多少字节（bytes）的内存，并返回申请到的内存地址指针。 栈（Stack）栈(Stack)以帧(stack frame)为单位。当程序调用函数的时候，比如main()函数中调用inner()函数，stack会向下增长一帧。帧中存储该函数的参数和局部变量，以及该函数的返回地址(return address)。此时，计算机将控制权从main()转移到inner()，inner()函数处于激活(active)状态。 位于栈最下方的帧，和全局变量一起，构成了当前的环境(context)。激活函数可以从环境中调用需要的变量。 当函数又进一步调用另一个函数的时候，一个新的帧会继续增加到栈的下方，控制权转移到新的函数中。当激活函数返回的时候，会从栈中弹出(pop，读取并从栈中删除)该帧，并根据帧中记录的返回地址，将控制权交给返回地址所指向的指令。 堆（Heap）当程序中使用malloc的时候，堆(heap)会向上增长，其增长的部分就成为malloc从内存中分配的空间。malloc开辟的空间会一直存在，直到我们用free系统调用来释放，或者进程结束。一个经典的错误是内存泄漏(memory leakage)，就是指我们没有释放不再使用的堆空间，导致堆不断增长，而内存可用空间不断减少。 溢出（overflow）栈和堆的大小则会随着进程的运行增大或者变小。当栈和堆增长到两者相遇时候，也就是内存空间图中的绿色区域(unused area)完全消失的时候，再无可用内存。进程会出现栈溢出(stack overflow)的错误，导致进程终止。 在现代计算机中，内核一般会为进程分配足够多的unused area，如果清理及时，栈溢出很容易避免。即便如此，内存负荷过大，依然可能出现栈溢出的情况。我们就需要增加物理内存了。 fork &amp;&amp; exec当一个程序调用fork的时候，实际上就是将上面的内存空间，包括text, global data, heap和stack，又复制出来一个，构成一个新的进程，并在内核中为该进程创建新的附加信息 (比如新的PID，而PPID为原进程的PID)。此后，两个进程分别地继续运行下去。新的进程和原有进程有相同的运行状态(相同的变量值，相同的instructions…)。我们只能通过进程的附加信息来区分两者。 程序调用exec的时候，进程清空自身内存空间的text, global data, heap和stack，并根据新的程序文件重建text, global data, heap和stack (此时heap和stack大小都为0)，并开始运行。 Linux 信号Linux以进程为单位来执行程序。信号(signal)就是一种向进程传递信息的方式。 相对于其他的进程间通信方式(interprocess communication)（比如 pipe, shared memory）来说，信号所能传递的信息比较粗糙，只是一个整数。但正是由于传递的信息量少，信号也便于管理和使用。信号因此被经常地用于系统管理相关的任务，比如通知进程终结、中止或者恢复等等。 信号可以产生于内核或其他进程，但统一由内核(kernel)管理。也就是说，进程间通过信号传递信号时，首先发送给内核，再由内核传递给目标进程。如果一个进程收到信号，会执行对应该信号的操作，称为信号处理（signal disposition）。 从信号的生成到信号的传递的时间，信号处于等待(pending)状态。我们同样可以设计程序，让其生成的进程阻塞(block)某些信号，也就是让这些信号始终处于等待的状态，直到进程取消阻塞(unblock)或者无视信号。 Linux 常见信号 SIGINT ：当键盘按下CTRL+C从shell中发出信号，信号被传递给shell中前台运行的进程，对应该信号的默认操作是中断 (INTERRUPT)该进程。 SIGQUIT ：当键盘按下CTRL+\\从shell中发出信号，信号被传递给shell中前台运行的进程，对应该信号的默认操作是退出 (QUIT) 该进程。 SIGTSTP： 当键盘按下CTRL+Z从shell中发出信号，信号被传递给shell中前台运行的进程，对应该信号的默认操作是暂停 (STOP)该进程。 SIGCONT：用于通知暂停的进程继续。 SIGALRM：起到定时器的作用，通常是程序在一定的时间之后才生成该信号。 信号处理当进程决定执行信号的时候，有下面几种可能： 无视(ignore)信号：信号被清除，进程本身不采取任何特殊的操作 默认(default)操作：每个信号对应有一定的默认操作。比如上面SIGCONT用于继续进程。 自定义操作：也叫做获取 (catch)信号。执行进程中预设的对应于该信号的操作。 进程间其他方式通信信号可以看作一种粗糙的进程间通信的方式，用以向进程封闭的内存空间传递信息。但是传递的信息量少，为了让进程间传递更多的信息量，我们需要其他的进程间通信方式。这些进程间通信方式可以分为两种: 管道(PIPE)机制在 Linux 中可以使用管道将一个进程的输出和另一个进程的输入连接起来，从而利用文件操作API来管理进程间通信。在shell中，我们经常利用管道将多个进程连接在一起，从而让各个进程协作，实现复杂的功能。 管道使用的是Fork机制，只能在有亲缘关系的进程之间传递信息。为了解决这一问题，Linux提供了FIFO方式连接进程。FIFO又叫做命名管道(named PIPE)。 FIFO (First in, First out)为一种特殊的文件类型，它在文件系统中有对应的路径。当一个进程以读(r)的方式打开该文件，而另一个进程以写(w)的方式打开该文件，那么内核就会在这两个进程之间建立管道，所以FIFO实际上也由内核管理，不与硬盘打交道。 写模式的进程向FIFO文件中写入，而读模式的进程从FIFO文件中读出。当删除FIFO文件时，管道连接也随之消失。FIFO的好处在于我们可以通过文件的路径来识别管道，从而让没有亲缘关系的进程之间建立连接。 传统IPC (interprocess communication)主要是指消息队列(message queue)，信号量(semaphore)，共享内存(shared memory)。这些IPC的特点是允许多进程之间共享资源，这与多线程共享heap和global data相类似。由于多进程任务具有并发性 (每个进程包含一个进程，多个进程的话就有多个线程)，所以在共享资源的时候也必须解决同步的问题。 并发与同步Linux中，虽然线程基于进程，其实现方式也有异于其它的UNIX系统，但Linux的多线程在逻辑和使用上与真正的多线程并没有差别。 多线程多线程就是允许一个进程内存在多个控制权，以便让多个函数同时处于激活状态，从而让多个函数的操作同时运行。即使是单CPU的计算机，也可以通过不停地在不同线程的指令间切换，从而造成多线程同时运行的效果。 多线程的进程在内存中有多个栈。多个栈之间以一定的空白区域隔开，以备栈的增长。 对于多线程来说，由于同一个进程空间中存在多个栈，任何一个空白区域被填满都会导致stack overflow的问题 并发与竞争多线程相当于一个并发(concunrrency)系统。并发系统一般同时执行多个任务。如果多个任务可以共享资源，特别是同时写入某个变量的时候，就需要解决同步的问题。 在并发情况下，指令执行的先后顺序由内核决定。同一个线程内部，指令按照先后顺序执行，但不同线程之间的指令很难说清楚哪一个会先执行。如果运行的结果依赖于不同线程执行的先后的话，那么就会造成竞争条件(race condition)，在这样的状况下，计算机的结果很难预知。我们应该尽量避免竞争条件的形成。 最常见的解决竞争条件的方法是将原先分离的两个指令构成不可分隔的一个原子操作(atomic operation)，而其它任务不能插入到原子操作中。 多线程同步同步(synchronization)是指在一定的时间内只允许某一个线程访问某个资源 。而在此时间内，不允许其它的线程访问该资源。我们可以通过互斥锁(mutex)，条件变量(condition variable)和读写锁(reader-writer lock)来同步资源。 互斥锁(mutex)互斥锁是一个特殊的变量，它有锁上(lock)和打开(unlock)两个状态。互斥锁一般被设置成全局变量。打开的互斥锁可以由某个线程获得。一旦获得，这个互斥锁会锁上，此后只有该线程有权打开。其它想要获得互斥锁的线程，会等待直到互斥锁再次打开的时候。 线程在mutex_lock和mutex_unlock之间的操作时，不会被其它线程影响，就构成了一个原子操作。 条件变量(condition variable)条件变量除了要和互斥锁配合之外，还需要和另一个全局变量配合,这个全局变量用来构成各个条件。 条件变量特别适用于多个线程等待某个条件的发生。如果不使用条件变量，那么每个线程就需要不断尝试获得互斥锁并检查条件是否发生，这样大大浪费了系统的资源。 读写锁(reader-writer lock)读写锁与互斥锁非常相似。读写锁有三种状态: 共享读取锁(shared-read) 互斥写入锁(exclusive-write lock) 打开(unlock)。 后两种状态与之前的互斥锁两种状态完全相同。 一个unlock的RW lock可以被某个线程获取R锁或者W锁。 如果被一个线程获得R锁，RW lock可以被其它线程继续获得R锁，而不必等待该线程释放R锁。但是，如果此时有其它线程想要获得W锁，它必须等到所有持有共享读取锁的线程释放掉各自的R锁。 如果一个锁被一个线程获得W锁，那么其它线程，无论是想要获取R锁还是W锁，都必须等待该线程释放W锁。 这样，多个线程就可以同时读取共享资源。而具有危险性的写入操作则得到了互斥锁的保护。","link":"/post/9cf7e81b.html"},{"title":"Ubuntu的一些奇技淫巧","text":"接触Linux越久，掉进莫名其妙的坑里就越多，于是我决定每遇到一个坑就记录下来，这样以后再踩的时候不至于爬不起来。 Ubuntu的一些使用技巧 目前 get 的有： 调整鼠标速度 解决双系统时间不同步的问题 系统更新提示 /boot 空间不足的解决办法 更改国内源，提高下载速度 利用 Xshell / SSH 在远程和本地之间传文件 编辑菜单 终端使用SS，查公有ip 管理ppa源 安装 jdk 1.8 更改 root 账户密码 apt安装不成功，每次 apt install 都报错 使用openssh远程连接 ROOT账户没有环境变量 如何正确地配置环境变量 Ubuntu出现了内部错误 Ubuntu/Debian 完全卸载Mysql 一. 调整鼠标速度1xset m N 其中 N 是速度速度值，0（最慢）- 10（最快） 二. 解决 win10 + Ubuntu 双系统 时间不同步的问题1. 先在 Ubuntu 下更新时间，确保时间无误12sudo apt-get install ntpdatesudo ntpdate time.windows.com 2. 然后将时间更新到硬件上1sudo hwclock --localtime --systohc 3. Enjoy！ 三. Ubuntu 提示 /boot 空间不足的解决办法Ubuntu 系统更新的时候，有时候会提示 /boot 空间不足，原因是 Linux 更新后，内核的旧版本不再使用，但还存放在 /boot 目录下。所以，手动将这些旧版本内核删除即可。 1. 查看旧版本内核1dpkg --get-selections|grep linux 看到带有 Linux-image-x.x.x的就是旧版本。 2. 删除1sudo apt-get remove Linux-image-(版本号) 3. 删除不干净的可以使用以下命令1sudo apt-get autoremove 4. Done！ 四. Ubuntu 国内更新源为了提高更新下载速度，可以把 Ubuntu 的更新源改为国内镜像。推荐使用阿里云源。因为大学的服务器在某些特殊时期因为某些原因可能无法访问，你懂的。 1. 备份1sudo cp /etc/apt/sources.list /etc/apt/sources.list.old 2. 查看当前系统版本12lsb_release -cCodename: bionic 3. 打开source.list1sudo gedit /etc/apt/sources.list 4. 添加以下国内源并覆盖原内容阿里云（推荐） 16.04 xenial 123456789101112131415161718# deb cdrom:[Ubuntu 16.04 LTS _Xenial Xerus_ - Release amd64 (20160420.1)]/ xenial main restricteddeb-src http://archive.ubuntu.com/ubuntu xenial main restricted #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial-updates main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial universedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates universedeb http://mirrors.aliyun.com/ubuntu/ xenial multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-updates multiversedeb http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ xenial-backports main restricted universe multiverse #Added by software-propertiesdeb http://archive.canonical.com/ubuntu xenial partnerdeb-src http://archive.canonical.com/ubuntu xenial partnerdeb http://mirrors.aliyun.com/ubuntu/ xenial-security main restricteddeb-src http://mirrors.aliyun.com/ubuntu/ xenial-security main restricted multiverse universe #Added by software-propertiesdeb http://mirrors.aliyun.com/ubuntu/ xenial-security universedeb http://mirrors.aliyun.com/ubuntu/ xenial-security multiverse 18.04 bionic 12345678910deb http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-security main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-updates main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-backports main restricted universe multiversedeb http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiversedeb-src http://mirrors.aliyun.com/ubuntu/ bionic-proposed main restricted universe multiverse 5. 更新1sudo apt-get update 五. 利用 Xshell / SSH 在远程和本地之间传文件购买了一台VPS，传文件还需要架设ftp服务器，实在是懒 找到一个用 Xshell 传文件的方法，基本满足日常试用啦。 2018.4.1 更新：后来发现 SSH 居然可以传文件！ 方法写在下面 使用 Xshell本地打开 Xshell5 – 文件 – 属性 – 文件传输 – 使用下列下载路径 下载路径选择一个文件夹，存放从 VPS 下载到本地电脑的文件 加载路径选择一个文件夹，这是从本地电脑上传文件到VPS默认打开的路径 远程1sudo apt-get install lrzsz 上传使用命令：sudo rz 输入rz后会从 windows 中选取文件，自动传输到VPS的当前目录下 下载使用命令：sudo sz 如果没有使用sudo，可能导致卡在上传中。 比如，要把VPS当前目录下的 gf.jpg 文件下载到本地电脑，直接rz gf.jpg 使用 SSHSSH登录1ssh jerry@97.61.22.1 -p22 这里的 jerry 是你 VPS 的用户名， 97.61.22.1 是 VPS 公网IP地址 ， -p22 指 SSH 的22端口 如果报 WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED！ 错误，是因为服务器可能重装了系统，用 ssh-keygen -R [server ip] 来更新 ssh-key SSH本地传文件到远程1scp /path/filename jerry@servername:/path/ 例如scp /var/www/test.php root@192.168.0.101:/var/www/ 把本机/var/www/目录下的test.php文件上传到192.168.0.101这台服务器上的/var/www/目录中 SSH从远程下载文件到本地1scp username@servername:/path/filename /var/www/local_dir（本地目录） 例如 scp root@192.168.0.101:/var/www/test.txt 把192.168.0.101上的/var/www/test.txt 的文件下载到/var/www/local_dir（本地目录） 六、编辑开始菜单1sudo apt install alacarte 然后直接在Ubuntu终端输入命令alacarte。可以任意增、改、隐藏、显示菜单，但无法删除菜单，即使拥有root权限。 七、终端使用SS，并查公有ip首先根据这篇文章配置好SS软件。 然后在终端中 1export ALL_PROXY=socks5://127.0.0.1:1080 注意: 该命令仅对本终端一次性有效 查看公有ip 1curl ipinfo.io/ip 八、管理ppa源Ubuntu 软件仓库十分方便，但是有一些软件是在第三方库里的，因此我们要添加相应的ppa源，才能用 apt install 123sudo add-apt-repository ppa:ownername/projectnamesudo apt updatesudo apt install something 有些库我们已经不需要了，用文本编辑器修改/etc/apt/sources.list.d/文件夹下对应的.list即可 1sudo rm /etc/apt/sources.list.d/xxxxxx.list 九、如何正确地在Ubuntu 16.04 安装 JDK1.8其实很简单 添加ppa源 123sudo apt install software-properties-commonsudo add-apt-repository ppa:webupd8team/javasudo apt update 如果第二行提示add-apt-repository: command not found，安装一些包即可 1sudo apt-get install software-properties-common python-software-properties 安装jdk8 1sudo apt-get install oracle-java8-installer 如果提示没有公钥，添加对应的公钥（deeepin系统会有这个问题） 1sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys C2518248EEA14886 如果你有其他版本的 jdk， 更改默认 1sudo update-alternatives --config java 输出 12345* 0 /usr/lib/jvm/java-7-oracle/jre/bin/java 1062 auto mode 1 /usr/lib/jvm/java-7-openjdk-amd64/jre/bin/java 1061 manual mode 2 /usr/lib/jvm/java-8-oracle/jre/bin/java 1062 manual modePress enter to keep the current choice[*], or type selection number: 选择想默认使用的版本即可 十、更改 root 账户密码1sudo passwd root 十一、apt安装不成功，每次 apt install 都报错oracle-java7-installer安装不成功，清除缓存，不要每次 apt install 都报错 1234567sudo rm /var/lib/dpkg/info/oracle-java7-installer*sudo apt-get purge oracle-java7-installer*sudo rm /etc/apt/sources.list.d/*java*sudo apt-get update 十二、使用openssh远程连接查看是否已经安装openssh （如果装了，应该输出不止一个ssh） 1ps -ef | grep ssh 安装 1sudo apt install openssh-server 这样就可以在 win10 用 Xshell 连接虚拟机开多个终端了。 十三、ROOT账户没有环境变量在/root/.bashrc文件尾部添加： 1source /etc/profile 保存后执行： 1./root/.bashrc 如果提示没有权限 1chmod +x ./root/.bashrc 就ok了 十四、如何正确地配置环境变量1234567891011121314151617181920212223242526#Java env.export JAVA_HOME=/your_Java_homeexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarexport PATH=$JAVA_HOME/bin:/usr/local/protobuf/bin:$PATH#Scala env.export SCALA_HOME=/your_Scala_homeexport PATH=$SCALA_HOME/bin:$PATH#Spark env.export SPARK_HOME=/your_Spark_homeexport PATH=$SPARK_HOME/bin:$PATH#Python env.export PYTHONPATH=/your_python_home#Hadoop env.export HADOOP_HOME=/your_hadoop_homeexport HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoopexport PATH=$PATH:$HADOOP_HOME/binexport HADOOP_HOME_WARN_SUPPRESS=not_null#Mahout env.export MAHOUT_HOME=/your_Mahout_homeexport MAHOUT_CONF_DIR=$MAHOUT_HOME/confexport PATH=$MAHOUT_HOME/conf:$MAHOUT_HOME/bin:$PATH Ubuntu出现了内部错误从 14.04 到 16.04 到 18.04 ，无论哪个版本动不动就报错，临时解决办法： 12cd /var/crash/sudo rm * 删除错误日志，这样下次开机不会继续报错。但这不代表系统就没错误了，下次遇到奇奇怪怪的问题是还是会报错。几乎无解。 完全卸载 Mysql12345sudo apt-get purge mysql-server mysql-common mysql-clientsudo rm -rf /etc/mysqlsudo rm -rf /var/lib/mysqlsudo rm -rf /var/log/mysqlsudo rm -rf /var/run/mysqld","link":"/post/2656dc91.html"},{"title":"gcc编译基本操作","text":"假设我现在有3个文件，分别是： mystrlen.c: 是我自己实现的一个计算字符串长度的算法函数。 mystrlen.h: 该算法的头文件。 test.c: main函数，里面有一些字符串需要调用上面的算法来计算长度 那么在 Linux 下，如何用 gcc 把 mystrlen.c 编译成动态链接库，方便 test.c 去使用呢 ？ 一、gcc各参数的用途 -shared ：指定生成动态链接库。 -static ：指定生成静态链接库。 -fPIC ：表示编译为位置独立的代码，用于编译共享库。目标文件需要创建成位置无关码，就是在可执行程序装载它们的时候，它们可以放在可执行程序的内存里的任何地方。 -L. ：表示要连接的库所在的目录。 -l：指定链接时需要的动态库。编译器查找动态连接库时有隐含的命名规则，即在给出的名字前面加上lib，后面加上.a/.so来确定库的名称。 -g ：编译器在编译的时候产生调试信息。 -c ：只激活预处理、编译和汇编,也就是把程序做成目标文件(.o文件)。 -o ：指定生成的文件名，如果不指定，默认为 a.out -ggdb ：此选项将尽可能的生成gdb的可以使用的调试信息。 -Wl,options ：把参数(options)传递给链接器ld。如果options中间有逗号,就将options分成多个选项，然后传递给链接程序。 -Wall ：生成所有警告信息。 二、使用gcc把 mystrlen 编译成动态库 libmystrlen.so1. 把 mystrlen.c 编译成目标文件1gcc -c mystrlen.c -o mystrlen.o 在当前目录会生成 mystrlen.o文件 2. 把目标文件编译成动态链接库1gcc -shared -fPIC mystrlen.o -o libmystrlen.so 在当前目录会生成 libmystrlen.so文件 三、使用gcc把 test.c 编译成可执行文件1.编译1gcc -L ./ test.c -lmystrlen -o test 在当前目录会生成 test可执行文件 2.运行1./test 程序里放了4个测试字符串，长度分别为0 3 10 26，如果匹配，则输出 pass 输出结果： 1234data_0 pass [0]data_1 pass [3]data_2 pass [10]data_3 pass [26] 值得注意的地方 我们的动态链接库文件名是libmystrlen.so，但在-l参数中，去掉lib和.so，只需要mystrlen就可以。 -l后面可以不用空格。 在gcc编译的时候，如果文件a依赖于文件b，那么编译的时候必须把a放前面，b放后面。 所以， 命令中test.c一定要放在-lmystrlen前面。 三、可能出现的报错error while loading shared libraries12jerrysheh@ubuntu:~/shiyan9$ ./test./test: error while loading shared libraries: libmystrlen.so: cannot open shared object file: No such file or directory 这是因为程序运行时找不到我们自己的动态链接库文件，解决办法很简单： 1. 打开配置文件 /etc/ld.so.conf1sudo vim /etc/ld.so.conf 2. 在配置文件的最后追加一行你的库文件所在的路径即可编辑完后类似这样： 12include /etc/ld.so.conf.d/*.conf/home/jerrysheh/shiyan9/ 3. 刷新配置文件1sudo ldconfig 4. 重新运行 test 程序1./test 找不到头文件如果头文件跟 .c 文件不在同一目录，使用 -I 参数，指定头文件的路径即可 如头文件在 /home/jerrysheh/shiyan9/include 里面，只需要 1gcc -I /home/jerrysheh/shiyan9/include -L ./ test.c -lmystrlen -o test","link":"/post/bbe22ae6.html"},{"title":"了解makefile","text":"使用 gcc 命令可以很方便地在Linux下编译C源代码，但是，当我们的工程变大了之后，项目下面有很多 .c、.h文件，各种依赖关系错综复杂。这时候，手工编译就不是那么划算了。makefile就是用于解决这个问题的。 假设我现在的工程下面有5个文件，分别是： main.c 主函数所在源文件 hello.c 输出hello的函数 hello.h 头文件 world.c 输出world的函数 world.h 头文件 我们可以在工程目录下，新建一个名称为makefile的文件（没有扩展名），然后往这个文件里写一些规则，再在shell下面执行make命令，就可以实现自动编译了。 makefile的四种规则写法一、显式规则makefile的规范： 目标 : 依赖(tab)命令 注意，命令前一定要是 TAB，不能是四个空格 make的执行:make 默认搜索当前目录下的makefile，或者Makefile文件,可以指定特殊的makefile文件，比如make -f makefile_xxxx(文件名) make默认实现makefile里的第一个目标，一般是二进制可执行文件也可以指定目标，比如make clean 一个简单的方法： 1234567891011121314main : main.o hello.o world.o gcc main.o hello.o world.o -o mainmain.o : main.c hello.c world.c gcc -c main.c -o main.ohello.o : hello.c gcc -c hello.c -o hello.oworld.o : world.c gcc -c world.c -o world.oclean : rm *.o main 解析： main是一个可执行文件（目标），它依赖于main.o hello.o world.o这三个文件（依赖），所以我们要用gcc编译main.o hello.o world.o，以生成main 我们的目录下现在还没有main.o hello.o world.o这三个文件，makefile会根据依赖文件 xxxx.o 去寻找和执行下面的依赖关系。以此类推。一步步生成上来。 二、常量替换类似于C语言的宏定义为了方便，我们可以这样写makefile： 在前面使用编程语言的赋值语句=，定义变量 在使用变量的地方用$(var)的方式表示 12345678910111213141516cc = gcctarget = testobjects = test.o mystrlen.o$(target) : $(objects) $(cc) $(objects) -o $(target)test.o : test.c mystrlen.h $(cc) -c test.c -o test.omystrlen.o : mystrlen.c $(cc) -c mystrlen.c -o mystrlen.oclean : rm $(objects) $(target) 三、隐式规则还可以再精简： 12345678910111213cc = gcctarget = testheaders = mystrlen.hobjects = test.o mystrlen.o$(target) : $(objects) $(cc) -o $(target) $(objects)%.o : %.c $(headers) $(cc) -c $&lt; -o $@clean : rm $(objects) $(target) 四、shell + 隐式规则结合shell命令，使用函数完成makefile，使其能够自动寻找目录下h文件和c文件，同时把c文件替换成o文件共object常量使用。 1234567891011121314cc = gcctarget = mainheaders = $(shell find ./ -name &quot;*.h&quot;)sources = $(shell find ./ -name &quot;*.c&quot;)objects = $(sources:%.c=%.o)$(target) : $(objects) $(cc) -o $(target) $(objects)%.o : %.c $(headers) $(cc) -c $&lt; -o $@clean: -rm -rf $(objects) $(target) 或者是需要目录的地方可以用 shell 语句找出目录 12345obj-m = hello.oall: make -C /lib/modules/$(shell uname -r)/build/ M=$(PWD) modulesclean: make -C /lib/modules/$(shell uname -r)/build M=$(PWD) clean gcc常用参数 gcc -c main.c -o main.o 编译main.c,生成main.o目标文件 gcc test1.o test2.o -o test 链接两个目标文件test1.o和test2.o生成可执行文件test gcc main.c -o main 编译main.c,然后链接生成main可执行文件 gcc main.c mystrlen.c hello.c -o main 编译多个文件 gcc -g main.c -o main 打开调试 gcc -I /usr/include main.c -o main 指定头文件目录 gcc -L /usr/lib -l ffmpeg main.c -o main 指定库文件目录和库文件libffmpeg.so gcc -MM main.c 查看main.o 的依赖关系，用于生成makefile","link":"/post/264103f9.html"},{"title":"Linux设备驱动开发（一）内核的配置与编译","text":"Linux内核的源码结构Linux内核主要由五个子系统组成： 进程调度 内存管理 虚拟文档系统 网络接口 进程间通信 进程调度（SCHED）功能：控制进程对CPU的访问 当需要选择下一个进程运行时，由调度程式选择最值得运行的进程。可运行进程实际上是仅等待CPU资源的进程，假如某个进程在等待其他资源，则该进程是不可运行进程。Linux使用了比较简单的基于优先级的进程调度算法选择新的进程。 内存管理（MM）功能：允许多个进程安全的共享主内存区域 Linux 的内存管理支持虚拟内存，即在电脑中运行的程式，其代码，数据，堆栈的总量能够超过实际内存的大小，操作系统只是把当前使用的程式块保留在内存中，其余的程式块则保留在磁盘中。必要时，操作系统负责在磁盘和内存间交换程式块。内存管理从逻辑上分为硬件无关部分和硬件有关部分。硬件无关部分提供了进程的映射和逻辑内存的对换；硬件相关的部分为内存管理硬件提供了虚拟接口。 虚拟文件系统（Virtual File System,VFS）隐藏了各种硬件的具体细节，为任何的设备提供了统一的接口，VFS提供了多达数十种不同的文档系统。虚拟文档系统能够分为逻辑文档系统和设备驱动程式。逻辑文档系统指Linux所支持的文档系统，如ext2,fat等，设备驱动程式指为每一种硬件控制器所编写的设备驱动程式模块。 网络接口（NET）提供了对各种网络标准的存取和各种网络硬件的支持。网络接口可分为网络协议和网络驱动程式。网络协议部分负责实现每一种可能的网络传输协议。网络设备驱动程式负责和硬件设备通讯，每一种可能的硬件设备都有相应的设备驱动程式。 进程间通讯(IPC)支持进程间各种通信机制。 内核结构目录 目录名 描述 arch 体系结构相关的代码，相对于具体的CPU架构，如：arm、m68k、mips、PowerPC等。在arm目录有mach-s3c2440目录，该目录下是针对2440的支持代码。 block 块设备的通用函数，如blk-core.c、blk-ioc.c等。 crypto 常用的加密或校验算法等。 drivers 目录中是系统中所有的设备驱动程序。它又进一步划分成几类设备驱动，每一种有对应的子目录，如：声卡的驱动对应于drivers/sound；drivers/block 下为块设备驱动程序；drivers/mtd下为Nor和Nand flash的驱动程序；drivers/char下为字符设备驱动程序。 Documents 关于内核的一些帮助文档,是对每个目录作用的具体说明。 firmware 一些固件驱动程序，如： fs Linux支持的文件系统代码，如：ext2、ext3、ext4、jffs2、nfs等。 include 目录包括编译核心所需要的大部分头文件，例如linux内核的头文件在include/linux子目录下，与cpu相关的头文件在include/asmgeneric子目录下；另外有些设备驱动程序的头文件，如：sound、video、net、pcmcia等。 init 内核的初始化代码（不是系统的引导代码），其中，main.c文件中的start_kernel函数是内核引导后运行的第一个函数。 ipc 目录包含了核心进程间的通信代码。 kernel 内核管理的核心代码，此目录下的文件实现了大多数linux系统的内核函数，其中最重要的文件当属sched.c；同时与处理器结构相关代码都放在arch/*/kernel目录下。 lib 目录包含了核心的库代码，不过与处理器结构相关的库代码被放在arch/*/lib/目录下。 nm 目录包含了所有独立于 cpu 体系结构的内存管理代码，如页式存储管理内存的分配和释放等。与具体硬件体系结构相关的内存管理代码位于arch/*/mm目录下 。 net 目录里是核心的网络部分代码，其每个子目录对应于网络的一个方面。 samples 一些调试的程序 scripts 用于配置、编译内核的脚本文件。 security 安全、密钥相关的代码。 sound 音频设备的驱动程序 tools 一些工具 usr 用来制作一个压缩的cpio归档文件：initrd的镜像，它可以作为内核启动后挂载的第一个文件系统 virt kvm Makefile 目录第一个Makefile文件。用来组织内核的各模块，记录了个模块间的相互这间的联系和依托关系，编译时使用；仔细阅读各子目录下的Makefile文件对弄清各个文件这间的联系和依托关系很有帮助。 ReadMe 目录里是核心及其编译配置方法简单介绍 REPORTING-BUGS 目录里是有关报告Bug 的一些内容 CREDITS 目录下是光荣榜。对Linux做出过很大贡献的一些人的信息。 COPYING 目录下是GPL版权申明。对具有GPL版权的源代码改动而形成的程序，或使用GPL工具产生的程序，具有使用GPL发表的义务，如公开源代码。 MAINTAINERS 目录存放了维护人员列表，对当前版本的内核各部分都有谁负责。 Linux内核源码的配置方法配置linux内核的方法主要有下面几种方法： make config:基于文本的最为传统的配置界面，不推荐使用 make menuconfig:基于文本选单的配置界面，字符终端下推荐使用 make xconfig:基于图形窗口模式的配置界面，Xwindow下推荐使用 make oldconfig:如果只想在原来内核配置的基础上修改一些小地方，会省去不少麻烦 例如，采用 make menuonfig 命令以文本选单的形式配置内核，直接在内核源码目录输入 1make menuconfig 配置选择选择相应的配置时，有三种选择，它们分别代表的含义如下： Y—-将该功能编译进内核N—-不将该功能编译进内核M—-将该功能编译成可以在需要时动态插入到内核中的模块 一些内核特性可以直接编译进内核。一些可以被编译为可装载的模块。一些则可以完全被一起移除。这里还有一些内核参数，它不是真正的特性，但是必须输入有效的十进制或者十六进制或者一些文本。 菜单项目中，以这些符号开始的表示特性可以： [ ]：编译或者移除 &lt; &gt;：编译或者模块化或者移除 { }：编译或者模块化（被其他特性选择） - -：被其他特性选择 在make menuconfig下，* 表示Y，M 表示 M，空白表示N。 为了改变这些特性，你需要用光标键移动使之高亮显示，同时按Y将其编译，按M模块化，按N将它移除。 你可能也需要按空格键来在几个选择中循环（Y -&gt; N -&gt; M -&gt; Y）。 可能出现的问题Ubuntu下，若 make menuconfig报以下错误，则需要安装库 报错信息 123Unable to find the ncurses libraries or the required header files. 'make menuconfig' requires the ncurses libraries. Install ncurses (ncurses-devel) and try again.make[1]: *** [scripts/kconfig/dochecklxdialog] Error 1make: *** [menuconfig] Error 2 解决 1sudo apt-get install ncurses-dev linux内核源码的编译1make -j 2 -j 参数表示允许多个任务并行编译 编译成功后，生成的linux内核映像（zImage）生成在/arch/arm/boot路径下。","link":"/post/2720656c.html"},{"title":"给自己的 Linux 备忘","text":"Linux 学习任重而道远，此文记录了我在 Linux 学习中需要知道或反复查阅使用的命令、表达式等内容，持续更新。 常用命令常规命令 常规命令 说明 mkdir myweb 创建目录 mkdir -p myweb/www/static 创建多级目录 rmdir 删除空目录 pwd 显示当前目录 touch a.txt 如果 a.txt 不存在，生成一个新的空文档a.txt。如果a.txt存在，那么只更改该文档的时间信息。 echo 创建带有内容的文件（见标准输出） cat 查看文件内容（当文件太大无法一页展示时，用more） more 多屏查看文件内容 （ space-翻页 回车-下一行 q-退出） less 多屏可滚动查看文件内容 （space-翻页 回车-下一行 q-退出 up/down-上下滚动 居然还可以用鼠标666） whatis ls 显示ls命令的作用 man ls 显示ls命令的手册（space翻页 j下行 k上行 /关键字搜索 n下一个关键字 shift+n上一个关键字） 文件系统命令 文件系统命令 说明 cd 切换目录 cp a.txt b.txt 拷贝. 在工作目录下，将a.txt复制到文件b.txt mv a.txt c.txt 重命名 a.txt 为 c.txt mv a.txt /home/jerrysheh 将 a.txt 移动到 /home/jerrysheh 目录下 rm 删除文件 rm -r 删除包括子目录和子文件 （-r 表示 recursive，递归） rm -f 强制删除 apropos -e “list directory contents” 精确反查带有”“list directory contents”功能的命令 ll -h 显示文件夹内文件详细信息 ls 显示当前目录下文件 ls -a 显示当前目录包括隐藏的文件 curl -o video.mp4 http:www.example.com/video.mp4 下载网络文件 压缩命令 压缩命令 说明 tar -zcvf xxxx.tar.gz /home/test 压缩 -z 有gzip属性的，，-c 压缩 -v 显示过程，-f 档案名（必须） tar -zxvf xxxx.tar.gz -C /tmp 解压， -x 解压 ， 其他参数同上 zip -r mydata.zip mydata 把 mydata 文件夹压缩 -r 递归（包括子目录） unzip mydata.zip -d mydatabak 解压 mydata.zip， -d 解压到指定目录 系统相关 系统相关 说明 shutdown now 关机 uname -a 查看内核信息 dpkg -i xxx.deb 安装已下载的.deb安装包 用户相关命令 用户相关(在root下操作) 说明 adduser jerry 创建 jerry 用户（自动创建/home目录） useradd jerry 创建 jerry 用户 （需要手动配置/home目录） passwd jerry 给 jerry 用户设置密码 userdel jerry 删除 jerry 用户 Tips 1: 如果不知道一个命令是干嘛用的，可以用 --help 参数显示帮助，或者用 man ls 显示手册。如 ls --help 和 man ls。按 q 离开 man 环境。 Tips 2: linux命令后面的参数，一般简写时是单横杠，如 -h ，全写是双横杠，如 --help。 关于 ls -l 命令终端输入ls -l 返回 123total 8drwxrwxr-x 2 jerrysheh jerrysheh 4096 Mar 27 11:59 downloaddrwxr-xr-x 3 root root 4096 Apr 30 10:26 www totaltotal 是所列出内容的磁盘占用空间总和值（kbytes）。 对于“占”的理解：数据在存放过程中占据的block的大小。比如，1个block占用4k，那8.7k数据，要用3个bolck来存储，也就占用12k空间。 每一行第一个字符 字符 含义 d 目录（dirtectory） - 普通文件 c 字符设备文件(character) l 链接文件 b 块设备文件(block) p 命令管道文件，与shell编程有关 s sock文件，与shell编程有关 块设备文件： 块设备文件(block)，一般置于/dev目录下，设备文件是普通文件和程序访问硬件设备的入口，是很特殊的文件。没有文件大小，只有一个主设备号和一个辅设备号。一次传输数据为一整块的被称为块设备，如硬盘、光盘等。最小数据传输单位为一个数据块(通常一个数据块的大小为512字节) 字符设备文件(character): 一般置于/dev目录下，一次传输一个字节的设备被称为字符设备，如键盘、字符终端等，传输数据的最小单位为一个字节。 Linux 通配表达式Linux 通配表达式 与 正则表达式 相类似，但语法有所不同。 命令 说明 × 任意多个字符 ？ 任意一个字符 [xyz] 字符 x 或 y 或 z [0-3] 数字 0 到 3 其中一个 [b-e] 字符 b 到 e 其中一个 [^mnp] 不是 m 或 n 或 p 的 一个字符 不要在删除文件到时候多敲了一个空格，会删除当前整个目录下的文件～ 1$rm * .txt 文件权限相关 命令 说明 sudo chmod 755 a.txt chmod = change mode ，改变 a.txt 的权限为 755 sudo chmod g-w a.txt 删去 同组 的 写（write）权限 sudo chmod go+r b.txt 同组 和 其他 用户 增加对 b.txt 的读取（read）权限 说明：Linux中，每个文件都有 9 位读写执行的权限。分为三组，三位一组。分别对应拥有者用户(user)，拥有组(owner group)中的用户和所有其他用户(other)。 7 = 111（2进制），表示 User 有读/写/执行 的权限， 5 = 101（2进制），表示 Owner group 有 读/执行 的权限，但没有写的权限。见下表。 十进制数 二进制数 权限 755 111 101 101 user 可读/写/执行， group 和 other 只能读/执行，不能写 710 111 001 000 user 可读/写/执行， group 只能执行， other没有任何权限 功能表 参数 说明 u 用户（user） g 同组（group） o 其他（other） a 所有 （all） 默认值 + 增加权限 - 减少权限 = 给定唯一权限 r 读 w 写 x 可执行 快捷操作 命令 说明 ctrl+a 定位到命令开头 ctrl+e 定位到命令结尾 ctrl+ ← 定位到上一个单词 标准输入，标准输出，标准错误，管道与重新定向 命令 说明 ls &gt; a.txt 不将 ls 命令的结果输出到屏幕上，而是输出到 a.txt 文件里面 ls &gt;&gt; a.txt 将 ls 命令的结果输出添加到 a.txt 文件的末尾 ls 2&gt;&gt; b.txt 如果ls命令出错，报错信息输出到 b.txt 的末尾 ls &gt; c.txt 2&gt;&amp;1 将结果和错误（如果同时有）都输出到 c.txt cat &gt;&gt;filetest 2&gt;&amp;1 &lt;&lt;END 建立filetest文件，当输入遇到END时，退出 echo helloworld 将 helloworld 这段文本输出到标准输出（屏幕） echo helloworld &gt; b.txt 将 helloworld 这段文本输出到 b.txt 文件里面 由于STDOUT与STDERR都会默认显示在终端上，为了区分二者的信息，就有了编号的0，1，2的定义，用1表示STDOUT，2表示STDERR。 2&gt;&amp;1，指标准错误重新定向到标准输出，即将标准输出、标准错误指定为同一输出路径。其中， &amp; 表示前面的命令放到后台执行。 管道以将一个命令的输出导向另一个命令的输入，从而让两个(或者更多命令)像流水线一样连续工作，不断地处理文本流。 命令 说明 cat 显示文件内容 wc word count 统计文本中的行、词以及字符的总数 命令：$cat &lt; a.txt | wc 执行步骤： 输入（标准输入被重定向为 a.txt ） → cat（处理） → 输出（作为wc命令的输入） 输入（cat命令的输出） → wc（处理） → 输出（标准输出，屏幕） 执行结果： 12jerrysheh@MI:~$ cat &lt; a.txt | wc 2 2 22 命令：$head -n 3 /etc/passwd | sort 将 passwd 文件到前3行输出并排序 可以使用 xargs 参数，让管道接受命令行参数 1echo /etc/nano | xargs -i cp {} /tmp/dir 将echo的输出作为参数，填入 cp 中的{} 使用 grep 和 cut 过滤信息ls --help | grep &quot; -l&quot;: 查看 ls 命令的 -l 参数用途 mkdir --help| grep “ -p”：查看 mkdir 命令的 -p 参数用途 grep -inr &quot;int printf&quot; /usr/include &gt;&gt; /tmp/out.txt: 搜索/usr/include目录下，含有 int printf 的文件内容，输出到 /tmp/out.txt 上 -i 忽略大小写 -n 打印行号 -r 包含子目录 grep -inr &quot;int printf&quot; /usr/include | cut -d : -f 1: 搜索/usr/include目录下，含有 int printf 的文件内容，用 cut 剪切每个搜索结果以冒号分隔的第一片 cut -d 分割 -f 第几片 vimvim命令相关 命令 说明 :q 退出 :q! 强制退出 :wq 保存并退出 :set number 显示行号 :set nonumber 隐藏行号 /apache 在文档中查找apache, n 下一个，shift+n 上一个 vim操作相关 命令 说明 h 左移 j 下一行 k 上一行 l 右移 a 补充文本（修改完记得Esc退出编辑模式） i 插入文本（修改完记得Esc退出编辑模式） x 删除光标所指字符 ra 替换光标所指字符为a u 撤销 U 撤销整行 0 （zero） 光标移动到行首 ce 删除光标所指到单词末尾，并进入编辑模式 ctrl+F 下一页 ctrl+B 上一页 ctrl+E 下滚一行 ctrl+Y 上滚一行 命令 说明 dw 从光标处删除至一个单字/单词的末尾 d2w 从光标处删除至两个单字/单词的末尾 d$ 从光标处删除这一行光标后面的内容 2w 光标往前两个单词（单词词首） 2e 光标往前两个单词（单词词尾） dd 删除行 2dd 删除两行 ddp 删除光标所在行，光标移动到其他位置，粘贴 yyp 复制光标所在行，光标移动到其他位置，粘贴","link":"/post/ee3d8fa1.html"},{"title":"HTTP之旅","text":"参考书籍：《计算机网络：自顶向下方法》 HTTP简介一个 Web 应用程序，首先接触的是应用层协议是 超文本传输协议（HyperText Transfer Protocol，HTTP），HTTP由两个程序实现：一个客户端、一个服务器。其连接模型大概为：客户端向服务器发起 请求（request） ，服务器收到请求后，进行 响应（response），返回客户端需要的内容。 与 HTTP 有关的概念web 对象一般来说，一个 Web page（页面）是由很多对象组成的。对象可以是 html、图片、视频，甚至是Java程序。例如，当我们访问 https://www.google.com ，这个 Web page 是由 Google 提供的一个基本 html 页面和搜索框上面大大的 logo 图片(以及其他对象)组成。 这个 html 页面是一个对象（通常为index.html），其中的 logo 图片也是一个对象。这些对象都存储在服务器上面。 实际上对象一般都可以通过 URL 寻址，比如谷歌首页的Logo图片，其URL地址是https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_272x92dp.png HTTP 定义了客户端如何向服务器请求 Web page。HTTP使用 TCP 作为支撑运输协议，所以不用担心请求的过程数据在中途丢失或出错的问题。 无状态协议我们可能注意到，我们使用浏览器打开Google.com，然后新建一个标签页又打开一次，Google 的页面还是会又一次地显示出来，不存在服务器之前已经给你发过了所以不再发这种事。因此我们说 HTTP 是 无状态协议(stateless protocol)。 非持续连接和持续连接如果一个客户与服务器的 每一个 请求/响应对，分别由单独的 TCP 连接发送，这样的 Web 应用程序称为 非持续连接（non-persistent connection）。假设在一个由 1 个 index.html 和 10 张 jpg 图片组成的 Web page 中传输，则会建立 11 个 TCP 连接。 反之，如果同一个客户端的所有请求及服务器对它的响应经过相同的 TCP 连接发送，称为 持续连接（persistent connection）。这样在上述例子中只需要建立 1 个 TCP 连接。 HTTP/1.0 协议使用非持久连接，即在非持久连接下，一个tcp连接只传输一个 Web 对象；HTTP/1.1 默认使用持久连接（当然，你也可以配置成使用非持久连接）。 HTTP报文request报文HTTP request报文结构如下： 一个简单的 HTTP 报文如下： 12345GET /www.zsc.edu.cn/index.html HTTP /1.1Accept-Language:zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7Host:www.zsc.edu.cnConnection: closeUser-Agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36 请求行1GET /www.zsc.edu.cn/index.html HTTP /1.1 HTTP 报文的第一行称为 请求行（request line） ，包含三部分：请求方法、请求地址、协议版本。之间用空格隔开。 GET 说明采用了 GET 方法， HTTP协议中，有GET、POST、HEAD、PUT、DELETE、OPTIONS、TRACE、CONNECT 等方法，其中最常用的是 GET 和 POST， GET用于获取内容， POST常用于表单提交。其后接着的是请求的URL地址以及采用的 HTTP 协议版本，这里是 1.1。 不是向服务器提交表单就一定要用 POST，比如我们在某网站的表单的name填 hello ， age 填 18，然后点击确定，浏览器可能会构造一个类似于 www.somesite.com/select?name=hello&amp;age=18 这样的URL传递给服务器。服务器解析这种 URL 就知道你填的是什么了。当然，这种情况不适合输入账号和密码。 首部行1234Accept-Language:zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7Host:www.zsc.edu.cnConnection: closeUser-Agent:Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36 请求行后面的几行称为 首部行（header line），用来提供一些额外的信息。 request常见首部 首部 解释 Accept 客户端能够处理的媒体类型 Accept-Charset 客户端能够支持的字符集 Accept-Encoding 客户端能够支持的内容编码 Accept-Language 客户端能够支持的自然语言集 Authorization 认证信息 Host 请求的主机域名（HTTP1.1中唯一一个必须包含的请求首部） Connection 是否需要持久连接。如果是close，表明客户端希望在本次连接后就断掉 TCP 连接 User-Agent 客户端的浏览器类型 Referer 包含一个URL，用户从该URL代表的页面出发访问当前请求的页面 Content-Length 请求消息正文的长度 Pragma 指定“no-cache”值表示服务器必须返回一个刷新后的文档，即使它是代理服务器而且已经有了页面的本地拷贝 一个简单的例子是，当我们访问 https://developer.android.com/studio/index.html 想要下载 Android Studio软件时，如果我们用的是Windows 系统的浏览器，页面则会默认显示Windows版本的Android Studio软件下载，反正如果我们用的是 Mac 系统，则会默认显示 Mac 版本。这就是因为服务器根据我们的 User-Agent判断我们是当前什么系统。 如果一个首部行有多个值，通常用 q=0.9 来排列相对优先级，如 1accept-language: zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7 如果是 POST 方法，在 首部行 后面会有一个空行，紧接着是 请求包体。包括了表单中提交的内容。 response报文 1234567891011HTTP/1.1 200 OKConnection:closeContent-Type:text/html; charset=UTF-8Date:Thu, 08 Mar 2018 08:37:21 GMTExpires:Thu, 08 Mar 2018 09:07:21 GMTPragma:no-cacheServer:Apache/2.2.15 (CentOS)Transfer-Encoding:chunkedX-Powered-By:PHP/5.3.3(data) 状态行第一行称为 状态行（status line），这一行包括了协议和状态码。常见的状态码有： 200 OK: 表示请求成功 301 Moved Permanently: 重定向转移 400 Bad request： 请求不能被服务器理解 404 Not Found： 请求的对象在服务器上找不到 500 Internal Server Error：服务器已收到请求，但服务器内部出错导致无法响应 首部行第一行后面几行称为 首部行（header line），内容与 request 的首部行大同小异。 最后是数据，也就是被请求的对象。如果请求的是 html 页面则在浏览器显示网页，如果请求的是图片则显示图片等。 cookieHTTP是无状态协议，那么网站是怎么识别我们的呢？ cookie 用于站点对同一用户进行识别。 cookie技术有 4 个组件： request报文首部中有一个 cookie 的首部行 response报文首部中有一个 cookie 的首部行 客户端系统中有一个 cookie 文件，由浏览器进行管理 服务器后端数据库中有 cookie 相关数据 比如说，当我们第一次登录 JD.com 进行购物的时候，JD服务器的 response 报文会对我的浏览器设置一个 set-cookie: 1678 的首部行，这个 set-cookie 把 cookie 值存入了我们的电脑。然后我们点击几样商品，转入购物车结算页面，此时对 HTTP 来说是一次全新的连接，但是结算页面却能准确显示我们刚才选的商品，这是因为我们在进入结算页面时，request首部中包含了刚刚 JD.com 给我们的 cookie: 1678， JD.com 就知道你是刚刚 1678 那个人了，于是把刚才页面你勾选的商品显示出来，进行结算。 Cookie 和 Session 的区别和联系在某些地方你可能会听说过 Session 这个名词，简单地说，Session是在服务端保存的一个数据结构，可以是任何类型的数据。它用来跟踪用户的状态，这个数据可以保存在内存、集群、数据库、文件中，但总而言之是保存在服务器端的，对客户端不可见。 而 Cookie 是客户端保存用户信息的一种机制，Cookie只能存储字符串，用来记录用户的一些信息，也是实现 Session 的一种方式。由于保存在客户端，因此最好对 cookie 进行加密。 例如，在 Java Servlet 开发中，我们可以这样设置 cookie： 1234567// 设置 cookieCookie cookie = new Cookie(\"key\",\"value\");cookie.setMaxAge(60*60*24); // 设置 cookie 有效期response.addCookie(cookie);// 读取 cookieCookie[] cs = request.getCookies(); 代理服务器Web 缓存器（Web cache），或者叫 代理服务器（proxy server）。用于存放真实服务器上面的一些对象。提高用户访问速度。 比如说，我们访问 www.somesite.com/campus.gif ， 如果对方服务器有配置代理服务器，则我们的请求会首先发给代理服务器，代理服务器检查自己有没有这个文件，如果有，直接 response 给客户，如果没有，代理服务器向真实服务器请求这个文件，获取到以后先自己复制一份，然后发送给客户。 这样做的好处就是降低了服务器的压力（因为服务器除了存储对象还有其他事要干，资源获取这种简单的活就交给代理服务器去干了）。同时，也有利于提高用户访问速度。 条件 GET 方法使用代理服务器有一个问题，那就是代理服务器缓存的对象，也可能是旧的。比如今天缓存了一张图片，明天真实服务器修改了这张图片，后天有一个浏览器请求这张图片。如果代理服务器直接发给客户，不就发了旧版本吗？ 解决方案是条件 GET 方法， 这个 GET 方法 由代理服务器向真实服务器 发出，其中包括 If-Modified-Since 首部行，如果与服务器上的一致，则证明是最新的，否则，从服务器请求最新的文件过来。 URL 和 URI 的区别URI：Universal Resource Identifier 统一资源标志符URL：Universal Resource Locator 统一资源定位符URN： Universal Resource Name 统一资源名称 也就是说，URI分为三种，URL or URN or （URL and URN） HTTP 中 URL 的参数如果我们： 登录知乎 https://www.zhihu.com/ 搜索“Spring”，回车。 会发现，浏览器的地址变成了 1https://www.zhihu.com/search?type=content&amp;q=Spring 其中， ?type=content&amp;q=Spring 部分就是参数。 参数由 ? 开头，每个参数形如 name=value 的形式，多个参数用 &amp; 符号连接。 HTTP参数实际上可以认为是一种用户的输入，根据不同的用户输入，服务器经过处理后返回不同的输出。 浅谈 http、tcp、socket当浏览器需要从服务器获取网页数据的时候，就会发出一次Http请求。Http会通过TCP建立起一个到服务器的连接通道，当本次请求需要的数据完毕后，Http会立即将TCP连接断开，这个过程是很短的。所以Http连接是一种短连接，是一种无状态的连接。所谓的无状态，是指浏览器每次向服务器发起请求的时候，不是通过一个连接，而是每次都建立一个新的连接。但是从http/1.1之后,也支持 keep-alive 保持连接功能。 如果要说 http 和 socket 有什么区别，那就是 http 是一种规定好的连接模型，而 socket 我们可以自由编程控制什么时候保持连接，什么时候断开，但他们两者本质上传输的都是底层tcp连接所建立的数据。 比较形象的描述：HTTP是轿车，提供了封装或者显示数据的具体形式；Socket是发动机，提供了网络通信的能力。","link":"/post/1707ee78.html"},{"title":"Socket编程实践（Java &amp; Python实现）","text":"之前在浅谈 Socket 编程一篇中，初步使用 Socket 套接字，在 linux 下用 C 实现了一个客户端/服务器 通信的例子。但是由于C语言比较隐晦难懂，很多自定义的数据结构也偏向于底层，导致我对于 TCP/UDP Socket 的过程理解不深。这一篇，主要站在应用的角度，用实际的例子，补充实践 Socket 通信的过程。一开始为了更好地理解，使用了 Python 语言。2019年1月9日闲来无事，用java重写了一遍，感受对比一下 java 的繁琐和 python 的简洁（真是无趣的家伙）。 参考书籍：《计算机网络：自顶向下方法》（第2章）。 TCP Socket的过程1. TCP连接TCP是面向连接的协议。客户端和服务器在发送数据之前，必须先握手和创建一个TCP连接。 一个TCP连接模型如下： 客户端应用程序 &lt;—&gt; 客户端Socket &lt;—&gt; TCP连接 &lt;—&gt; 服务器Socket &lt;—&gt;服务器应用程序 2. 欢迎之门和连接之门TCP连接中，客户端需要首先向服务器发起接触。也就是说，服务器必须提前准备好（即服务器应用必须先运行起来），而且，服务器必须有一扇“特殊的门”，我们可以称之为“欢迎之门”（欢迎Socket，ServerSocket），欢迎来自任意主机上的客户端进程来敲门。 客户端要向服务器发起连接的时候，首先创建一个TCP Socket，这个 Socket 指定了服务器中欢迎Socket的地址（即服务器IP和端口号）。创建完毕后，客户端即可向服务器发起三次握手并建立与服务器的TCP连接了。 在三次握手期间，客户端敲的是服务器的“欢迎之门”。当服务器听到敲门后，将生成一个新的门，这个新门就是连接Socket（connection Socket），专门用于特定的客户。 对于应用程序来说，客户端Socket和服务器连接Socket（注意不是欢迎Socket）直接通过一根管道连接。服务器和客户端可以互相发送或接收字节。 Python 实现 TCP Socket 的例子TCPClient.py 客户端12345678910111213141516171819202122from socket import *serverName = \"servername\"serverPort = 12000# 初始化客户端socketclientSocket = socket(AF_INET,SOCK_STREAM)# 客户端socket向服务器发起连接clientSocket.connect((serverName,serverPort))sentence = input(\"Input lowercase sentence:\")# 客户端socket向服务器发送内容clientSocket.send(sentence)# 客户端socket接收来自服务器的内容modifiedSentence = clientSocket.recv(1024)print(\"From Server:\", modifiedSentence)# 关闭客户端socketclientSocket.close() 逐行解释: 1. clientSocket = socket(AF_INET,SOCK_STREAM)使用socket()初始化函数，创建了一个客户端Socket，第一个参数AF_INET指明底层网络使用的是IPv4，第二个参数SOCK_STREAM指明该Socket是SOCK_STREAM类型，也就是TCP。 clientSocket就是一个 Socket对象，它具有connect、send、recv等方法。 2. clientSocket.connect((serverName,serverPort))前面提到，当客户端创建完一个TCP Socket之后，就可以向服务器发起三次握手并建立与服务器的TCP连接了，这一句就是连接。第一个参数serverName指明服务器的名字（即ip地址），第二个参数serverPort指明了服务器进程的端口。 3. sentence = input(“Input lowercase sentence:”)用户输入一个句子，并存储在 sentence 变量中。 4. clientSocket.send(sentence)clientSocket对象的send方法，将用户输入的句子放到TCP连接中去，交给TCP去发送。 5. modifiedSentence = clientSocket.recv(1024)当字符到达服务器时，就会被放在modifiedSentence这个字符串变量中，字符持续积累，直到遇到结束符。clientSocket对象的recv方法，把服务器发回来的字符串放入modifiedSentence中。 6. clientSocket.close()关闭Socket，关闭了客户端和服务器之间的TCP连接。 TCPServer.py 服务器123456789101112131415161718192021222324from socket import *serverPort = 12000# 初始化服务器SocketserverSocket = socket(AF_INET,SOCK_STREAM)# 绑定端口号serverSocket.bind((\"\",serverPort))# 服务器开始监听serverSocket.listen(1)print(\"The server is ready to receive\")# 一旦收到客户端的connect，立即接受（accept）并建立连接，成立特定服务于该客户端的 connectionSocketwhile True: connectionSocket, addr = serverSocket.accept() sentence = connectionSocket.recv(1024) capitalizedSentence = sentence.upper() # 服务器连接socket向客户端发送数据 connectionSocket.send(capitalizedSentence) # 关闭连接socket connectionSocket.close() 逐行解释: 1. serverSocket = socket(AF_INET,SOCK_STREAM)使用socket()初始化函数，创建了一个服务器Socket。也就是serverSocket，这是上文提到的欢迎Socket。 2. serverSocket.bind((“”,serverPort))bind方法绑定一个端口号。 3. serverSocket.listen(1)一切准备就绪，开始聆听某个客户端来敲门。参数1表示最大连接客户数量为1 4. connectionSocket, addr = serverSocket.accept()当有客户敲门时，服务器的欢迎Socket通过accept()函数创建了一个新的Socket（连接Socket），为这个特定的客户专用。客户端和服务器完成了握手，这时候，在客户端的clientSocket和服务器的serverSocket之间创建了一个TCP连接，这个TCP连接让客户端的clientSocket服务器的connectionSocket之间互传数据。 5. connectionSocket.close()传输完数据后，我们关闭的是connectionSocket，但serverSocket保持打开。所以另一个客户敲门时，服务器仍继续响应。 Python 实现 UDP Socket 的例子UDP是无连接的，不可靠的数据传送服务。当使用UDP时，必须先将目的地址和源地址附在分组上面。目的地址和源地址，都包括其IP地址和Socket应用程序的端口号。 需要注意的是，将源地址附在分组上这个动作是由底层操作系统来完成的，不用我们关心。 UDPClient.py 客户端123456789101112131415161718from socket import *serverName = 'hostname'serverPort = 12000# 初始化一个客户端SocketclientSocket = socket(AF_INET, SOCK_DGRAM)message = input('Input lowercase sentence:')# 客户端socket向服务器发送数据clientSocket.sendto(message,(serverName,serverPort))# 客户端socket接收来自服务器的数据modifiedMessage, serverAddress = clientSocket.recvfrom(2048)print(modifiedMessage)# 关闭客户端socketclientSocket.close() 逐行解释： 1. clientSocket = socket(AF_INET, SOCK_DGRAM)使用socket()初始化函数，创建了一个客户端Socket，第一个参数AF_INET指明底层网络使用的是IPv4，第二个参数SOCK_DGRAM指明该Socket是SOCK_DGRAM类型，也就是UDP。 clientSocket就是一个 Socket对象，它具有connect、send、recv等方法。 注意，创建客户端Socket时，并没有指定客户端的端口号，这件事由操作系统来做。 2. message = input(‘Input lowercase sentence:’)用户输入一个句子，并存储在 sentence 变量中。 3. clientSocket.sendto(message,(serverName,serverPort))clientSocket对象的sendto方法，将用户输入的句子放到UDP连接中去，交给UDP去发送。第一个参数是刚刚用户输入的内容，第二个参数指定了服务器的地址和端口号。 4. modifiedMessage, serverAddress = clientSocket.recvfrom(2048)当一个来自服务器的分组到达这个客户端Socket的时候，该分组的数据就会被放到modifiedMessage这个变量中，对方的源地址（包含IP和端口号）被放置到变量serverAddress中。事实上，在这个UDP的例子中，UDPClient并不需要服务器的地址信息，因为它一开始就已经知道了。但这行代码仍然提供了服务器的地址。 5. clientSocket.close()关闭Socket，关闭了客户端和服务器之间的UDP连接。 UDPServer.py 服务器123456789101112131415from socket import *serverPort = 12000# 初始化服务器socketserverSocket = socket(AF_INET, SOCK_DGRAM)# 绑定服务器端口serverSocket.bind(('', serverPort))print(\"The server is ready to receive\")# 接收来自客户端的消息，处理并发送while True: message, clientAddress = serverSocket.recvfrom(2048) modifiedMessage = message.upper() serverSocket.sendto(modifiedMessage, clientAddress) 逐行解释： 1. serverSocket = socket(AF_INET, SOCK_DGRAM)使用socket()初始化函数，创建了一个服务器Socket。 2. serverSocket.bind((‘’, serverPort))bind方法绑定一个端口号。 3. message, clientAddress = serverSocket.recvfrom(2048)当一个来自客户端的分组到达这个服务器Socket的时候，该分组的数据就会被放到message这个变量中，对方的源地址（包含IP和端口号）被放置到变量clientAddress中。使用该源地址信息，服务器就可知道接下来的应答要发往何处。 4. modifiedMessage = message.upper()把接收到的数据message，转化成大写，并存在modifiedMessage这个变量中。 5. serverSocket.sendto(modifiedMessage, clientAddress)erverSocket对象的sendto方法，将转换成大写的数据，放到UDP连接中去，交给UDP去发送。第一个参数是刚刚转换过的内容，第二个参数指定了客户端的地址和端口号。（客户端的地址和端口号在第3步就接收到了） Java 实现 TCP socket服务器1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253import java.io.*;import java.net.ServerSocket;import java.net.Socket;public class server { // 服务器端口 private static final int SERVER_PORT = 7767; public static void main(String[] args) throws IOException { boolean STOP = false; ServerSocket serverSocket = new ServerSocket(SERVER_PORT); System.out.println(\"服务已启动，监听端口：\" + SERVER_PORT); while (!STOP){ // accept方法是阻塞的 Socket connectSocket = serverSocket.accept(); try { System.out.println(\"远程计算机 \" + connectSocket.getRemoteSocketAddress() + \"已连接\"); // 从连接socket获取来自客户端的输入流 InputStream in = connectSocket.getInputStream(); // 将输入流封装到数据流中（方便后续操作字符串） DataInputStream dataIn = new DataInputStream(in); // 从数据流中读UTF String recv = dataIn.readUTF(); System.out.println(\"成功接收来自 \" + connectSocket.getRemoteSocketAddress() + \"的数据：\" + recv); String send = recv.toUpperCase(); // 封装输出流 OutputStream out = connectSocket.getOutputStream(); DataOutputStream dataOut = new DataOutputStream(out); // 发送 dataOut.writeUTF(send); System.out.println(\"向\" + connectSocket.getRemoteSocketAddress() + \"发送转换后的数据：\" + send); // 关闭资源 dataIn.close(); dataOut.close(); connectSocket.close(); } catch (IOException e) { e.printStackTrace(); } } }} 客户端1234567891011121314151617181920212223242526272829303132333435363738394041import java.io.*;import java.net.Socket;import java.util.Scanner;public class client { public static void main(String[] args) throws IOException { // 设定服务器地址 Scanner scanner = new Scanner(System.in); System.out.println(\"请输入服务器地址，如 192.168.1.1\"); String serverName = scanner.nextLine(); Socket client = new Socket(serverName, 7767); // 封装输出流 OutputStream out = client.getOutputStream(); DataOutputStream dataOut = new DataOutputStream(out); // 控制台获取输入 System.out.println(\"\\n请输入要发送的数据：\"); String send = scanner.next(); // 发送数据 dataOut.writeUTF(send); System.out.println(\"向服务器 \" + client.getRemoteSocketAddress() + \"发送了：\" + send); // 接收数据 InputStream in = client.getInputStream(); DataInputStream dataIn = new DataInputStream(in); String recv = dataIn.readUTF(); System.out.println(\"接收来自服务器的数据：\" + recv + '\\n'); // 关闭资源 dataIn.close(); dataOut.close(); client.close(); scanner.close(); }} Java 的 UDP socket ？ 下次再说吧。","link":"/post/78265215.html"},{"title":"TCP与UDP的区别","text":"TCP和UDP是OSI模型运输层中的协议。 TCP提供可靠的通信传输，而UDP则常被用于让广播和细节控制交给应用的通信传输。 UDP (User Datagram Protocol)UDP不提供复杂的控制机制，利用IP提供面向无连接的通信服务。并且它是将应用程序发来的数据在收到的那一刻，立刻按照原样发送到网络上的一种机制。 即使是出现网络拥堵的情况下，UDP也无法进行流量控制等避免网络拥塞的行为。 此外，传输途中如果出现了丢包，UDP也不负责重发。甚至当出现包的到达顺序乱掉时也没有纠正的功能。如果需要这些细节控制，那么不得不交给由采用UDP的应用程序去处理。 换句话说，UDP将部分控制转移到应用程序去处理，自己却只提供作为传输层协议的最基本功能。UDP有点类似于用户说什么听什么的机制，但是需要用户充分考虑好上层协议类型并制作相应的应用程序。 TCP(Transmission Control Protocol)TCP充分实现了数据传输时各种控制功能，可以进行丢包的重发控制，还可以对次序乱掉的分包进行顺序控制。而这些在UDP中都没有。 此外，TCP作为一种面向有连接的协议，只有在确认通信对端存在时才会发送数据，从而可以控制通信流量的浪费。TCP通过检验和、序列号、确认应答、重发控制、连接管理以及窗口控制等机制实现可靠性传输。 TCP与UDP如何加以区分使用？TCP用于在传输层有必要实现可靠性传输的情况。由于它是面向有连接并具备顺序控制、重发控制等机制的。所以它可以为应用提供可靠传输。 另一方面，UDP主要用于那些对高速传输和实时性有较高要求的通信或广播通信。 举一个IP电话进行通话的例子。如果使用TCP，数据在传送途中如果丢失会被重发，但是这样无法流畅地传输通话人的声音，会导致无法进行正常交流。而采用UDP，它不会进行重发处理。从而也就不会有声音大幅度延迟到达的问题。即使有部分数据丢失，也只是影响某一小部分的通话。 此外，在多播与广播通信中也使用UDP而不是TCP。RIP、DHCP等基于广播的协议也要依赖于UDP。 TCP与UDP区别总结 TCP面向连接（如打电话要先拨号建立连接);UDP是无连接的，即发送数据之前不需要建立连接 TCP提供可靠的服务。也就是说，通过TCP连接传送的数据，无差错，不丢失，不重复，且按序到达;UDP尽最大努力交付，即不保证可靠交付 TCP面向字节流，实际上是TCP把数据看成一连串无结构的字节流;UDP则是面向报文的。UDP没有拥塞控制，因此网络出现拥塞不会使源主机的发送速率降低（对实时应用很有用，如IP电话，实时视频会议等），并且UDP速度更快。 每一条TCP连接只能是点到点的;UDP支持一对一，一对多，多对一和多对多的交互通信 TCP首部开销20字节;UDP的首部开销小，只有8个字节 TCP的逻辑通信信道是全双工的可靠信道，UDP则是不可靠信道 TCP UDP 面向连接 无连接 提供可靠的服务。 尽最大努力，不保证可靠交付 面向字节流 面向报文 只能点到点 支持一对一，一对多，多对一和多对多 首部开销 20 字节 首部开销 8 个字节 可靠逻辑通信信道（全双工） 不可靠逻辑通信信道","link":"/post/4399c62c.html"},{"title":"计算机网络——网络层探究","text":"好久没写博客了。感觉最近有点懒了。重新拾起《计算机网络——自顶向下方法》看看，这一篇聊聊网络层。 简述网络层的作用即是将分组从一台主机移动到另一台主机。转发 和 路由选择 共同完成这项工作。 除此之外还有连接建立(connection setup)的功能。 转发（forwarding）转发指的是分组在单一的路由器从一条入链路到出链路的传送。 路由选择（routing）路由选择涉及一个网络中的所有路由器，它们经由选择协议共同交互，以决定分组从源到目的地所采用的路径。计算这些路径采用了 路由选择算法（routing algorithm）。 分组交换机分组交换机（packet switch）是一个通用概念，指的是能根据分组首部字段的值，从输入链路接口 转移分组 到输出链路接口的交换设备。 分组交换机包括两种： 在数据链路层，基于链路层字段中的值做转发决定的称为 链路层交换机(link-layer switches) 在网络层，基于网络层字段中的值做转发决定的称为 路由器(router)。 虚电路和数据报网络类似于运输层能够提供面向连接的服务（TCP）或者无连接的服务（UDP），网络层也能提供连接服务或无连接服务。 网络层中的连接服务，称为 虚电路(Virtual-Circuit, VC)；无连接服务，称为 数据报(datagram)。 值得注意的是，网络层并不同时提供这两种服务，在一个计算机网络中，仅提供其一。我们所熟悉的 Internet， 属于数据报网络， 但在一些其他的网络体系结构（ATM、帧中继等）属于虚电路网络。 此外，跟运输层在端系统与端系统间实现TCP连接不同，网络层的连接服务除了在端系统之间，也存在于网络核心的路由器。 虚电路网络一条虚电路的组成如下： 源和目的主机之间的路径（一系列链路和路由器） 沿着该路径的每段链路的号码（称为VC号） 沿着该路径的每台路由器中的转发表表项 虚电路的三个阶段： 虚电路建立：发送运输层指定接收方地址，网络层决定发送方与接受方的路径，并为每条链路决定一个VC号，最后为该路径的每台路由器增加一个表项。 数据传送 虚电路拆除 数据报网络当一个端系统要发送分组时，就会为该分组加上目的地址，然后将分组推进网络。网络中的每一台路由器，都根据转发表，为目的地址查找适当的输出链路，然后对这个分组进行转发。 路由器会将目的地址的前缀与转发表表项进行匹配，当有多个匹配项时，采用 最长前缀匹配规则 来最终选择。 未完待续","link":"/post/69f0eb47.html"},{"title":"计算机网络——传输层探究","text":"前言我们知道，在 TCP/IP 五层协议模型中，最上层是应用层，也就是我们的应用程序（例如我们的浏览器，通过应用层http协议收发数据），之后数据通过传输层下发到网络世界（网络层）当中去。而像网络层的设备和协议，例如路由器和IP协议，数据交付是不可靠的，会存在丢包。而本篇的主角——运输层，解决的正是这样一个问题：两个实体怎样才能在一种会丢失或损坏数据的媒体上可靠地通信。 首先，有几个概念要理清一下： 传输层的协议是一种逻辑协议。想象一下，两台计算机的应用程序通过网路连接，就好像直接相连一样。这是一种逻辑连接，物理上，其背后可能连接了成千上万的路由器和交换机。实际上，网络层也是逻辑通信，只不过网络层是不同的主机与主机的逻辑通信，而传输层是不同主机上的进程与进程之间的逻辑通信。 传输层协议是在端系统（计算机、主机）中实现，而不是路由器。 传输层将应用程序的报文（message）分组，每个分组就是一个报文段（segment），然后交付到网络层。 传输层协议概览总的来说，网络层的目标是将一台主机的数据交付到另一台主机，而传输层的目标是，将到达一台主机（可以理解为网卡）的数据，分发给目标的应用程序，以及将应用程序的数据，打包发到主机（网卡）。 多路复用和多路分解传输层协议最基本的责任是，将两个端系统间IP的交付服务扩展为运行在端系统上的两个进程之间的交付服务。这种将主机间的交付扩展为进程间的交付，称为 多路复用 和 多路分解。 用大白话来讲就是，多路复用相当于把一台主机多个进程多个端口号的数据，统一加工和收集，生成报文段，交付给网络层。多路分解则是把网络层到达主机的数据，根据发送时标记的信息，分发到各个进程各个端口。 那么，网路向进程传递数据，以及进程向网络传输数据，这件事是谁来干的呢？ 答案就是我们既熟悉又陌生的 socket 套接字。 如何实现多路复用和多路分解 socket 有唯一标识符（毕竟 Unix 的哲学，万物皆文件） 报文段有特殊字段来指示要交付到哪个套接字 于是我们就引申出了 端口号 这个概念了。端口号用来识别是哪一个网络应用程序（socket）。因为传输层既需要 A 到 B，也需要 B 到 A，所以需要有 源端口号 和 目标端口号。端口号是一个 16 bits 的数字，取值在 0-65535 之间。 面向连接和无连接的传输层协议传输层有两种著名协议，分别是 UDP 和 TCP 。 UDP 是不可靠的，无连接的，只要做完了自己该做的事情就好了。而 TCP 是可靠的，面向连接的，必须准确无误。 因为 UDP 是无连接的，只需要一个 目的IP 和一个 目的端口 号就可以识别一个 UDP socket。所以，如果两个UDP报文有相同的目的IP和目的端口，但具有不同的源IP或端口，那么这两个报文段将通过相同的目的 socket 到达目的进程。 而 TCP 是面向连接的，需要 源IP、源端口、目的IP、目的端口 四个组合来唯一确定一个 TCP socket。任意一个不一样，都不会是同一个 socket。 设计可靠的数据传输协议如果让我们来设计一个可靠的数据传输协议，我们会怎样设计呢？无非是两点： 数据比特不会损坏或丢失 所有数据都是按照发送顺序进行交付，不会错乱 那么如何保证数据比特不会损坏（例如发送1却收到0）呢？想象我们打电话，当我们讲了几句话，对方会用 “嗯”、“OK” 等回复来表示对方收到了，或者用 “没听清”，“请再说一遍” 来表示没收到。 这正是一种 肯定确认 和 否定确认 的机制。可以用来解决这个问题。使用这种机制的可靠数据传输协议，称为 自动重传请求协议。它需要有 3 个功能： 差错检测（checksum） 接收方反馈 重传（检测到差错或对方太久没反馈，就重传） 有了重传机制，我怎么知道哪些数据是重复的呢？（例如第一次发因为网络阻塞迟迟没到，触发了重传，第二次发的收到后，第一次发的同一份数据终于姗姗来迟），且由于网络层是不可靠的，来自对方的肯定确认或否定确认也可能丢失。再次，先发的数据可能后到，要怎么样保证数据的顺序性？解决这个问题的方法其实很简单，给每个数据块分组加上 序号 就行了。这样我就能知道哪些数据丢了需要重传，哪些数据需要放在哪个顺序位置上。","link":"/post/cda53c5c.html"},{"title":"TCP之旅","text":"前言前面两篇介绍 Socket 的文章中，简单描述了 Socket 网络编程的过程。这一篇，主要介绍一下 TCP 的工作原理。包含以下六点： TCP连接简介 TCP报文段 连接的建立和断开（三次握手，四次挥手） TCP可靠在哪里（序号、ACK回复、超时重传） 滑窗机制 拥塞控制机制 一、TCP连接简介TCP 全称 Transmission Control Protocol，传输控制协议，是传输层的协议。它的任务是将应用层的数据准确地交付给网络层。 两个应用程序，如果用TCP来发送数据，那么他们必须先互相“握手”。也就是说，在正式传数据之前，要先互相发送一些预备报文段，以建立确保数据传输的参数。所以我们说，TCP是面向连接的(connection-oriented)，也是可靠的传输。 虽然TCP是面向连接的，但是这种“连接”，不是端到端线路意义上的连接，也不是虚电路。TCP的连接，是保留在两个端系统的状态当中的。因此，中间路由器对TCP连接是视而不见的。 TCP提供的是全双工服务，数据可以从A到B，也能从B到A。同时，TCP是点对点的，TCP连接是单个发送方与单个接收方之间的连接，不能多播。（但这并不代表一个服务器不能与多个客户端建立连接，只是说，一个连接只能在两台主机之间，如果一台主机要接收另外两台主机的数据，需要为那两台主机分别建立TCP连接） TCP是怎样建立连接的（三次握手）？ 首先，客户端先发送一个特殊的TCP报文段 服务器返回另一个特殊的报文段响应 客户端用第三个特殊报文段作为响应 前两个报文段，不承载“有效载荷”（不包含应用层的数据），仅仅是打招呼。后一个报文段，可以承载有效载荷。由于在这两台主机之间发送了 3 个报文段，所以这种连接建立的过程，我们称之为“三次握手”，稍后我们详细讨论。 二、TCP报文段TCP将应用程序的报文（message）分组，再为每个分组加上TCP首部，形成多个TCP报文段（TCP segment），再下传给网络层。报文段的首部如下图： 首部包含了以下信息： 源端口号（source port） 和 目的端口号(destination port)：各16位，因为16位最大能表示的数字是65535，所以端口号最大值也只能是65535。 序号字段(sequence number field)：32位，用来实现可靠数据传输，例如一个500000字节的文件被分为500个TCP报文段，初始序号可以随意指定，后续的序号是前面序号+携带的字节数，例如初始序号79，每个报文段携带1000字节，第二个序号就是1079 确认号字段(Acknowledgement number field)：32位，也是用来实现可靠数据传输，表示期望对方发送的下一字节的序号 接收窗口字段(receive windows field)：16位，用于流量控制，表示接收方愿意接受的字节数量 首部长度字段(header length field)：4位，TCP的首部长度是可变的，这个字段表示首部长度 选项字段(options field)：不定位数，用作窗口调节因子 标志字段(flag field)，6位，包括ACK、RST、SYN、FIN、PSH、URG，各占1位 我们主要关注三个点： 一个TCP头部需要包含出发端口和目的地端口。这些与IP头中的两个IP地址共同确定了连接。 每个TCP片段都有序号。这些序号最终将数据部分的文本片段整理成为文本流。 只有标志字段的ACK位设定的时候，确认号字段才有效。ACK确认号说明了接收方期待接收的下一个片段，所以ACK确认号为最后接收到的片段序号加1。 三、TCP连接的建立和断开三次握手前面提到，TCP建立连接的过程称为三次握手。其详细过程如下： 第一步：客户端先发送一个特殊的TCP报文段，不包含应用层数据。但首部标志字段的SYN位被置为1（称为SYN报文段），并随机指定一个初始序号（seq）。（为什么初始序号要随机，主要是安全方面考虑）。 第二步：服务器收到客户端的SYN报文段后，就会为该TCP连接分配TCP缓存和变量，并回复一个报文段（称为SYNACK报文段）。在这个回复报文段里，SYN位也是被置为1，确认号ack置为客户端刚刚发来的初始序号seq+1，并随机指定一个自己的初始序号seq。 第三步：客户端收到服务器的SYNACK报文段后，在客户端为该TCP连接分配缓存和变量，同时也回复了一个报文段，此时连接已经建立，所以SYN置为0，ACK确认号为服务器的初始序号seq+1，seq为自己第一步的seq+1 四次挥手当TCP连接的任意一方想断开连接时，将会发起断开信号，连接结束后，主机里的TCP连接资源（缓存和变量）随即被释放。断开的过程需要通信四次，所以称为四次挥手。其详细过程如下： 第一步：客户端发起关闭连接命令。此时会向服务器发送一个特殊的报文段，标志字段的FIN位被置为1。 第二步：服务器收到这个特殊的报文段后，回复一个确认报文段。 第三步：稍后，服务器也向客户端发起一个FIN位为1的特殊报文段，表示可以终止。 第四步：客户端回复一个确认报文段进行确认，之后连接断开。 四、TCP 为何可靠“流”和次序我们之前提到，Linux的哲学是“一切皆文件”，一切都可以用“打开open –&gt; 读写write/read –&gt; 关闭close”的模式来操作。计算机程序之间的通信，是一个进程写入文本流(byte stream)，而另一个进程读取这个流。TCP协议虚拟了文本流的通信。 要知道，在两台相隔很远的主机中，隔着许许多多的路由器和交换机，因此数据发送的时候，先发的数据可能会后到。好在TCP协议确保了数据到达的顺序与文本流顺序相符。这就是为什么TCP报文段里面需要有序号的原因。TCP接收方将接收到的许许多多报文段按照序号排列起来，组成原始数据。 “收到请回复”TCP为什么需要确认号呢？我们知道，TCP是全双工的协议，在A主机向B主机发送数据的同时，B主机也能向A主机发送数据（在同一个TCP连接中）。例如，A向B发送8字节数据时携带了序号，seq=79，B向A发数据时也需要携带一个序号seq=45，同时，“回复”确认收到了A主机seq=79的序号，并期望接收A主机seq=87（为什么不是80，因为前一个序号有8字节）的序号，所以就有了确认号ack=87。 也就是说，TCP发送方每发送一个报文段，接收方都会回复一个确认号。以确保这个片段收到了。比如已经接收到了片段1，片段2，片段3，那么接收方就开始期待片段4。值得注意的是，如果此时收到了片段5 片段6，也不会丢弃，会暂时存起来，等到片段4到达再拼接，但是如果此时收到了片段9，那么接收方就可能拒绝接收了。 报文段丢了，重发IP协议是不可靠的，也就是说，交付给网络层的报文段，可能会传着传着就丢了。那咋办？ TCP有一个定时器超时，规定如果一段时间之后，还没有收到接收方的确认（ACK），就默认这个报文段丢了。就会重新发一个过去，直到接收方回复确认收到。 那么，如果说，这个报文段发过去了，接收方也接收到了。接收方返回给发送方的“确认”信息丢了，怎么办呢？ 这种情况下，发送方依然会重发。 接收方一看，咦你居然发了两个一样的报文段？就会自动丢弃其中的一个了，当然，还要给发送方再发一次“收到”回复，以免发送方孜孜不倦、不辞劳苦地一直重发、一直重发。 五、滑窗我们已经知道，TCP发送方片段1发出去，接收方回复ACK已收到1，发送方再发片段2，接收方再回复ACK已收到2…… 在这种模式下，发送方保持发送-&gt;等待ACK-&gt;发送-&gt;等待ACK…的状态，虽然很“可靠”，但是效率太慢了。为了提高效率，同时发多个片段，又怕后发的先到了，怎么办呢？ 我们可以这么做：利用缓存保留一些“不那么乱”的片段，期望能在短时间内补充上之前的片段(暂不处理，但发送相应的ACK)；对于“乱”的比较厉害的片段，则将它们拒绝(不处理，也不发送对应的ACK)。 滑窗(sliding window)被同时应用于接收方和发送方，以解决以上问题。发送方和接收方各有一个滑窗。当片段位于滑窗中时，表示TCP正在处理该片段。滑窗中可以有多个片段，也就是可以同时处理多个片段。滑窗越大，越大的滑窗同时处理的片段数目越多(当然，计算机也必须分配出更多的缓存供滑窗使用)。 TCP有专门的算法动态调整滑窗的大小。 六、TCP拥塞控制在TCP协议中，我们使用连接记录TCP两端的状态，使用序号和分段保证了TCP传输的有序，使用滑窗（中的某些机制）来实现发送方和接收方处理能力的匹配，并使用重复发送来实现TCP传输的可靠性。 一切看似都很美好，但是，随着互联网的发展，越来越多的主机之间要相互发送数据，有时候中间路由器会处理不过来从而发生丢包，一丢包，这些基于TCP的主机就又重新发送，路由器不堪重负，就会发生更严重的丢包，构成了一个恶性循环。这称为堵塞崩溃。 因此，为了避免发送堵塞崩溃，TCP加入了拥塞控制机制。当TCP发送方探测到网络拥堵时，会控制自己发送片段的速率，以缓解网络的交通状况。 如何探测网络拥堵当发生ACK超时和重复ACK。发送方就认为TCP片段丢失，则认为网络中出现堵塞。 如何控制速率TCP协议通过控制滑窗(sliding window)大小来控制发送速率。在TCP滑窗管理中，有一个窗口限制，就是advertised window size，以实现TCP流量控制。TCP还会维护一个congestion window size，以根据网络状况来调整滑窗大小。真实滑窗大小取这两个滑窗限制的最小值，从而同时满足两个限制 (流量控制和堵塞控制)。 （TCP拥塞控制和滑窗的内容来自vamei的博客，vamei写得太好了，值得好好学习）","link":"/post/e997edc6.html"},{"title":"浅谈 socket 编程","text":"计算机通信和socket计算机程序之间的通信，是进程与进程之间的通信。之前在 Linux 学习中就遇到用管道（PIPE）来让一个进程的输出和另一个进程的输入连接起来，从而利用文件操作API来管理进程间通信。 Unix/Linux的基本哲学之一就是“一切皆文件”，一切都可以用打开(open) –&gt; 读写(read/write) –&gt; 关闭(close)的模式来操作。socket可以看成一个进程向socket的一端写入或读取文本流，而另一个进程可以从另一端读取或写入。比较特别的是，这两个建立socket通信的进程可以分别属于两台不同的计算机，可以简单地把socket理解为一种特殊的文件，我们通过操作socket函数，实现文本流在多台计算机之间传输，同时也就实现了计算机之间的通信。 一个socket包含四个地址信息: 两台计算机的IP地址和两个进程所使用的端口(port)。IP地址用于定位计算机，而端口用于定位进程 (一台计算机上可以有多个进程分别使用不同的端口)。 TCP和UDP在开始 socket 编程之前，有必要简单了解一下TCP和UDP协议。 TCP（传输控制协议）提供面向连接、可靠的字节流服务。客户端和服务器彼此交换数据前，必须先在双方之间建立一个TCP连接，之后才能传输数据。TCP提供超时重发，丢弃重复数据，检验数据，流量控制等功能，从而保证数据能从一端传到另一端。 UDP（用户数据报协议）是一个简单的面向数据报的运输层协议。UDP不提供可靠性，它只是把应用程序传给IP层的数据报发送出去，但是并不能保证它们能到达目的地。由于UDP在传输数据报前不需在客户端和服务器之间建立一个连接，且没有超时重发等机制，故而传输速度很快。 socket函数1. socket()socket()可以理解成初始化： 1int socket(int domain, int type, int protocol); 参数 内容 释义 举例 1 domain 协议族（family） 常用的 domain 有 AF_INET（ipv4网络通信）、AF_INET6（ipv6网络通信）、AF_LOCAL（或称AF_UNIX，本地通信，将绝对路径名作为地址）等 2 type socket类型 常用的 socket type 有 SOCK_STREAM（字节流）、SOCK_DGRAM（数据报）、SOCK_RAW（原始）、SOCK_PACKET（分组）、SOCK_SEQPACKET（有序分组）等 3 protocol 指定协议 常用的协议有，IPPROTO_TCP（TCP传输协议）、IPPTOTO_UDP（UDP传输协议）、IPPROTO_SCTP、IPPROTO_TIPC等 type 和 protocol 并不是可以随意组合，比如使用SOCK_STREAM（这是TCP相关类型）的时候就不能用IPPROTO_UDP（UDP相关类型）。 2. bind()bind()函数赋予socket以固定的地址和端口，例如AF_INET就是把一个 ipv4地址和端口号组合 赋给socket。 1int bind(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数 内容 描述 1 sockfd socket文件描述符 2 addr 指向要绑定给sockfd的协议地址的指针，这个地址结构根据地址创建socket时的地址协议族的不同而不同 3 addrlen 地址的长度 ipv4地址结构的具体实现 12345678910struct sockaddr_in { sa_family_t sin_family; // address family: AF_INET in_port_t sin_port; // port in network byte order struct in_addr sin_addr; // internet address};// Internet address.struct in_addr { uint32_t s_addr; // address in network byte order}; 创建socket时的地址协议族, 如果不是 AF_INET（ipv4），那么上面这个结构体的内容也是不一样的。第二个参数的指针就是指向你创建socket时对应协议族的协议地址。 3. listen()、connect()listen()用于服务器监听，connect()用于客户端连接。 1int listen(int sockfd, int backlog); 参数 内容 描述 1 sockfd 要监听的socket描述字 2 backlog 最大连接个数 1int connect(int sockfd, const struct sockaddr *addr, socklen_t addrlen); 参数 内容 描述 1 sockfd 客户端的socket描述字 2 addr 指针指向服务器的socket地址 3 addrlen socket地址的长度 4. accept()TCP服务器端依次调用socket()、bind()、listen()之后，就会开始监听指定的socket地址。 TCP客户端依次调用socket()、connect()之后就向TCP服务器发送了一个连接请求。 TCP服务器监听到这个请求之后，就会调用accept()函数取接收这个请求，这样连接就建立好了。 之后就可以开始网络I/O操作，类同于普通文件的读写I/O操作。 1int accept(int sockfd, struct sockaddr *addr, socklen_t *addrlen); 参数 内容 描述 1 sockfd 服务器的socket描述字 2 addr 指向struct sockaddr *的指针，用于返回客户端的协议地址 3 addrlen 协议地址的长度 accept()的第一个参数为服务器的socket描述字，是服务器开始调用socket()函数生成的，称为监听socket描述字；而accept()返回的是已连接的socket描述字。 5. recvmsg() 、sendmsg()经过上面的几个步骤，服务器与客户端已经建立好连接了。现在就可以开始调用网络I/O进行读写操作。 网络I/O操作有下面几组： read() / write() recv() / send() readv() / writev() recvmsg() / sendmsg() recvfrom() / sendto() 它们的声明如下： 123456789101112131415161718#include &lt;unistd.h&gt; ssize_t read(int fd, void *buf, size_t count); ssize_t write(int fd, const void *buf, size_t count); #include &lt;sys/types.h&gt; #include &lt;sys/socket.h&gt; ssize_t send(int sockfd, const void *buf, size_t len, int flags); ssize_t recv(int sockfd, void *buf, size_t len, int flags); ssize_t sendto(int sockfd, const void *buf, size_t len, int flags, const struct sockaddr *dest_addr, socklen_t addrlen); ssize_t recvfrom(int sockfd, void *buf, size_t len, int flags, struct sockaddr *src_addr, socklen_t *addrlen); ssize_t sendmsg(int sockfd, const struct msghdr *msg, int flags); ssize_t recvmsg(int sockfd, struct msghdr *msg, int flags); 具体用法可参见man文档 6. close()在服务器与客户端建立连接之后，会进行一些读写操作，完成读写操作之后要关闭相应的socket描述字。 1int close(int fd); 一个客户端与服务器通信的例子（C语言）服务器端1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889#include &lt;sys/types.h&gt;#include &lt;sys/socket.h&gt;#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#include &lt;unistd.h&gt;#include &lt;netinet/in.h&gt;#define SERVPORT 14001#define BACKLOG 10#define MAX_CONNECTED_NO 10#define MAXDATASIZE 50int main(){ // 声明服务器和客户端的socket结构体 struct sockaddr_in server_sockaddr,client_sockaddr; // 声明数据大小 int sin_size,recvbytes; // 声明socket文件描述符 int sockfd,client_fd; // 当前时间 time_t currentTime; char timebuffer[MAXDATASIZE+1]; // 缓存 char buf[MAXDATASIZE]; // 初始化socket if((sockfd = socket(AF_INET,SOCK_STREAM,0))==-1){ perror(\"socket\"); exit(1); } printf(\"socket success!,sockfd=%d\\n\",sockfd); // 声明协议 server_sockaddr.sin_family=AF_INET; server_sockaddr.sin_port=htons(SERVPORT); server_sockaddr.sin_addr.s_addr=INADDR_ANY; bzero(&amp;(server_sockaddr.sin_zero),8); // 绑定 if(bind(sockfd,(struct sockaddr *)&amp;server_sockaddr,sizeof(struct sockaddr))==-1){ perror(\"bind\"); exit(1); } printf(\"bind success!\\n\"); // 监听 if(listen(sockfd,BACKLOG)==-1){ perror(\"listen\"); exit(1); } printf(\"listening....\\n\"); sin_size = sizeof(struct sockaddr); // 接收 if((client_fd=accept(sockfd,(struct sockaddr *)&amp;client_sockaddr,&amp;sin_size))==-1){ perror(\"accept\"); exit(1); } currentTime = time(NULL); snprintf(timebuffer, MAXDATASIZE, \"%s\\n\", ctime(&amp;currentTime)); // 向socket客户端写数据 if ((recvbytes =write(client_fd, timebuffer, strlen(timebuffer))) &lt;0 ) { perror(\"write\"); exit(1); } while (1) { if((recvbytes=recv(client_fd,buf,MAXDATASIZE,0))==-1){ perror(\"recv\"); exit(1); } buf[recvbytes] = '\\0'; printf(\"received msg from clients :%s\\n\",buf); currentTime = time(NULL); snprintf(timebuffer, MAXDATASIZE, \"%s\\n\", ctime(&amp;currentTime)); write(client_fd, timebuffer, strlen(timebuffer)); } // 关闭socket close(sockfd);} 客户端123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;#include &lt;netdb.h&gt;#include &lt;sys/types.h&gt;#include &lt;netinet/in.h&gt;#include &lt;sys/socket.h&gt;#define SERVPORT 14001#define MAXDATASIZE 300main(int argc,char *argv[]){ int sockfd,sendbytes; char buf[MAXDATASIZE]; struct hostent * host; struct sockaddr_in serv_addr; if(argc &lt; 2){ fprintf(stderr,\"Please enter the server's hostname!\\n\"); exit(1); } if((host=gethostbyname(argv[1]))==NULL){ perror(\"gethostbyname\"); exit(1); } if((sockfd=socket(AF_INET,SOCK_STREAM,0))==-1){ perror(\"socket\"); exit(1); } serv_addr.sin_family=AF_INET; serv_addr.sin_port=htons(SERVPORT); serv_addr.sin_addr=* ((struct in_addr * )host-&gt;h_addr); bzero(&amp;(serv_addr.sin_zero),8); // 连接 if(connect(sockfd,(struct sockaddr *)&amp;serv_addr,\\ sizeof(struct sockaddr))==-1){ perror(\"connect\"); exit(1); } // 接收数据 if((sendbytes=recv(sockfd,buf,MAXDATASIZE,0))==-1){ perror(\"recv\"); exit(1); } buf[sendbytes] = '\\0'; printf(\"received msg from server:%s\\n\",buf); while (1) { printf(\"Enter the message : \"); if(fgets(buf, sizeof(buf) - 1, stdin) == NULL) { break; } if((sendbytes=send(sockfd,buf,strlen(buf),0))==-1){ perror(\"send\"); exit(1); } printf(\"sent %d bytes \\n\", sendbytes); if((sendbytes=recv(sockfd,buf,MAXDATASIZE,0))==-1){ perror(\"recv\"); exit(1); } buf[sendbytes] = '\\0'; printf(\"received time from server:%s\\n\",buf); } // 关闭socket close(sockfd);} 参考链接 Linux Socket编程 Python应用01 原始Python服务器 Linux进程间通信","link":"/post/bfa70c14.html"},{"title":"当你输入一个网址的时候，实际会发生什么?","text":"前言一个 web 应用是如何运行的？作为软件开发者，我们必须得有一个完整的层次化的认知。这一篇将从浏览器，到 HTTP，HTML，web server，request handles 等方面切入，聊聊当我们输入一个网址的时候，后台到底发生了什么。 本文转载自：韩星的博客，对翻译进行了调整。 英文原文：what-really-happens-when-you-navigate-to-a-url 1. 输入网址一切从你在浏览器输入一个网址开始 2. DNS查找 浏览器所做的第一步是通过访问的域名找出对应的IP地址。这一步叫DNS查找。 DNS查找过程 浏览器缓存：浏览器会缓存DNS记录一段时间。操作系统没有规定浏览器要存储DNS记录多长时间，所以不同浏览器储存各自的缓存时长也不尽相同（一般2分钟到30分钟不等）。 系统缓存：如果在浏览器缓存里没有找到需要的记录，浏览器会做一个系统调用（windows里是gethostbyname）。这样便可获得操作系统中的DNS缓存。 路由器缓存：如果系统缓存也没有，查询请求会继续发向路由器，路由器一般会有自己的DNS缓存。 ISP缓存：接下来要查找的就是ISP缓存DNS的服务器。在这里一般都能找到相应的缓存记录。 递归搜索：你的ISP的DNS服务器从根域名服务器开始进行递归搜索，从.com顶级域名服务器到Facebook的域名服务器。一般DNS服务器的缓存中会有.com域名服务器中的域名，所以到顶级服务器的匹配过程不是那么必要了。 ISP，因特网服务提供商（Internet Service Provider）ISP有很多，比如住宅区ISP，公司ISP，大学ISP，这些低层的ISP，通过区域的ISP（比如市级、省级ISP）互联，区域ISP又由国家或国际的高层ISP互联起来。形成了一个网络的网络。 DNS递归查找如下图所示： 解决多个ip对应一个域名的问题像 wikipedia.org 或者 facebook.com 这样的域名，看上去好像只能对应一个单独的IP地址。但往往一个域名可能要对应好几个ip地址，有几种解决办法： 循环 DNS (Round-robin DNS)： DNS 查找时返回多个IP的解决方案。举例来说，Facebook.com实际上对应了四个IP地址。 负载均衡 (Load-balancer)：是一个能够监听特定IP地址并将网络请求转发到其他服务器上的硬件设备。 一些大型的站点一般都会使用这种昂贵的高性能负载均衡器。 地理 DNS(Geographic DNS)：根据用户所处的地理位置，通过把域名映射到多个不同的IP地址提高可扩展性。这样不同的服务器不能够更新同步状态，但映射静态内容的话非常好。 Anycast：是一个将IP地址映射多个物理服务器上的路由技术。 美中不足的是，Anycast与TCP协议并不是很兼容，所以很少应用在一些方案中。大多数DNS服务器使用Anycast来获得高效低延迟的DNS查找。 3.发送HTTP请求 像Facebook主页这样的动态页面，打开后浏览器缓存很快甚至马上就会过期。毫无疑问动态页面不能从浏览器缓存中读取。 所以，浏览器把以下请求发送到Facebook所在的服务器： 1234567GET http://facebook.com/ HTTP/1.1 Accept: application/x-ms-application, image/jpeg, application/xaml+xml, [...] User-Agent: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; [...] Accept-Encoding: gzip, deflate Connection: Keep-Alive Host: facebook.com Cookie: datr=1265876274-[...]; locale=en_US; lsd=WW[...]; c_user=2101[...] GET 这个请求定义了要读取的URL： “ http://facebook.com/ ” 。浏览器自身定义 (User-Agent header)，并且声明浏览器能够接受什么类型的相应 (Accept and Accept-Encoding 头). Connection头要求服务器为了后边的请求不要关闭TCP连接。 请求中也包含浏览器存储的该域名的cookies。在不同页面请求当中，cookies是与跟踪一个网站状态相匹配的键值。cookies会存储登录用户名，服务器分配的密码和一些用户设置等。并以文本文档形式存储在客户机里，每次请求时发送给服务器。 如何查看 HTTP 请求？用来看原始HTTP请求及其相应的工具很多。作者比较喜欢使用fiddler，当然也有像FireBug这样其他的工具。这些软件在网站优化时会帮上很大忙。 POST 请求除了 GET 请求，还有一种是 POST 请求，它常在提交表单用到。GET 请求通过 URL传递其参数(e.g.: http://robozzle.com/puzzle.aspx?id=85 )。POST 请求在请求正文头之后发送其参数。 末尾斜杠像 http://facebook.com/ 中的斜杠是至关重要的。这种情况下，浏览器能安全的添加斜杠。而像 http://example.com/folderOrFile 这样的地址，因为浏览器不清楚folderOrFile到底是目录还是文件，所以不能自动添加斜杠。这时，浏览器就不加斜杠直接访问地址，服务器会响应一个重定向，结果造成一次不必要的握手。 4.重定向响应 图中所示为Facebook服务器发回给浏览器的响应： 12345678910111213HTTP/1.1 301 Moved Permanently Cache-Control: private, no-store, no-cache, must-revalidate, post-check=0, pre-check=0 Expires: Sat, 01 Jan 2000 00:00:00 GMT Location: http://www.facebook.com/ P3P: CP=&quot;DSP LAW&quot; Pragma: no-cache Set-Cookie: made_write_conn=deleted; expires=Thu, 12-Feb-2009 05:09:50 GMT; path=/; domain=.facebook.com; httponly Content-Type: text/html; charset=utf-8 X-Cnection: close Date: Fri, 12 Feb 2010 05:09:51 GMT Content-Length: 0 服务器给浏览器响应一个301永久重定向响应，这样浏览器就会访问“ http://www.facebook.com/ ” 而非“ http://facebook.com/ ”。 为什么要重定向？为什么服务器一定要重定向而不是直接发会用户想看的网页内容呢？这个问题有好多有意思的答案。其中一个原因跟搜索引擎排名有关。如果一个页面有两个地址，就像 http://www.igoro.com/ 和 http://igoro.com/ ,搜索引擎会认为它们是两个网站，结果造成每一个的搜索链接都减少从而降低排名。而搜索引擎知道301永久重定向是什么意思，这样就会把访问带www的和不带www的地址归到同一个网站排名下。还有一个原因是用不同的地址会造成缓存友好性变差。当一个页面有好几个名字时，它可能会在缓存里出现好几次。 5.浏览器跟踪重定向地址 现在，浏览器知道了 “ http://www.facebook.com/ ” 才是要访问的正确地址，所以它会发送另一个获取请求： 12345678GET http://www.facebook.com/ HTTP/1.1 Accept: application/x-ms-application, image/jpeg, application/xaml+xml, [...] Accept-Language: en-US User-Agent: Mozilla/4.0 (compatible; MSIE 8.0; Windows NT 6.1; WOW64; [...] Accept-Encoding: gzip, deflate Connection: Keep-Alive Cookie: lsd=XW[...]; c_user=21[...]; x-referer=[...] Host: www.facebook.com 头信息以之前请求中的意义相同。 6.服务器“处理”请求 服务器接收到获取请求，然后处理并返回一个响应。这表面上看起来是一个简单的任务，但其实这中间发生了很多有意思的事情。 6.1应用服务器web服务器软件（如apache、tomcat）接收到HTTP请求，然后确定执行什么请求处理来处理它。请求处理就是一个能够读懂请求并且能生成HTML来进行响应的程序（像ASP.NET,PHP,RUBY…）。 举个最简单的例子，需求处理可以以映射网站地址结构的文件层次存储。像 http://example.com/folder1/page1.aspx 这个地 址会映射 /httpdocs/folder1/page1.aspx 这个文件。web服务器软件可以设置成为地址人工的对应请求处理，这样 page1.aspx 的发布地址就可以是 http://example.com/folder1/page1 6.2 请求处理请求处理读取请求内容以及参数、cookies等信息。它会读取也可能更新一些数据，并将数据存储在服务器上。然后，需求处理会生成一个HTML响应。 如何存储数据所有动态网站都面临一个有意思的难点——如何存储数据。小网站一半都会有一个SQL数据库来存储数据，存储大量数据和/或访问量大的网站不得不找一些办法把数据库分配到多台机器上（分表分库）。解决方案 有：sharding （基于主键值将数据表分散到多个数据库中），复制，利用弱语义一致性的简化数据库。 委托工作给批处理是一个廉价保持数据更新的技术。举例来讲，Fackbook得及时更新新闻feed，但数据支持下的“你可能认识的人”功能只需要每晚更新（作者猜测是这样的，该功能如何完善不得而知）。批处理作业更新会导致一些不太重要的数据陈旧，但能使数据更新耕作更快更简洁。 7.服务器发回一个HTML响应 图中为服务器生成并返回的响应： 12345678910111213HTTP/1.1 200 OK Cache-Control: private, no-store, no-cache, must-revalidate, post-check=0, pre-check=0 Expires: Sat, 01 Jan 2000 00:00:00 GMT P3P: CP=&quot;DSP LAW&quot; Pragma: no-cache Content-Encoding: gzip Content-Type: text/html; charset=utf-8 X-Cnection: close Transfer-Encoding: chunked Date: Fri, 12 Feb 2010 09:05:55 GMT 2b3Tn@[...] 整个响应大小为35kB，其中大部分在整理后以blob类型传输。 内容编码头告诉浏览器整个响应体用gzip算法进行压缩。解压blob块后，你可以看到如下期望的HTML： 12345678&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Strict//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd\"&gt; &lt;html xmlns=\" http://www.w3.org/1999/xhtml \" xml:lang=\"en\" lang=\"en\" id=\"facebook\" class=\" no_js\"&gt; &lt;head&gt; &lt;meta http-equiv=\"Content-type\" content=\"text/html; charset=utf-8\" /&gt; &lt;meta http-equiv=\"Content-language\" content=\"en\" /&gt; ... 关于压缩，头信息说明了是否缓存这个页面，如果缓存的话如何去做，有什么cookies要去设置（前面这个响应里没有这点）和隐私信息等等。 请注意报头中把Content-type设置为“text/html”。报头让浏览器将该响应内容以HTML形式呈现，而不是以文件形式下载它。浏览器会根据报头信息决定如何解释该响应，不过同时也会考虑像URL扩展内容等其他因素。 8.浏览器开始显示HTML在浏览器没有完整接受全部HTML文档时，它就已经开始显示这个页面了： 9.请求其他对象 在浏览器显示HTML时，它会注意到需要获取其他地址内容的标签。这时，浏览器会发送一个获取请求来重新获得这些文件。 下面是几个我们访问facebook.com时需要重获取的几个URL： 图片 http://static.ak.fbcdn.net/rsrc.php/z12E0/hash/8q2anwu7.gifhttp://static.ak.fbcdn.net/rsrc.php/zBS5C/hash/7hwy7at6.gif… CSS 式样表 http://static.ak.fbcdn.net/rsrc.php/z448Z/hash/2plh8s4n.csshttp://static.ak.fbcdn.net/rsrc.php/zANE1/hash/cvtutcee.css… JavaScript 文件 http://static.ak.fbcdn.net/rsrc.php/zEMOA/hash/c8yzb6ub.jshttp://static.ak.fbcdn.net/rsrc.php/z6R9L/hash/cq2lgbs8.js… 这些地址都要经历一个和HTML读取类似的过程。所以浏览器会在DNS中查找这些域名，发送请求，重定向等等… 但不像动态页面那样，静态文件会允许浏览器对其进行缓存。有的文件可能会不需要与服务器通讯，而从缓存中直接读取。服务器的响应中包含了静态文件保存的期限 信息，所以浏览器知道要把它们缓存多长时间。还有，每个响应都可能包含像版本号一样工作的ETag头（被请求变量的实体值），如果浏览器观察到文件的版本 ETag信息已经存在，就马上停止这个文件的传输。 试着猜猜看“fbcdn.net”在地址中代表什么？ 聪明的答案是”Facebook内容分发网络”。Facebook利用内容分发网络（CDN）分发如图片，CSS表和JavaScript文件这些静态文件。所以，这些文件会在全球很多CDN的数据中心中留下备份。 静态内容往往代表站点的带宽大小，也能通过CDN轻松的复制。通常网站会使用第三方的CDN。例如，Facebook的静态文件由最大的CDN提供商Akamai来托管。 举例来讲，当你试着ping static.ak.fbcdn.net的时候，可能会从某个akamai.net服务器上获得响应。有意思的是，当你同样再ping一次的时候，响应的服务器可能就不一样，这说明幕后的负载平衡开始起作用了。 10.浏览器发送异步（AJAX）请求 在Web 2.0伟大精神的指引下，页面显示完成后客户端仍与服务器端保持着联系。 以 Facebook聊天功能为例，它会持续与服务器保持联系来及时更新你那些亮亮灰灰的好友状态。为了更新这些头像亮着的好友状态，在浏览器中执行的 JavaScript代码会给服务器发送异步请求。这个异步请求发送给特定的地址，它是一个按照程式构造的获取或发送请求。还是在Facebook这个例 子中，客户端发送给 http://www.facebook.com/ajax/chat/buddy_list.php 一个发布请求来获取你好友里哪个 在线的状态信息。 提起这个模式，就必须要讲讲”AJAX”– “异步JavaScript 和 XML”，虽然服务器为什么用XML格式来进行响应也没有个一清二白的原因。再举个例子吧，对于异步请求，Facebook会返回一些JavaScript的代码片段。 除了其他，fiddler这个工具能够让你看到浏览器发送的异步请求。事实上，你不仅可以被动的做为这些请求的看客，还能主动出击修改和重新发送它们。AJAX请求这么容易被蒙，可着实让那些计分的在线游戏开发者们郁闷的了。（当然，可别那样骗人家~） Facebook聊天功能提供了关于AJAX一个有意思的问题案例：把数据从服务器端推送到客户端。因为HTTP是一个请求-响应协议，所以聊天服务器不能把新消息发给客户。取而代之的是客户端不得不隔几秒就轮询下服务器端看自己有没有新消息。 这些情况发生时长轮询是个减轻服务器负载挺有趣的技术。如果当被轮询时服务器没有新消息，它就不理这个客户端。而当尚未超时的情况下收到了该客户的新消息，服务器就会找到未完成的请求，把新消息做为响应返回给客户端。 总结简单表述 输入网址 DNS查找目标ip 浏览器向目标ip地址发起tcp三次握手连接 连接建立后发起 http request 服务器处理 request 服务器返回一个 http response 给浏览器 浏览器将 response 内容显示在页面上","link":"/post/82216935.html"},{"title":"操作系统漫游（三）处理机调度和死锁","text":"在多道程序环境下，系统需要按照某种算法，动态地将处理机分配给处于就绪状态的一个进程。分配处理机的任务，就由处理机调度程序来完成。 调度的层次高级调度或者称长程调度或作业调度，在多道批处理系统中配置。分时、实时系统不需配置。 外存（后备队列） -&gt; 内存（就绪队列） 低级调度或者称短程调度或进程调度，在多道批处理、分时、实时系统中，都必须配置这级调度。 内存（就绪队列） -&gt; 处理机 中级调度或者称内存调度。目的是提高内存利用率和系统吞吐量。 内存（暂时不能允许的进程） -&gt; 外存（swap分区） 作业调度算法作业调度算法主要解决的是如何从外存后被队列中调入哪些进程到内存就绪队列中。 周转时间 = 完成时间 - 到达时间 带权周转时间 = 周转时间/服务时间 先来先服务（first-come first-served，FCFS） 从后备队列中选择几个最先进入该队列的作业，调入内存。 短作业优先（short job first, SJF） 作业越短，优先级越高。 优先级调度算法（priority-scheduling algorithm, PSA） 基于紧迫性。 高响应比优先调度算法（Hihest Response Ratio Next, HRRN） 即考虑作业的等待时间，又兼顾作业运行时间。这样，照顾了短作业又不至于让长作业等待时间过长。 其实现是为每个作业引入一个动态优先级，优先级随着等待时间延长而增加。 优先权 = （等待时间+要求服务时间） / 要求服务时间 进程调度算法 轮转调度算法（round robin, RR）：按照时间片 优先级调度算法：按照紧迫性 多队列调度算法 多级反馈队列的调度算法 基于公平原则的调度算法 实时调度算法抢占式和非抢占式 最低松弛度优先（Least Laxity First）算法松弛度 = 完成截止时间 - 运行时间 - 当前时刻 死锁死锁指的是，两个或多个进程都持有一些资源，但又想申请对方拥有的资源，双方都希望对方释放出自己所需的资源，导致僵持的一种状态。 《计算机操作系统》（第四版）对死锁的定义是： 如果一组进程中的每一个进程都在等待仅由该组进程中的其他进程才能引发的事件，那么该组进程是死锁的（Deadlock）。 死锁的起因通常是进程推进顺序非法，导致多个进程对资源的争夺。（包括对不可抢占式资源和可消耗资源的争夺） 死锁的必要条件 互斥条件 请求和保持条件 （进程已经获得某个资源，又要申请另一资源） 不可抢占条件 （进程获得的资源在未使用完之前不能被其他进程抢占） 循环等待条件 死锁的检测采用资源分配图简化算法。 资源分配图中，找出一个既不阻塞又非独立的进程结点Pi，在顺利的情况下，Pi可获得所需资源而继续运行，直至运行完毕，将所有请求边删去，成为孤立结点。Pi释放资源后，P(i+1)获得资源继续运行。以此类推，如果到最后所有的结点都成为孤立结点，那么该图是可完全化简的。不会导致死锁。 同样可以证明： S为死锁的充分条件是，当且仅当S状态的资源分配图是不可完全化简的。（死锁定理） 处理死锁的方法 预防死锁 避免死锁 检测死锁 解除死锁 预防死锁的两种协议 协议一：进程一开始就一次性申请整个运行过程所需的全部资源。（会导致资源浪费） 协议二：申请 -&gt; 释放 -&gt; 申请 -&gt; 释放 除了两种协议之外，还可以破坏“不可抢占”这个必要条件，例如，提出新的资源请求而不能得到满足时，必须释放已经保持的所有资源。 避免死锁当系统处于安全状态时，就可以避免死锁。所谓安全状态，就是系统能按照某种进程推进顺序为每个进程分配其所需资源，直至满足每个进程对资源的最大需求，使每个进程都可顺利地完成。 可以用银行家算法来避免死锁。 当每一个进程在进入系统时，必须先申明运行过程中可能需要的每种资源类型的最大单元数目。当进程请求一组资源时，系统必须首先确定是否有足够的资源分配给它。若有，计算分配后是否会让系统处于不安全状态，如果不会，才将资源分配给它。","link":"/post/cec034a9.html"},{"title":"计算机网络漫游","text":"京东图书日买了几本专业书籍。其中一本是《计算机网络：自顶向下方法》，算是很知名的一本介绍计算机网络的书了。今天晚上看了第一章，很是过瘾。大二的计算机网络课程，虽然拿了90+的成绩，但说实话，对计算机网络的很多概念（包括七层模型）都是模糊的。希望看完这本书，能补一补大二欠下的计算机网络的知识吧。决定开坑，把这本书的一些知识点归纳到博客里。 一、从物理角度理解因特网（Internet）是世界范围的计算机网络。计算机网络，即是计算设备互联互通的一个网络。这里的设备，可以是我们的PC个人电脑，可以是服务器，也可以是我们的手机、平板电脑、电视、游戏机等等。也就是说，计算机网络把我们的这些设备连接了起来，实现不同设备之间的信息传输。 上面提到的设备，可以统称为主机（host）或端系统（end system），端系统通过通信链路（communication link）和分组交换机（packet switch）连接到一起。一台端系统向另一台端系统发送数据时，发送端将数据分段，并给每段加上首部字节，首部+数据段这样的信息包，就称为分组(packet)。 分组交换机包括路由器(router)和链路层交换机(link-layer switch)，路由器常用于网络核心，链路层交换机则常用于接入网。一个分组，从发送端系统到接收端系统，所经历的一系列通信链路和分组交换机，称为路径(path/route)。 那么有了端系统，我们怎么接入因特网呢？这个工作就要由因特网服务提供商（Internet Service Provider, ISP）来做。ISP有很多，比如住宅区ISP，公司ISP，大学ISP，这些低层的ISP，通过区域的ISP（比如市级、省级ISP）互联，区域ISP又由国家或国际的高层ISP互联起来。形成了一个网络的网络。 二、从服务角度描述我们平时收发电子邮件、浏览web网页、使用QQ微信等即时通讯软件，这些应用程序涉及到多台相互交换数据的端系统，我们称这类应用程序为分布式应用程序（distributed application）。与因特网相连的端系统，有一个应用程序编程接口（Application Programming Interface，API），这个接口规定了一个端系统应用软件（比如小明手机上的微信）如何通过因特网向另一个运行在另一台端系统的软件（比如小红手机上的微信）交付数据。 端系统也叫做主机，是因为它用来运行应用程序。主机可以划分为客户端（client）和服务器（server），常见的客户端包括我们的PC，智能手机等，常见的服务器有Web服务器等。大部分为我们提供web、搜索、电子邮件、视频等服务的服务器，属于数据中心（data center）。Google就有50个左右的数据中心，其中许多数据中心有10万台以上的服务器。 三、从接入网到网络核心普通家庭可通过数字用户线（DSL）、电缆、光纤（FTTH）、拨号和卫星来接入（access）互联网，或者用以太网以及Wi-Fi来接入。智能手机，上网本等还可用3G、LTE等接入互联网。 接入了互联网，我们还需要物理媒体来承载我们的信息（用电磁波或光脉冲来发送比特）。这些物理媒体包括：双绞铜线、同轴电缆、光纤、陆地无线电信道、卫星无线电信道。 前面提到，端系统发送数据时，要分段成为很多分组。这些分组不是一下子就发送到目的端系统，而是首先会被发送到分组交换机中去，分组交换机有一个存储转发传输（store-and-forward transmission）机制，这个机制规定，要从链路输入端接收到整个分组后，才能开始向链路输出端传输比特。 由于每个分组交换机有很多条链路，如果某条链路接收到一个分组，要传输到另一条链路上（这个过程中需要时间，称为存储转发时延），但是另一条链路正忙于传输其他分组，那么这个分组就会被暂时放到输出缓存（output buffer）中等待。这就是排队时延（queue delay） 由于缓存空间有限，如果一个到达的分组发现缓存空间已经被其他过来排队等待的分组充满了，那么这个分组或者已经在排队的分组之一，就会被丢弃。这种现象就叫做丢包（packet lost）。 我们已经知道，路由器从一条链路得到分组，将分组转发到另一条链路中去。那么路由器是怎么知道要往哪条链路转发的呢？前面提到，每个分组都被加了首部，首部里面包含了目的地的IP地址。而路由器有一个转发表（forwarding table），用于将目的地址映射成输出链路。当路由器接收到一个分组，路由器会搜索转发表找到适当的输出链路。那么，转发表又是如何设置的呢？事实上，因特网有一些特殊的路由选择协议（routing protocol）会自动设置这些转发表，不用我们操心。 上面我们讨论的，是链路和交换机移动数据的分组交换（packet switching），事实上，还有一种交换数据的方式，叫做电路交换（circuit switching），在这里就不介绍了。 四、协议层次计算机网络中，为了实现数据的传输，我们需要定义很多通信协议来告诉计算机在每一个地方（应用程序中、传输链路中、物理介质中）应该怎样去传输数据。为了给这些协议一个清晰的结构，我们引出分层（layer）的概念。 因特网的协议栈有5个层次：物理层、链路层、网络层、运输层和应用层。 1. 应用层应用层用于网络应用程序之间，如HTTP、SMTP、FTP等协议。一个端系统中的应用程序（如微信）使用应用层协议与另一个端系统中的应用程序交换信息分组。这种应用程序之间的分组，称为报文（message）。 2. 运输层应用层的报文，需要在某一个端点传送出去或者接收进来。如何传？如何接？就需要运输层协议来规定了。运输层协议有TCP和UDP，都可以传输应用层的报文，只是怎么传的区别罢了。运输层的分组，称为报文段(segment)。 3. 网络层运输层协议把报文段和目的地址，交付给网络层。网络层将报文段和目的地址打包成数据报（datagram），然后把他们从一台主机移动到另一台主机。网络层最著名的协议是IP协议。 4. 链路层网络层的分组要从一台主机移动到另一台主机，不是一下子就能移动过去的，而是要经过很多结点（结点可以是主机或路由器）。为了将分组从一个结点移动到路径上的下一个结点，我们需要链路层来完成这个工作。链路层把数据包封装成帧（frame），一个帧从一个结点传输到下一个结点之后，就会解包成数据包上传给下一个结点的网络层。链路层的例子包括以太网、Wi-Fi等。 5. 物理层链路层的任务，是把整个帧从一个结点移动到下一个结点。一个帧中有很多比特的数据，物理层就是用来把帧中的一个又一个的比特。从一个结点移动到下一个结点的。以太网是链路层的协议，但以太网也有物理层的协议，这些帧的每一个比特，是要用双绞铜线来传输，还是用同轴电缆，或者光纤，这是物理层所要决定的。","link":"/post/c022ff2f.html"},{"title":"操作系统漫游（一）引论","text":"什么是操作系统（Operating System）操作系统是配置在计算机硬件上的第一层软件。主要作用是管理好硬件设备，以提高硬件的利用率和吞吐量。同时，操作系统为用户和应用程序提供接口，便于计算机的使用。 操作系统发展过程人工和纸带自1945年第一台计算机发明到20世纪50年代期间，还处于无操作系统时代，操作计算机主要是靠人工操作或者纸带脱机输入输出的方式。 批处理系统后来到50年代中期出现了单道批处理系统和多道批处理系统。 单道批处理系统的程序是顺序执行的，缺点是在程序调度IO的时候，CPU就空闲下来了，直到程序调度完毕，才载入第二个程序，CPU才能继续工作。 多道批处理系统解决了这个问题。它将需要处理的作业按照队列（称为后备队列）放在外存上，依照一定的算法选择若干作业调入内存，使它们共享CPU和其他资源。这样，当程序A执行IO调度的时候，CPU可以处理程序B，提高了系统资源利用率和吞吐量，充分利用了CPU资源。但是平均周转时间长，也没有和用户交互的能力。 分时系统直到60年代，出现了分时系统，简单地说就是一台主机配有多台显示器和键盘，允许多个用户同时操作自己的终端，且互不干扰。分时系统引入了时间片的概念，也就是每个作业只能运行一小段时间，然后暂停，调度下一个作业，然后暂停，然后调度下一个作业……一直循环。分时系统实现了多用户以及交互性。 实时系统后来又出现了实时系统，所谓实时，指的是及时。实时系统能响应外部事件的请求，在规定的时间内完成对该事件的处理，并控制所有实时任务协调一致地执行。 微机操作系统之后又出现了微机操作系统，包括单用户单任务的MS-DOS，单用户多任务的Windows(从Windows 1.0 -Windows 10)、多用户多任务的Unix OS及其延伸Solari OS 和 Linux。 操作系统的目标方便性操作系统提供了一系列接口和命令，让用户很方便地使用计算机。同时它提供的编译命令使程序员可以采用高级语言编程。 有效性 提高系统资源的利用率 提高系统的吞吐量 可扩充性无结构 -&gt; 模块化结构 -&gt; 层次化结构 -&gt; 微内核结构 开放性遵循世界标准规范，尤其是OSI国际标准 操作系统的作用作为用户与计算机硬件系统之间的接口操作系统提供了一系列接口和命令，甚至是图形界面，让用户很方便地使用计算机。 操作系统同时提供系统调用，供软件开发时的函数调用。用户程序通过系统调用获得操作系统的服务。 管理计算机系统资源所谓资源，包括了处理机、存储器、IO设备、文件（数据+程序），操作系统可对这些资源进行有效的管理。 同时，在多用户操作系统中，操作系统协调多个用户对共享资源的使用。 操作系统的特性操作系统的共同特征有：并发、共享、虚拟 和 异步。 并发（Concurrence）并行（parallel） 是指多个时间同一时刻同时发生。并发（Concurrence） 是指宏观上同时执行，但微观上多个事件在时间间隔内（交替）发生。操作系统中最能体现并发的，就是引入进程的概念。并发和进程是现代操作系统最重要的基本概念。 共享（sharing）共享包括互斥共享方式和同时访问方式。互斥共享方式规定一段时间内，只允许一个进程访问某资源。而同时访问方式则没有这个限制，所有进程都能同时访问某资源。 值得注意的是，这里的同时，指的是宏观上的同时，在微观上，多个进程访问某一资源，是交替进行的。 虚拟（virtual）OS 利用时分复用技术让用户或应用程序感觉计算机只为其服务。 利用空分复用技术实现内存利用率，比如，一个100M的应用程序之所以能运行在30M的内存空间上，是因为内存只把暂时需要的数据调入内存，等到运行完成后释放掉这部分数据，调入下一部分的数据。 异步（Asynchronism）不同的进程，有些CPU运算多一点，有些IO调度多一点，因为CPU速度比IO快得多，因此，后运行的进程可能比先运行的进程提前结束。进程的异步性指的就是进程是以人们不可预知的速度向前推进的。如果多个进程共享了同一个数据资源，那么由于并发，可能导致多次执行的结果不可再现，因此要在操作系统中配置完善的进程同步机制。 操作系统的功能OS的基本功能包括：处理机管理、存储器管理、设备管理 和 文件管理。同时还需向用户提供方便的 用户接口。 处理机管理处理机，可以理解为CPU。处理机管理包括进程控制和进程同步。进程控制指的是创建新的和撤销已结束的进程，以及控制进程在运行过程的状态转换。进程同步指OS利用进程互斥或者同步的方式，对多个进程的运行进行协调。 除此之外，进程与进程之间有时候需要通信，也是由OS来管理。由于处理机一个时刻只能处理一个进程，OS还要按照一定的算法把处理机分配给进程，称为调度。其中包括作业调度和进程调度。 存储器管理包括内存的分配、内存的保护、地址映射和内存扩充。 设备管理包括缓冲管理、设备分配、设备处理以及虚拟设备等功能。 文件管理包括文件存储空间管理、目录管理、文件的读写管理以及文件的共享和保护等功能。","link":"/post/eb7c8f24.html"},{"title":"操作系统漫游（二）进程","text":"程序的顺序执行和并发执行顺序执行一个程序，通常由多个程序段组成。当前程序段执行结束之后，才运行后一程序段，这样的执行方式称为顺序执行。例如，输入 - 计算 - 输出，就是一个顺序执行的例子。 顺序执行的程序具有三个特征：顺序性，封闭性，可再现性。 并发执行假设有三个设备，分别要进行 输入 - 计算 - 请求IO - 计算 - 输出。当 A 设备请求IO的时候，CPU 可以为 B 设备进行计算。这样的执行方式称为并发执行。 并发执行的程序具有三个特征：间断性、失去封闭性、不可再现性。 并发带来的程序不可再现性，是我们不希望出现的，因此我们要采取并发的控制。 进程的概念进程是具有独立功能的程序在一个数据集合上运行的过程，它是系统进行资源分配和调度的一个独立单位。 为了使并发执行的多个程序能独立地运行，操作系统提供了一个专门的数据结构，称为进程控制块（Process Control Bolck, PCB）。因此，进程实体（或者称进程映像）包括 PCB、程序段 和 数据段 三个部分。 值得注意的是，PCB是由OS进行管理的，进程本身无法操作其对应的PCB。 一般来说，操作系统分配资源以进程为基本单位。但是在操作系统内核支持线程的情况下，调度是以线程为单位的。 进程的特征进程的特征有：动态性、并发行、独立性、异步性。 进程的基本状态 就绪（Ready）状态：万事俱备，只等CPU 执行（Running）状态：获得CPU，正在执行 阻塞（Block）状态： 发生某事件（例如IO请求）从而无法继续执行 有时候，用户或者操作系统会将暂时不用的进程执行挂起（suspend）操作，这时候进程会进入挂起状态，表示该进程暂不接受调度。直至被重新激活（active）。 除此之外，进程还有创建状态和终止状态。 当计算机系统没有用户进程执行时，处理机没有停止工作，而是执行 IDLE 程序。 进程控制进程控制主要包括创建新进程、终止已完成的进程、阻塞异常进程、转换进程状态等。 为了防止OS本身以及PCB等关键数据被应用程序破坏，处理机的执行状态分为系统态（管态）和用户态（目态）。系统态有较高的特权，能执行一切指令。用户态则只能访问特定寄存器和存储区。 OS的进程控制中，主要有三种支撑功能：中断处理、时钟管理、原语操作。 所谓原语（Primitive），是由若干条指令组成的用于完成一定功能的一个过程。它是一种原子操作，不允许被中断。进程的原语操作有： CREATE、TERMINATION、BLOCK、WAKEUP、SUSPEND 和 ACTIVE。 进程同步前面提到，并发执行带来的程序不可再现性，是我们不希望出现的，因此我们要采取并发的控制。我们用进程同步来解决这一问题。 进程同步规则 空闲让进：临界资源闲时，进程进入 忙则等待：临界资源忙时，进程需等待 有限等待：超时机制，避免死等 让权等待：对不能进入临界区的进程，应立即释放处理机 基于这4个规则设计的进程同步机制，不会导致进程无限等待。 临界资源的概念临界资源（Critical Resource）指的是一段时间内只允许一个进程访问的资源，只能够互斥访问。进程中访问互斥资源的那段代码称为临界区。 信号量（Semaphores）机制信号量机制是1965年荷兰学者 Dijkstra 提出的一种进程同步工具。信号量可用于进程同步、进程互斥、控制进程的前驱关系。目前广泛用在单处理机、多处理机和计算机网络中。 在信号量机制中，分为 P操作 wait(S)（申请资源） 和 V操作 signal(S)（释放资源）。这是两个原子操作，在执行时是不可中断的。 整形信号量整形信号量原型如下： 12345678wait(S){ while (S&lt;=0); //do no-op S--}signal(S){ S++;} 即资源为0或者小于0时，进行等待。 但是这样会导致忙等，没有遵循让权等待的原则。于是又出现了记录型信号量。 记录型信号量记录型信号量即是建立一个链表，让申请资源的进程进行排队。 原型如下： 1234567891011121314typedef struct { int value; struct Process_control_block *list;}semaphore;wait(semaphore *S){ S-&gt;value--; if(S-&gt;value &lt; 0) block(S-&gt;list);}signal(semaphore *S){ S-&gt;value++; if(S-&gt;value &lt;=0) wakeup(S-&gt;list);} S-&gt;value的初始值表示系统中某类资源数目。 AND型信号量假设 共享数据D 和 共享数据E 是可以被 进程A 和 进程B 访问的数据。 无论哪个进程，需要同时获得数据D和E后，方能进行操作。 那么，考虑以下情况： 1234process A: wait(Dmutex)； // Dmutex = 0process B: wait(Emutex)； // Dmutex = 0process A: wait(Emutex)； // Dmutex = -1 阻塞process B: wait(Dmutex)； // Dmutex = -1 阻塞 也就是说，A获取了D资源， B获取了E资源， A想要再取得E资源才能进行操作，可是E资源在B那里，于是A进行阻塞等待。B想要再取得D资源才能进行操作，可是D资源在A那里，于是B也进行阻塞等待。 这样就造成了僵持状态，也就是死锁。 为了避免这种情况，我们可以用AND同步机制。其核心思想是：将进程在运行中需要的所有资源，一次性分配给该进程。 也就是说，要么一次性把 D资源和E资源 都分配给进程A，要么就都不分配。 信号量的应用 实现进程同步 实现进程互斥 实现前驱关系 经典进程同步问题生产者-消费者问题定义变量 123var mutex, empty, full = 1, n, 0buffer:array[0...n-1] of itemin,out :Integer = 0, 0 mutex 用来加锁，某进程持有锁的时候其他进程不可进入 empty 表示缓存区可用空间，生产=往缓冲区放置，empty-1， 消费=从缓冲区读取，empty+1 full 表示可用产品，为0时消费者不可继续消费 生产者进程 123456789101112131415//process pbegin while(true): do begin produce nextp wait(empty) wait(mutex) buffer[in] = nextp in = (in + 1) mod n signal(mutex) signal(full) endend 消费者进程 1234567891011121314begin while(true): do begin wait(full) wait(mutex) nextp = buffer[out] out = (out + 1) mod n signal(mutex) signal(empty) endend 读者-写者问题定义变量 12var rmutex, wmutex: Semaphores = 1, 1 ReadCount: Integer = 0 rmutex表示读锁 wmutex表示写锁 读者进程 1234567891011121314151617begin while(true): wait(rmutex) if ReadCount == 0 then wait(wmutex) ReadCount++ signal(rmutex) // 读文件操作 wait(rmutex) ReadCount-- if ReadCount == 0 then signal(wmutex) signal(rmutex) endend 写者进程 1234567begin while(true): wait(wmutex) //写文件操作 signal(wmutex) endend","link":"/post/be1528d7.html"},{"title":"操作系统漫游（五）输入输出系统","text":"操作系统中的I/O系统用于管理I/O设备（打印机、扫描仪等）和存储设备（磁盘驱动器、磁带机等）。 I/O系统的基本功能 方便用户使用I/O设备 提高CPU和I/O设备的利用率 为用户在共享设备时提供方便 I/O系统对I/O设备的控制对 I/O设备进行控制是驱动程序的功能。目前包括 4 种控制方式： 采用轮询的可编程 I/O 方式 采用中断的可编程 I/O 方式：适用于打印机、键盘终端等低速设备 直接存储器访问方式（DMA）：适用于磁盘、光盘等高速设备 I/O通道方式：使I/O操作的组织和运行无需CPU的干预，独立运行。 I/O系统的层次结构I/O软件分层通常把I/O软件组织成四个层次： 用户层I/O软件：产生I/O请求，格式化I/O，Spooling 设备独立性软件：映射、分块、保护、缓冲、分配 设备驱动程序：设置设备寄存器：检查状态 中断处理程序：中断处理 经过四个层次之后，I/O操作将交给硬件执行。 I/O系统分层 中断处理程序：直接与硬件进行交互 设备驱动程序：进程和设备控制器之间通信的程序，将上层的I/O请求转化为具体的命令和参数。一般驱动程序都是由设备制造商提供，而非OS设计者。 设备独立性软件：软件独立于具体使用的物理设备。好处是增加新设备和替换老设备时不需对I/O软件进行修改 I/O系统接口在 I/O系统中，根据类型不同，可分为三种接口：块设备接口、流设备接口、网络接口。 块设备接口所谓块设备，是指数据的存储和传输都是以块为单位的设备，例如磁盘。其特点是传输速率高，能够寻址，可随机读写其中任意一块。磁盘设备的I/O常采用 DMA 方式。 块设备接口隐藏了磁盘的二维结构，将抽象的命令映射为低层的操作。 虚拟存储器也需要块设备接口。因为当发生缺页中断时，需要通过块设备接口从磁盘中调入所缺的页面。 流设备接口流设备接口又称为字符设备接口。所谓字符设备，是指数据的存储和传输是以字符为单位的设备，例如键盘、打印机。其特点是传输速率低，不可寻址。字符设备的I/O常采用中断驱动方式。 由于字符设备不可寻址，因此只能顺序存储。通常，我们会为字符设备建立一个缓冲区（队列），字符流在缓冲区中读写。分别使用 get 和 put 操作来读和写。 大多数流设备都属于独占设备（例如打印机），因此必须采用互斥方式实现共享。流设备接口提供来 open 和 close 操作，如果被 open 表示正在被某个进程使用。 网络通信接口通过网络通信接口，计算机可以与网络上的其他计算机通信。 I/O 设备和设备控制器I/O设备包括：执行I/O操作的机械部分 和 执行I/O控制的电子部分。 机械部分是一般的I/O设备，而电子部分称为设备控制器或适配器（adapter） 设备控制器设备控制器的作用是控制一个或多个I/O设备，以实现I/O设备和计算机之间的数据交换。它接收CPU发来的命令，去控制I/O设备工作，使处理机从繁杂的设备控制事务中解脱出来。 设备控制器基本功能包括： 接收和识别指令 数据交换 标识和报告设备的状态 地址识别 数据缓冲区 差错控制 I/O通道虽然有来设备控制器,CPU对I/O的干预已经减少了。但是外设变多的时候，CPU还是负担很重。为此，又增设了 I/O通道（I/O Channel）。 I/O通道的作用是建立独立的I/O操作，使数据的传送独立于CPU，而且有关对I/O的操作都尽量独立。解放CPU。 有来I/O通道，CPU只需向通道发送一条指令，通道便开始执行通道程序。待完成来之后向CPU发送响应中断。 实际上，I/O通道是一种特殊的处理机。 在单处理机系统中，I/O通道和处理机可以实现并行操作。 假脱机（Spooling）系统多道程序技术将一台物理CPU虚拟为多台逻辑CPU，从而允许多个用户共享一台主机。 类似地，假脱机技术（Simultaneous Peripheral Operation On-Line, SPOOLing），就是将一台 物理I/O设备 虚拟为多台 逻辑I/O设备，这样就允许多个用户共享一台物理I/O设备。 Spooling技术通过预输入和缓冲输出，将低速的I/O设备上的数据传送到高速磁盘上，把独占设备改造成了共享设备，使得多个作业同时使用设备。在Spooling中，设备与输入输出井之间的数据传输是由外围控制机实现的，而不是用户程序控制。 磁盘调度算法为了减少磁盘寻道的时间，我们需要采用合适的磁盘调度算法。常见的磁盘调度算法包括： 先来先服务（FCFS）：先来先服务 最短寻道时间优先（SSTF）：寻道时间短的优先，但是会导致“饥饿”现象 扫描算法（SCAN，电梯算法）：根据磁头方向，先上再下，或先下再上 循环扫描算法（CSCAN）：先上到顶，然后从底开始上；或者反过来先下到底，然后从顶往下 （方向一致） N步扫描 FSCAN 文件控制块（FCB）FCB包括文件名、扩展名、物理位置、逻辑结构、物理结构、存取权限、建立日期、修改日期、使用信息等。 当我们使用 open 打开一个文件时，把文件的FCB调入了内存，但没有将文件内容读入内存。","link":"/post/c8d50731.html"},{"title":"操作系统漫游（四）存储器管理","text":"计算机系统存储层次大致可以分为： 寄存器 -&gt; 高速缓存 -&gt; 主存储器 -&gt; 磁盘缓存 -&gt; 固定磁盘 -&gt; 可移动存储介质 由于存储器还是一种稀缺资源，操作系统对存储器的管理主要是对主存储器（主存、或者通俗地称内存）的管理。 程序的装入和链接用户程序在执行前，必须先装入内存，然后才变成一个进程。 这个过程分为以下几步: 编译：由编译器（Compiler）对源码进行编译，形成目标模块（Object Module） 链接：由链接器（Linker）将 Object Modules 与所需的库函数链接在一起，形成装入模块（Load Module）。包括静态链接和装入时动态链接。 装入：由装入器（Loader）将模块装入内存 程序的装入三种装入方式： 绝对装入方式：只适用于单道程序环境，使用的是绝对地址（地址值可由编译器生成或程序员指定） 可重定位装入方式：重定位在装入时一次性完成，故也称静态重定位。其程序地址空间也就是逻辑地址空间。 动态运行时的装入方式：其物理地址是在程序运行时才确定的。 程序的链接三种链接方式： 静态链接方式 装入时动态链接 运行时动态链接 动态分区分配算法根据实际需要，动态地为程序分配内存空间。包括以下算法： 首次适应（First Fit）：在分配内存时，从链首开始顺序查找，直到找到一个大小能满足要求的空闲分区。这种算法优先利用低址部分的空闲分区，保留高址部分的大空闲区。 最佳适应（Best Fit）：先将所有的空闲分区按容量从小到大排序，然后再找到满足要求的空闲区。这样就能做到把既满足空间大小要求、又是最小的空闲分区分配给作业。 交换技术（Swapping）存储管理中采用覆盖与交换（swap）技术是为了减少程序占用主存空间。将内存中暂时不会被调用的进程交换到外存上。这有效提高了内存利用率，减少程序所占的主存空间。 Swapping是在逻辑上扩充主存，并不能从物理上扩充主存容量。 Swap中的虚拟内存的容量由内存和外存容量之和决定，取决于逻辑地址位数。 离散分配如果允许将一个进程 分散地 装入到许多不相邻的分区中，就可以充分地利用内存空间。 分页存储管理方式分页存储把进程的逻辑地址空间分为若干个页，称为页面，比如第0页、第1页、第2页，每一个都有固定的大小，称为页面大小（通常是2的幂）。 其地址结构如下： 如上图，是一个 32 位的地址结构。其中，第 0 - 11 位叫做 位（偏）移量（也就是页内地址），第 12 - 31 位 是页号，也就是第几页的二进制表示。 于是，给定一个逻辑地址空间A，页面大小为L 页号 P 为：P = [INT] A / L 页内地址 d 为： [A] MOD L 分段存储管理方式为了满足用户（程序员）在编程和使用上多方面的要求，引入分段存储管理方式。 这种方式把作业的地址空间划分为若干个段、每个段定义了一组逻辑信息。例如主程序段MAIN、自程序段X、数据段D、栈段S等。 系统为每一个段分配一个连续的分区，一个程序中的各个段，可以载入到内存中不同的分区中。通过段表来实现逻辑段到物理内存的映射。 有以下公式： 偏移量 = 逻辑地址 % 页面大小 物理地址 = 块号 × 页面大小 + 偏移量 段页式存储管理方式将分页和分段结合起来，既能减少存储碎片，又能方便实现数据和程序的共享。 虚拟存储器GTA 5这款游戏，解压完以后有大约 65 GB，运行这个游戏，很少有人拥有 65 GB 以上的内存。这时候就要用到虚拟存储器。虚拟存储器是一种从逻辑上实现对内存容量扩充的技术。 传统的存储器管理方式，有两个特征：一次性 和 驻留性。也就是作业必须一次性装入内存，然后才开始运行，装入内存后，执行过的片段依然会驻留在内存里，浪费内存空间。 我们可以利用程序运行的 局部性原理，也就是说，程序运行过程中，在一较短时间内通常只访问某个部分的内存。于是，我们没有必要将应用程序一次性全部装入内存，而仅须将当前要运行的少数页面或段先装入内存，其余部分暂留在硬盘上。然后通过一些算法在内存和外存中置换。 虚拟存储器定义所谓虚拟存储器，指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统。其三个特征为：多次行、对换性、虚拟性。 换进和换出能有效地提高内存利用率。 虚拟存储器实现在分页系统的基础上，增加调页功能和页面置换功能。允许用户程序只装入少数页面的程序（及数据）即可启动运行，然后通过调页功能和页面置换功能陆续地把即将运行的页面调入内存。 硬件支持首先 请求页表 将用户空间的逻辑地址映射为内存空间中的物理地址。请求页表如下： 状态位P：指示该页是否已调入内存 访问字段A：记录本页在一段时间内被访问的次数（供给置换算法换进换出时参考） 修改位M：标识该页换进内存后是否被修改过（供置换页面时参考） 外存地址：指出该页在外存上的地址 此外，还要有一个缺页中断机构，不同于普通中断，表现在： 普通中断在一条指令执行结束后，才检查是否有中断请求。缺页中断是在指令执行期间，若发现缺页，便立即产生和处理缺页中断信号，及时把所需的页调入内存。 系统中的硬件机构应能保存多次中断时的状态。 置换算法基本： 最佳（Optimal）页面置换算法：把以后不使用的，或者是在最长（未来）时间内不再被访问的页面，置换出去。该算法是无法实现的，因为无法预知未来哪个页面不再被访问。但可以作为其他算法性能的参考。 先进先出（FIFO）页面置换算法：顾名思义，最先进入的最先被置换出去。 最近最久未使用（LRU，Least Recently Used）置换算法：选择最近最久未使用的页面予以淘汰。 改进： Clock置换算法：添加一个访问位，当某页被访问时，将访问位置1。然后将所有页面通过指针链接成循环队列。在选择置换的时候，判断访问位，如果是0，将该页换出，如果是1，将其置0，给予该页第二次驻留内存的机会。指针往后移动。 改进型Clock置换算法：在上面的基础上，增加一个修改位。优先淘汰访问位为0且未被修改的页面。","link":"/post/260127af.html"},{"title":"组成原理漫游","text":"概念 CPU：Central Processing Unit，中央处理机（器），是计算机硬件的核心部件，主要由运算器和控制器组成。 PC：Program Counter，程序计数器，其功能是存放当前欲执行指令的地址，并可自动计数形成下一条指令地址。 IR：Instruction Register，指令寄存器，其功能是存放当前正在执行的指令。 CU：Control Unit，控制单元（部件），为控制器的核心部件，其功能是产生微操作命令序列。 ALU：Arithmetic Logic Unit，算术逻辑运算单元，为运算器的核心部件，其功能是进行算术、逻辑运算。 ACC：Accumulator，累加器，是运算器中既能存放运算前的操作数，又能存放运算结果的寄存器。 MQ：Multiplier-Quotient Register，乘商寄存器，乘法运算时存放乘数、除法时存放商的寄存器。 X：此字母没有专指的缩写含义，可以用作任一部件名，在此表示操作数寄存器，即运算器中工作寄存器之一，用来存放操作数。 MAR：Memory Address Register，存储器地址寄存器，在主存中用来存放欲访问的存储单元的地址。 MDR：Memory Data Register，存储器数据缓冲寄存器，在主存中用来存放从某单元读出、或要写入某存储单元的数据。 I/O：Input/Output equipment，输入/输出设备，为输入设备和输出设备的总称，用于计算机内部和外界信息的转换与传送。 MIPS：Million Instruction Per Second，每秒执行百万条指令数，为计算机运算速度指标的一种计量单位。 指令和数据都存于存储器中，计算机如何区分它们？计算机区分指令和数据有以下2种方法： 通过不同的时间段来区分指令和数据：即在取指令阶段（或取指微程序）取出的为指令，在执行指令阶段（或相应微程序）取出的即为数据。 通过地址来源区分：由PC提供存储单元地址的取出的是指令，由指令地址码部分提供存储单元地址的取出的是操作数。 二进制数和十进制数 二进制 十进制 1 1 10 2 100 4 1000 8 11000 16+8 可以看到，有几个0，就表示 2的几次方 。 移位计算左移一位，相当于乘了 2， 右移一位，相当于近似除以 2。 用最有效率的方法算出 2 乘以 8 等於几2 &lt;&lt; 3，因为 将一个数左移 n 位，就相当于乘以了 2 的 n 次方，那么，一个数乘以 8 只要将其左移 3 位即可，而位运算 cpu 直接支持的，效率最高，所以，2 乘以 8 等於几最效率的方法是 2 &lt;&lt; 3 。","link":"/post/6f3023c1.html"},{"title":"聊聊并发和并发模型","text":"问题的来源以前的计算机都只有一个 CPU， 并且一次只能执行一个程序。后来出现了 多任务（multitasking） 使得计算机可以同时执行多个程序，但这并不是真正的“同时”，只是把 CPU 分成多个时间片，由操作系统去调度切换。再之后出现了 多线程（multithreading） 使得在一个程序里面可以同时执行多个控制流，就像你有多个 CPU 在执行同一个程序一样。在单 CPU 的计算机中，多线程的“同时”并不是“同时”，但现代计算机一般都是多核 CPU，不同的线程可以被不同的 CPU 核心同时执行，是真正的同时。 如果一个线程在读一块内存区域的同时，另一个线程在往里面写，那么这块区域的值是什么？或者两个线程同时写一块内存区域，它的值又是什么？假如我们没有对这些可能出现的结果进行防范，那么结果将是不可预测的。什么情况都可能发生。因此，我们需要在一些共享资源上做一些措施，例如内存、文件、数据库等。 为什么要多线程？利 更好的资源利用：多线程程序在一个线程加载 IO 的同时，另一个线程可以处理已经加载完毕的 IO，以节省时间。 简化程序设计：单线程程序，既要负责加载IO，又要负责处理。多线程程序，可以让一个线程专门加载，另一个线程专门处理。程序逻辑更加清晰。 更加高效的程序：当一个请求进来时，处理请求可能需要耗费一些时间。单线程程序这时候就无法接收新的请求了，而多线程程序一个线程负责接收请求，每次收到请求都开一个专门的线程去处理，实现了多请求。 弊 更加复杂的设计：多线程有时候会让程序变得更加复杂（complex）。 上下文切换消耗：CPU从一个线程切换到另一个线程时，要先保存上一个线程的 local data，程序指针等。这会带来一些消耗。 提高资源消耗：多线程本身需要一些内存用于存储其 local stack，这可能消耗一些内存资源。不要以为它很小，实际上可能比你想象的多。 并发模型（Concurrency Models）并发模型指的是线程如何在系统中协同完成一项工作。不同的并发系统可以用不同的并发模型来实现。 并发模型和分布式系统的相似性并发系统模型跟分布式系统（distributed systems）十分相似。例如，并发系统是不同的线程之间互相通讯（communicate），而分布式系统是不同的进程之间互相通讯（这些进程可能在不同的计算机上）。 进程和线程在某些时候十分相似，这也是为什么不同的并发模型往往看起来都很像分布式系统架构。分布式系统需要面临网络请求可能失败、远程计算机或进程可能挂掉等问题，在并发系统中也会遇到类似 CPU 故障、网卡故障、硬盘故障等问题，虽然这些故障发生的概率很低，但理论上确实存在。 正因为并发模型和分布式系统十分相似，因此他们之间有些设计思想是相通的。例如，并发里面用于分配 workers（threads）的模型，就类似于分布式系统的负载均衡（load balancing in distributed systems）。 模型1：并行 Workers 模型 在这个模型中，所有 Worker（Thread）都由 delegator 来委派。每一个 Worker 都完成一个完整的工作。例如，在一个车间工厂，一辆车从零到一都只由一个 Worker 来完成。 这种模型在 Java 中用得非常多。在 java.util.concurrent 包中，许多的并发工具都是用这个模型来设计的。在 J2EE 应用服务器中也能看到这种模型的影子。 模型2：流水线模型流水线模型，也叫响应式系统或者事件驱动系统。 在这个模型中，每一个 Worker 只负责整个工作的一小部分，一旦完成自己的部分，就交给下一个 Worker 接着做。每个 Worker 都运行在单独的线程上，与其他 Worker 不共享状态。因此，流水线模型也叫做无共享（shared nothing）模型。这种模型通常用 非阻塞IO（non-blocking IO，NIO） 来实现。 所谓响应式，或者事件驱动，指的是当一个事件发生，Worker 就响应对应的动作。例如，一个HTTP请求进来，或者一个文件被加载进内存。响应式平台的例子有Vert.x、Akka、Node.JS。 模型3：函数式并行函数式并行的基本思想是采用函数调用实现程序。函数都是通过拷贝来传递参数的，所以 除了接收函数外没有实体可以操作数据，这就避免了共享数据带来的竞争。同样也使得函数的执行类似于原子操作。每个函数调用的执行独立于任何其他函数的调用。 一旦每个函数调用都可以独立的执行，它们就可以分散在不同的CPU上执行了。这也就意味着能够在多处理器上并行的执行使用函数式实现的算法。在 Java8 中，并行 streams 能够用来帮助我们并行的迭代大型集合。 Same-threadingSame-threading 是一种并发模型。当一个单线程系统扩展到多线程系统时，每个线程所做的工作跟单线程时一样，用在多核CPU上，每个CPU占一个线程。 分布式微服务是一个例子。将多个相同的服务部署在同一台机器上，这台机器的每个CPU占一个服务实例。 并发和并行暂时略过。","link":"/post/3bdfeb29.html"},{"title":"设计模式（一）会飞的鸭子（策略模式）","text":"设计原则: 多用组合（composition），少用继承。 鸭子类首先我们有一个鸭子类 12345public abstract class duck{ quack(); swim(); display();} 然后具体是哪种鸭子，只要去继承这个鸭子类就好了。 比如 MallardDuck 重写 display() 方法，它就是绿头鸭。 123456public class MallardDuck extends duck{ @Overwrite display(){ //... green }} 现在，我们得让鸭子能飞 123456public abstract class duck{ quack(); swim(); display(); fly(); // it fly} 然后你会惊奇地发现，橡皮鸭（RubberDuck）居然飞起来了。这不科学！ 可能的解决方案 重写：可以重写橡皮鸭（RubberDuck）的 fly 方法，变成什么都不做。但是这样假若我们又添加了诱饵鸭（DecoyDuck），不会 fly 也不会 quack ， 我们又要去重写。显然也很麻烦。 接口：可以把 fly 抽象成一个 flyable 接口，让会飞的鸭子去实现这接口。但是我们有 48 个 鸭子子类，都要去实现一遍吗？ 显然，继承或重写不能解决问题，因为鸭子的行为在子类里不断地改变，并且让所有的子类都有这些行为是不切当的。 抽象出 flyable 接口 和 quackable 接口，让具备这些功能的鸭子子类去实现这些接口，要写很多重复代码，无法复用。 设计原则: 找出应用中可能需要变化的地方，把它们独立出来，不要和那些不需要变化的代码混在一起。 解决方案既然 fly 和 quack 会随着鸭子的不同而改变，那么不妨把这两个行为抽出来，新建成 鸭子行为 类。然后在鸭子类中包含设定行为的方法。 关键点: 新建鸭子行为类 在鸭子类中添加设定行为的方法 这样一来，我们 new 一个 绿头鸭（MallardDuck）的时候，就能给它指定特定的 fly 行为 和 quack 行为。 设计原则: 针对接口编程，而不是针对实现编程。 具体实施定义FlyBehavior接口，里面有一个 fly() 方法。FlyWithWings类实现了这个接口，表示用翅膀飞，FlyNoWay类也实现这个接口，表示不会飞，FlyWithRocket类也实现这个接口，表示用火箭发动机飞。 同理，定义QuackBehavior接口，然后有几个不同的实现类。比如Quack()表示呱呱叫，MuteQuack()表示不会叫。 现在，鸭子类是这样的 123456789101112131415161718192021222324public abstract class duck{ QuackBehavior quackBehavior; FlyBehavior flyBehavior; public void performQuack(){ quackBehavior.quack(); } public void performFly(){ flyBehavior.fly(); } //设定鸭子的飞行行为 public void setFlyBehavior(FlyBehavior fb){ flyBehavior = fb; } //设定鸭子的叫声行为 public void setQuackBehavior(QuackBehavior qb){ quackBehavior = qb; } //... more} 现在，橡皮鸭（RubberDuck）类看起来是这样的 12345678public class RubberDuck extends Duck { public RubberDuck(){ //一开始，橡皮鸭并不会飞 flyBehavior = new FlyNoWay(); QuackBehavior = new Quack(); }} 测试类 1234567891011121314public static void main(String[] args){ // 创建一个橡皮鸭实例，此时调用橡皮鸭的构造方法 //也就是为橡皮鸭设定了不会飞，呱呱叫 Duck rubber = new RubberDuck(); // 飞一下看看（结果：不会飞） rubber.performFly(); //设定新的飞行行为 rubber.setFlyBehavior(new FlyWithRocket()); // 再飞一下看看（结果：火箭动力飞） rubber.performFly();} 至此，我们的鸭子就飞起来了。 所谓组合，就是鸭子类和鸭子行为类的组合。实例化一个鸭子的时候，给它组装上对应的行为。 以上，其实就是设计模式中的 策略模式（Strategy Pattern） 了。策略模式提供了多种实体类和行为类，使用者需要哪种实体和哪种行为，可以自己去组装。 参考： 《Head First 设计模式》","link":"/post/69895030.html"},{"title":"设计模式（三）工厂模式","text":"简单工厂模式假设我们有一个发送机制，有两种发送模式：短信发送和邮件发送。具体要用哪种发送，由专门的工厂帮我们做就好，这就是工厂模式。 以消息发送为例，首先有一个发送接口 123public interface Sender { void send();} 短信发送 123456public class MessageSender implements Sender { @Override public void send() { System.out.println(\"Message sent !\"); }} 邮件发送 123456public class EmailSender implements Sender { @Override public void send() { System.out.println(\"Email sent !\"); }} 我们是要发送邮件，还是发送短信，需要一个工厂来造。 12345678910111213public class SenderFactory { // 造一个短信发送类 public static Sender getMessageSender(){ return new MessageSender(); } // 造一个邮件发送类 public static Sender getEmailSender(){ return new EmailSender(); }} 测试类 需要邮件发送类，还是短信发送类，统一从工厂造 1234567891011public static void main(String[] args) { // need a Email Sender Sender emailSender = SenderFactory.getEmailSender(); emailSender.send(); // need a Message Sender Sender messageSender = SenderFactory.getMessageSender(); messageSender.send();} 这就是简单的工厂模式了。我们使用静态方法定义简单工厂，称为静态工厂方法。静态工厂的好处是不需要创建工厂对象，但这样也有缺点：不能通过继承来改变创建方法的行为。 工厂方法模式（继承）工厂方法模式定义了一个创建对象的接口，但由子类来决定要实例化的类是哪一个工厂方法让类把实例化推迟到子类。 抽象工厂模式（组合）抽象工厂模式提供一个接口，用于创建相关或依赖对象的家族，而不需要明确指定具体类。 依赖倒置原则高层组件不应该依赖于底层组件，底层也不应该依赖于高层。高层和底层应该都依赖于抽象。","link":"/post/c0765a5b.html"},{"title":"设计模式（五）观察者模式","text":"观察者模式（Observer）是 JDK 中使用最多的模式之一 有时候，我们的对象需要在收到某些通知时及时作出响应，此时可以用观察者模式。观察者模式定义了对象之间的一对多依赖，当一个对象改变状态时，它的所有依赖者都会收到通知并自动更新。 可以以订阅报纸类比，出版社作为发布者，所有订阅了报纸的用户，在有新报纸出版时，都会收到一份最新的报纸。只不过，在观察者模式中，出版社叫做 主题（Subject），订阅者叫 观察者（Observer）。 主题（Subject）主题就是发送通知的人。 12345public interface Subject { void registerObserver(Observer observer); // 注册一个观察者 void removeObserver(Observer observer); // 取消注册 void notifyObservers(); // 发送通知} 一个可以发布小说和新闻的报社，它维护了一个观察者列表，需要订阅这家报社的人，都会被加到这个 List 进来。 1234567891011121314151617181920212223242526272829303132public class Publisher implements Subject { private List&lt;Observer&gt; observers; private String story; // 小说 private String news; // 新闻 Publisher(){ observers = new ArrayList&lt;&gt;(6); } @Override public void registerObserver(Observer o) { observers.add(o); } @Override public void removeObserver(Observer o) { observers.remove(o); } // 对每一个观察者都进行通知 @Override public void notifyObservers() { observers.forEach(o -&gt; o.update(story, news)); } // 设置通知信息 public void setMessages(String story, String news){ this.story = story; this.news = news; notifyObservers(); }} 观察者（Observer）观察者就是接收通知的人，当有通知来到，它自动会更新。 123public interface Observer { void update(String news); // 通知内容作为参数传递进来} 假设有个新闻爱好者，想订阅新闻： 1234567891011121314public class NewsObserver implements Observer { private String news; // update 是在报社那里被调用的 @Override public void update(String story, String news) { this.news = news; displayNews(); } public void displayNews(){ System.out.println(this.getClass().getName() + \"获取到：\" + this.news); }} 同理，小说爱好者，想订阅小说： 12345678910111213public class StoryObserver implements Observer { private String story; @Override public void update(String story, String news) { this.story = story; displayStory(); } public void displayStory(){ System.out.println(this.getClass().getName() + \"获取到：\" + this.story); }} 测试12345678910111213141516public static void main(String[] args) { // 初始化主题 Publisher dailyPublisher = new Publisher(); // 初始化观察者 Observer storyObserver = new storyObserver(); Observer newsObserver = new NewsObserver(); // 注册观察者 dailyPublisher.registerObserver(storyObserver); dailyPublisher.registerObserver(newsObserver); // 发布消息，观察者自动会收到 dailyPublisher.setMessages(\"最新小说\", \"每日新闻\");} 结果： 12StoryObserver获取到：最新小说NewsObserver获取到：每日新闻 Java 内置的观察者模式在 java.util 包内，自带了 Observer接口 与 Observable类，跟我们自己实现的观察者模式大同小异。但是，jdk内置的主题是继承Observable类，而不是实现接口。但是在 java 9 中， 已经被标记为 deprecated，原因是，他们的扩展性不够好，可以用 Listeners 代替。见 Observer is deprecated in Java 9. What should we use instead of it? 参考：《Head First 设计模式》","link":"/post/592ab43e.html"},{"title":"设计模式（四）装饰器模式","text":"在代码运行期间动态增加功能的方式，称之为装饰器（Decorator），装饰器的好处是，为一个类的对象添加新的功能，而无需继承。 装饰器模式例子一个图形接口 123public interface Shape { void draw();} 矩形 123456public class Rectangle implements Shape { @Override public void draw() { System.out.println(\"draw a rectangle\"); }} 矩形绘制 12345public static void main(String[] args) { // 普通矩形 Shape rectangle = new Rectangle(); rectangle.draw();} 现在，我们增强图形 自身 的功能，让它在绘制的时候会发光！我们不想改接口，也不想在每个实现类中都去写发光的代码（因为都一样）。 解决办法：新增一个图形发光装饰类 12345678910111213141516171819202122/** * 为 shape 添加发光功能 */public class ShapeLightingDecorator implements Shape { private Shape shape; public ShapeLightingDecorator(Shape shape) { this.shape = shape; } public void lighting(){ System.out.println(\"lighting when draw\"); } // 绘制时发光 @Override public void draw() { shape.draw(); lighting(); }} 看看效果 123456789public static void main(String[] args) { // 普通矩形 Shape rectangle = new Rectangle(); rectangle.draw(); // 装饰过发光功能的矩形 Shape lightingRectAngle = new ShapeLightingDecorator(new Rectangle()); lightingRectAngle.draw();} 装饰器模式跟代理模式的区别两者都是对类的方法进行扩展，但 装饰器模式强调的是增强自身，在被装饰之后你能够在被增强的类上使用增强后的功能。增强后你还是你，只不过能力更强了；代理模式则强调要让别人帮你去做一些本身与你业务没有太多关系的职责（记录日志、设置缓存）。代理模式是为了实现对象的控制，因为被代理的对象往往难以直接获得或者是其内部不想暴露出来。 强行区分这两者的区别并没有太多意义，毕竟他们之间的边界确实比较模糊。 参考： Java中“装饰模式”和“代理模式”有啥区别？ JDK中使用 Decorator 模式的例子IO流1BufferedInputStream bufferedInputStream = new BufferedInputStream(inputStream); BufferedInputStream 装饰了 inputStream 。 java.io 包中，输入流的抽象类是 InputStream, FileInputStream 继承 InputStream 并拥有文件输入流的特性。而 FliterInputStream 是一个抽象装饰器，我们熟悉的 BufferedInputStream 正是 FliterInputStream 的一个具体类，它包装一个了 InputStream，并为之扩展缓冲的功能。 在一些框架中，如 Spring，使用了 Decorator pattern 的一般类名中都含有 Wrapper 或 Decorator。作用基本上都是动态地给一个对象添加一些额外的职责。 Python 中的 Decorator在 Python 中实现装饰器非常简单 首先我们要绘制： 12def draw(): print(\"draw\") 现在想在绘制之后发光，但又不想修改 draw() 本身，可以用装饰器来加强 draw，这个装饰器传入了一个函数，对函数进行增强，然后返回增强后的函数 12345def draw_lighting_decorator(func): def wrapper(): func() print(\"lighting\") return wrapper 调用 12345# draw 是一个函数draw = draw_lighting_decorator(draw)# 函数调用draw() 输出： 12drawlighting 语法糖Python 提供了 @ 语法糖，让我们不必显式调装饰函数，只需要在原函数上加上注解，自动装饰。 123456789101112131415def draw_lighting_decorator(func): @functools.wraps(func) def wrapper(): func() print(\"lighting\") return wrapper@draw_lighting_decoratordef draw(): print(\"draw\")if __name__ == '__main__': draw() @functools.wraps(func) 的作用是，在装饰后，函数名还是 draw() 函数的名，而不是 draw_lighting_decorator() 函数的名","link":"/post/fb099b33.html"},{"title":"设计模式（二）代理模式","text":"假设我们需要转账，转账有支付宝和微信支付两种方式，两种方式的转账前都需要检查一下账户信息，转账后显示余额。我们可以提供一个代理人，专门帮我们做检查账户信息和显示余额这种切面工作，而转账类（无论是支付宝还是微信支付）只负责转账本身。这就是代理模式。 静态代理首先提供一个转账接口 1234public interface Transfer { // 转账 void transfer(int amount);} 支付宝类和微信支付类分别有他们自己的转账实现 支付宝 1234567public class AliPayTransfer implements Transfer { @Override public void transfer(int amount) { System.out.println(\"使用支付宝转出了 \" + amount + \" 元\"); }} 微信支付 123456public class WechatPayTransfer implements Transfer { @Override public void transfer(int amount) { System.out.println(\"使用微信支付转出了 \" + amount + \" 元\"); }} 我们还需要一个支付代理人，帮我们做转账前的检查账户和转账后的显示余额： 12345678910111213141516171819202122232425public class TransferProxy implements Transfer { private Transfer transfer; // 支付宝转账还是微信转账，是通过构造方法传递进来给代理人的 public TransferProxy(Transfer transfer) { this.transfer = transfer; } @Override public void transfer(int amount) { before(); this.transfer.transfer(amount); after(); } private void before(){ System.out.println(\"检查账户\"); } private void after(){ System.out.println(\"显示余额\"); }} 现在，可以开始转账了： 12345678910111213public static void main(String[] args) { // 支付宝转账 100 元 Transfer aliTransfer = new AliPayTransfer(); Transfer transferProxy = new TransferProxy(aliTransfer); transferProxy.transfer(100); // 微信转账 100 元 Transfer wechatTransfer = new WechatPayTransfer(); Transfer transferProxy2 = new TransferProxy(wechatTransfer); transferProxy2.transfer(100);} 这就是静态代理，无论我们选用何种方式转账，都交给代理帮我们负责售前、转账、售后服务。但是，假设未来我们增加了现金交易，需要在 TransferProxy 中加入现金交易的构造方法，再之后，加入网银、云闪付等等，无疑我们的代理类会越来越沉重。于是，有没有一种方法，可以让代理类在运行时动态地知道即将进行的是何种方式的转账，这样就不用在代理类编写很多转账类了。动态代理就是这样来的。 动态代理首先，还是一个接口 1234public interface Transfer { // 转账 void transfer(int amount);} 支付宝转账 1234567public class AliPayTransfer implements Transfer { @Override public void transfer(int amount) { System.out.println(\"使用支付宝转出了 \" + amount + \" 元\"); }} 微信支付转账 123456public class WechatPayTransfer implements Transfer { @Override public void transfer(int amount) { System.out.println(\"使用微信支付转出了 \" + amount + \" 元\"); }} 动态代理人 12345678910111213141516171819202122232425import java.lang.reflect.Proxy;public class TransferDynamicProxy { public Object getTransferWay(Transfer transfer){ return Proxy.newProxyInstance(transfer.getClass().getClassLoader(), new Class[]{Transfer.class}, (proxy, method, args) -&gt; { before(); Object invoke = method.invoke(transfer, args); after(); return invoke; }); } private void before(){ System.out.println(\"检查账户\"); } private void after(){ System.out.println(\"显示余额\"); }} 开始转账 12345678910public static void main(String[] args) { // 使用支付宝转账 Transfer transferDynamicProxy = (Transfer) new TransferDynamicProxy().getTransferWay(new AliPayTransfer()); transferDynamicProxy.transfer(100); // 使用微信支付 Transfer transferDynamicProxy2 = (Transfer) new TransferDynamicProxy().getTransferWay(new WechatPayTransfer()); transferDynamicProxy2.transfer(100);} 我们只需要给代理人 Transferproxy 类传入不同的转账类实例（微信还是支付宝），动态代理类就会对应地去生成具体代理类，然后通过具体代理类进行相关转账前、中、后操作。这就是动态代理。 Proxy 类在上面 getTransferWay 中，我们接收一个真实的转账类（支付宝转账类），并动态地生成对应的代理类（支付宝转账代理类）。这个工作由 java.lang.reflect.Proxy 来实现。 在 Proxy 类中，提供了 static 方法 newProxyInstance ： 12345@CallerSensitivepublic static Object newProxyInstance(ClassLoader loader, Class&lt;?&gt;[] interfaces, InvocationHandler h) throws IllegalArgumentException 该方法通过反射生成具体的代理类，接收三个参数： 类加载器 代理类实现的所有接口 要处理的事情（InvocationHandler） InvocationHandler 本质上是一个函数式接口，表示要处理的事情 123public interface InvocationHandler { public void invoke(Object o, Method m); } 面向切面编程（AOP）在 Spring AOP 中，正是通过动态代理来实现切面功能的，例如日志记录，事务等。 MyBatis 为什么通过一个接口就能访问数据库？","link":"/post/413a96e9.html"},{"title":"使用Python遍历文件","text":"下载了很多歌曲，有些是.mp3格式的，有些是.flac格式，还有的是.wav、.ape各种各样。我们知道，.flac和.ape是无损格式，所以我想保留这两种格式的文件，删掉.wav、.mp3格式的音乐。 可以用 Python 自动化处理。 代码首先我的歌曲全都是放在D:\\CloudMusic这个目录下，而这个目录下还有很多子目录，现在要做的就是把D:\\CloudMusic和它的子目录下所有.wav、.mp3格式的音乐找出来。 123456789import osmusic_dir = \"D:\\\\CloudMusic\"for root, dirs, files in os.walk(music_dir): for file in files: target = os.path.join(root, file) if file.endswith(\".mp3\") or file.endswith(\".wav\"): print(target) 先看os.walk()的用法： os.walk(top[, topdown=True[, onerror=None[, followlinks=False]]]) top 参数让 os.walk() 根目录下每一个文件夹（包括根目录）产生一个3-元组 (dirpath, dirnames, filenames)【文件夹路径, 文件夹名字, 文件名】 因此，for root, dirs, files in os.walk(music_dir):中的root、dirs、files分别表示文件夹路径, 文件夹名字, 文件名。 12&gt;&gt;&gt;for root, dirs, files in os.walk(music_dir):&gt;&gt;&gt; print(root) 输出的是CloudMusic目录下的所有子文件夹路径： 12345678910D:\\CloudMusicD:\\CloudMusic\\CacheD:\\CloudMusic\\IUD:\\CloudMusic\\IU\\IU - Last.FantasyD:\\CloudMusic\\IU\\IU - Real 2010 FLACD:\\CloudMusic\\IU\\IU - 꽃갈피(花书签)D:\\CloudMusic\\IU\\IU chat-shireD:\\CloudMusic\\IU\\IU-Can You Hear MeD:\\CloudMusic\\IU\\PaletteD:\\CloudMusic\\MV 12&gt;&gt;&gt;for root, dirs, files in os.walk(music_dir):&gt;&gt;&gt; print(dirs) 输出的是CloudMusic目录下的所有子文件夹名字(放在一个list里)： 12345678910['Cache', 'IU', 'MV'][]['IU - Last.Fantasy', 'IU - Real 2010 FLAC', 'IU - 꽃갈피(花书签)', 'IU chat-shire', 'IU-Can You Hear Me', 'Palette'][][][][][][][] 第一个空list表示 Cache 里没有子文件夹了， 第二个空list表示 IU - Last.Fantasy 里没有子文件夹了，以此类推。 12&gt;&gt;&gt;for root, dirs, files in os.walk(music_dir):&gt;&gt;&gt; print(files) 输出的是CloudMusic目录下(包括子文件夹)的所有文件名字(放在一个list里)： 12345678['01 Welcome To New York.flac', '02 Blank Space.flac', '03 Style.flac', '04 - Mean.flac', '05 All You Had To Do Was Stay.flac', '06 Shake It Off.flac', '07 I Wish You Would.flac', '08 Bad Blood.flac', '09 Wildest Dreams.flac', '10 How You Get The Girl.flac', '11 This Love.flac', '12 I Know Places.flac', '13 Clean.flac', '14 Wonderland.flac', '15 You Are In Love.flac', '16 New Romantics.flac', '17 I Know Places - Voice Memos.flac', '18 I Wish You Would - Voice Memos.flac', '19 Blank Space - Voice Memos.flac', 'AlbumArtSmall.jpg', 'C Allstar - 天梯.flac', 'Chen、Punch - Everytime.ape', 'Davichi - 这份爱.ape', 'desktop.ini', 'Folder.jpg', 'G.E.M.邓紫棋 - 喜欢你.flac', 'Gummy - You Are My Everything(English Ver.).flac', 'Gummy - You Are My Everything.flac', 'K.Will - 说干什么呢.flac', 'LYn - With You.flac', 'M.C. The Max - 为你化成风.flac', 'Mad Clown、金娜英 - 再次见到你.flac', 'SG WANNABE - 让我们相爱.flac', '____.flac', '光良 - 第一次.flac', '其实我介意.flac', '孙燕姿 - 雨天.flac', '小幸运.flac', '曲婉婷 - Drenched.flac', '李克勤 - 友情岁月.flac', '林宥嘉-想自由.flac', '林宥嘉-浪费.flac', '林宥嘉-说谎.APE', '梁静茹 - 爱久见人心.flac', '荒木毬菜 - 小雨と君.wav', '许美静 - 倾城.wav', '许美静-遗憾.WAV', '逃跑计划 - 夜空中最亮的星.flac', '金俊秀 - How Can I Love You.flac', '陈奕迅 - 富士山下.flac', '陈奕迅 - 最佳损友.flac', '陈奕迅 - 陪你度过漫长岁月.flac']['IU - 至少有那天 【视频from：微博@德米安】.mp3', 'IU - 너의 의미(你的意义).mp4', '[onlyU字幕组][MV] IU아이유–Through the Night 夜信[1080P精效中字].mp4', '（中字720P）《至少有那天》饭拍：wj_淮.mp4']['01. 비밀.flac', '02. 잠자는 숲 속의 왕자 (feat. 윤상).flac', '03. 별을 찾는 아이 (feat. 김광진).flac', '04. 너랑 나.flac', '05. 벽지무늬.flac', '06. 삼촌 (feat. 이적).flac', '07. 사랑니.flac', &quot;08. Everything's Alright (feat. 김현철).flac&quot;, '09. Last Fantasy.flac', '10. Teacher (feat. Ra.D).flac', '11. 길 잃은 강아지.flac', '12. 4AM.flac', &quot;13. 라망 (L'amant).flac&quot;]['01. 이게 아닌데.flac', '02. 느리게 하는 일.flac', '03. 좋은 날.flac', '04. 첫 이별 그날 밤.flac', '05. 혼자 있는 방.flac', '06. 미리 메리 크리스마스.flac', '07. 좋은 날 (Inst.).flac', 'cover.jpg']['01. 나의 옛날이야기.flac', '02. 꽃（花）.flac', '03. 삐에로는 우릴 보고 웃지（小丑在对着我们微笑）.flac', '04. 사랑이 지나가면（当爱已逝去）.flac', '05. 너의 의미 (Feat. 김창완)（你的意义）.flac', '06. 여름밤의 꿈（仲夏夜之梦）.flac', '07. 꿍따리 샤바라 (Feat. 클론)（Kungtari Shabara）.flac', 'AlbumArtSmall.jpg', 'Folder.jpg']['Red Queen.flac', 'Zezé.flac', '무릎(膝盖).flac', '새 신발(新鞋).flac', '스물셋(二十三).flac', '안경(眼镜).flac', '푸르던(曾经蔚蓝).flac']['01 Beautiful Dancer.wav', '02 Truth.wav', '03 Fairytale.wav', '04 Voice-mail.wav', '05 New World.wav', '06 The Age Of The Cathedrals.wav', 'IU Can You Hear Me cover pics.jpg']['01 這一刻.flac', '02 Palette.flac', '03 這種結局.flac', '04 爱情很好.flac', '05 Jam Jam.flac', '06 Black Out.flac', '07 終止符.flac', '08 夜信.flac', '09 愛情就那樣.flac', '10 致名字.flac'][] 用os.remove()删除 12345678910import osmusic_dir = \"D:\\\\CloudMusic\"for root, dirs, files in os.walk(music_dir): for file in files: target = os.path.join(root, file) if file.endswith(\".mp3\") or file.endswith(\".wav\"): print(\"deleting \" + target) os.remove(target) target这个变量主要是把文件夹路径和文件名拼接起来，构成一个完整的文件路径，比如： 1D:\\CloudMusic\\IU\\IU-Can You Hear Me\\06 The Age Of The Cathedrals.wav 后面的就是判断后缀名是否为 .mp3 和 .wav ， 是的话就删除之。 知识点写这篇记录的目录主要还是学习一个知识点： 输入： 123L = [[1,2,3],[4,5,6],[7,8,9],[10,11,12]]for i in L: print(i) 输出： 1234[1, 2, 3][4, 5, 6][7, 8, 9][10, 11, 12] 输入： 123L = [[[1,11,111],2,3],[[4,44,444],5,6],[[7,77,777],8,9]]for i,j,k in L: print(i) 输出： 123[1, 11, 111][4, 44, 444][7, 77, 777] 输入： 1234L = [[[1,11,111],2,3],[[4,44,444],5,6],[[7,77,777],8,9]]for i,j,k in L: for ii in i: print(ii) 输出： 123456789111111444444777777","link":"/post/c78ec954.html"},{"title":"Python 随记","text":"Python 程序入口有时候我们会看到 123if __name__ == '__main__': dosomething() # ... 这个语句中， __name__ 是当前模块名，当模块被直接运行时模块名为 __main__。 这句话的意思就是，当模块被直接运行时，dosomething()块将被运行，当模块是被导入时，dosomething()块不被运行。 -m 参数python xxx.py 与 python -m xxx.py ，这两种运行 Python 程序的方式的不同点在于，一种是直接运行，一种是当做模块来运行。 直接运行的时候，xxx.py 所在目录是 sys.path 以模块运行的时候，当前工作路径是 sys.path 直接参数有时候我们用命令行运行 python 程序，如： 1python test.py jerry 20 这里的 jerry 和 20 都是参数，在 python 里面用 sys 模块来获取参数： 12345import sysfilename = sys.argv[0] # test.pyuser = sys.argv[1] # jerryage = sys.argv[2] # 20 参考： Python 中的 if __name__ == ‘__main__’ 该如何理解 python 3.6 print新特性: Formatted string literals使用 %在 python 3.6 之前，我们想 print ， 一般是用 % 符号 123name = \"jerry\"age = 18print(\"my name is %s, and I am %d years old\" % (name, age)) 使用 {}在 python 3.6 可以用 {} ，类似于 kotlin 语法 注意： 引号前面有个 f 123name = \"jerry\"age = 18print(f\"my name is {name}, and I am {age} years old\") 可以在 {} 里运算 1234width = 10precision = 4 # 有效数字value = decimal.Decimal(\"12.34567\")print(f\"result: {value:{width}.{precision}}\") # nested fields 输出：12.34 （4位有效数字） 参考 what is New in python 3.6 获取输入参数用 sys.argv[] 来获取输入参数 myinfo.py 12345import sysname = sys.argv[1]age = sys.agrv[2]print(f\"my name is {name}, and I am {age} years old\") 终端输入 1$ python3 myinfo.py jerry 18 终端输出 1$ my name is jerry, and I am 18 years old myinfo.py 本身是一个参数， 即 argv[0] jerry 是argv[1] 18 是argv[2] 注意： 输入参数都是 string 类型， 这里的 18 其实是字符串18，不是数字18，可以用int(sys.agrv[2]) 转换成数字18 切片（Slice）操作有一个 List 1L = ['Michael', 'Sarah', 'Tracy', 'Bob', 'Jack'] 切片操作 123456# 取出前3个元素L[0:3] # ['Michael', 'Sarah', 'Tracy']L[:3] # 其中，0可以省略# 取出下标为1（包含）到 4（不包含）的元素L[1:4] 倒数切片 12# 取出-2（包含）到0（不包含）L[-2:0] # ['Bob'，'Jack'] 还可以每隔两个数取一个 12# 下标为0（包含）到10（不包含）L[0:10:2] 如果看到下面这种操作，表示所有数每隔5个取一个 1L[::5] tupletuple 是另一种有序列表，中文叫元组。它也可以切片操作，操作结果仍为 tuple。 tuple 跟 list 的区别在于一旦初始化便不可更改。 看一个 tuple 例子 12345&gt;&gt;&gt; t = ('a', 'b', ['A', 'B'])&gt;&gt;&gt; t[2][0] = 'X'&gt;&gt;&gt; t[2][1] = 'Y'&gt;&gt;&gt; t('a', 'b', ['X', 'Y']) 在这个例子中， t[0] 表示 tuple 的第一个元素，也就是 'a'， t[1] 表示 'b'， t[2]表示 ['A', 'B'] 连接数据库1234567891011121314151617181920212223import pymysqlconnect = pymysql.connect(host=\"127.0.0.1\", port=3306, user=\"root\", passwd=\"YOURPASSWD\", db=\"YOURDBNAME\")cursor = connect.cursor()sql = \"SELECT * FROM rate\"cursor.execute(sql)results = cursor.fetchall()file = open(\"C:\\\\Users\\\\JerrySheh\\\\IdeaProjects\\\\mall\\\\dataset\\\\douban_large_clean.dat\", \"w\")for row in results: userid = str(row[0]) bookid = str(row[1]) rating = str(int(row[2])) line = str(userid + \"::\" + bookid + \"::\" + rating + \"\\n\") print(line) file.write(line)file.close()","link":"/post/f9031a66.html"},{"title":"用Python查成绩(一) 模拟登录","text":"前言碎语这个小项目的起因是每到期末，成绩总是一科一科不定时地出，每天都要登录教务系统查询成绩页面看看成绩出了没，出了没？ 于是乎，就想到能不能用Python爬虫模拟登录教务系统，一键获取本学期所有科目的成绩！当然，一开始是想放到后台不断地自动查询、获取，等成绩更新的时候自动推送Email或微信。但鉴于时间、难度、寒假安排…想想还是暂时先做个一键脚本吧。 Just do it ！首先来看看教务系统长什么样 学校的教务系统是流行的正方教务管理系统，我们可以用 Python 的 requests 库来模拟登录。然后往方框里提交（post）正确的学号、密码和验证码，即可登录。 需要的储备知识： http协议 python 3基本语法，request库的使用 xpath和正则表达式 cookie和session的功能和区别 建立会话我们用requests每访问一个网页，都相当于一个全新的连接。比如我们登录了知乎，再点击知乎的编辑个人主页页面，如果单纯用requests去get，知乎的服务器会认为你没有登录，不能进入编辑页面，从而跳转到登录页面去。 而requests库的Session会话对象可以跨请求保持某些参数。意思就是你使用Session成功登录了某个网站，则在再次使用该Session对象访问该网站的其他网页都会默认使用该Session之前使用的cookie等参数。 用了Session后，之前登录的信息会保留下来，这样远程服务器就认为你已经登录，允许后续操作。 所以，我们首先实例化一个 Session对象。 12import requestss = requests.Session() 查看header根据 http 协议，我们每次请求一个网站都会带一个请求头，我们可以用Chrome的F12工具抓包查看请求头。然后用这个请求头把我们的Python代码伪装成浏览器。 然后构造成字典： 123456789headers = { \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\", \"Accept-Encoding\": \"gzip, deflate\", \"Accept-Language\": \"zh-CN,zh;q=0.8\", \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\", \"Host\": \"jwgl.zsc.edu.cn:90\", \"Referer\": \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/default2.aspx\", \"Upgrade-Insecure-Requests\": \"1\"} 模拟登录用request.Session访问教务系统response是request.get返回的内容 1234number = input('请输入学号：')password = input(\"请输入密码：\")url = \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/default2.aspx\"response = s.get(url) 记录cookie, 并加入到header中cookie的作用是让服务器记住你，所以我们也要把cookie加入到header中。但上面我们构造的header中不包括cookie，因为cookie是会变的，我们需要Session自动帮我们添加。 我们用requests的session方法保持cookie时，requests不能保持手动构建的cookie。原因是requests只能保持 cookiejar 类型的cookie，而我们手动构建的cookie（在header里面）是dict类型的。所以这里要做一个转换，然后把cookie加入到header里面去。 1234# 把cookie转变成字典类型，并加入到header中cookies = requests.utils.dict_from_cookiejar(s.cookies)headers.update(cookies)headers_code.update(cookies) 下载验证码并打开，手动输入验证码验证码实际上也是一个链接，用F12找到链接是http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/CheckCode.aspx 我们需要提前给它也设一个 header ，上面的headers_code.update(cookies)就是给验证码链接header加cookie的。 123456headers_code = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\", \"Referer\": \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/default2.aspx\", \"Host\": \"jwgl.zsc.edu.cn:90\", \"Cache-Control\": \"max-age=0\"} 然后需要用到Pillow库，它可以打开并显示本机图片。 1234567891011from PIL import Imageimport oscheck_code_url = \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/CheckCode.aspx\"pic_response = session.get(check_code_url, headers=headers_code).contentwith open('ver_pic.jpg', 'wb') as f: f.write(pic_response)image = Image.open('{}\\\\ver_pic.jpg'.format(os.getcwd()))image.show() 构造post需要提交的数据我们先随便在教务系统上输入一个错误的密码，然后用F12查看post的数据 可以看到，post究竟提交了什么内容。 分析如下： VIEWSTATE：.net特有的一个特征码，可以在网页源码中找到并提取出来 txtSecretCode：验证码 txtUserName：学号 TextBox2： 密码 RadioButtonList1：实际上是网页中“学生”那个按钮 我们先用xpath提取VIEWSTATE的值 1234from lxml import etree# VIEWSTATE 教务系统 post 需要用到的一个随机值selector = etree.HTML(response.content)__VIEWSTATE = selector.xpath('//*[@id=\"form1\"]/input/@value')[0] 然后构建post字典 12345678910111213# post 数据data = { 'txtSecretCode': str(input('请输入图片中的验证码：')), 'txtUserName': str(number), 'Textbox1': '', 'TextBox2': str(password), '__VIEWSTATE': __VIEWSTATE, 'RadioButtonList1': u\"学生\".encode('gb2312', 'replace'), 'Button1': '', 'lbLanguage': '', 'hidPdrs': '', 'hidsc': ''} post登录教务系统如果成功登录进教务系统，右上角会显示：欢迎您，XXX同学 因此可以从网页源码中获取到姓名 写一个获取基本信息的函数，传入网页的response和xpath查找规则，返回我们需要提取的信息。 12345def getInfor(response, xpath): content = response.content.decode('gb2312') # 网页源码是gb2312要先解码 selector = etree.HTML(content) infor = selector.xpath(xpath)[0] return infor 然后开始post，并加入错误判断 12345678910111213141516171819response = s.post(url, data=data, headers=headers)print(\"正在登录...\")print(response.status_code)if \"验证码不正确\" in response.text: print(\"验证码不正确\") return login_jcgl(s)if (\"密码错误\" or \"密码不能为空\") in response.text: print(\"密码错误\") return login_jcgl(s)if (\"用户名不能为空\" or \"用户名不存在或未按照要求参加教学活动\") in response.text: print(\"学号错误\") return login_jcgl(s)else: print(\"登录成功！\") global student student = getInfor(response, '//*[@id=\"xhxm\"]/text()').replace(\"同学\", \"\") # student = student.replace(\"同学\",\"\") print(\"你好，\" + student + \" \" + number) 如果一切正常，输出应该为： 1234请输入图片中的验证码：nxgy正在登录...200你好，（姓名+学号） 这样我们就成功登录进教务系统了。 先写到这里，下一篇继续讲如何获取成绩。 完整代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091929394959697# -*-coding:utf-8-*-import osimport requestsfrom lxml import etreefrom PIL import Image# 浏览器头headers = { \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\", \"Accept-Encoding\": \"gzip, deflate\", \"Accept-Language\": \"zh-CN,zh;q=0.8\", \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\", \"Host\": \"jwgl.zsc.edu.cn:90\", \"Referer\": \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/default2.aspx\", \"Upgrade-Insecure-Requests\": \"1\"}# 验证码页面浏览器头headers_code = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\", \"Referer\": \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/default2.aspx\", \"Host\": \"jwgl.zsc.edu.cn:90\", \"Cache-Control\": \"max-age=0\"}def login_jcgl(session): global number number = input('请输入学号：') password = input(\"请输入密码：\") url = \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/default2.aspx\" response = session.get(url) # 把cookie转变成字典类型，并加入到header中 cookies = requests.utils.dict_from_cookiejar(s.cookies) headers.update(cookies) headers_code.update(cookies) # Download checkcode check_code_url = \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/CheckCode.aspx\" pic_response = session.get(check_code_url, headers=headers_code).content with open('ver_pic.jpg', 'wb') as f: f.write(pic_response) # open checkcode image = Image.open('{}\\\\ver_pic.jpg'.format(os.getcwd())) image.show() # VIEWSTATE 教务系统 post 需要用到的一个随机值 selector = etree.HTML(response.content) __VIEWSTATE = selector.xpath('//*[@id=\"form1\"]/input/@value')[0] # post 数据 data = { 'txtSecretCode': str(input('请输入图片中的验证码：')), 'txtUserName': str(number), 'Textbox1': '', 'TextBox2': str(password), '__VIEWSTATE': __VIEWSTATE, 'RadioButtonList1': u\"学生\".encode('gb2312', 'replace'), 'Button1': '', 'lbLanguage': '', 'hidPdrs': '', 'hidsc': '' } # 登录教务系统 response = s.post(url, data=data, headers=headers) print(\"正在登录...\") print(response.status_code) if \"验证码不正确\" in response.text: print(\"验证码不正确\") return login_jcgl(s) if (\"密码错误\" or \"密码不能为空\") in response.text: print(\"密码错误\") return login_jcgl(s) if (\"用户名不能为空\" or \"用户名不存在或未按照要求参加教学活动\") in response.text: print(\"学号错误\") return login_jcgl(s) else: print(\"登录成功！\") global student student = getInfor(response, '//*[@id=\"xhxm\"]/text()').replace(\"同学\", \"\") # student = student.replace(\"同学\",\"\") print(\"你好，\" + student + \" \" + number) return responsedef getInfor(response, xpath): content = response.content.decode('gb2312') # 网页源码是gb2312要先解码 selector = etree.HTML(content) infor = selector.xpath(xpath)[0] return infors = requests.Session()response = login_jcgl(s)","link":"/post/567b287d.html"},{"title":"Python 中的 virtualenv","text":"开发 Python 应用程序的时候，需要安装（import）各种各样的第三方包。默认情况下，都会被安装到Python 3的 site-packages 目录下面。比如，我的第三方包统一安装在目录C:\\Program Files\\Python36\\Lib\\site-packages下面。 但是，当我们开发多个项目的时候，如果应用A需要jinja 2.7，而应用B需要jinja 2.6怎么办？ virtualenv 就是用来为特定的应用程序创造一套独立的运行环境的。 如何你用的是Python 3，还可以直接创建虚拟环境（见第二部分） 一. 使用 virtualenv1. 安装1pip3 install virtualenv 2. 创建一个工程目录12mkdir webAppcd webApp 3. 创建独立Python运行环境1virtualenv venv 4. 进入该环境Linux / Mac 1source venv/bin/activate Windows 1.\\venv\\Scripts\\activate 此时命令行前面出现了 (venv) 表示已经进入独立的虚拟Python运行环境 1(venv) D:\\Python\\new\\venv&gt; 此时可以用 pip 安装该项目所需的 Python 包 1(venv) D:\\Python\\new\\venv&gt; pip install jinja2 5. 退出venv环境123(venv) D:\\Python\\new\\venv&gt; deactivateD:\\Python\\new&gt; 6. 删除venv环境删除目录即可 二. 使用 Python 3 自带的venvvirtualenv 可用在 python 2 或 python 3， 但如果是 python 3 项目， 其实还可以使用 python 3 自带的 venv 1. 创建虚拟环境1python -m venv myvenv 默认是干净的环境，如果虚拟环境中需要使用系统的环境，可用 1python -m venv --system-site-packages myvenv 使虚拟环境指向系统环境包目录（非复制），在系统环境pip新安装包，在虚拟环境就可以使用。 2. 激活虚拟环境不同的命令行工具有不同的激活方法： bash/zsh 1source &lt;venv&gt;/bin/activate fish 1&lt;venv&gt;/bin/activate.fish csh/tcsh 1&lt;venv&gt;/bin/activate.csh cmd 1&lt;venv&gt;\\Scripts\\activate.bat PowerShell 1&lt;venv&gt;\\Scripts\\Activate.ps1 这里的 &lt;venv&gt; 指的是刚刚执行创建虚拟环境的目录 3. 关闭虚拟环境1deactivate 4. 删除虚拟环境直接删除目录即可 下载 requirements有时候，一个项目里所需的依赖会导出到 requirements.txt，使用以下命令来安装所有依赖 1pip install -r requirements.txt 更换 pip 源使用 -i 参数临时使用 1pip install -i https://pypi.tuna.tsinghua.edu.cn/simple [some-package] 升级 pip 到最新的版本 (&gt;=10.0.0) 后进行配置，永久使用 12pip install pip -Upip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple","link":"/post/e7cabdd8.html"},{"title":"用Python查成绩(二) 获取成绩","text":"前言碎语上一篇 用Python的requests库伪装成浏览器，模拟登录了学校的教务系统。登录进去之后，就可以开始做我们想做的事啦！ 这一篇主要写写登录进去之后进入查询成绩页面，以及如何提取成绩信息。 访问查询成绩页面构造URL用Chrome F12工具可以看到，当我们进入教务系统，点击成绩查询按钮后，获取的URL是 http://jwgl.zsc.edu.cn:90/(bmdsd0ur5p4fbu4512erwdzt)/xscj_gc.aspx?xh=2015XXXXXX9&amp;xm=%D9%XXXXXF3&amp;gnmkdm=N121605 其中2015XXXXXX9是学号，%D9%XXXXXF3是姓名的urlencode编码后的字符串 学号在前面已经输入过了，姓名字符串可以用urllib库 123456# student变量在上文中已经得到，即学生姓名# number即上一篇输入过的学号# student_name是姓名urlencode编码后的字符串import urllib.parsestudent_name = urllib.parse.quote(student.encode(\"gb2312\"))grade_url = \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/xscj_gc.aspx?xh={}&amp;xm={}&amp;gnmkdm=N121605\".format(number, student_name) 这样就得到我们需要的URL 访问页面，获取网页源码访问之前先更新一下cookie，然后get成绩页面获取网页源码 123cookies = requests.utils.dict_from_cookiejar(s.cookies)grade_headers.update(cookies)response = session.get(grade_url, headers=grade_headers) 构造post所需的数据可以看到，要查询成绩，需要先选择学年和学期，然后点击下面不同的按钮 先随便点一个学年和学期，然后点击按学年查询，用F12工具追踪post数据 发现提交的数据包括一个新的__VIEWSTATE值，以及ddlXN、ddlXQ、Button5。不难猜测ddlXN是学年，ddlXQ是学期。至于Button5，其实是下面的“按学年查询”、“按学期查询”这些按钮。 我们刚刚已经用get方法访问了一次成绩查询页面，得到了其源码，因此在网页源码中可以直接找到新的__VIEWSTATE值，用etree和xpath提取出来。 然后构造post数据，再用post方法访问网页。 1234567891011selector = etree.HTML(response.content)__VIEWSTATE = selector.xpath('//*[@id=\"Form1\"]/input/@value')[0]# post 数据data = { \"__VIEWSTATE\": __VIEWSTATE, \"ddlXN\": \"2017-2018\", \"ddlXQ\": 1, \"Button5\": u\"按学年查询\".encode('gb2312', 'replace'),}response = s.post(grade_url, headers=grade_headers, data=data) response是服务器返回给我们的网页，至此我们已经得到一个含有成绩信息的网页了。离成功不远了！ 提取成绩得到一个含有成绩信息的网页之后，分析其源码，看看网页中成绩是怎么显示的 123456789101112&lt;tr class=\"datelisthead\"&gt; &lt;td&gt;学年&lt;/td&gt;&lt;td&gt;学期&lt;/td&gt;&lt;td&gt;课程代码&lt;/td&gt;&lt;td&gt;课程名称&lt;/td&gt;&lt;td&gt;课程性质&lt;/td&gt;&lt;td&gt;课程归属&lt;/td&gt;&lt;td&gt;学分&lt;/td&gt;&lt;td&gt;绩点&lt;/td&gt;&lt;td&gt;平时成绩&lt;/td&gt;&lt;td&gt;期中成绩&lt;/td&gt;&lt;td&gt;期末成绩&lt;/td&gt;&lt;td&gt;实验成绩&lt;/td&gt;&lt;td&gt;成绩&lt;/td&gt;&lt;td&gt;辅修标记&lt;/td&gt;&lt;td&gt;补考成绩&lt;/td&gt;&lt;td&gt;重修成绩&lt;/td&gt;&lt;td&gt;学院名称&lt;/td&gt;&lt;td&gt;备注&lt;/td&gt;&lt;td&gt;重修标记&lt;/td&gt;&lt;td&gt;课程英文名称&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;2017-2018&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;10327540&lt;/td&gt;&lt;td&gt;linux 软件开发基础&lt;/td&gt;&lt;td&gt;必修课&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;4.0&lt;/td&gt;&lt;td&gt; 3.91&lt;/td&gt;&lt;td&gt;90&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;94&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;93&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;计算机学院&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=\"alt\"&gt; &lt;td&gt;2017-2018&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;10302530&lt;/td&gt;&lt;td&gt;多媒体技术基础&lt;/td&gt;&lt;td&gt;限选课&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;3.0&lt;/td&gt;&lt;td&gt; 3.39&lt;/td&gt;&lt;td&gt;59&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;92&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;82&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;计算机学院&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt; &lt;td&gt;2017-2018&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;10337040&lt;/td&gt;&lt;td&gt;嵌入式网络协议及应用开发&lt;/td&gt;&lt;td&gt;限选课&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;4.0&lt;/td&gt;&lt;td&gt; 3.88&lt;/td&gt;&lt;td&gt;93&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;91&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;92&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;计算机学院&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr class=\"alt\"&gt; &lt;td&gt;2017-2018&lt;/td&gt;&lt;td&gt;1&lt;/td&gt;&lt;td&gt;10329020&lt;/td&gt;&lt;td&gt;嵌入式最小系统设计&lt;/td&gt;&lt;td&gt;必修课&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;2.0&lt;/td&gt;&lt;td&gt; 4.00&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;100&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;100&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;计算机学院&lt;/td&gt;&lt;td&gt;&amp;nbsp;&lt;/td&gt;&lt;td&gt;0&lt;/td&gt;&lt;td&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt; 这种情况，可以先用Beautifulsoup库的find方法，找到所有的tr标签的内容，存到trs变量中。然后在每一行tr中，依次找到课程名字、学分、绩点、平时成绩、期末成绩、总评（每一行的第3个td是课程名字，第6个td是学分，以此类推…）。最后构建一个字典，把数据存进去。 具体实现如下： 1234567891011121314151617181920212223def getGrade(response): html = response.content.decode(\"gb2312\") soup = BeautifulSoup(html, \"html5lib\") trs = soup.find(id=\"Datagrid1\").findAll(\"tr\")[1:] Grades = [] for tr in trs: tds = tr.findAll(\"td\") tds = tds[3:4] + tds[6:9] + tds[10:13:2] oneGradeKeys = [\"课程名字\", \"学分\", \"绩点\", \"平时成绩\", \"期末成绩\", \"总评\"] oneGradeValues = [] for td in tds: s = td.string.replace(\" \", \"\") # 去掉空格 s = \"\".join(s.split()) # 去掉 \\xa0 ，\\xa0 是不间断空白符 &amp;nbsp; oneGradeValues.append(s) oneGrade = dict((key, value) for key, value in zip(oneGradeKeys, oneGradeValues)) Grades.append(oneGrade) return Gradesresult = getGrade(response)for go in result: print(go) 至此，成绩已经提取出来了。看看输出结果： 总结这是我第一次做了一个像样的实用Python爬虫小项目，部分代码和成绩提取的内容参考了网上的代码。写得也不怎么样，不过最终还是实现了一开始的构想，已经很满足了。 参考链接：link 完整代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166# -*-coding:utf-8-*-import osimport requestsfrom lxml import etreefrom PIL import Imagefrom bs4 import BeautifulSoupimport urllib.parse# 浏览器头headers = { \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\", \"Accept-Encoding\": \"gzip, deflate\", \"Accept-Language\": \"zh-CN,zh;q=0.8\", \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\", \"Host\": \"jwgl.zsc.edu.cn:90\", \"Referer\": \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/default2.aspx\", \"Upgrade-Insecure-Requests\": \"1\"}# 验证码页面浏览器头headers_code = { \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\", \"Referer\": \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/default2.aspx\", \"Host\": \"jwgl.zsc.edu.cn:90\", \"Cache-Control\": \"max-age=0\"}# 成绩页面浏览器头grade_headers = { \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\", \"Accept-Encoding\": \"gzip, deflate\", \"Accept-Language\": \"zh-CN,zh;q=0.9,en;q=0.8,zh-TW;q=0.7\", \"Cache-Control\": \"max-age=0\", \"Connection\": \"keep-alive\", \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36\", \"Host\": \"jwgl.zsc.edu.cn:90\", \"Referer\": \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/default2.aspx\", \"Upgrade-Insecure-Requests\": \"1\"}def login_jcgl(session): global number number = input('请输入学号：') password = input(\"请输入密码：\") url = \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/default2.aspx\" response = session.get(url) # 把cookie转变成字典类型，并加入到header中 cookies = requests.utils.dict_from_cookiejar(s.cookies) headers.update(cookies) headers_code.update(cookies) # Download checkcode check_code_url = \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/CheckCode.aspx\" pic_response = session.get(check_code_url, headers=headers_code).content with open('ver_pic.jpg', 'wb') as f: f.write(pic_response) # open checkcode image = Image.open('{}\\\\ver_pic.jpg'.format(os.getcwd())) image.show() # VIEWSTATE 教务系统 post 需要用到的一个随机值 selector = etree.HTML(response.content) __VIEWSTATE = selector.xpath('//*[@id=\"form1\"]/input/@value')[0] # post 数据 data = { 'txtSecretCode': str(input('请输入图片中的验证码：')), 'txtUserName': str(number), 'Textbox1': '', 'TextBox2': str(password), '__VIEWSTATE': __VIEWSTATE, 'RadioButtonList1': u\"学生\".encode('gb2312', 'replace'), 'Button1': '', 'lbLanguage': '', 'hidPdrs': '', 'hidsc': '' } # 登录教务系统 response = s.post(url, data=data, headers=headers) print(\"正在登录...\") print(response.status_code) if \"验证码不正确\" in response.text: print(\"验证码不正确\") return login_jcgl(s) if (\"密码错误\" or \"密码不能为空\") in response.text: print(\"密码错误\") return login_jcgl(s) if (\"用户名不能为空\" or \"用户名不存在或未按照要求参加教学活动\") in response.text: print(\"学号错误\") return login_jcgl(s) else: print(\"登录成功！\") global student student = getInfor(response, '//*[@id=\"xhxm\"]/text()').replace(\"同学\", \"\") # student = student.replace(\"同学\",\"\") print(\"你好，\" + student + \" \" + number) return response# 获取基本信息（用于验证是否登录成功）def getInfor(response, xpath): content = response.content.decode('gb2312') # 网页源码是gb2312要先解码 selector = etree.HTML(content) infor = selector.xpath(xpath)[0] return infordef login_grade(session): student_name = urllib.parse.quote(student.encode(\"gb2312\")) grade_url = \"http://jwgl.zsc.edu.cn:90/(enfj1b45crtyfibn2cj2u045)/xscj_gc.aspx?xh={}&amp;xm={}&amp;gnmkdm=N121605\".format(number, student_name) cookies = requests.utils.dict_from_cookiejar(s.cookies) grade_headers.update(cookies) response = session.get(grade_url, headers=grade_headers) selector = etree.HTML(response.content) __VIEWSTATE = selector.xpath('//*[@id=\"Form1\"]/input/@value')[0] # post 数据 data = { \"__VIEWSTATE\": __VIEWSTATE, \"ddlXN\": \"2017-2018\", \"ddlXQ\": 1, \"Button5\": u\"按学年查询\".encode('gb2312', 'replace'), } response = s.post(grade_url, headers=grade_headers, data=data) return responsedef getGrade(response): html = response.content.decode(\"gb2312\") soup = BeautifulSoup(html, \"html5lib\") trs = soup.find(id=\"Datagrid1\").findAll(\"tr\")[1:] Grades = [] for tr in trs: tds = tr.findAll(\"td\") tds = tds[3:4] + tds[6:9] + tds[10:13:2] # 0 1 3 4 6 7 8 10 12 oneGradeKeys = [\"课程名字\", \"学分\", \"绩点\", \"平时成绩\", \"期末成绩\", \"总评\"] oneGradeValues = [] for td in tds: s = td.string.replace(\" \", \"\") # 去掉空格 s = \"\".join(s.split()) # 去掉 \\xa0 ，\\xa0 是不间断空白符 &amp;nbsp; oneGradeValues.append(s) oneGrade = dict((key, value) for key, value in zip(oneGradeKeys, oneGradeValues)) Grades.append(oneGrade) return Gradess = requests.Session()response = login_jcgl(s)response = login_grade(s)result = getGrade(response)for go in result: print(go)os.system(\"pause\") 代码写得比较烂，请多批评指教。","link":"/post/d7517b3d.html"},{"title":"Python中的函数式编程","text":"在 Java简明笔记(九)中就提过函数式编程的概念，由于最近要用到 Python 的高阶函数，所以这一篇以 Python 为例，重新体会一下函数式编程的思想。 高阶函数概念在 Python 中，abs(-10)用于取绝对值， 其中，-10 是参数，abs 是函数本身，abs()才是函数调用。我们可以把函数本身作为变量，赋值给另一变量。 如假设我们定义f = abs，现在，f(-10) 和 abs(-10) 完全一样。 既然函数本身可以作为变量赋值，那么它就可以作为参数，传给另一个函数。 如 12345def add(x, y, f): return f(x) + f(y)f = absadd(-5, 6, f) 当我们调用add() 的时候， 把函数f本身传递了进去。 像这样，如果有一个函数，它可以接收另一个函数作为参数，这种函数就称之为高阶函数（Higher-order function）。 Iterable 和 Iterator可以直接作用于 for 循环的对象统称为可迭代对象（Iterable）。 可以被 next() 函数调用并不断返回下一个值的对象称为迭代器（Iterator）。 Python的 Iterator 对象表示的是一个数据流，Iterator对象可以被 next() 函数调用并不断返回下一个数据，直到没有数据时抛出 StopIteration 错误。 可以把这个数据流看做是一个有序序列，但我们却不能提前知道序列的长度，只能不断通过 next() 函数实现按需计算下一个数据，所以 Iterator 的计算是惰性的，只有在需要返回下一个数据时它才会计算。 list、dict、str等数据类型不是 Iterator，因为他们的长度是可知的。 Python内置的高阶函数mapmap 函数接收两个参数，一个是函数，一个是Iterable。返回一个Iterator。 举个例子： 12345def pow(x): return x*x;r = map(pow, [1,2,3,4,5])print(list(r)) 输出 1[1, 4, 9, 16, 25] [1,2,3,4,5] 是一个可迭代对象，map会将函数pow分别作用于其中的每一个元素。结果r是一个Iterator。 reducereduce函数能把结果继续和序列的下一个元素做累积计算。结果就是计算的结果。 12345678from functools import reducedef sum(x, y): return x+yr = reduce(sum, [1, 2, 3, 4, 5])print(r) 输出 115 reduce的执行过程： 1+2，结果为3 3+3，结果为6 6+4，结果为10 10+5，结果为15 filterfilter()函数用于过滤序列。和map()类似，filter()也接收一个函数和一个序列。 但是filter()把传入的函数依次作用于每个元素，然后根据返回值是 True 还是 False 决定保留还是丢弃该元素。其作用是筛选。 filter()返回的也是一个Iterator。 123456def is_odd(n): return n % 2 == 1r = filter(is_odd, [1,2,3,4,5])print(list(r)) 输出： 1[1, 3, 5] sorted 在 Java 中，我们对一个类实现 Comparable 接口，那么它就有了默认的比较方法。但是我们有时候要自己定义比较的方式（比如String默认是根据首字母来比较，而我们现在想比较的是字符串的长度），就必须得实现 Comparator 接口的 compare 方法了。 在 Python 中， sorted()函数提供了默认的排序方法，但也支持自己定义，只需要指定第二个参数。 比如，按绝对值比较 12345# 默认比较sorted([36, 5, -12, 9, -21])# 按绝对值比较sorted([36, 5, -12, 9, -21], key=abs) 怎么实现的呢？实际上，是先对[36, 5, -12, 9, -21]进行key=abs操作，先生成一个key列表[36, 5, 12, 9, 21]，然后对key所对应的value进行 sorted()操作。所以最终的输出还是原始数字。 下面的例子为忽略大小写按首字母排列字符串 1sorted(['bob', 'about', 'Zoo', 'Credit'], key=str.lower) sorted还支持第三个参数，reverse=True 即可将结果反转。 返回函数在 Python 高阶函数中，可以把函数作为结果值返回。 1234567def lazy_sum(*args): def sum(): ax = 0 for n in args: ax = ax + n return ax return sum 当我们调用 lazy_sum() 时，返回的是 sum 函数本身，而不是一个具体的数据类型。 闭包在函数中定义另一函数，内部函数可以引用外部函数的参数和局部变量。当外部函数返回内部函数时，相关的参数和变量都保存在返回的内部函数中。这种程序结构，称为闭包。 vczh：闭包不是“封闭内部状态”，而是“封闭外部状态”。一个函数如何能封闭外部状态呢？当外部状态的 scope 失效的时候，还有一份留在内部状态里面。 匿名函数在使用 map() 函数的时候，我们传入一个函数参数和一个Iterable。我们还要特地去定义传入的函数，比如： 1234def f(x): return x * xmap(f(x), [1, 2, 3, 4, 5, 6, 7, 8, 9]) 我们可以使用 lambda 表达式，直接表示 f(x) ，而不用特地去定义。 1map(lambda x: x * x, [1, 2, 3, 4, 5, 6, 7, 8, 9]) 这就是匿名函数和lambda表达式的用法。 装饰器（Decorator）函数对象在 Python 中，函数是对象，可以赋值给变量 12345678def now(): print(\"2018-05-17\")myfun = now# 可以通过 __name__ 属性获取函数的名字now.__name__myfun.__name__ 装饰器现在，我们要在调用 now() 函数前，执行日志打印，但又不希望修改 now() 函数的内容。这时候可以用装饰器（Decorator）。 在代码运行期间动态增加功能的方式就是 Decorator，本质上 Decorator 就是一个返回函数的高阶函数。 123456789101112def log(func): def wrapper(*args, **kw): print('call %s():' % func.__name__) return func(*args, **kw) return wrapperdef now(): print('2018-05-17')now = log(now)now() 我们把 now() 函数作为参数，传给 log() 函数，然后log() 函数返回一个内部函数 wrapper。 而 wrapper 在返回前打印了日志，然后返回了传进去的 now() 函数。 现在， now 这个变量保存了 wrapper() 函数。（注意：wrapper并没有执行，只是保存了状态） 最后，我们调用 now()，now() 执行刚刚保存的 wrapper() ，也就是打印日志，然后返回 now() 本身，也就是打印2018-05-17。 所以，我们最后看到的结果是： 12call now():2018-05-17 这就实现了我们想要的功能：在调用 now() 函数前，执行日志打印。 事实上，为了方便，我们可以用 @log 来修饰函数 ，如 123@logdef now(): print('2015-3-25') 等同于 1234def now(): print('2018-05-17')now = log(now) 用装饰器装饰过后的函数， __name__ 会变成装饰函数的内部函数，以这个例子为例， now.__name__ 从 now 变成了 wrapper。所以我们要在装饰器函数里把原始函数的 name 属性复制到 wrapper() 内部函数中。 你可能马上想到用wrapper.__name__ = func.__name__，事实可以直接@functools.wraps(func)。 一个完整的Decorator： 12345678import functoolsdef log(func): @functools.wraps(func) def wrapper(*args, **kw): print('call %s():' % func.__name__) return func(*args, **kw) return wrapper","link":"/post/551bad5b.html"},{"title":"醍醐灌顶","text":"don’t care about the audience of your blog JUST WRITE","link":"/post/dd2a840f.html"},{"title":"浅析协程","text":"前言以前我们的程序都是单线程，只有一个控制流，在像Web服务这样的应用里不能服务多个用户。后来我们使用多线程，一个用户由一个线程全程负责，CPU根据时间片在线程之间切换，只要CPU切换得够快，用户就感受不到延迟。 但是多线程切换是由操作系统调度的，我们的应用代码无法控制。虽然说，被IO操作阻塞的线程，内核会把它挂起，不参与线程切换。但是线程也不能无限增加，否则CPU时间就花在线程切换和挂起唤醒上了，真正运行代码的时间就少了。 这时候我们就会想，多线程不就是多个控制流嘛，能不能只有一个线程，但有多个控制流，什么时候切换由我们自己决定。当然可以，这就是 协程(Coroutine)。 协程和线程的区别线程由操作系统抢占式调度，一旦开启就不会停下。而协程可以主动暂停、让出。 协程最核心的点：执行到一半的函数或程序片段能够被挂起，稍后再在挂起的地方恢复。 挂起和恢复是应用程序自己控制的。所谓协程，协作式线程也。协程通过主动挂起，让出运行权来实现协作，因此当我们在讨论协程时，我们讨论的是一种程序控制流程的机制。 Python 中的协程generatorPython 的协程是通过 生成器(generator) 来实现的。如果一个函数定义中包含 yield 关键字，那么这个函数就不再是一个普通函数，而是一个generator。 generator 和 函数的区别先来看函数 123456789def funny(): print(1) print(5) print(8)k = funny() # k是 funny 调用的结果， funny 调用了g = funny # g 指向 funny ，funny没有调用g() # g() 等同于 funny() g = funny 说明 g 指向了 funny ，但没有调用， g() 才是调用。但是如果函数里有 yield 关键字，情况就不同了： 12345678910def funny(): yield 1 yield 5 yield 8g = funny()next(g) # 1next(g) # 5next(g) # 8 这里 funny() 是一个 generator，并不是函数调用，所以这里 funny 并没有执行。g 是一个 generator 。执行 next(g) 会返回 yield 后面的值，下一次 next(g) 时，会从上一次 yield 的地方接着往下执行，直到又遇到 yield 又返回。 上面的 next(g) 还可以写成 g.send(None)，是一样的。 12345678910def funny(): yield 1 yield 5 yield 8g = funny()g.send(None) # 1g.send(None) # 5g.send(None) # 8 yield 接收参数用 g.send(None) 调用 generator ，也就是 funny()，实际上，generator 还可以接收参数。 12345678910111213def funny(): param = yield 5 # 第 2 步 yield 5，返回5 | 第 5 步 param = 666 print(param) # 第 6 步 打印 666 yield 8 # 第 7 步 yield 8g = funny()a = g.send(None) # 第 1 步print(a) # 第 3 步，打印 5b = g.send(666) # 第 4 步print(b) # 第 8 步，打印 8 第一次启动 generator 时，只能用 None 作参数。第二次就可以传参了。输出结果为： 12356668 执行过程如下： a = g.send(None)，进入 funny() 协程执行 yield 5，返回5 主程序print(a)，打印了5 主程序g.send(666) 协程从 yield 5 处继续执行，注意，yield 5 之后，不是 print(param)，而是赋值语句 param = print(param)，把 666 打印出来。 yield 8 ，返回 8 主程序print(b)，打印了8 Python协程常用范式比如我有一个 +1 服务，每次 send 就把参数 + 1，实现如下，关键是要理解，第一次会直接 yield response，第二次开始，每次都是从 param = （send的参数） 开始。 123456789101112131415def plus_one(): response = 'init..' while True: param = yield response if not param: return response = param + 1 print(response)po = plus_one()po.send(None)po.send(1)po.send(55)po.send(108) Python协程实现生产者消费者模式123456789101112131415161718192021def consumer(): r = '' while True: n = yield r if not n: return print('[CONSUMER] Consuming %s...' % n) r = '200 OK'def produce(c): c.send(None) n = 0 while n &lt; 5: n = n + 1 print('[PRODUCER] Producing %s...' % n) r = c.send(n) print('[PRODUCER] Consumer return: %s' % r) c.close()c = consumer()produce(c) 例子来自廖雪峰的 Python 教程，就不多说了，自己到 PyCharm 里调试一下，很快就能明白执行过程。 asyncio 和 async/awaitasyncio 是 Python 3.4 引入的标准库， async/await 则是 Python 3.5 引入对使用 asyncio 更好的语法。 简而言之，当我们有多个任务，可以丢到 asyncio 模块的 EventLoop 去，当其中某个任务遇到IO等阻塞操作时，线程不会等待，而是执行 EventLoop 里的下一个任务。 Python 3.4 1234567891011@asyncio.coroutinedef hello(): print(\"Hello world!\") r = yield from asyncio.sleep(1) print(\"Hello again!\")# 获取EventLoop:loop = asyncio.get_event_loop()# 执行coroutineloop.run_until_complete(hello())loop.close() Python 3.5 1234async def hello(): print(\"Hello world!\") r = await asyncio.sleep(1) print(\"Hello again!\") Go 中的协程待补充 Kotlin 中的协程待补充 参考： 《深入理解Kotlin协程》 廖雪峰的 Python 教程","link":"/post/64bfaa6e.html"},{"title":"Docker探索","text":"前言很早之前就听过 Docker 这个名词，知道大概是类似于VM（虚拟机）但又比VM更好的一种新技术，但一直觉得这玩意离我太远。直至在一次又一次地折腾本地虚拟机、云服务器（从VPS到微软云到腾讯云），一次一次地搞崩重新安装之后，我突然想起 Docker 这玩意来，于是这一次决定一探究竟。作为一名开发者，还是不要太拒绝新东西。 什么是 Docker知乎上有一个高赞回答通俗地解释了 Docker 是什么，我的理解是，一台大型服务器（云计算机器）可以看成是一艘大货轮，计算资源就是货轮的荷载。而 Docker 是集装箱，我们只需要把我们的应用规整地打包到集装箱里面，这样我们就无需关心集装箱外部的环境了（一个应用在 Ubuntu 下部署和在 CentOs 下部署配置往往不同，而 Docker 屏蔽了这些不同）。这样，当换一艘货轮，我们只要把集装箱迁走，而不需要对货物进行拆卸重组，省时省力。 在初步理解 Docker 概念的时候，看到国外的一篇文章Docker Use Cases（中文翻译），里面提到，Docker 是一个便携的应用容器。我们可以在 Docker 里面运行几乎任何 Linux 应用，数据库、Node.js服务、Web服务等等。Docker 并不在乎你的应用程序是什么、做什么，Docker 提供了一组应用打包、传输和部署的方法，以便你能更好地在容器内运行任何应用。 Docker用在哪里？快速搭建环境，尝试新软件很多新技术要去使用前可能要搭建环境并测试，而 Docker 让你用一条命令搭建好特定的环境。比如，Docker 只需要一条命令便可以运行 MySQL 数据库： 1docker run -d -p 3306:3306 tutum/mysql 普通用户大概需要一天的时间去搭建 Gitlab 平台，而 Docker 则只需要一条命令。 避免“我机器上可以运行”有时候一个项目，在开发电脑上运行得好好的，到测试机器或生产环境就会出现各种各样的问题（通常是环境和依赖问题）。Docker 镜像并不会因为环境的变化而不能运行，也不会在不同的电脑上有不同的运行结果。可以给测试人员提交含有应用的 Docker 镜像，这样便不再会发生“在我机器上是可以运行的”这种事情。 虚拟机和 Docker 的区别StackOverFlow 有一个问答 How is Docker different from a virtual machine? [closed] 解释了 VM 和 Docker 的区别。其中最重要的一点是，Docker用了 runC(libcontainer) 技术，让运行在 Docker 中的应用能够在共享操作系统上的资源。例如，假如我们有 1GB 的容器镜像要跑在5台机器上，如果我们用5台虚拟机，就分别需要5个1GB。而使用 Docker，仍然只需要1GB因为它们共享了操作系统资源。 下面这张图片介绍了 VM 和 Docker 的区别： Docker 架构Docker的引擎结构： Docker的架构： Docker 核心概念 镜像（image）：包含完整的操作系统环境，类似于我们在微软官网或者Ubuntu官网下载的 .iso 系统镜像文件。只不过，Docker 的镜像里面包含了配置好的应用，并且是轻量级的。Docker 提供了一个很简单的机制来创建镜像或者更新现有的镜像，用户甚至可以直接从其他人那里下载一个已经做好的镜像来直接使用。 仓库(repository)：集中存放镜像文件的场所。有专门的仓库注册服务器（Registry），存放着多个仓库，每个仓库中又包含了多个镜像，每个镜像有不同的标签（tag）。仓库类似于 git，而仓库注册服务器类似于 github。 容器(container)：容器是从镜像创建的运行实例，可以对容器进行启动、删除、开始、停止。可以把容器看做是一个简易版的 Linux 环境（包括root用户权限、进程空间、用户空间和网络空间等）和运行在其中的应用程序。 详细可参阅Docker官方文档。 Docker 安装到 docker官网 下载对应系统的 docker 安装程序。用 Windows 开发，下载Docker Desktop (Windows)。注意：Docker 需要 Hyper-V，因而只有专业版 Windows 10 才能正常安装，但是家庭版也能绕过，如果很不幸你是家庭版，参考这篇文章。安装过程参考官网：https://hub.docker.com/editions/community/docker-ce-desktop-windows 安装完毕后，打开任意终端，输入 1docker version 看到版本信息，即安装成功。 运行 Docker 应用把 Docker 想象成虚拟机，你可以在 Docker 里面运行任何应用。 例如，在win10 Powershell 或 CMD 输入： 1docker run ubuntu:16.04 /bin/echo &quot;hello world&quot; 意思是，在 ubuntu:16.04 的环境下（尽管你现在在用着Windows），运行 /bin/echo 这个程序，echo 在linux系统里是输出文字，这里我们输出hello world。 可以看到，我们电脑上没有 ubuntu:16.04 镜像，于是 docker 自动从网上拉取，完成后执行我们的程序。 用以下命令来交互式： 1docker run -i -t ubuntu:16.04 /bin/bash -i:允许你对容器内的标准输入 (STDIN) 进行交互。 -t:在新容器内指定一个伪终端或终端。 现在，我们跟得到了一个真实的 ubuntu 系统一样，可以命令行操作。这太酷了吧！ docker-composedocker-compose 是一个用来把 docker 自动化的东西。有了 docker-compose ，你可以把所有繁复的 docker 操作全都一条命令，自动化的完成。 参考： 菜鸟教程 CSDN","link":"/post/b1f3af76.html"},{"title":"给自己的 git 备忘","text":"给自己的 git 备忘： git使用流程 git分支管理 git撤销 连接到github fork IDEA git项目颜色含义 git使用流程初始化于一个目录下，初始化git 1git init add新建/修改文件后，把修改内容 add 到 git 上面 1git add . 三个 add 的区别 git add .他会监控工作区的状态树，使用它会把工作时的所有变化提交到暂存区，包括文件内容修改(modified)以及新文件(new)，但不包括被删除的文件。 git add -u他仅监控已经被add的文件（即tracked file），他会将被修改的文件提交到暂存区。add -u 不会提交新文件（untracked file）。（git add –update的缩写） git add -A是上面两个功能的合集（git add –all的缩写） commit 提交到仓库1git commit -m &quot;modified&quot; 关联和同步关联远程仓库1git remote add origin git@github.com:JerrySheh/repository_name.git 推送到远程第一次推送，加 -u 参数 1git push origin branch_name 同步如果远程已经有文件，需要先 pull 1git pull origin master 从远程仓库克隆1git clone git@github.com:jerrysheh/helloworld diffgit diff filepath 工作区与暂存区比较 git diff HEAD filepath 工作区与HEAD ( 当前工作分支) 比较 git diff --staged 或 --cached filepath 暂存区与HEAD比较 git diff branchName filepath 当前分支的文件与branchName 分支的文件进行比较 git diff commitId filepath 与某一次提交进行比较 git 分支管理新建并切换到分支 1git checkout -b branch_name 把新建的本地分支 push 到远程 1git push origin branch_name:branch_name 删除远程分支 1git push origin -d branch_name git 撤销查看更改日志，找到你想返回去的commit_id （一般第一条是你搞错了的，第二条就是上次你想返回去的id） 1git log 撤销提交和修改过的代码 1git reset --hard commit_id 只撤销提交，不撤销修改过的代码（可以直接通过 git commit 重新提交对本地代码的修改） 1git reset commit_id 如果想撤销的commit已经提交到远程仓库了，在本地 reset 修改后，重新强制提交。这样上次的错误提交就消失了。但是这样做有个弊端，就是如果你的错误commit（如commit3）之后还有其他人再提交了(commit4)， commit4也会消失。 1git push --force 在新电脑配置git，并连接到githiub设置 git 的username 和 usermail 12git config --global user.name &quot;yourname&quot;git config --global user.email &quot;youremail&quot; 生成SSH密钥 查看是否已经有了ssh密钥：cd ~/.ssh如果没有密钥则不会有此文件夹，有则备份删除生成密钥： 1ssh-keygen -t rsa -C “haiyan.xu.vip@gmail.com” 按3个回车，密码为空。 1234Your identification has been saved in /home/tekkub/.ssh/id_rsa.Your public key has been saved in /home/tekkub/.ssh/id_rsa.pub.The key fingerprint is:……………… 最后得到了两个文件：id_rsa和id_rsa.pub 在 .ssh 文件夹中执行 ssh-add id_rsa，再输入正确密码 在github上添加ssh密钥，这要添加的是“id_rsa.pub”里面的公钥。 打开 https://github.com/ ,在设置中添加密钥 测试： 123456$: ssh git@github.comThe authenticity of host ‘github.com (207.97.227.239)’ can’t be established.RSA key fingerprint is 16:27:ac:a5:76:28:2d:36:63:1b:56:4d:eb:df:a6:48.Are you sure you want to continue connecting (yes/no)? yesWarning: Permanently added ‘github.com,207.97.227.239′ (RSA) to the list of known hosts.ERROR: Hi Jerrysheh! You’ve successfully authenticated, but GitHub does not provide shell access 测试成功就可以push code和 git clone 之类的操作了。 fork一般如果要参与开源项目，都是先 fork 别人的项目到自己的github，然后通过 git clone 自己的仓库克隆到本地进行修改。修改完毕后，通过pull request向原作者提交合并申请。 但是我们 fork 了别人的项目之后， 原作者 commit 了新内容， 我们 fork 的项目并不会更新。解决办法为：在本地建立两个库的中介，把两个远程库都clone到本地，然后拉取原项目更新到本地，合并更新，最后push到你的github。 流程如下： 1git clone https://我们fork的地址.git cd 进入该目录，git remote -v，可以看到只有两条我们自己的。 1git remote add nsd https://原作者的地址.git 再次git remote -v，可以看到多出来两条。 nsd 只是一个别名，可以任意取 把原作者的更新 fetch 到本地 1git fetch nsd 查看分支 1git branch -av 可以看到，出现一条 remotes/nsd/master xxxxx 的更新 合并 12git checkout mastergit merge nsd/master 如果有冲突，需要丢掉本地分支 1git reset –hard hunter/master 这时你的当前本地的项目变成和原作者的主项目一样了，可以把它提交到你的GitHub库 123$ git commit -am ‘更新到原作者的主分支’$ git push origin$ git push -u origin master -f –强制提交 参考：https://www.jianshu.com/p/633ae5c491f5 LF/CRLFLF will be replaced by CRLF 禁用自动转换即可 1git config –global core.autocrlf false 代理1234567891011# 设置sock5代理git config --global http.proxy 'socks5://127.0.0.1:1080'git config --global https.proxy 'socks5://127.0.0.1:1080'# 设置http代理git config --global https.proxy http://127.0.0.1:1080git config --global https.proxy https://127.0.0.1:1080# 取消代理git config --global --unset http.proxygit config --global --unset https.proxy IDEA git项目颜色含义 绿色： 创建了仓库没有的新文件，还未提交 蓝色： 仓库已有的文件，被修改了，还未提交 红色： 没有添加到版本控制的文件（包括 ignore 的） 参考： IntelliJ IDEA 中git的使用图文教程","link":"/post/9f9a74a3.html"},{"title":"如何从零开始造一台计算机","text":"加法计算是计算机唯一要做的工作。 最近在读 Charles Petzold 的《编码——隐匿在计算机软硬件背后的语言》，英文书名是《Code：The Hidden Language of Computer Hardware and Software》。作者的文笔可谓是轻松风趣，第一页那句“众所周知，手电筒是为了让孩子们能够躲在被子下看书而发明的”就让我产生极大兴趣。读来发觉这本书实际上就是从最基本的电学开始讲起，一步步地揭开一台原始的计算机是如何诞生的这一神秘面纱。同时这本书也帮助我补充了不少数字电路和组成原理的知识，也算是补补基础了。下面是一些笔记。 编码与组合《美国传统英语词典》对编码的其中一个定义是：由被赋予了一定主观意义（arbitrary meanings）的符号、字母以及单词所组成的系统，可用于传输需要 保密或简短 的信息。本质上，编码就是交流。从计算机的角度看，编码是一种人与机器传递信息的方式。莫尔斯电码就是一种经典的编码，用点（dot）和划（dash）的组合来对应不同的字母。例如，求救信号SOS就是一个易于记忆的莫尔斯电码（··· — ···）。 事实上，两个不同的事物，只要经过适当的组合，就可以表示所有类型的信息。而组合的长度，就决定了码字的数目。例如，长度为 1 的组合只能表示 2 种码字（单个点或者单个划），长度为 2 的组合能表示 4 种码字（点点、点划、划点、划划）。实践中我们发现，点和划的数目跟码字的数目的函数关系为 2 的幂次方，如下表： 点和划的数目 码字的数目 1 2 2 4 (2^2) 3 8 (2^3) 4 16 (2^4) 5 32 (2^5) 6 64(2^6) n 2^n 优先码路易斯·布莱叶（Louis Braille）是19世纪法国的一个盲人，他改良的盲文实际上是一种6位的二进制码（6个点），从上表可以知道，6个点可以有64种可能的编排方式。布莱叶盲文中有很大一部分码字会根据上下文的不同有着双重身份，例如，某一个位置的点点上了，就代表数字标识状态，不点上，就切换回字母。这跟我们键盘的 Caps Lock 键很像，按下 Caps Lock 键，输入的就是大写字母，否则是小写。像这样的编码通常称作优先码(precedence codes) 或 换挡码（shift codes）。 进制在我们熟悉的十进制中，数字3572表示2个1 + 7个10 + 5个100 + 3个1000。而在八进制中数字3572表示2个1 + 7个8 + 5个64 + 3个512 。百位是个位和十位的乘的结果。在二进制中，位数从右到左，依次为1的个数，2的个数，4的个数，8的个数……例如，1101表示1个1 + 0个2 + 1个4 + 1个8，结果为十进制的13。之所以在计算机中要用二进制，是从电报机或者灯泡中得到的启示——开/关即可传递信息，再用它们的组合来编码。 电报机和继电器在线路的一端采取一些措施，使线路的另一端发生某种变化，能够实现这种功能的机器就是一个简易的电报机。电磁铁是电报机的基础，在一根铁棒上面用细导线绕几百圈，然后给导线通电，这根铁棒就成了电磁铁。用一个开关和电池来给导线通电，导线一直铺设到远处，一旦通电，远处的铁棒就有了磁性，磁力把旁边的活动横杠拉动，发出“滴”的声音。这样的设备，就是一个电报机。 我们知道，导体越长，电阻越大。如果电报机两端的距离很远，电阻很大以至于电池不足以提供足够的电流。这时候就要用到继电器了，继电器用传进来的电流去驱动电磁铁，拉动金属杠，金属杠又作为一个新的开关，连接了新的电池和导线，传递到另一个远处。这样，我们就可以用多个继电器来延长电报机的传输距离。 继电器就是这样一种用于放大微弱信号来生成强信号的机器。继电器是需要供电的。 布尔代数和逻辑表达式布尔代数是19世纪英格兰数学家乔治·布尔提出的数学理论。传统的代数，操作数代表数字，算子(+、-、×、÷)表示如何运算，而在布尔代数的世界里，操作数是类（class），一个类就是一个事物的群体，也被称为集（set）。“+”表示并集（∪），“×”表示交集（∩）。如果用F表示雌猫，用W表示白猫，那么 F×W 表示白色的雌猫。为了方便，我们用大写英文 OR 来代替“+”，用 AND 代替“×”，用 NOT 代替 “1-”（从全集中去掉某些元素）。 如果我们用F表示雌猫，M表示雄猫，W表示白猫，B表示黑猫。现在我们想得到白色的雌猫，在备选项F、M、W、B的一些表达式中，F和W可以用 1 表示，而其他选项为 0 。这种表示大大简化了表达式。 有了布尔代数和逻辑表达式及其简化表示之后，我们就可以用灯泡、导线、开关来制造我们的AND、OR、NOT计算器了。这其实就是计算机的原型。 逻辑门我们可以给由灯泡、导线、开关组成的电路加多几个支路和开关，以实现更加复杂的功能。比如，闭合两个开关灯泡才会亮的 AND 逻辑电路，闭合两个中的任意一个开关灯泡就会亮的 OR 逻辑电路，以及不闭合开关灯泡才会亮的 NOT 电路。 但是要实现更加复杂的功能，就得用到继电器了。继电器可以作为一个电流控制而非人工控制的开关，我们用不同的接法连接继电器，最终就能实现不同的效果。比如我们串联两个继电器，继电器A的电源开关打开，继电器B的电源开关也打开，然后在起始段通电，这样，电流从起始端到继电器A，再到继电器B，最后到灯泡，导致灯泡亮。而灯泡亮的必要条件是继电器A和继电器B的开关都打开，实际上这就是一个 AND 逻辑电路。 同样，我们可以换一种接法，实现 OR 或 NOT 逻辑电路。再把简单逻辑电路组合成复杂逻辑电路，实现各种各样的功能。 在数字电路中，有与门、或门、与非门、或非门四种逻辑门和反向器（NOT）。 二进制加法器如果想搭建一台计算机，首先要造出可以计算两数之和的器件。事实上，加法计算是计算机唯一要做的工作。只要我们实现了加法，就可以用加法来实现减法、乘法、除法等等。 二进制数相加，当遇到1+1=10时，结果10的1表示进位位，10的0表示加法位。我们可以用与门来实现进位位的表示。将一个与非门和一个或门连接到共同的输入，再加一个与门，就可以用来实现加法位的表示，这种接法叫做异或门 XOR（奇数个1位1，偶数个1为0）。 现在，与门的结果表示进位位，异或门的结果表示加法位，我们将这两个逻辑门接入共同的输入。这就是一个半加器（Half Adder）。半加器的缺陷是，只能实现1位的二进制数相加，多于1位进位位并不会向左累积。 事实上，二进制数相加，是三个位的相加，输入A、输入B和进位输入。用两个半加器和一个或门就能实现，这种组合称为全加器（Full Adder）。把8个全加器串联起来，就能实现8位二进制数的加法了。最低有效位的一对数字相加所得出的进位输出，作为下一对数字的进位位，以此类推。 回归本质，全加器-&gt;半加器-&gt;逻辑门-&gt;继电器，这一切只不过是许多继电器的组合而已！尽管现在的计算机已经用晶体管代替继电器，但原理都是一样的。 如何实现减法在十进制中，999-176=823，我们把 823 叫做 176 的补数，计算对9的补数不需要借位。但如果是 253-176=77 呢？个位 3-6 需要向十位借位，不方便机器计算，为了消灭借位，我们可以把上式改为 253 + (999 - 176) + 1 - 1000。但如果是 176-253=-77呢？改造后的式子176 + (999-256) = 922,922-999依然需要借位，但是我们有一个技巧，因为我们已经知道结果为负，直接把被减数和减数调换，999-922=77，再取负，得-77。简而言之，就是被减数与减数的补数之和，跟999相减。这种方法在二进制中非常好用，因为 在二进制中，求对1补数只需要将0变成1，将1变成0即可。 在二进制中，有没有什么办法来表示负数呢？假如我们有一张银行卡，银行允许你透支500元，账户最多储存不超过500元，那涉及的数字是从-500到+499，在三位十进制中，我们的数字是从000-999，000-499的部分用来表示余额，那透支-500到-1部分，为什么不可以用正数来表示呢？也就是，用500表示-500，用501表示-499…用998表示-2，用999表示-1。这就构成了一个循环。 在二进制中，对2的补数表示如下： 二进制 十进制 1000 0000 -128 1000 0001 -127 1000 0010 -126 1000 0011 -125 … … 1111 1101 -3 1111 1110 -2 1111 1111 -1 0000 0000 0 0000 0001 1 … … 0111 1110 126 0111 1111 127 可以发现，最高位实际上就是符号位（sign bit），1表示负数，0表示正数。计算对2的补数，先计算对1的补数，再加1。这就是我们熟悉的逐位取反再加一。 所以，计算124-127=-3，实际上只需要将-127和124等价的两个二进制数相加。-127用补码表示为10000001，124用补码表示为01111100，相加得11111101，对应上表就是-3。 补码的本质，就是用 0 - 255 来表示-128 - 127。 n 位加法器本身又可以当一个黑箱来使用：它有两个 n 位输入，一个进位输入，一个进位输出以及一个 n 位输出（加法运算的结果）。利用 2 的补码，减法很容易就可以实现，只需要一个由非门构成的求补器和一个表明符号的输入端。 如何计数 用如上图所示的方法连接电磁铁和导线，可以发现，当开关闭合，电磁铁磁力把横杠向下拉，由于横杠断开，电路断开，电磁铁失去磁力，横杠又复原，随着横杠的复原，电路又被接通了，电磁铁又有了磁力把横杠向下拉……像这样，会不断以恒定的频率在连通、开路之间变化的电路称为振荡器（oscillator），又称为时钟（clock），通过振荡器计数也是一种记时方式。 用两个或非门可以组装一种特殊的电路，接通开关A，灯泡亮，断开A灯泡依然亮着，此时接通开关B灯泡被熄灭，断开B灯泡依然熄灭。当两个开关都断开时，电路有两个稳定态，这类电路统称为触发器（Flip-Flop）。触发器的最大特定是它可以保持信息！它可以让电路“记住”之前发生了什么事情。 最简单的触发器是R-S触发器（Reset-Set，复位/置为），用Q表示输出状态，置位就是把Q设为1，复位就是把Q设为0。除了R-S触发器之外，还有一种D触发器，D表示data（数据端输入），除了数据端输入之外还有一个保持位，保持位为1输出就是数据位输入值，保持位为0输出不再随着数据位变化而变化。跟这种触发器相同的电路就是所谓的电平触发D型锁存器，它表示电路锁存住一位数据并保持它，以便将来使用。也称为1位存储器。可以把8个1位锁存器的时钟输入端（保持位）连在一起，构成8位锁存器。加法器计算的结果，可以存放在锁存器里面。 还有一种触发器，只有当电平从0变化到1的瞬间数据端的输入才会影响输出。这种触发器叫边沿触发器（edge-triggered）。我们可以用振荡器作为时钟端的的输入，这样时钟端就不断地在0、1之间切换，从而在规律的时间里影响输出，从而实现计数功能。 将一个振荡器与边沿触发的触发器连到一起，输出结果与振荡器类似，但是频率减半，这是一个分频器。分频器可以继续连接下去，得到时钟频率四分之一、八分之一……的信号。通过控制计数频率，我们就得到了计数器。 字节与十六进制在构造加法器、锁存器等组件时，为什么总喜欢用8位比特流而不是6位、7位或10位呢？其实没有什么特别的原因，只是因为使用8位时，一切工作都显得特别的方便。最早在1956年IBM公司就提出用一个字节（byte）表示8位比特（bit）。一个字节的取值范围从0000 0000 到 1111 1111，代表2^8，即 256 种不同的事物。世界上大部分书面语言的字符都少于 256 个，因此 1 个字节就足以保存不同的文本符号（例如ASCII码）。当然中文、日文等象形文字远远超过256个，然而世界上没有什么是 1 个字节解决不了的，如果有，那就 2 个。所以，2 个字节可以表示 65536 个不同的事物，足以覆盖绝大多数的汉字。 一个8位二进制数，比如10110110，这种表达方式虽然足够直观和自然，但是不够简洁。用十进制表示要经过一系列换算显然更不方便。八进制（最大值为111）3位一组，不太适合。十六进制（最大值1111）正好是两个半字节。1011是十六进制的B，0110是十六进制的6，用B6h表示10110110即直观又方便。 存储器由一个反向器、两个与门、两个或非门构成的D型电平触发器，本质上也是一个1位锁存器。保持位（时钟输入）在这里叫做写操作端，写操作端置为1（之后再置为0），数据输入的结果会被写入到输出端中，这个过程我们叫做存储（stored）。把8个1位锁存器组织成8位锁存器，就可以存储8位二进制数。 然而，假如我们只有一个灯泡可以鉴别输出，对于8位二进制数我们要把灯泡依次连接在8位锁存器的每一个锁存器上面，才能知道每一位的输出是0还是1，这有点麻烦。我们不妨直接在输出端用一个灯泡，再在电路中用3个开关来表示 0 到 7 这 八个数（000-111），通过打开关来鉴别每一位的输出，例如，开关（选择端）为101的时候，输出D5锁存器的值，为001的时候，输出D1锁存器的值。这种用开关来选择应该输出哪个锁存器的值的装置叫做8-1选择器。 还有一个问题，8个1位锁存器连接，数据输入端可以连在一起，但是写操作端却不可以，因为我们很可能要向每个锁存器依次写入数据。我们还是可以用3个开关，来表示我们要把哪个锁存器的写端置1，比如，开关为101的时候，将D5锁存器的写操作端置1，D5的数据端就会写入到输出端。这种装置跟选择器功能类似，作用相反，叫做3-8译码器。 现在，我们有一个3-8译码器、1个8位锁存器（由8个1位锁存器组成）、1个8-1选择器组装起来的家伙。选择器利用 n 位信号（地址）选择总共 2^n 位的锁存器（数据）中哪一位被访问，这样的装置叫做随机访问存储器（Random Access Memory，RAM），或者叫读/写存储器（read/write memory）。之所以叫做随机访问存储器，是因为读写操作很自由，我们只需要改变地址及相关的输入，就可以从8个锁存器中读出或写入需要的数据。 RAM通过特殊的配置可形成RAM阵列（Array）。2个RAM共享写操作端和开关（也叫地址），就形成8×2的RAM阵列，表示可存储的二进制数依然是8个，但位宽位2位。或者，在RAM的输入加多1-2译码器，输出加多一个2-1选择器，变成16×1的RAM阵列，表示存储容量为16。 这样，我们就可以构造任意大小的RAM阵列了。注意，我们现在所构造的RAM，本质上里面都是一个个由电磁铁组成的逻辑门组件，如果断电，这些电磁铁都会失去磁性，然后金属片弹回原位，所有继电器都还原到未触发状态，RAM中存储的数据都会丢失，因此随机访问存储器（RAM）也叫做易失性（volatile）存储器，一旦断电数据就会丢失。 自动操作用8位加法器和8位锁存器，可以先输入一个数到加法器中，然后储存到锁存器里，通过开关往加法器输入第二个数，再将锁存器的值与加法器的数相加，不断循环这种操作，就可以计算多个数的和。用来累加多个数的锁存器称为累加器（accumulator）。 但假如，我们不需要把100个数加在一起，而只是想分别计算100个数某几个之和然后分别存储。这时候可以用存储器RAM来读取数据和保存结果。当然，我们需要振荡器和16位计数器，来选取RAM里面哪个数（地址）该送往累加器里面，然后通过计算，把结果送回RAM里特定的地址。我们把这套装置叫做自动累加器。 实际上我们希望自动累加器完成四件事：第一，把一个字节从存储器传送到累加器中，这个过程叫做加载（load）；第二，把存储器中的另一个字节加（Add）到累加器的内容中去；第三，把累加器中的计算结果取出并存回存储器中（store）;第四，需要一个方法让自动加法器停下来（Halt）。 既然我们有一些需要求和的数据，又有4种操作，为什么不用另一个RAM来存放4种操作，然后通过控制面板决定当前要执行哪种操作呢？于是我们加多一个RAM，用来存储操作码，如 10h 表示 Load， 11h表示 Store，20h表示 Add，FFh表示Halt。这被称为指令码(instruction code)或者操作码(operation code)。他们用来指示电路要执行哪种操作。通过对电路进行改进，我们可以实现更多的操作码，例如减法(Subtract)、进位加法(Add with Carry)、地址跳转（Jump）等。 事实上，没有必要使用两个RAM来分开数据和指令，用3字节长的指令格式，即存放指令本身，也存放操作数所在的存储地址。 计算机能否控制重复操作或者循环（looping）是计算机（computer）和计算器（calculator）的区别。至此，我们可以说我们已经造出了一台原始的计算机，包含四个部分：处理器（processor）、存储器（memory）、至少一个输入设备（input）和输出设备（output）。处理器也叫做中央处理单元（central processing unit，CPU），处理器内部又分为算术逻辑单元（ALU）和程序计数器（PC）。在我们的例子中，ALU由8位反向器和8位加法器构成，只能加减运算，实际上更高级的ALU还能进行逻辑运算。PC由16位计数器构成。 后来，随着科技的发展，渐渐地用真空管替代了继电器，再之后随着半导体技术的崛起，晶体管又替代了真空管。人们才得以把这些逻辑门组件（加法器、累加器、选择器、译码器）集成在微小的电子电路里面，集成电路（IC）得以发展，后来演变成微处理器。微处理器是计算机的大脑。 机器语言和汇编语言操作码在计算机里面，也叫做机器码或者机器语言，表示可以被计算机处理器响应的代码。例如指令代码10h表示加载（Load），11h表示加法（Add），编写代码时，程序员可能难以记住这些代码的意思，因此我们用一些助记符来帮助我们辨认，如用 LOD 表示 Load，用 SUB 表示 Subtract，用 JMP 表示 Jump 等等。数据存放的位置也不用实际的地址，而是用标号（label）来指代，如 2000h 存放结果，我们用 RESULT 代替。于是，我们的程序就演变成这样： 12345678BEGIN: LOD A, [RESULT + 1] ADD A, [NUM1 +1] STO [RESULT + 1], ANEG1: HLTNUM1: 00h, A7hRESULT: 00h, 00h 这就是汇编语言（assembly language）。 字符编码现在，我们已经能用计算机表示数字并进行计算了。但如果要显示文本呢？业界常用ASCII码（美国信息交换标准码）来将十六进制编码映射为字符，ASCII码是7位二进制数，一般用十六进制表示，从00h ~ 7Fh。例如，30h表示字符0（不是数字0），41h表示字符A。ASCII码包括95个图形字符和33个控制字符，例如09h表示水平制表符，当计算机遇到 41 09 42 这样的ASCII码，会输出A B，中间的 tab 空格，就是控制字符09h的含义。 ASCII码也有不足的地方，例如无法统一各国的语言符号（尤其是像中文这样的象形文字）。这导致各国都有自己的一套编码系统，例如中国有国标GBK编码。1988年开始，几大著名计算机公司决定合作研究一套统一的编码系统，取名 Unicode，采用16位编码，每个字符 2 个字节，范围从 0000h ~ FFFFh，总共可以表示65536个不同的字符。 磁盘之前，我们用RAM来存储信息，但是RAM会随着断电而丢失数据。最早人们是通过纸带打孔卡片的方式来保存永久信息。后来丹麦发明家波尔森发明了世界上第一块可用的磁介质存储器。这种设备记录和读取信息是利用电磁铁的磁头（head）来完成的，磁盘的表面被划分为许多同心圆，称为磁道（tracks），每个磁道又被划分为扇形的扇区（sectors），每个扇区可以存放一定数量的字节。微处理器不能直接从磁盘读取数据，而是要先将所需的数据载入内存中，然后才能对其进行访问。 时至今日，磁盘又被分为软盘和硬盘，硬盘又分为机械硬盘和固态硬盘，但固态硬盘的原理跟磁盘已经不是一回事了。 参考资料：《编码——隐匿在计算机软硬件背后的语言》","link":"/post/2f0bdd16.html"},{"title":"给自己的正则表达式备忘","text":"正则表达式（Regular Expression，在代码中常简写为 regex、regexp 或 RE），又称规则表达式，是计算机科学的一个概念。通常被用来检索、替换那些符合某个模式(规则)的文本。 正则表达式的基本规则单个字符匹配 字符 规则 例子 \\ 转义字符 \\(表示左括号 . 匹配除了\\n之外的单个字符一次 a.c \\d 匹配一个数字，等同[0-9] 1\\d8匹配 138 \\D 匹配一个非数字 1\\d8匹配 1A8 \\w 匹配一个字母、数字或下划线(w的意思是word) \\W 匹配一个非字母、数字或下划线 \\s 匹配任何空白字符（空格、制表符、换页符等） \\S 匹配任何非空白字符 x | y 匹配x或者y（表达式） ^ 匹配行首 ^www匹配以www开头 $ 匹配行尾 $com匹配以com结尾 [^A-F] 取反 [^A-F]匹配A-F之外的字符 多个字符匹配 字符 规则 例子 [xyz] 匹配包含的任意一字符 a[xyz]b，匹配 axb，ayb, azb [a-z] 匹配指定范围内的任意字符 [0-9] * 匹配前面的子表达式零次或多次 zo*，匹配z，zo，zoo + 匹配前面的子表达式一次或多次 zo+，匹配zo，zoo ? 匹配前面的子表达式零次或一次 do(es)?，匹配do，does {n,m} 最少匹配n次，最多匹配m次 (o{1,3})，匹配foooood中的3个o {n} 匹配确定的n次 o{2}，匹配food中的oo，不匹配fod中的o 分组匹配可以用括号把要匹配的内容分组，例如匹配带区号的电话号码，可以把区号和电话分组。这样更容易看。 字符 规则 例子 () 分组 (\\d{3,4})\\-(\\d{6,8}) (|) 分组和或的组合 hello\\s(world|ketty|jerry) 分组还有一个好处，当你想使用正则替换时，可以用 $1、$2 来表示第几组的内容。例如，在 Java 中为匹配到的内容前后分别加 &lt;b&gt; &lt;/b&gt; : 1s.replaceAll(\"\\\\s([a-z]{4})\\\\s\", \" &lt;b&gt;$1&lt;/b&gt; \"); 非贪婪匹配假设要求 1230000 后面有几个零，正则为 (\\d+)(0*)，但是却发现第一组匹配到 1230000，第二组匹配到空白。我们期望的是第一组匹配到 123，第二组匹配到 0000。 此时可以在第一组末尾加 ? 表示非贪婪匹配，如：(\\d+?)(0*)，这样第一组就会少匹配，第二组多匹配。 而对于 (\\d??)(9*)， 匹配 9999 时，第一组匹配到空白，第二组匹配到 9999。因为第一个问号表示零次或一次，第二个问号表示非贪婪，正则表达式会按最少的零次来匹配。 匹配中文匹配非ASCII字符，例如中文，用\\u####的十六进制表示，例如：a\\u548cc匹配字符串a和c，中文字符和的Unicode编码是548c。 进阶零宽断言零宽断言，指定的内容的前面或后面会出现满足指定规则的内容，而自己不占匹配位置。例如 123abc ，我想匹配 123 后面的内容abc，而不包括 123 本身。 字符 规则 例子 （?=pattern） 匹配 pattern 前面的内容 \\d(?=\\sword)， 从 1 word 中匹配到 1 （?&lt;=pattern） 匹配 pattern 后面的内容 (?&lt;=num:)\\d， 从 num:5 中匹配到 5 (?!pattern) 匹配非 pattern 前面的内容 i(?!k) ，从 wikipedia 中匹配到不是k前面的i，即 wikipedia (?&lt;!pattern) 匹配非 pattern 后面的内容 (?&lt;!k)i ，从 wikipedia 中匹配到不是k后面的i，即wikipedia 一些实例1.匹配以 Str 开头， r 结尾， 中间任意个任意字符1Str.*r 匹配到 Stringbuffer， StringBuilder 2. 匹配所有以 , 结尾，修改成 comment ‘’,12345查找：(.*),替换：$1 comment '', .表示任意字符，* 表示任意多个，括号用于在下面 $1 保留原内容 效果： 1234567原：not null,NUMBER(20),现：not null comment '',NUMBER(20) comment '', 3. 匹配所有以 [DEBUG] 开头，]] 或 yet 结尾，并且最后有换行符的，由于换行符在 Windows 为 CRLF ，在 Linux 为 LF，所以我们匹配1或2次，第一次 \\s 匹配 CR，第二次匹配 LF 。1\\[DEBUG\\].*(\\]\\]|yet)(\\s{1,2}) tips：用 \\ 来转义特殊符号，如匹配 [ ，要输入 \\[ 4. 匹配16进制数1[0-9a-fA-F] 5. Linux中使用 grep 和正则表达式，查找文件1grep -E --color '[xyz]' filename 一些有用的网站 正则可视化 正则验证和可视化 参考 廖雪峰教程 知乎：你是如何学会正则表达式的？","link":"/post/e36ce161.html"},{"title":"Ubuntu 下配置SS和SSR","text":"Ubuntu 下配置 shadowsocks-qt注意：shadowsocks-qt只能用于SS，不能用于SSR 安装123sudo add-apt-repository ppa:hzwhuang/ss-qt5sudo apt updatesudo apt install shadowsocks-qt5 对于 UBuntu 18.04 ppa:hzwhuang/ss-qt5 并没有18.04版本的源，所以再执行update时会出现 E: 仓库 “http://ppa.launchpad.net/hzwhuang/ss-qt5/ubuntu bionic Release” 没有 Release 文件 的错误。 这时，只要编辑 /etc/apt/sources.list.d/hzwhuang-ubuntu-ss-qt5-bionic.list 文件，将bionic (18.04版本代号)改成xenial（16.04版本代号）。 配置添加服务器地址、密码、连接方式。 gui友好界面。 配置Chrome ，使用插件SwitchyOmega用你能想到的方法找到Chrome SwitchyOmega 插件的 crx 离线包 打开 Chrome 的扩展程序，将 crx 托进去及安装完毕 第一步 新建一个情景模式，更名 shadowsock 代理协议选择 sock5，代理服务器 127.0.0.1， 代理端口 1080 第二步 选择 autoswitch 规则列表设置选择 Autoproxy 规则列表网址如下1https://raw.githubusercontent.com/gfwlist/gfwlist/master/gfwlist.txt 立即更新情景模式 切换规则 - 规则列表规则选择 shadowsock Have fun :) 使用 SSR 客户端安装1234wget http://www.texfox.com/ssr sudo mv ssr /usr/local/binchmod 766 /usr/local/bin/ssr ssr install 一般安装的或者自己写的把全局脚本放在 usr/local/bin 下，这样在终端任意位置可以使用脚本命令 配置1ssr config 然后在弹出来的配置文件中填写你的服务器信息 123456\"server\":\"0.0.0.0\", //服务器ip \"server_port\":8388, //端口 \"password\":\"m\", //密码 \"protocol\":\"origin\", //协议插件 \"obfs\":\"http_simple\", //混淆插件 \"method\":\"aes-256-cfb\", //加密方式 一般配置完之后就会自动启动，如果没有，使用以下命令来启动 1ssr start 使用以下命令来关闭 1ssr stop Chrome 配置同SS","link":"/post/879f3462.html"},{"title":"Win10升级1709后亮度调节失效的解决方法","text":"笔记本升级Win10秋季创意者更新后，发现亮度调节不了了。起初以为是 ATK 热键驱动的问题，到 ASUS 官网重新下载安装了一遍，还是不行。后来在一个台湾的论坛找到解决方法。如下： win10搜索框搜索 Device Manager 或 设备管理器 找到 监视器 会看到一个叫 PnP-Monitor (Standard) 的东西 卸载它！ 操作 - 扫描检测硬件改动 然后神奇地好了。 参考链接： [教程] Windows 10的螢幕亮度無法調整了怎麼辦？","link":"/post/536d7ea0.html"},{"title":"Android 10 ROOT","text":"前言最近收到了一加推送的 OnePlus 5T 氢OS Android 10.0.1 的固件更新，不得不说一加还是很良心的，三年前的机型还保持着官方升级。立马更新尝鲜了，但是更新后，发现我的 ROOT 权限没了。于是到一加社区一番搜索，发现了 这个帖子 提到可以用 platform-tools （这个工具应该不陌生了，线刷必备） 手动刷 magisk.apk 和 magisk_patched.img。 magisk.apk 我知道是我们熟悉的面具软件，但直觉告诉我这个 img 应该是跟固件相关的，帖子里是 10.0 公测版的固件，img 肯定跟 10.0.1 不同了。 那么，从哪里制作对应固件的 magisk_patched.img 呢？ Google It经过一番 Google，在 magisk 的官方文档 里找到了这么一段话： You would want to choose this method if either your device does not have custom recoveries, your device is A/B and you don’t want to mix recovery and boot images, or your device is using system-as-root without A/B partitions. To use this method, you are required to obtain a copy of the stock boot/recovery image, which can be found by extracting OEM provided factory images or extracting from OTA update zips. If you are unable to obtain one yourself, you might be able to find it somewhere on the internet. The following instructions will guide you through the process after you have the copy of boot/recovery image. 意思是说，只要我们能拿到固件刷机包里的 boot image 文件， 用 Magisk 软件可以对其进行 patch， 实际上 magisk_patched.img 就是 boot.img 的修改。并给出了步骤： Copy the boot/recovery image to your device Download and install the latest Magisk Manager If you are patching a recovery image, manually check “Recovery Mode” in Advanced Settings! Press Install → Install → Select and Patch a File, and select your stock boot/recovery image file Magisk Manager will patch the image, and store it in [Internal Storage]/- Download/magisk_patched.img Copy the patched image from your device to your PC. If you can’t find it via MTP, you can pull the file with ADB: adb pull /sdcard/Download/magisk_patched.imgFlash the patched boot/recovery image to your device and reboot. For most devices, here is the fastboot command:123fastboot flash boot /path/to/magisk_patched.img# orfastboot flash recovery /path/to/magisk_patched.img 刚刚下载固件时忘记保存安装包了，更新后被系统升级自动删除了。于是又到一加社区搜到了全量包的下载地址，解压后把里面的 boot.img 提取出来，照着上面的方法很快就制作好了 magisk_patched.img 。 Do It简单复述下步骤，如下： 1. 解锁BootLoader 警告：解锁BootLoader会清空数据，请提前备份 开发者选项OEM解锁打开，开启USB调试连接电脑，adb输入以下命令重启至 bootloader 模式 1adb reboot bootloader 之后在手机上选择 unlock， 重启即解锁 2. 提取 boot.img到官网下载固件全量包，如果是zip，解压缩能看到 boot.img， 直接把 boot.img 拖出来。如果是 payload.bin ，需要用 Payload_Dumber_x64 工具（网上下载）提取（源码参考 github ）。 3. platform-tools使用 platform-tools （网上下载）安装 magisk（网上下载），使用 adb 安装到手机 1adb install magisk.apk 4. 制作 magisk_patched.img就是在 magisk app 里面点安装，再点选择并修补一个文件，将前期提取的固件里的 boot.img 放到手机存储里面，选择你的 boot.img ，然后 magisk 会自动修复，并生成 magisk_patched.img，将 magisk_patched.img 提取到电脑 platform-tools 目录下。 5. 刷入img重启到 bootloader，刷入img。这一步的意思是使用我们的 magisk_patched.img 来驱动手机启动。 12adb reboot bootloaderfastboot boot magisk_patched.img 手机自动重启后，即获得临时 root 权限。 6. 直接安装到 magisk app 里面点安装，再点直接安装，即可获得永久 root 。","link":"/post/3903647e.html"},{"title":"Hexo多终端同步","text":"Hexo 多终端同步问题 我有两台电脑，一台 windows， 一台 Ubuntu 。之前在 Windows 机器下部署了 hexo 博客，现在想在另一台机子的 Ubuntu 系统下同步之前的博客，折腾了一晚上终于搞定。 一、将网站文件上传到 githubhexo部署完毕之后，在 yourname.github.io 上面默认 master 分支是 hexo 编译生成的静态网站，而我们需要将原始网站文件同步到一个新分支上。 1. 新建一个 stat 分支并切换到这个分支1git checkout -b stat 2. 将本地文件上传到 stat 分支123git add .git commit -m &quot;upload static file&quot;git push origin stat:stat 现在，你的 github 仓库 yourname.github.io 下就有两个分支了，一个是 master，存放 hexo编译生成的静态网站，一个是 stat，也就是原始文件。 二、 在新电脑下同步你的原始文件1. 首先安装 nodejs123sudo add-apt-repository ppa:chris-lea/node.jssudo apt-get updatesudo apt-get install nodejs 2. 安装 git1sudo apt-get install git 3. 安装 hexo1sudo npm install hexo -g 4. 配置 git SSH key如果是第一次在这台电脑用git，需要先添加 user.name 和 user.email 可参考我之前写的 git 备忘 然后再配置SSH key 参考：配置SSH key详细教程 5. 在合适的位置新建一个目录，并在这个目录下打开终端5. 打开一个合适的目录位置6. 克隆原始文件（stat）分支到本地1git clone git@github.com:JerrySheh/JerrySheh.github.io.git -b stat blog 这里的 stat 是远程分支名字， blog是新建名为blog的文件夹并把这个分支clone到这个文件夹里 7. 切换到克隆生成的目录1cd blog 8. 依次执行123npm install hexonpm installnpm install hexo-deployer-git 注意：不需要 hexo init ！ 这里有一个坑 由于Ubuntu下已经有一个名叫node的库，因此Node.js在ubuntu下默认叫nodejs，需要额外处理一下 1sudo ln -s /usr/bin/nodejs /usr/bin/node 9. 尝试修改些什么，然后执行123hexo cleanhexo ghexo s --debug 如果出现Error: Cannot find module ‘hexo-util’错误，尝试重装util 1npm install -- save-dev hexo-util 没问题了，开始部署 1hexo d 10. 将静态文件上传到 github stat分支123git add .git commit -m &quot;somethings update&quot;git push origin stat 三、 回到旧电脑，拉取新电脑的更新1. 同步1git pull origin stat:stat 如果遇到以下报错 123456789There is no tracking information for the current branch.Please specify which branch you want to merge with.See git-pull(1) for details git pull &lt;remote&gt; &lt;branch&gt;If you wish to set tracking information for this branch you can do so with:git branch --set-upstream-to=origin/&lt;branch&gt; 将本地 static 和 远程 origin/static 链接即可 1git branch --set-upstream-to=origin/stat stat 2. 开始写文章3. 重新部署123hexo cleanhexo ghexo d 部署前最好先在本地测试一下 ， 使用 hexo s --debug，然后在 127.0.0.1:4000 查看 4. 提交静态文件并推送到远程123git add .git commit -m &quot;somethings update&quot;git push origin stat","link":"/post/63b47f65.html"},{"title":"通过SSH反向代理连接学校内网服务器","text":"问题的来源从老师那里借了两台服务器跑数据，但是老师的服务器没有公网ip，只有学校内网ip，故只能在实验室或者图书馆登录。有没有什么办法，能让我在宿舍或者家里，远程连接进这两台学校内网的服务器呢？答案肯定的，那就是 反向代理。前提是，我得有一台有公网ip的服务器（例如，阿里云服务器或VPS都可以）。 什么是代理？要搞清楚什么是反向代理，就得知道什么是 代理（Proxy）。代理其实就是一个跳板。比如我要去图书馆借一本书，我把要借的书的信息写在纸上，交给图书馆管理员，由图书馆管理员去仓库帮我把书取出来交给我。那我们就说，图书馆管理员是我的代理。 在计算机网络中，代理分为 正向代理 和 反向代理 。 正向代理假如我们访问不了某网站，但是代理服务器可以访问，我们可以让代理服务器去帮助我们访问目标网站，并把结果返回给我们。对于远程目标网站来说，它只得到了一次请求记录，并不知道是我们通过代理服务器访问的，因此正向代理隐藏了我们自身的信息，但也取决于代理服务器告不告诉目标网站。对于我们客户端来说，我自己是知道我使用了代理去访问某个网站的。 总的来说，正向代理是一个位于客户端（client）和原始服务器(origin server)之间的服务器（proxy server）。客户端为了从原始服务器取得内容，向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。 正向代理的用途 访问原来无法访问的资源，如Google 可以做缓存，加速访问资源，如nginx 对客户端访问授权，上网进行认证 代理可以记录用户访问记录（上网行为管理），对外隐藏用户信息 反向代理反向代理（Reverse Proxy）就是用来解决文章开头提出的问题的。在一些服务器群中，只有一台服务器（即反向代理服务器）向外接收来自互联网的连接请求。然后将请求转发给其他真正提供服务的服务器。对于远程服务器来说，服务器之间是知道代理的存在的，相反，对于我们客户端来说，我们并不知道我们连接的是一个反向代理服务器，我们只知道我们向对方发起了某请求，并获得了回应。 反向代理的用途 保证内网的安全：可以使用反向代理提供WAF功能，阻止web攻击。通常，大型网站都会将反向代理作为公网访问地址，Web服务器是内网。 负载均衡：通过反向代理服务器来优化网站的负载 正向代理和反向代理的区别 使用 SSH 反向代理回到文章开头的问题，如何使用反向代理，让我无论在哪里都可以访问学校内网的服务器呢？这就需要用到 SSH 的反向代理功能了。在学校内网服务器中，我们可以通过 SSH 设置反向代理，指向一个有公网ip的服务器（作为我们的反向代理服务器），之后用客户端连接公网服务器时，公网服务器会把请求转交给内网服务器，从而间接登录学校的内网服务器，整个过程，我们作为客户端是感知不到代理服务器的存在的。客户端是否能感知代理服务器的存在，是区别正向代理和反向代理的关键。 SSH 参数介绍12345# 反向代理命令ssh -fCNR# 正向代理命令ssh -fCNL 参数说明： Header One Header Two -f 后台执行ssh指令 -C 允许压缩数据 -N 不执行远程指令 -R 将远程主机(服务器)的某个端口转发到本地端指定机器的指定端口 -L 将本地机(客户机)的某个端口转发到远端指定机器的指定端口 -p 指定远程主机的端口 学校内网服务器操作先跑一趟实验室或图书馆，在内网里面进行操作。 12# ssh -fCNR 远程端口:localhost:本地端口 远程用户@远程ipssh -fCNR 2999:localhost:22 remote_user@123.123.123.123 这句命令的意思是，将远程公网服务器 2999 端口转发至本地 22 端口， remote_user@123.123.123.123是远程服务器用户名和ip 使用 ps aux | grep ssh 来查看是否运行。 公网服务器操作恰好我有一台腾讯云服务器学生机，配有公网ip，可以拿这台服务器作为跳板机（远程代理服务器）。 12# ssh -fCNL *:客户端登录端口:localhost:本地端口 localhostssh -fCNL *:11111:localhost:2999 localhost 这句命令的意思是，将 11111 端口作为本地转发端口，用于与互联网进行通信，并将数据转发至 2999 端口，而 2999 端口的数据会被刚刚配置的学校内网服务器接收。 登录现在，用一台位于任意地方的电脑 1ssh -p11111 学校内网用户名@公网ip地址 这样就可以访问到学校内网了。 免密登录1ssh-copy-id 公网用户名@公网ip 用autossh建立稳定隧道autossh 跟 shh 不同的地方在于，当隧道断开的时候，autossh 会自动重新连接，而ssh不会。 centos 安装（内网服务器操作） 1yum install autossh 反向代理（内网服务器操作） 1autossh -M 6666 -fCNR 2999:localhost:22 公网用户名@公网ip -M参数指定一个端口，这个端口是公网机器用来接收内网机器的信息，如果隧道不正常而返回给内网机器让他实现重新连接。 配置开机启动（内网服务器操作）123vi /etc/rc.d/rc.localautossh -M 6666 -fCNR 2999:localhost:22 公网用户名@公网ipchmod +x /etc/rc.d/rc.local 不止SSH到这里就已经解决了文章一开始的问题了。但是突发奇想，除了ssh之外，有没有办法，能够远程访问没有公网ip的电脑上面架设的Web服务或者Ftp服务呢？例如，在家里的电脑（没有公网ip）上架了一个网站，那出门的时候有没有办法远程访问家里的整个网站？事实上，这是完全可行的，借助的也是反向代理，但有了一个新的名词——内网穿透。现在市面上内网穿透的软件很多，比如花生壳、ngrok，使用这些工具，不仅仅可以反向代理ssh的22端口，还可以代理任意 tcp 或 udp 端口，非常有用。 使用 ngrok 进行内网穿透ngrok 的官网是 https://ngrok.com/ ，是一个专注于建立反向代理隧道的软件。 客户端使用方法到官网申请一个账号，会得到一个 TOKEN ，下载安装完客户端软件后，执行以下命令即可： 123unzip /path/to/ngrok.zip./ngrok authtoken &lt;YOUR_AUTH_TOKEN&gt;./ngrok http 8080 这样，你内网机器的80端口即会被映射到公网上了。例如，访问 http://myapp.ngrok.io ，即相当于访问了你内网里面的 127.0.0.1:8080 自己编译服务端软件ngrok是开源的，可以自己编译服务端软件，并将自己的公网服务器作为反向代理服务器。前提是得有公网ip + 域名（国内需备案）。 由于我没有域名，所以这部分就没有实践了。具体步骤可以参考官方文档教程：https://developer.github.com/webhooks/configuring/ 参考资料 利用ssh反向代理以及autossh实现从外网连接内网服务器","link":"/post/44ca081e.html"},{"title":"记一次玄幻的重装系统经历","text":"慢慢地对 Windows 的依赖越来越少，装了 Win10 + Ubuntu 16.04 双系统的电脑经常要切来切去，SSD也只有128G，一分区差不多就没了。而且一台电脑同时搞两套系统确实太烦了。索性想着把 Win10 格掉，直接128G SSD里面只装一个 Ubuntu 16.04 。 于是用熟悉的 U 盘装系统方法，却突然发现，U盘借别人了，要一周后才还回来。 等待了几天之后，突然发现家里有张 8G 内存卡 + 读卡器， 组合起来不就是一个U盘嘛。 说干就干， 用 UltralISO 刻录了镜像文件， 插上我的小米笔记本， BIOS选择U盘启动， 进入 Ubuntu 安装界面。 一切操作都是那么完美，然鹅，安装界面启动后卡了几秒钟，然后闪退，回到试用界面，再次点击 Install Ubuntu， 闪退。。 用另一台电脑，重新刻录了U盘镜像文件，还是不行， 换一个软件，大名鼎鼎的rufus，尝试了 MBR+GPT多种启动方式， 还是如此。 查了很多资料，怀疑是 内存卡 + 读卡器 组合，读写速度太慢或者跟小米笔记本 USB 3.0 接口兼容性问题balabala什么的。 遂放弃，等待我的U盘回来。 就这样，几天过去了。我的U盘拿回来了。 第一件事就是用老办法，刻录，重装。 熟悉的Ubuntu暗紫色启动界面 5秒钟之后，黑屏白字，出现： 12...unable to find a medium containing a live file system WTF! 用多种方式重新刻录，无果，还是unable to find a medium containing a live file system WTF! ！！ 各种百度、Google、StackOverflow，没办法。 只能往U盘里装个PE，进去先把win10格掉，128G的SSD全部清空！ 然鹅，还是不行！ 然后无意间浏览到不知道是不是 Ubuntu 官方论坛的一个网站（ https://askubuntu.com/ ） 看到一个提问 When I start the Ubuntu ISO, initramfs says “unable to find a medium containing a live file system”) 然后看到一个回答 Using Ubuntu 17.04 ISO on a SanDisk 32GB USB stick. My m/board is ASROCK B250M. None of the suggestions I read online worked for me. I noticed, though, that the USB stick was mounted when I pulled it out and plugged it back in, so when the installation was showing the Ubuntu ‘wait’ screen with flashing dots, I figured it was looking for the installation media, so I pulled out the USB stick and pushed it back in. Hey presto! - the installation media was found and I managed to install Ubuntu. 同样是装系统，同样是SanDisk 32GB 的 U盘，遇到同样的问题 简单地说，他的解决办法是：在Ubuntu暗紫色启动界面闪烁的时候，重新插拔一下U盘。 哦？这么神奇的吗？试试 就是这个界面，对准U盘，拔——插—— WTF ！！ It work！！ 然后就进入到安装程序了。 终。 最后简单说几点 SD卡 + 读卡器 组合装系统，有可能会出错装不了 （但是我在另一台电脑却可以，应该是兼容性问题） FAT32格式的U盘装系统不用 Disable Secure BOOT, NTFS的需要 SanDisk 的U盘装系统有坑！ PE推荐 WePE 学好英语还是有用的","link":"/post/e84807f.html"},{"title":"使用Synergy在两台电脑之间共享键盘鼠标","text":"之前写过如何在两台电脑中同步hexo博客编辑，利用 git 和 github 同步hexo的博客。 然后又经历了一次玄幻的重装系统经历 都是两台电脑引起的。 然鹅这次，一切又要从有两台电脑说起… 问题有两台电脑，一台是 Windows 10 操作系统， 另一台是 Ubuntu 16.04， 两台电脑同时使用的时候，只有一套键鼠，插来拔去非常不方便。 有没有什么办法，一套键鼠，同时控制两台电脑呢？ 答案是肯定的。 Synergy网上搜寻了很多解决方案，最佳的貌似只有 Synergy 了。 Synergy是一款跨平台软件，可以实现多台电脑共用一个鼠标和键盘。 官方的介绍是： Synergy将您的桌上设备结合，升华成为一种综合性的体验。这是一款能够让您的几台电脑，共享一个鼠标和键盘的软件。它可在Windows、macOS和Linux上运行。 但是查资料发现，Synergy以前是有免费版的，现在好像要付费了，价钱是19美元/终身，淘宝也有一些代理只要19人民币永久授权。 不过，在 github 上面还是能搜到免费开源的版本 该版本已不可用，老老实实买正版吧 项目地址：https://github.com/brahma-dev/synergy-stable-builds/ 下载地址：https://www.brahma.world/synergy-stable-builds/ 开始使用建议两个系统使用同一个版本，且最好下载最新版（目前2018/02/09是 1.8.8 版本），如果版本不一样或者虽然一样但是版本比较旧，可能会产生一些奇奇怪怪的问题。比如我一开始折腾的时候下载了1.8.7 和 1.6.0 （Ubuntu apt仓库的版本），就出现了鼠标在客户机无法移动的问题。 我这里 Windows 10 下载 Windows X64 ， Ubuntu 下载 Ubuntu/Debian - x86_64 （v1.8.8-stable） Windows 10 服务机配置直接安装，然后选择 Server 作为服务端，点击设置服务端，将右上角的电脑拖到合适的位置（根据你的办公桌两台电脑摆放的相对位置），然后双击刚刚放上去的电脑图标，名字改为Ubuntu系统的电脑名字。 最后点击应用，然后点开始，服务就启动了。可以把软件最小化到托盘。 Ubuntu 客户机配置安装deb包 1sudo dpkg -i synergy-v1.8.8-stable-Linux-x86_64.deb 安装相关依赖 1sudo apt-get install -f 启动synergy 1synergy 然后选择 Client 作为客户端，服务端ip填局域网服务机的 ip （在win10下打开cmd输入 ipconfig /all， 192.168.x.x 那个），或者在synergy软件可以看到这个ip地址。 然后直接点击应用，开始。 这样，两台电脑就实现了两台电脑共享一套键鼠的神操作了。 最后Synergy 还支持复制粘贴文件，剪贴板等功能，不得不说确实很强大。 但是有时候在客户机操作的时候会发现有一点点卡顿，或者失灵，很大的可能性是wifi不稳定导致的。解决办法很简单，这里提供两个方法： 用一根网线将两台电脑连接起来，然后在以太网设置里给两部机分别分配一个ip，再重新填一下synergy客户机的ip地址，连接外网可以用wifi win10自带共享热点，在设置-网络和Internet-移动热点里面开一下热点，然后客户机连接这个热点上网即可，当然别忘了重新填一下synergy客户机的ip地址 （完）","link":"/post/da6510de.html"},{"title":"Hadoop 配置遇到的一些坑","text":"一、 Connection refused根据官方文档 Hadoop 3.0 配置，在 1sbin/start-dfs.sh 的时候报错， 1pdsh@ubuntu: localhost: connect: Connection refused 原因是pdsh默认采用的是rsh登录，修改成ssh登录即可，在环境变量/etc/profile里加入： 1export PDSH_RCMD_TYPE=ssh 然后source /etc/profile 之后重新sbin/start-dfs.sh 二、jps 没有 namenode 或者 datanode每次开机都得重新格式化一下namenode才可以看到namenode 格式化了namenode，datanode又没有了 其实问题就出在tmp文件，默认的tmp文件每次重新开机会被清空，与此同时namenode的格式化信息就会丢失 于是我们得重新配置一个tmp文件目录 首先在home目录下建立一个hadoop_tmp目录 1sudo mkdir ~/hadoop_tmp 然后修改hadoop-3.0.0/etc/hadoop目录里面的core-site.xml文件，加入以下节点： 12345&lt;property&gt; &lt;name&gt;hadoop.tmp.dir&lt;/name&gt; &lt;value&gt;/home/jerrysheh/hadoop_tmp&lt;/value&gt; &lt;description&gt;A base for other temporary directories.&lt;/description&gt;&lt;/property&gt; 注意：我的用户是jerrysheh，所以目录是/home/jerrysheh/hadoop_tmp OK了，重新格式化Namenode 1hadoop namenode -format 然后启动 1hadoopstart-all.sh 然后输入 jps， namenode 和 datanode 应该都出来了 三、关于 HDFS 文件夹位置根据 官方文档 第一次运行，启动 start-dfs.sh 之后，要先创建用户 12bin/hdfs dfs -mkdir /userbin/hdfs dfs -mkdir /user/&lt;username&gt; 然后创建一个 input 文件夹，用来放数据 1bin/hdfs dfs -mkdir input 发现了吗？ -mkdir /user 和 -mkdir /user/&lt;username&gt; 是在根目录下创建 user 文件夹，然后在 user 文件夹里创建 username 文件夹， 这没有问题。 但是创建 input 文件夹的时候， 前面没有 / 意味着，是在默认的 username 文件夹里面创建了这个 input ！ 也就是， input 的实际位置在 /user/&lt;username&gt;/input 打开 web UI ( 127.0.0.1:8088 )看一下 果然如此 另， 12hdfs dfs -ls . /*表示当前用户目录*/hdfs dfs -ls / /*表示根目录*/ 使用 hdfs dfs -ls . 的时候， HDFS 上的 username 必须和你本地linux系统的 username 一致！否则会显示没有该目录或文件。 四、Windows 环境下 JAVA_HOME 路径不对配置好环境以后，执行格式化 1hdfs namenode -format 然后报错 12Error: JAVA_HOME is incorrectly set. Please update F:\\hadoop\\conf\\hadoop-env.cmd 原因是蛋疼的微软， Program Files文件夹有一个空格，导致不能被 Hadoop 识别。 解决办法： 方法1：用路径替代符 1C:\\PROGRA~1\\Java\\jdk1.8.0_91 PROGRA~1 ===== C:\\Program Files 目录的dos文件名模式下的缩写长于8个字符的文件名和文件夹名，都被简化成前面6个有效字符，后面1，有重名的就 ~2,3, 方法2：用引号括起来 1&quot;C:\\Program Files&quot;\\Java\\jdk1.8.0_91 五、IDEA 报 java.lang.ClassNotFoundException 问题在 IDEA 本地环境运行 hadoop 程序时， IDEA报错 1java.lang.ClassNotFoundException: org.apache.hadoop.conf.Configuration 原因： 在 maven 中， 把依赖项的 provided 标签删掉即可 。因为加上provided标签意味着 the scope tag tells Maven that you’re using this dependency for building, but it indicates that the dependency will be provided during runtime, so you’ll either need to remove this tag or … (具体可到 StackOverFlow 看) 感谢 StackOverFlow 解决困扰了我一天一夜的问题 123456&lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt;&lt;/dependency&gt; 六、IDEA Hadoop程序 单机运行 和 在本地伪分布式 运行单机运行新建 Java Maven 工程，pom.xml添加依赖 1234567891011121314151617181920212223242526272829&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;!--&lt;scope&gt;provided&lt;/scope&gt;--&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-client&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-mapreduce-client-core&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-mapreduce-client-common&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt; &lt;artifactId&gt;hadoop-hdfs&lt;/artifactId&gt; &lt;version&gt;3.0.0&lt;/version&gt; &lt;/dependency&gt; &lt;/dependencies&gt; 依赖去哪里找？ 有一个 mavenrepository 仓库，地址是：mavenrepository 然后在上面搜索 hadoop ，一些常见的依赖在上面，点击，选择版本，然后复制它的maven代码， 在pom.xml粘贴。 当然这里有坑！ 看上面第五！！ 然后右下角 import， maven 会自动帮我们下载依赖包 点 Run -&gt; Edit configuration， Program argument填入 1input/ output/ Main class 填你的main程序所在的 class ，可以输入前几个字母然后 IDEA 会自动帮我们检索 然后在项目目录下，新建一个文件夹 input ， 往里面放你输入的数据（比如 mydata.log），可以放多个文件 然后运行即可 本地伪分布式运行本地Hadoop环境先配起来，具体看这篇 http://blog.csdn.net/songhaifengshuaige/article/details/79575308 环境变量 HADOOP_HOME， 设置为 C:\\hadoop-3.0.0 （根据你的目录）Path， 添加%HADOOP_HOME%\\bin 和 %HADOOP_HOME%\\sbin 然后先启动 start-dfs.cmd 和 start-yarn.cmd 输入jps命令，看看 datanode 和 namenode 启动没，确保集群环境启动了 然后把 C:\\hadoop-3.0.0\\etc\\hadoop\\ 里面的配置文件 （几个dfs、core、mapred、yarn相关的 xml 文件），放到 项目 src/main/resource 里面 然后运行。DONE！ 七、Spark standalone 模式集群配置记得关防火墙 12service iptables statusservice iptables stop 有一个WARN，提示你本地ip是127.0.0.1，应该该到 172.x.x.x 或 192.x.x.x ，否则局域网机器访问不到。 12cp ./conf/spark-env.sh.template ./conf/spark-env.shvim ./conf/spark-env.sh 添加 123SPARK_LOCAL_IP=172.x.x.xSPARK_MASTER_HOST=172.x.x.xSPARK_EXECUTOR__MEMORY=16G","link":"/post/a44bfe3f.html"},{"title":"Hadoop大数据生态（一）初识","text":"前言当数据量变大的时候，一台机器完成一个问题要计算好久好久。这时候就需要多台机器并行运算。然而，每台机器不能用单台机器运行的算法，自己算自己的。而是要有不同的分工，联合起来共同算完这个问题。 Hadoop就是这样的一个大数据处理框架。其中包括很多开源的处理框架，比如： 文件存储：Hadoop HDFS、Tachyon、KFS 离线计算：Hadoop MapReduce、Spark 流式、实时计算：Storm、Spark Streaming、S4、Heron K-V、NOSQL数据库：HBase、Redis、MongoDB 资源管理：YARN、Mesos 日志收集：Flume、Scribe、Logstash、Kibana 消息系统：Kafka、StormMQ、ZeroMQ、RabbitMQ 查询分析：Hive、Impala、Pig、Presto、Phoenix、SparkSQL、Drill、Flink、Kylin、Druid 分布式协调服务：Zookeeper 集群管理与监控：Ambari、Ganglia、Nagios、Cloudera Manager 数据挖掘、机器学习：Mahout、Spark MLLib 数据同步：Sqoop 任务调度：Oozie 那这么多，要怎么学呢？吴军博士在《数学之美》中提到： 分治算法是计算机科学中最漂亮的工具之一，我称为“各个击破”法。 我们就来各个击破。当然，先挑重点的学习。 MapReduce假设我们要统计一本10000页的书里面，”apple”、”banana”、”orange”这三个单词出现的次数。由于规模很大，用一台机器来算，要算很久。我们能不能把规模缩小，交给多台机器去算呢？我们容易想到，可以拿4台服务器，假设为1，2，3，4，每台服务器计算2500页，各自算各自的。 好了，现在每台服务器把各自负责的2500页统计完了。但我们关心的是 10000 页这个总量里面单词出现的次数，而不是4个独立的2500页。这 4 个 2500 页的结果分别保存在1，2，3，4四台服务器上。我们现在要想办法合并结果。 于是我们找来另外三台服务器，假设为A，B，C： 让 A 计算在机器1，2，3，4上面 “apple” 单词出现的总次数。 让 B 计算在机器1，2，3，4上面 “banana” 单词出现的总次数。 让 C 计算在机器1，2，3，4上面 “orange” 单词出现的总次数。 这样，我们就知道每个单词出现的总次数了。 以上就是 Hadoop 简单的基本原理。我们称为 MapReduce模型。这个模型分为三个阶段： Map阶段：每台机器先处理本机上的数据。（对于机器1来说，就是计算前2500页”apple”出现的次数） Shuffle阶段：各个机器处理完自己的数据后，用另一批机器（或者还是这些机器）去收集某个数据的总和。（对于机器 A 来说，就是把 4 个 2500页 的”apple” 汇总。） Reduce阶段：把多个数据的总和规约、合并，出最终结果。（把汇总的“apple”、”banana”、”orange” 归并） MapReduce编程模型首先，程序会先读取文件，交给 InputFormat 预处理。InputFormat主要做两件事： getSplits：返回 InputSplit 数组，即对数据进行 split 分片，每片交给map操作一次 getRecordReader：返回 RecordReader 对象，对每个 split 分片进行转换为 key-value 键值对格式传递给map 实际上常用的是 TextInputFormat，就是将文件的内容按行分割（split），形成 K-V 对。key是偏移量，value是该行的值。使用的是hadoop内置的数据类型，比如longwritable、text等。 例如，原始文件为 123hello hadoopand hello sparkspark TextInputFormat预处理后的结果为 123&lt;0，hello hadoop&gt;&lt;13, hello spark&gt;&lt;29, spark&gt; 之后，将这个 K-V 对集合输入 mapper，进行业务处理过程，将其转换成需要的key-value再输出。 mapper后的结果为 12345&lt;hello, 1&gt;&lt;hadoop, 1&gt;&lt;hello, 1&gt;&lt;spark, 1&gt;&lt;spark, 1&gt; 之后，进行 shuffle(洗牌)操作，这个过程把 key 相同的value合并成list，作为reduce输入。 shuffle后的结果为 123&lt;hello, &lt;1,1&gt;&gt;&lt;hadoop, 1&gt;&lt;spark, &lt;1,1&gt;&gt; reduce的结果为 123&lt;hello, 2&gt;&lt;hadoop, 1&gt;&lt;spark, 2&gt; Hadoop Distribute Filesystem (HDFS)当数据集大小超过一台计算机的存储能力时，就有必要对它进行分区（partition）并存储到多台计算机上。管理网络中跨多台计算机存储的文件系统称为 分布式文件系统（distribute filesystem）。 Hadoop 自带一个分布式文件系统，称为 HDFS。 HDFS 的设计包括可存储超大文件、流式数据访问、用于商用硬件（指的是普通硬件而不是精密昂贵的硬件）、低时间延迟的数据访问、大量的小文件、单用户写入和只添加等设计特点。 数据块HDFS上的文件被划分为多个分块（chunk），作为独立的存储单元。 NameNodeHDFS 之所以可以存很大的文件，是因为每个文件都会被分成一些 data block，存在不同机器上。但是当我们操作 HDFS 时，并不需要关心数据是如何分布式存储在各个结点上的，HDFS 展现给我们的只是类似于普通 Linux 那样的文件系统。那么，数据怎么存，存在哪里，这些信息是谁管理的呢？这就需要 NameNode 了。 NameNode 主要是用来保存 HDFS 的元数据信息，比如命名空间信息，块信息等。当它运行的时候，这些信息存在内存中（也可以持久化到磁盘上）。namenode 负责记录一个文件有哪些 data block，以及这些 data block 分别存放在哪些机器上。 SecondaryNameNode在 HDFS 中，有这么两个文件 fsimage：它是在 NameNode 启动时对整个文件系统的快照 edit logs：它是在 NameNode 启动后，对文件系统的改动序列 只有在 NameNode 重启时，edit logs才会被合并到 fsimage 中，从而得到一个文件系统的最新快照。但是，在产品集群中，NameNode 是很少重启的，因此 edit logs 可能会变得非常大，导致下一次 NameNode 启动时要合并很多文件，启动时间非常久。 我们要做的事情是：如何在不重启 NameNode 的前提下，及时更新系统快照，减少edit logs文件的大小，得到一个最新的fsimage文件 ? SecondaryNameNode 就是负责做这件事的。其主要任务是 合并 NameNode 的edit logs（修改过的日志）到 fsimage（系统快照） 文件中。 datanodedatanode是工作节点，用于存储并检索数据块（data block）。定期向 namenode 发心跳包。 当我们读取一个文件时发生了什么 HDFS client 联系 Name nodes，获取文件的 data blocks 组成、以及每个 data block 所在的机器以及具体存放位置； HDFS client 联系 Data nodes, 进行具体的读写操作； 数据备份分布式文件系统中，文件存储在多台机器上。如果其中某一台故障了，系统要确保依然能够正常运行。HDFS 是如何保证在机器故障情况下文件数据依然不丢失的呢？说白了，就是做数据备份，也就是多存几份。我们可以手动配置备份数量，HDFS默认是 3 份。 一般存储 HDFS 文件的机器都是在机架（Rack）上的，很多数据中心里的故障都是一整个 Rack 出问题。因此通常在同一个 Rack 上储存一份，然后在另一个 Rack 上储存另两份。这样就保证数据有更高的安全性。 HDFS client 写文件创建新的 block 时，NameNode 会为这个 block 创建一个唯一 ID， 并决定由哪些 dataNode 来存放。被选中的 dataNode 组成一个队列，client 只向队列第一个 dataNode 写，第一个 dataNode 存储完毕后，继续向队列第二个 dataNode 传递。 HDFS 的基本操作必须先启用 HDFS 之后才能进行操作。 1./sbin/start-hdfs.sh 将本地文件上传到 hdfs 上（原路径只能是一个文件） 1hdfs dfs -copyFromLocal /local/data /hdfs/data 和 copyFromLocal 区别是，put 原路径可以是文件夹等 1hdfs dfs -put /tmp/ /hdfs/ 查看根目录文件 1hadoop fs -ls / 查看/tmp/data目录 1hadoop fs -ls /tmp/data 查看 a.txt，与 -text 一样 1hadoop fs -cat /tmp/a.txt 创建目录dir 1hadoop fs -mkdir dir 删除目录dir 1hadoop fs -rm -r dir 在 HDFS 中，就不要 cd 了， 用 ls + 目录 Hadoop fs 和 hdfs dfs的区别Hadoop fs：使用面最广，可以操作任何文件系统。 hadoop dfs与hdfs dfs：只能操作HDFS文件系统相关（包括与Local FS间的操作），前者已经Deprecated，一般使用后者。 Yet Another Resource Negotiator (YARN)YARN 是 Hadoop 的集群资源管理系统。 YARN 提供请求和使用集群资源的API。但很少用于用户代码，因为在 YARN 之上的如MapReduce、Spark等分布式计算框架向用户隐藏了资源管理的细节。 一般来说，HDFS在Storage底层、YARN在Compute中间层，往上的Application上层才是MapReduce、Spark等计算框架。（甚至Application之上还能再封装一层，如Pig、Hive等） Hadoop有两类长期运行的守护进程： 资源管理器：管理集群上资源的使用 节点管理器：运行在集群中所有节点上切能够启动和监控容器的东西 YARN 则是管理这两个守护进程的。 Hivehive是基于Hadoop的一个数据仓库工具，可以将结构化的数据文件映射为一张数据库表，并提供简单的sql查询功能，可以将sql语句转换为MapReduce任务进行运行。 小结HDFS是Hadoop提供的分布式存储框架，它可以用来存储海量数据，MapReduce是Hadoop提供的分布式计算框架，它可以用来统计和分析HDFS上的海量数据，而Hive则是SQL On Hadoop，Hive提供了SQL接口，开发人员只需要编写简单易上手的SQL语句，Hive负责把SQL翻译成MapReduce，提交运行。","link":"/post/e2142b57.html"},{"title":"Scala中的函数式编程","text":"Scala是一门多范式编程语言，混合了 面向对象编程 和 函数式编程 的风格。 在大数据处理中为什么要函数式编程？ 函数式编程的一个重要特性就是值不可变性，这对于编写可扩展的并发程序而言可以带来巨大好处。因为它避免了对公共的可变状态进行同步访问控制的复杂问题。简单地说，我们完全不需要进行传统并发编程里面的同步、加锁等操作。 函数字面量在面向过程和面向对象编程中，数据包括：类型 + 值。在函数式编程中，函数也可以跟其他数据类型一样，进行传递和操作。函数的使用跟其他数据类型没什么区别。函数也包括 类型 + 值。函数的值，就是函数字面量。 函数的类型考虑下面的例子 123def counter(value: Int): Int = { value += 1 } 输入一个 Int， 输出一个 Int ，因此这个函数的类型是：Int =&gt; Int 函数的值把函数的类型声明部分（def counter）去掉，剩下的就是函数的值了。 在上面的例子中，输入 value， 输出 value+1 ，因此这个函数的值是： 1(value) =&gt; {value += 1} 用函数式的方法定义函数定义一个 Int 类型变量，可以： 1val num: Int = 5 有了函数式编程的思想后，定义一个函数，可以： 1val counter: Int =&gt; Int = { (value) =&gt; value += 1} 我们定义了一个 counter 函数。 这个函数的类型是Int =&gt; Int，输入一个 Int，输出一个 Int 这个函数的值是value =&gt; value +=1，输入一个 value，输出 value + 1 Lambda表达式与闭包像 (参数) =&gt; 表达式 这样的定义形式，我们称之为 Lambda 表达式。其实就是用函数式的方法定义函数。例如： 1val myNumFunc: Int =&gt; Int = (num: Int) =&gt; num * 2 Scala有类型推断，因此可以简化为： 12345// 省略前面类型val myNumFunc = (num: Int) =&gt; num * 2// 省略后面类型val myNumFunc: Int=&gt;Int = (num) =&gt; num * 2 闭包闭包是一种比较特殊的函数。闭包会引用函数外部的变量。 vczh：闭包不是“封闭内部状态”，而是“封闭外部状态”。一个函数如何能封闭外部状态呢？当外部状态的 scope 失效的时候，还有一份留在内部状态里面。 例如，定义一个函数： 1val addMore = (x: Int) =&gt; x + more 变量more并不是在函数内部定义的，而是函数外部的变量。 闭包（是一个函数）对捕获的外部变量做出的改变，在闭包之外是可见的！ 高阶函数一个接受其他函数作为参数 或者 返回一个函数 的函数就是高阶函数。 以求和函数为例： 不使用高阶函数123def sumInts(a: Int, b: Int): Int = { if (a &gt; b) 0 else a + sumInts(a+1, b)} 使用高阶函数12345678910// 求和函数，传入一个函数、两个 Intdef sum(func: Int =&gt; Int, a: Int, b: Int): Int = { if (a &gt; b) 0 else a + sum(func, a+1, b)}// self函数def self(x: Int): Int = x// 重新定义sumInts函数def sumInts(a: Int, b: Int): Int = sum(self, a, b) sum 函数的参数是 （Int=&gt;Int, Int, Int）， 结果是 Int， 因此， sum 函数的类型是： 1（Int=&gt;Int, Int, Int） =&gt; Int 也就是说，函数sum是一个接受函数参数的函数，因此，是一个高阶函数。 占位符语法当每个参数在函数中最多出现一次时，可以使用 _ 占位符来表示一个或多个参数。 12345678910111213object Run { def main(args: Array[String]): Unit = { val list = List(-3, -5, 1, 9, 6, -99) val list2 = rList.filter(x=&gt;x &gt; 0) println(list2) val list3 = List.filter(_ &gt; 0) println(list3) }} list2 和 list3 完全一样。也就是说，在这个例子中，x =&gt; x 和 _ 完全一样。即把 List 中的每一个元素作为 x 传入。 Scala内置的高阶函数mapmap 对集合中的每个元素进行操作。 12345val numberList = List(-3, -5, 1, 9, 6, -99)val numberList2 = numberList.map(x =&gt; x+1)println(numberList2) 输出： List(-2, -4, 2, 10, 7, -98) flatMapflatMap是map的一种扩展。跟 map 不同的是， flatMap 会将子集合进行合并。 12val books = List(\"haddop\", \"spark\", \"scala\")println(books.map(s=&gt;s.toList)) 输出：List(List(h, a, d, d, o, p), List(s, p, a, r, k), List(s, c, a, l, a)) 12val books = List(\"haddop\", \"spark\", \"scala\")println(books.flatMap(s=&gt;s.toList)) 输出：List(h, a, d, d, o, p, s, p, a, r, k, s, c, a, l, a) filter遍历一个集合，并从中获取满足指定条件的元素组成一个新的集合。 reducereduce函数能把结果继续和序列的下一个元素做累积计算。结果就是计算的结果。 1234val numberList = List(-3, -5, 1, 9, 6, -99)val numberList2 = numberList.reduce(_ + _)println(numberList2) 输出：-91 reduceLeft 和 reduceRight1234val a = List(1,7,2,9)val a1 = a.reduceLeft(_ - _) // ((1-7) - 2) - 9 = -17val a4 = a.reduceRight(_ - _)// 1 - (7 - (2-9) ) = -13 foldfold意为折叠，跟reduce类似。只不过 fold 提供了一个种子值，集合的第一个元素首先会跟种子值进行运算。 1234val numberList = List(1, 9, 6)val numberList2 = numberList.fold(4)(_ + _)println(numberList2) 输出：20","link":"/post/bcfc34da.html"},{"title":"Scala 入门","text":"Scala是一门现代的多范式编程语言，平滑地集成了 面向对象 和 函数式语言 的特性，旨在以简练、优雅的方式来表达常用编程模式。 Scala运行于JVM上，并兼容现有的Java程序，Scala代码可以调用Java方法，访问Java字段，继承Java类和实现Java接口。 在面向对象方面，Scala是一门非常纯粹的面向对象编程语言，也就是说，在Scala中，每个值都是对象，每个操作都是方法调用。 在函数式方面，函数是一等公民，可以像操作其他数据类型那样操作函数。 Scala与Java的区别 在Scala中声明 private 变量,Scala编译器会自动生成get,set方法 在Scala中变量需要初始化 在Scala中没有静态修饰符,在object下的成员全部都是静态的,如果在类中声明了与该类相同的名字的object则该object是该类的”伴生对象” 可以理解为Scala把类中的static集中放到了object对象中,伴生对象和类文件必须是同一个源文件,可以用伴生对象做一些初始化操作. 在Java中可以通过interface实现多继承,在Scala中可以通过特征(trait)实现多重继承,但是与Java不同的是,它可以定义自己的属性和实现方法体 object不能提供构造器参数,也就是说object必须是无参的 Scala中object与class的区别 在Scala中,类名可以和对象名为同一个名字,该对象称为该类的伴生对象,类和伴生对象可以相互访问他们的私有属性,但是它们必须在同一个源文件中 class只会被编译,不能直接执行，而object可以运行,类的声明和主构造器在一起被声明,在一个类中,主构造器只有一个. 类和它的伴生对象可以相互访问其私有成员 class和object的一个差别是,单例对象不带参数,而类可以.因为你不能用new关键字实例化一个单例对象,你没有机会传递给它参数 每个单例对象都被作为由一个静态变量指向的虚构类. 特别要指出的是,单例对象会在第一次被访问的时候初始化 不与伴生类共享名称的单例对象被称为孤立对象:standalone object 基本语法基本数据类型Scala的数据类型包括：Byte、Char、Short、Int、Long、Float、Double和Boolean 在Scala中，这些类型都是“类”，并且都是包scala中的成员 对于字符串，Scala用 java.lang.String 类来表示字符串 声明变量不可变 val123val str = \"hello world!\" //隐式声明val str2 : String = \"hello again\" //显式声明val str3 : java.lang.String = \"again and again\" //显式声明 事实上，在每个应用程序中，Scala都会自动添加一些引用，这样，就相当于在每个程序源文件的顶端都增加了一行下面的代码 import java.lang._，所以我们可以直接声明 str 可变 var12var myNum : Double = 6.66myNum : Double = 9.99 允许对字面量直接执行方法 125.toString() //产生字符串\"5\"\"abc\".intersect(\"bcd\") //输出\"bc\" Range类似于 fori， Range可以支持创建不同数据类型的数值序列，包括Int、Long、Float、Double、Char、BigInt和BigDecimal等。 用法 ： 123456789// 1-5的序列，包含51 to 51.to(5)// 1-5的序列，不包含51 until 5// 0.5-5.9的序列，步长0.80.5f to 5.9f by 0.8f 读写文件 用 PrintWriter 来写文件 （记得close） 用 Source 来读文件 用 for 来打印 123456789101112import java.io.PrintWriterimport scala.io.Sourceobject Fun extends App{ val out = new PrintWriter(\"test2.txt\") for (i &lt;- 1 to 5) out.println(i) out.close() val in = Source.fromFile(\"test.txt\") val lines = in.getLines() for (line &lt;- lines) print(line + \"\\t\")} 控制结构if语句跟 Java 类似，但是声明变量的时候可以用 if 赋值给变量。 12val x = 5val a = if (x &gt; 0) 1 else -1 while 和 do-while同 Java for循环语法： for (变量&lt;-表达式) 语句块 “变量&lt;-表达式”被称为“生成器（generator） 实例 123for (i &lt;- 1 to 5) println(i) // 输出 1 2 3 4 5for (i &lt;- 1 to 5 by 2) println(i) // 输出 1 3 5for (i &lt;- 1 to 5 if i%2==0) println(i) // 输出 2 4 实例2 1for (i &lt;- 1 to 5; j &lt;- 1 to 3) println(i*j) for推导式1for (i &lt;- 1 to 5 if i%2==0) yield i 通过 for 循环遍历一个或多个集合，对集合中的元素进行“推导”，从而计算得到新的集合，用于后续的其他处理。 上面的语句会生成一个 IndexedSeq[Int] ， 内容为 Vector(2, 4) 针对每一次 for 循环的迭代, yield 会产生一个值，被循环记录下来 (内部实现上，像是一个缓冲区)。当循环结束后, 会返回所有 yield 的值组成的集合。返回集合的类型与被遍历的集合类型是一致的。 数据结构数组12val intValueArr = Array(12,45,33)val myStrArr = Array(\"BigData\",\"Hadoop\",\"Spark\") 列表(list)列表中的元素类型必须相同 构建列表12345678910val intList = List(1,2,3)// h 是一个 int，值为1val h = intList.head// t 是一个 List，值为 List(2,3)val t = intList.tail// anotherList是intList在前面添加0，值为 List(0,1,2,3)val anotherList = 0::intList 构建列表另一种方法12345val intList = 1::2::3::Nilval intList1 = List(1,2)val intList2 = List(3,4)val intList3 = intList1:::intList2 Nil表示空列表 可以用 intList.sum 对列表元素求和 List的遍历使用 for 遍历12val list = List(1,3,5,7)for (elem &lt;- list) println(elem) 使用 foreach 遍历12345val list = List(1,3,5,7)list.foreach(elem =&gt; println(elem))// 可化简为：list.foreach(println) 使用 map 来遍历123val list = List(1,3,5,7)var temp = list.map(x =&gt; x)println(temp.mkString(\",\")) mkString方法把一个 Iterator 转化为一个字符串 元组(tuple)元组是 值的聚集。可以包含不同类型元素。 1val tuple = (\"BigData\",2015,45.0) 当需要访问元组中的某个元素的值时，可以通过类似tuple._1、tuple._2、tuple._3这种方式实现。 集(set)集(set)是 不重复 元素的集合。集包括可变集和不可变集，默认创建的是不可变集，通常我们使用不可变集。 123var mySet = Set(\"Hadoop\",\"Spark\")mySet += \"Scala\" //向mySet中增加新的元素println(mySet.contains(\"Scala\")) //返回 true 虽然可变集和不可变集都有添加或删除元素的操作，但是，二者有很大的区别。对不可变集进行操作，会产生一个新的集，原来的集并不会发生变化。而对可变集进行操作，改变的是该集本身， 映射(Map)映射(Map)是一系列键值对的集合，也就是，建立了键和值之间的对应关系。在映射中，所有的值，都可以通过键来获取。 映射包括可变和不可变两种，默认情况下创建的是不可变映射，如果需要创建可变映射，需要引入scala.collection.mutable.Map包。 不可变映射1234567val name = Map(\"J\" -&gt; \"Jerry\", \"C\" -&gt; \"Calm\",\"S\"-&gt;\"Superman\")println(name(\"J\")) // 返回 Jerryval x = if (name.contains(\"J\")) name(\"J\") else 0val y = if (name.contains(\"D\")) name(\"D\") else 0println(x) // 返回 Jerryprintln(y) // 返回 0 可变映射1234import scala.collection.mutable.Mapname + = (\"TJU\"-&gt;\"Tianjin University\") //添加一个新元素name + = (\"SDU\"-&gt;\"Shandong University\",\"WHU\"-&gt;\"Wuhan University\") //同时添加两个新元素 遍历映射语法：for ((k,v) &lt;- 映射) 语句块 1234val name = Map(\"J\" -&gt; \"Jerry\", \"C\" -&gt; \"Calm\",\"S\"-&gt;\"Superman\")// 输出 Jerry Calm Supermanfor ( (k,v) &lt;- name) println(v) 迭代器迭代器（Iterator）不是一个集合，但是，提供了访问集合的一种方法。 当构建一个集合需要很大的开销时（比如把一个文件的所有行都读到内存），迭代器就可以发挥很好的作用。 迭代器包含两个基本操作：next和hasNext next可以返回迭代器的下一个元素 hasNext用于检测是否还有下一个元素。 while循环遍历迭代器1234val iter = Iterator(\"Hadoop\",\"Spark\",\"Scala\")while (iter.hasNext) { println(iter.next())} 2点注意 iter.next和iter.next()都是可以的，但是，hasNext后面不能加括号 上述操作执行结束后，迭代器会移动到末尾，就不能再使用了 for循环遍历迭代器1234val iter = Iterator(\"Hadoop\",\"Spark\",\"Scala\")for (elem &lt;- iter) { println(elem)} 模式匹配类似于 switch-case 语句 简单匹配12345678val colorNum = 1val colorStr = colorNum match { case 1 =&gt; \"red\" case 2 =&gt; \"green\" case 3 =&gt; \"yellow\" case _ =&gt; \"Not Allowed\"}println(colorStr) 模式匹配中可以使用变量 类型匹配123456789for (elem &lt;- List(9,12.3,\"Spark\",\"Hadoop\",'Hello)){ val str = elem match{ case i: Int =&gt; i + \" is an int value.\" case d: Double =&gt; d + \" is a double value.\" case \"Spark\"=&gt; \"Spark is found.\" case s: String =&gt; s + \" is a string value.\" case _ =&gt; \"This is an unexpected value.\" }println(str) 类和对象 见另一篇：Scala中的类与对象 函数式编程 见另一篇：Scala中的函数式编程 执行Scala使用shell命令1scala TestCounter.scala 使用Scala解释器终端输入 scala 进入 Scala解释器 1scala&gt; :load /usr/local/scala/mycode/TestCounter.scala 用:quit退出 Scala 解释器 在 IntelliJ IDEA 中使用 Scala 在插件中安装 Scala 插件 （Setting - Plugins - 搜索Scala） 重启 IDEA 新建一个 Scala Project new 一个 Scala Class，kind 选择 Object 输入helloworld代码，运行 123456object hello { def main(args: Array[String]): Unit = { val str = \"Hello\" println(str) }}","link":"/post/b8de25eb.html"},{"title":"Spark中的数据读写","text":"Spark 支持多种文件格式的读写，包括 本地文本文件：Json、SequenceFile 等文件格式 文件系统：HDFS、Amazon S3 数据库：MySQL、HBase、Hive 本地文件读写文本文件使用以下语句从文件系统中读写文件 1234567val text = sc.textFile(\"file:///home/jerrysheh/word.txt\")// .first() 是一个\"action\"text.first()// 从RDD写回文件系统，saveAsTextFile是一个actiontext.saveAsTextFile(\"file:///home/jerrysheh/wordWriteBack\") spark的惰性机制使得在“转换”操作时，即使遇到错误也不会立即报错，直到”行动（action）“操作时才开始真正的计算，这时候如果有错误才会报错。 wordWriteBack 是一个文件夹，写回后存放在该文件夹里，里面有part-00000 和 _SUCCESS 两个文件。part-00000 里面的内容就是写会的内容。 当我们想把输出的结果再次加载到RDD中，只要在textFile()中定位到 wordWriteBack 这个目录即可。 1val text = sc.textFile(\"file:///home/jerrysheh/wordWriteBack\") json文件12345// jsonStr的类型是：org.apache.spark.rdd.RDD[String]val jsonStr = sc.textFile(\"file:///home/jerrysheh/people.json\")// 使用 foreach 遍历jsonStr.foreach(println) 输出： 123{&quot;name&quot;:&quot;Michael&quot;}{&quot;name&quot;:&quot;Andy&quot;, &quot;age&quot;:30}{&quot;name&quot;:&quot;Justin&quot;, &quot;age&quot;:19} 可以用 scala 自带的 JSON 库 —— scala.util.parsing.json.JSON 进行解析。 从HDFS读写跟本地文件类似，只不过把 file:// 换成 hdfs:// 1val textFile = sc.textFile(\"hdfs://localhost:9000/user/jerrysheh/word.txt\")","link":"/post/e884ae58.html"},{"title":"Spark SQL 和 DataFrame","text":"RDD 和 DataFrame 的区别RDD 是弹性分布式数据集，其本质是 Dataset。Dataset 可以从 JVM 对象中构建 （例如 rating 对象，即 javabean ），然后通过 map、flatMap、filter 等方法转换来操作。 为了更好地读写数据以及使用类似SQL语句一样简单地操作，Spark SQL 提供了 DataFrame (其前身是SchemaRDD)。 DataFrame 能够让你知道数据集中的每一行和列。这个概念跟关系型数据库中的表（table）类似，但是比表更强大。如下图： DataFrame 可以从结构化的数据文件（structured data files）、Hive中的表、外部数据库或者已存在的RDD中构建。 在 Java 中，使用 Dataset&lt;Row&gt; 来表示 DataFrame。 Getting Started初始化 Spark12345SparkSession spark = SparkSession .builder() .appName(\"Java Spark SQL basic example\") .config(\"spark.some.config.option\", \"some-value\") .getOrCreate(); 创建 DataFrames通过 SparkSession，可以从已存在的RDD、Hive表、或者其他数据源 来创建DataFrames 例如，从一个 json 文件创建 DataFrames： 1234567891011Dataset&lt;Row&gt; df = spark.read().json(\"examples/src/main/resources/people.json\");// Displays the content of the DataFrame to stdoutdf.show();// +----+-------+// | age| name|// +----+-------+// |null|Michael|// | 30| Andy|// | 19| Justin|// +----+-------+ 操作 DataFramedf可以像数据库表一样进行操作： df.printSchema()：打印DataFrames结构 df.select(&quot;name&quot;).show(): 选择 name 列打印 df.filter(col(&quot;age&quot;).gt(21)).show()：筛选出年龄列大于21的 df.groupBy(&quot;age&quot;).count().show()：统计各年龄人数 或者，把它变成一张临时的表 12// Register the DataFrame as a SQL temporary viewdf.createOrReplaceTempView(\"people\"); 现在，我们的内存里就存在一张临时 people 表了。然后通过 Spark SQL 来操作： 123456789Dataset&lt;Row&gt; sqlDF = spark.sql(\"SELECT * FROM people\"); sqlDF.show(); // +----+-------+ // | age| name| // +----+-------+ // |null|Michael| // | 30| Andy| // | 19| Justin| // +----+-------+ df.createOrReplaceTempView(&quot;people&quot;)的生命周期在 Spark Session，Session一关闭临时表就不存在了。如果要用应用程序级别的全局临时表，使用df.createGlobalTempView(&quot;people&quot;)，使用全局表需要在SQL语句添加 .global_temp 1234df.createGlobalTempView(\"people\");// Global temporary view is tied to a system preserved database `global_temp`spark.sql(\"SELECT * FROM global_temp.people\").show(); 一个agg的例子从数据库读一张表，然后根据相同的 userId，将 productId 聚合为 List 1234567891011121314151617181920212223242526272829// 转换前+------+---------+|userId|productId|+------+---------+| 3| 1786670|| 3| 2679073|| 3| 1082387|| 8| 1082734|| 9| 4039416|| 9| 1734231|| 1| 5252677|| 10| 1141406|| 10| 1026425|| 10| 3426048|| 1| 1193101|| 1| 1051440|+------+---------+//转换后+------+--------------------+|userId| productIds|+------+--------------------+| 1|[5252677, 1193101...|| 3|[1056461, 1786670...|| 9|[1734231, 4039416] || 8|[1082734] || 10|[1141406, 3426048...|+------+--------------------+ 方法： 1234567891011val dataset = MySQLUtils .readFromMySQL(spark, \"likes\") .select(\"userId\", \"productId\")dataset.show()val dataFormat = dataset .groupBy(\"userId\") .agg(collect_set(\"productId\") as \"productIds\")dataFormat.show() groupBy 以 userId， 将一个 dataframe 分成多个， 然后 agg 将多个 DataFrame 聚合， 聚合的参数是 collect_set(“productId”) 。 更多操作见： 官方文档 官方示例 DataFrame 的函数Action 操作1、 collect() ,返回值是一个数组，返回dataframe集合所有的行2、 collectAsList() 返回值是一个Java类型的数组，返回dataframe集合所有的行3、 count() 返回一个number类型的，返回dataframe集合的行数4、 describe(cols: String*) 返回一个通过数学计算的类表值(count, mean, stddev, min, and max)，这个可以传多个参数，中间用逗号分隔，如果有字段为空，那么不参与运算，只这对数值类型的字段。例如df.describe(“age”, “height”).show()5、 first() 返回第一行 ，类型是row类型6、 head() 返回第一行 ，类型是row类型7、 head(n:Int)返回n行 ，类型是row 类型8、 show()返回dataframe集合的值 默认是20行，返回类型是unit9、 show(n:Int)返回n行，，返回值类型是unit10、 table(n:Int) 返回n行 ，类型是row 类型 dataframe的基本操作1、 cache()同步数据的内存2、 columns 返回一个string类型的数组，返回值是所有列的名字3、 dtypes返回一个string类型的二维数组，返回值是所有列的名字以及类型4、 explan()打印执行计划 物理的5、 explain(n:Boolean) 输入值为 false 或者true ，返回值是unit 默认是false ，如果输入true 将会打印 逻辑的和物理的6、 isLocal 返回值是Boolean类型，如果允许模式是local返回true 否则返回false7、 persist(newlevel:StorageLevel) 返回一个dataframe.this.type 输入存储模型类型8、 printSchema() 打印出字段名称和类型 按照树状结构来打印9、 registerTempTable(tablename:String) 返回Unit ，将df的对象只放在一张表里面，这个表随着对象的删除而删除了10、 schema 返回structType 类型，将字段名称和类型按照结构体类型返回11、 toDF()返回一个新的dataframe类型的12、 toDF(colnames：String*)将参数中的几个字段返回一个新的dataframe类型的，13、 unpersist() 返回dataframe.this.type 类型，去除模式中的数据14、 unpersist(blocking:Boolean)返回dataframe.this.type类型 true 和unpersist是一样的作用false 是去除RDD 集成查询1、 agg(expers:column) 返回dataframe类型 ，同数学计算求值df.agg(max(“age”), avg(“salary”))df.groupBy().agg(max(“age”), avg(“salary”))2、 agg(exprs: Map[String, String]) 返回dataframe类型 ，同数学计算求值 map类型的df.agg(Map(“age” -&gt; “max”, “salary” -&gt; “avg”))df.groupBy().agg(Map(“age” -&gt; “max”, “salary” -&gt; “avg”))3、 agg(aggExpr: (String, String), aggExprs: (String, String)\\) 返回dataframe类型 ，同数学计算求值df.agg(Map(“age” -&gt; “max”, “salary” -&gt; “avg”))df.groupBy().agg(Map(“age” -&gt; “max”, “salary” -&gt; “avg”))4、 apply(colName: String) 返回column类型，捕获输入进去列的对象5、 as(alias: String) 返回一个新的dataframe类型，就是原来的一个别名6、 col(colName: String) 返回column类型，捕获输入进去列的对象7、 cube(col1: String, cols: String) 返回一个GroupedData类型，根据某些字段来汇总8、 distinct 去重 返回一个dataframe类型9、 drop(col: Column) 删除某列 返回dataframe类型10、 dropDuplicates(colNames: Array[String]) 删除相同的列 返回一个dataframe11、 except(other: DataFrame) 返回一个dataframe，返回在当前集合存在的在其他集合不存在的12、 explode[A, B](inputColumn: String, outputColumn: String)(f: (A) ⇒ TraversableOnce[B])(implicit arg0: scala.reflect.api.JavaUniverse.TypeTag[B]) 返回值是dataframe类型，这个 将一个字段进行更多行的拆分df.explode(“name”,”names”) {name :String=&gt; name.split(“ “)}.show();将name字段根据空格来拆分，拆分的字段放在names里面13、 filter(conditionExpr: String): 刷选部分数据，返回dataframe类型 df.filter(“age&gt;10”).show(); df.filter(df(“age”)&gt;10).show(); df.where(df(“age”)&gt;10).show(); 都可以14、 groupBy(col1: String, cols: String) 根据某写字段来汇总返回groupedate类型 df.groupBy(“age”).agg(Map(“age” -&gt;”count”)).show();df.groupBy(“age”).avg().show();都可以15、 intersect(other: DataFrame) 返回一个dataframe，在2个dataframe都存在的元素16、 join(right: DataFrame, joinExprs: Column, joinType: String)一个是关联的dataframe，第二个关联的条件，第三个关联的类型：inner, outer, left_outer, right_outer, leftsemidf.join(ds,df(“name”)===ds(“name”) and df(“age”)===ds(“age”),”outer”).show();17、 limit(n: Int) 返回dataframe类型 去n 条数据出来18、 na: DataFrameNaFunctions ，可以调用dataframenafunctions的功能区做过滤 df.na.drop().show(); 删除为空的行19、 orderBy(sortExprs: Column) 做alise排序20、 select(cols:string) dataframe 做字段的刷选 df.select($”colA”, $”colB” + 1)21、 selectExpr(exprs: String) 做字段的刷选 df.selectExpr(“name”,”name as names”,”upper(name)”,”age+1”).show();22、 sort(sortExprs: Column) 排序 df.sort(df(“age”).desc).show(); 默认是asc23、 unionAll(other:Dataframe) 合并 df.unionAll(ds).show();24、 withColumnRenamed(existingName: String, newName: String) 修改列表 df.withColumnRenamed(“name”,”names”).show();25、 withColumn(colName: String, col: Column) 增加一列 df.withColumn(“aa”,df(“name”)).show();","link":"/post/21c6c0f6.html"},{"title":"Scala中的类与对象","text":"类定义类1234567class Counter { private var value = 0 //大括号和返回类型可以省略 def increment(): Unit = { value += 1} def current(): Int = {value}} 字段没有 private 修饰的默认为 public 用def来声明方法 Unit是 increment()方法的返回类型 方法的最后一条表达式就是返回值，不需要写return 创建对象1234567891011object theCounter{ def main(args: Array[String]): Unit = { // 用 new 创建一个对象 val myCounter = new theCounter //调用对象方法 myCounter.increment() println(myCounter.current()) }} 在object里执行 调用方法时（）括号可以省略 =_ （getter 和 setter）Scala 中没有 getter 和 setter， 如果要修改 private 变量，用 =_ 123456789private var value = 0// 首先定义一个方法，指向私有的 value 变量def changeValue = value// 用 _= 来修改def changeValue_=(newValue: Int): Unit = { if (newValue &gt; 0) value = newValue} 构造器跟Java构造方法不同，Scala的主构造器是整个类体。 需要在类名称后面罗列出构造器所需的所有参数，这些参数被编译成字段，字段的值就是创建对象时传入的参数的值。 12345678910111213141516171819202122class Counter(val name: String, val mode: Int) { //value用来存储计数器的起始值 private var value = 0 def increment(step: Int): Unit = { value += step} def current(): Int = {value} def info(): Unit = {printf(\"Name:%s and mode is %d\\n\",name,mode)}}object MyCounter{ def main(args:Array[String]){ val myCounter = new Counter(\"Timer\",2) //显示计数器信息 myCounter.info //设置步长 myCounter.increment(1) //显示计数器当前值 printf(\"Current Value is: %d\\n\",myCounter.current) }} 单例对象Scala 没有 Java 的静态类或者静态方法。要实现单例，可用 object 1234567object Person { private var lastId = 0 //一个人的身份编号 def newPersonId() = { lastId +=1 lastId }} 伴生对象Java 中，有些类既有实例方法又有静态方法。在Scala中用伴生对象来实现。 当单例对象与某个类具有相同的名称时，它被称为这个类的“伴生对象”。 1234567891011121314151617181920212223242526272829303132333435class Person { //调用了伴生对象中的方法 private val id = Person.newPersonId() // 给名字赋值 private var name = \"\" def this(name: String) { this() this.name = name } // 打印信息 def info() { printf(\"The id of %s is %d.\\n\",name,id) }}object Person { //一个人的身份编号 private var lastId = 0 //被实例化一个Person时调用 private def newPersonId() = { lastId +=1 lastId } // main def main(args: Array[String]){ val person1 = new Person(\"Ziyu\") val person2 = new Person(\"Minxing\") person1.info() person2.info() }} 在 object 中才可以使用 main apply方法和update方法 用括号传递给变量(对象)一个或多个参数时，Scala 会把它转换成对apply方法的调用； 当对带有括号并包括一到若干参数的对象进行赋值时，编译器将调用对象的update方法，在调用时，把括号里的参数和等号右边的对象一起作为update方法的输入参数来执行调用 继承Scala中的继承与Java有着显著的不同： 重写方法必须用 override 只有主构造器可以调用父类的主构造器 可以重写父类中的字段，也是要用 override 特质（trait）trait 类似 java 的接口。trait 可以同时有抽象方法 和 具体方法。 Scala中，一个类只能继承自一个父类，却可以实现多个trait，重用trait中的方法和字段，从而实现了多重继承。 定义1234trait CarId{ var id: Int def currentId(): Int //定义了一个抽象方法}","link":"/post/230ce50d.html"},{"title":"使用 Spark Streaming 进行实时流计算(二)","text":"Spark Streaming 除了可以从三个基本数据源（文件、TCP套接字、RDD）读取数据，还能从高级的数据源中读取。这里的高级数据源，指的是 Kafka 或 Flume。 Kafka 简介Kafka 是 LinkedIn 开发的一种高吞吐量的分布式发布订阅消息系统。 相比更擅长批量离线处理的 Flume 和 Scribe， Kafka 的优点是可以同时满足在线实时处理和批量离线处理。 Kafka 在很多公司的大数据平台中，通常扮演数据交换枢纽角色。Hadoop 生态系统中有很多的组件，每当有一种新的产品加入到企业的大数据生态系统中时，就要为这款产品开发与 Hadoop 各个组件的数据交换工具，显得比较麻烦。 而 Kafka，是一种通用工具，起到数据交换枢纽的作用。 不同的分布式系统（如关系数据库、流处理系统、批处理系统等）都可以统一接入 Kafka。 Kafka的核心概念 Broker： Kafka集群包含一个或多个服务器，这种服务器被称为broker Topic： 每条发布到Kafka集群的消息都有一个类别，这个类别被称为Topic。（物理上不同Topic的消息分开存储，逻辑上一个Topic的消息虽然保存于一个或多个broker上但用户只需指定消息的Topic即可生产或消费数据而不必关心数据存于何处） Partition： Partition是物理上的概念，每个Topic包含一个或多个Partition. Producer： 负责发布消息到Kafka broker Consumer： 消息消费者，向Kafka broker读取消息的客户端。 Consumer Group： 每个Consumer属于一个特定的Consumer Group（可为每个Consumer指定group name，若不指定group name则属于默认的group） Kafka简单实例 安装完 Kafka 后， 会发现解压的 kafka 文件夹不是属于我的用户组， 修改所有者 1sudo chown -R jerrysheh ./kafka Kafka 是基于 zookeeper 的，因此首先要开启 zookeeper 服务 shell 1 1bin/zookeeper-server-start.sh config/zookeeper.properties 开启 kafka 服务 shell 2 1bin/kafka-server-start.sh config/server.properties topic是发布消息发布的 category , 现在以单节点的配置创建一个叫test的topic shell 3 1bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test 用 --list 参数查看 topic 是否存在 shell 3 1bin/kafka-topics.sh --list --zookeeper localhost:2181 用 producer 生产一些数据 shell 3 1bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test 随便输入点数据，比如 12This is a messageThis is another message 用consumer来接收数据 shell 4 1bin/kafka-console-consumer.sh --zookeeper localhost:2181 --topic test --from-beginning 可以看到，刚刚我们用producer生产的数据，在shell 4 ，也就是consumer终端接收到了。 参考：官方文档 使用 Kafka 作为 DStream 数据源放弃治疗","link":"/post/76774483.html"},{"title":"Spark编程入门（二）RDD编程","text":"RDD 简介弹性分布式数据集（Resilient Distributed Dataset，RDD），是分布式内存的一个抽象概念，它提供了一种高度受限的内存模型。本质上，RDD是一个只读的分区记录集合。一个RDD可以分成多个分区，每个分区就是一个数据集片段。不同的分区可以保存在集群的不同节点上，从而可以进行并行计算。 RDD是只读的，不能直接修改。但是RDD提供了 转换 和 行动 两种操作。转换操作返回一个新的RDD，行动操作用于执行计算并指定输出，返回非RDD。 典型的RDD执行过程如下： RDD读入外部数据源（或内存中的集合），进行创建。 RDD经过一系列的转换操作，每一次都产生不同的RDD，给下一次转换使用。 最后一个RDD经行动操作进行处理，输出到外部数据源。 需要注意的是，RDD采用了惰性调用，即转换操作并不会真的进行转换，只是记录。直到行动操作的时候，才从头开始进行一系列计算。 RDD的依赖关系RDD的依赖关系分为 窄依赖（Narrow Dependency） 与 宽依赖（Wide Dependency）。窄依赖即一个或多个父RDD的分区对应一个子RDD的分区，典型的例子有map、filter、union、join，而宽依赖则是一个父RDD的分区对应多个字RDD的分区，典型的例子有groupByKey、join。 为什么要这样设计依赖关系？为了提高容错性，以加快 Spark 的执行速度。因为 RDD 通过“血缘关系”记住了它是如何从其它 RDD 演变过来的，血缘关系记录的是粗颗粒度的转换操作行为，当这个RDD的部分分区数据丢失时，它可以通过血缘关系获取足够的信息来重新运算和恢复丢失的数据分区，由此带来了性能的提升。 RDD运行过程 创建RDD对象； SparkContext负责计算 RDD 之间的依赖关系，构建 DAG； DAGScheduler负责把 DAG 图分解成多个阶段，每个阶段中包含了多个任务，每个任务会被任务调度器分发给各个工作节点（Worker Node）上的Executor去执行。 编写 RDD 应用程序首先新建一个 maven 工程 添加依赖根据官方文档，添加 spark-core 的依赖 （如果要读写 HDFS, 还要添加 hadoop-client 的依赖） pom.xml 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-core_2.11&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt;&lt;/dependency&gt; 初始化 SparkRDDsample.java 12345678910import org.apache.spark.api.java.JavaSparkContext;import org.apache.spark.api.java.JavaRDD;import org.apache.spark.SparkConf;public class RDDsample { public static void main(String[] args) { SparkConf conf = new SparkConf().setAppName(\"RDD sample\").setMaster(\"local[4]\"); JavaSparkContext sc = new JavaSparkContext(conf); }} conf 的 setMaster 是设置集群（master is a Spark, Mesos or YARN cluster URL, or a special “local” string to run in local mode）这里以本地四个线程为例，写入 local[4] 创建 RDDRDD可以通过两种方式创建： 第一种：读取一个外部数据集。比如，从本地文件加载数据集，或者从HDFS文件系统、HBase、Cassandra、Amazon S3等外部数据源中加载数据集。Spark可以支持文本文件、SequenceFile文件（Hadoop提供的 SequenceFile是一个由二进制序列化过的key/value的字节流组成的文本存储文件）和其他符合Hadoop InputFormat格式的文件。 1JavaRDD&lt;String&gt; lines = sc.textFile(\"file:///home/jerrysheh/data.txt\"); lines是一个String类型的RDD，可以简单称为RDD[String]，也就是说，这个RDD[String]里面的元素都是String类型。 第二种：调用SparkContext的parallelize方法，在Driver中一个已经存在的集合（数组）上创建。 12List&lt;Integer&gt; data = Arrays.asList(1, 2, 3, 4, 5);JavaRDD&lt;Integer&gt; distData = sc.parallelize(data); RDD 操作RDD 支持两种操作： 转换（Transformations）： 基于现有的数据集创建一个新的数据集。 行动（Actions）：在数据集上进行运算，返回计算值。 转换每一次转换操作都会产生不同的RDD，供给下一个“转换”使用。转换过程只是记录了转换的轨迹，并不会发生真正的计算。 常见的转换操作（Transformation API）：： filter(func)：筛选出满足函数func的元素，并返回一个新的数据集 map(func)：将每个元素传递到函数func中，并将结果返回为一个新的数据集 flatMap(func)：与map()相似，但每个输入元素都可以映射到0或多个输出结果 groupByKey()：应用于(K,V)键值对的数据集时，返回一个新的(K, Iterable)形式的数据集 reduceByKey(func)：应用于(K,V)键值对的数据集时，返回一个新的(K, V)形式的数据集，其中的每个值是将每个key传递到函数func中进行聚合。 行动行动操作是真正触发计算的地方。Spark程序执行到行动操作时，才会执行真正的计算，包括从文件中加载数据，完成一次又一次转换操作，最终，完成行动操作得到结果。 常见的行动操作（Action API）： count()： 返回数据集中的元素个数 collect()： 以数组的形式返回数据集中的所有元素 first()： 返回数据集中的第一个元素 take(n)： 以数组的形式返回数据集中的前n个元素 reduce(func)： 通过函数func（输入两个参数并返回一个值）聚合数据集中的元素 foreach(func)： 将数据集中的每个元素传递到函数func中运行 如果程序中多个地方触发行动操作，每个地方都会从头开始执行。可以用 RDD.cache()来缓存。这样第二次触发行动操作，会从缓存的地方开始计算。 键值对RDD （pair RDD）我们前面创建的是 RDD[String]， 我们还可以创建 RDD[(String, Int)] 123JavaRDD&lt;String&gt; lines = sc.textFile(\"data.txt\");JavaPairRDD&lt;String, Integer&gt; pairs = lines.mapToPair(s -&gt; new Tuple2(s, 1));JavaPairRDD&lt;String, Integer&gt; counts = pairs.reduceByKey((a, b) -&gt; a + b); Java比较难理解的话，用 Python理解一遍 123lines = sc.textFile(\"data.txt\")pairs = lines.map(lambda s: (s, 1))counts = pairs.reduceByKey(lambda a, b: a + b) 键值对转换reduceByKey(func)使用func函数合并具有相同键的值 比如：reduceByKey((a,b) -&gt; a+b) 转换前 1(“spark”,1)、(“spark”,2)、(“hadoop”,3)和(“hadoop”,5) 转换后 1(“spark”,3)、(“hadoop”,8) groupByKey()对具有相同键的值进行分组 转换前 1(“spark”,1)、(“spark”,2)、(“hadoop”,3)和(“hadoop”,5) 转换后 1(“spark”,(1,2))，(“hadoop”,(3,5)) keys把键值对RDD中的key返回形成一个新的RDD 转换前：四个键值对构成的RDD 1(“spark”,1)、(“spark”,2)、(“hadoop”,3)和(“hadoop”,5) 转换后：一个RDD[Int] 1{“spark”,”spark”,”hadoop”,”hadoop”} values把键值对RDD中的value返回形成一个新的RDD 转换前：四个键值对构成的RDD 1(“spark”,1)、(“spark”,2)、(“hadoop”,3)和(“hadoop”,5) 转换后：一个RDD[Int] 1{1,2,3,5} sortByKey()返回一个根据键排序的RDD mapValues(func)`只对键值对RDD的value部分进行处理，而不是同时对key和value进行处理。对键值对RDD中的每个value都应用一个函数，但是，key不会发生变化。 转换前 1(“spark”,1)、(“spark”,2)、(“hadoop”,3)、(“hadoop”,5) 使用 pairRDD.mapValues(x -&gt; x+1) 转换后 1(“spark”,2)、(“spark”,3)、(“hadoop”,4)、(“hadoop”,6)。 join （内连接）对于给定的两个输入数据集(K,V1)和(K,V2)，只有在两个数据集中都存在的key才会被输出，最终得到一个(K,(V1,V2))类型的数据集。 pairRDD1 （键值对集合） 1{(“spark”,1)、(“spark”,2)、(“hadoop”,3)、(“hadoop”,5)} pairRDD2 （键值对集合） 1{(“spark”,”fast”)} 进行 pairRDD1.join(pairRDD2) 操作 转换后 1{(“spark”,1,”fast”),(“spark”,2,”fast”)} 分区RDD是弹性分布式数据集，通常RDD很大，会被分成很多个分区，分别保存在不同的节点上。RDD分区的一个分区原则是使得分区的个数尽量等于集群中的CPU核心（core）数目。对于不同的Spark部署模式而言（本地模式、Standalone模式、YARN模式、Mesos模式），都可以通过设置spark.default.parallelism这个参数的值，来配置默认的分区数目。 一般而言： 本地模式：默认为本地机器的CPU数目，若设置了local[N],则默认为N； Apache Mesos：默认的分区数为8； Standalone 或 YARN：在“集群中所有CPU核心数目总和”和“2”二者中取较大值作为默认值； 因此，在创建RDD的第二种方法中，parallelize()可以接收第二个参数（可选），表示多少个分区。如： 1JavaRDD&lt;Integer&gt; distData = sc.parallelize(data, 2); //设置2个分区 打印元素本地模式：rdd.foreach(println)或者rdd.map(println) 集群模式： rdd.collect().foreach(println)（可能导致内存溢出） rdd.take(100).foreach(println) 共享变量和累加器Spark在集群的多个不同节点的多个任务上并行运行一个函数时，它会把函数中涉及到的每个变量，在每个任务上都生成一个副本。但是我们有时候需要在多个任务之间，或者在任务（Task）和任务控制节点（Driver Program）之间共享变量。 Spark提供了两种类型的变量：广播变量（broadcast variables）和累加器（accumulators）。广播变量用来把变量在所有节点的内存之间进行共享。累加器则支持在所有不同节点之间进行累加计算（比如计数或者求和）。 使用SparkContext.broadcast(v)来从一个普通变量v中创建一个广播变量 一个数值型的累加器，可以通过调用SparkContext.longAccumulator()或者SparkContext.doubleAccumulator()来创建 参考： 厦门大学数据库实验室","link":"/post/9c5fa7c3.html"},{"title":"使用 Spark Streaming 进行实时流计算(一)","text":"使用Spark Streaming 进行实时流计算，主要运用 DStream 编程模型。这种模型包括 输入、转换和输出 三个部分。这一篇主要介绍三种简单的输入。下一篇将会介绍高级数据源和转换，输出部分。 Spark Streaming 简介Spark Streaming是 Spark 的实时计算框架，为Spark提供了可扩展、高吞吐、容错的流计算能力。支持多种数据输入源，如 Kafka、Flume、HDFS 或 TCP套接字。 基本原理将实时输入的数据以时间片（秒级）为单位进行拆分，经 Spark 引擎以类似批处理的方式处理每个时间片数据。 Spark Streaming 最主要的抽象是 DStream(Discretized Stream，离散化数据流)，表示连续不断的数据流。Spark Streaming的输入数据按照时间片分成一段一段的 DStream，每一段数据转换为 Spark 中的 RDD，并且对 DStream 的操作最终转变为相应的 RDD 操作。 DStream是 Spark Streaming 的编程模型，DStream 的操作包括 输入、转换和输出。 Spark Streaming 与 Storm 对比 Spark Streaming 无法实现毫秒级别的流计算， Storm 可以。 Spark Streaming 小批量处理的方式可以同时兼容批量和实时数据处理的逻辑和算法，方便在需要历史数据和实时数据联合分析的应用场合。 Spark Streaming编程步骤 Spark Streaming 应用程序可以用 Scala、Java、Python来编写， 官方提供了一种叫 spark-shell 的命令行环境，使用 Scala 语言来编写，或者使用 python 语言的 pyspark。但是我们一般是在 IDE 里编写独立的应用程序。 编写 Spark Streaming 程序的基本步骤是： 通过创建输入DStream来定义输入源; 通过对 DStream 应用的 转换操作 和 输出操作 来定义流计算; 用streamingContext.start()来开始接收数据和处理流程; 通过streamingContext.awaitTermination()方法来等待处理结束（手动结束或因为错误而结束）; 可以通过streamingContext.stop()来手动结束流计算进程。 创建对象如果用 pyspark，默认已经获得了一个SparkConext（sc），否则，需要手动创建，如下 123456from pyspark import SparkContext, SparkConffrom pyspark.streaming import StreamingContextconf = SparkConf()conf.setMaster('local[2]') # 表示运行在本地模式下，并且启动2个工作线程。conf.setAppName('TestDStream')sc = SparkContext(conf = conf) pyspark 默认有 sc，那么如何开 local[2] ? 答案：spark-submit --master local[4] your_file.py 要运行一个Spark Streaming程序，首先要生成一个StreamingContext对象 1ssc = StreamingContext(sc, 15) # 15表示每隔15秒钟自动执行一次流计算 从文件流读取数据Spark支持从兼容HDFS API的文件系统中读取数据，创建数据流。 首先创建一个 logdir 目录，里面有 log1.txt 和 log2.txt 两个日志文件 然后在 python 中继续写 123456lines = ssc.textFileStream('file:///home/jerrysheh/logdir')words = lines.flatMap(lambda line: line.split(' '))wordCounts = words.map(lambda x : (x,1)).reduceByKey(add)wordCounts.pprint()ssc.start() # 如果用 pyspark，到这里会循环监听，下面的语句无法输入ssc.awaitTermination() 输出： 1234567891011-------------------------------------------Time: 2018-04-05 23:45:00--------------------------------------------------------------------------------------Time: 2018-04-05 23:45:15--------------------------------------------------------------------------------------Time: 2018-04-05 23:45:30------------------------------------------- 可以发现，程序每隔10秒监听一次。但是没有把 logdir 目录下的 log1.txt 和 log2.txt 这两个文件中的内容读取出来。原因是，监听程序只监听目录下在程序启动后新增的文件，不会去处理历史上已经存在的文件。 现在，用 vim 在 logdir 目录里新增一个 log3.txt ，并写入 hello， 保存。 过一会儿，就能发现屏幕中输出了 log3.txt 里面的信息。 1234-------------------------------------------Time: 2018-04-05 23:45:45-------------------------------------------('hello', 1) 从TCP套接字流读取数据pyWordCountServer.py 1234567891011121314151617181920from __future__ import print_functionimport sysfrom pyspark import SparkContextfrom pyspark.streaming import StreamingContextif __name__ == \"__main__\": if len(sys.argv) != 3: print(\"Usage: network_wordcount.py &lt;hostname&gt; &lt;port&gt;\", file=sys.stderr) exit(-1) sc = SparkContext(appName=\"PythonStreamingNetworkWordCount\") ssc = StreamingContext(sc, 5) lines = ssc.socketTextStream(sys.argv[1], int(sys.argv[2])) counts = lines.flatMap(lambda line: line.split(\" \"))\\ .map(lambda word: (word, 1))\\ .reduceByKey(lambda a, b: a+b) counts.pprint() ssc.start() ssc.awaitTermination() 在9999端口设置网络监听 -k 参数 Keep inbound sockets open for multiple connects -l 参数 Listen mode, for inbound connects shell 1 1nc -lk 9999 shell 2 1python3 pyWordCountServer.py localhost 9999 在 shell 1 里输入一些东西， shell 2可以接收到 但是这里报了 WARN 1Block input-0-1522945797400 replicated to only 0 peer(s) instead of 1 peers 而且也没有任何数据 stackoverflow 给出了解释 The warning in your case means that incoming data from stream are not replicated at all. The reason for that may be that you run the app with just one instance of Spark worker or running in local mode. Try to start more Spark workers and see if the warning is gone. 所以应该跟我是单机环境有关， stackoverflow，说 I think you should specify more executors while submitting the application. For example: spark-submit --master local[4] your_file.py Do not run Spark Streaming programs locally with master configured as local or local[1]. This allocates only one CPU for tasks and if a receiver is running on it, there is no resource left to process the received data. Use at least local[2] to have more cores. 所以开多几个线程就好了。 修改程序 创建SparkContext加 master 参数 1sc = SparkContext(appName=\"PythonStreamingNetworkWordCount\", master=\"local[4]\") 重新运行，还是报了 WARN， 但是 shell 1 的数据已经能够接收了 123456789102018-04-06 00:46:45 WARN RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer/s.2018-04-06 00:46:45 WARN BlockManager:66 - Block input-0-1522946805600 replicated to only 0 peer(s) instead of 1 peers------------------------------------------- Time: 2018-04-06 00:46:48-------------------------------------------('are', 5)('now', 1)('you', 2)('what', 1)('doing', 1) 从 RDD 队列流读取数据在调试Spark Streaming应用程序的时候，我们可以使用streamingContext.queueStream(queueOfRDD)创建基于RDD队列的DStream。 12345678910111213141516171819202122232425import timefrom pyspark import SparkContextfrom pyspark.streaming import StreamingContextif __name__ == \"__main__\": sc = SparkContext(appName=\"PythonStreamingQueueStream\") ssc = StreamingContext(sc, 1) # Create the queue through which RDDs can be pushed to # a QueueInputDStream rddQueue = [] for i in range(5): rddQueue += [ssc.sparkContext.parallelize([j for j in range(1, 1001)], 10)] # Create the QueueInputDStream and use it do some processing inputStream = ssc.queueStream(rddQueue) mappedStream = inputStream.map(lambda x: (x % 10, 1)) reducedStream = mappedStream.reduceByKey(lambda a, b: a + b) reducedStream.pprint() ssc.start() time.sleep(6) ssc.stop(stopSparkContext=True, stopGraceFully=True) 以上主要介绍了从三个基本数据源（文件、TCP套接字、RDD）读取数据操作。下一篇继续介绍高级数据源（Kafka、Flume）以及数据的转换操作 和 输出操作。 参考 《大数据技术原理与应用》 林子雨","link":"/post/bcfe91a1.html"},{"title":"Spark编程入门（一） QuickStart","text":"Spark 基本概念在实际应用中，大数据处理主要包括： 复杂的批量数据处理（数十分钟 - 几小时） 基于历史数据的交互式查询（数十秒 - 几分钟） 基于实时流的数据处理 （数百毫秒 - 几秒） Spark 的设计遵循“一个软件栈满足不同的应用场景”，有一套完整的生态系统。包括内存计算框架、SQL即时查询、实时流式计算、机器学习和图计算等。Spark可以部署在 YARN 资源管理器上，提供一站式的大数据解决方案。 RDD：弹性分布式数据集（Resilient Distributed Dataset），分布式内存的一个抽象概念，提供了一种高度受限的内存模型。 DAG：有向无环图（Directed Acyclic Graph, DAG），反映RDD之间的依赖关系。 Executor：运行在工作节点（Worker Node）上的一个进程，负责运行任务，为应用程序存储数据。 应用：用户编写的 Spark 程序 任务：运行在 Executor 上的工作单元 作业：一个作业包含多个RDD以及作用域相应RDD的各种操作 阶段：是作业的基本调度单位，一个作业分为多组任务，每组任务被称为“阶段”，或者“任务集”。 在 Spark 中，一个应用（Application）由一个任务控制节点（Driver）和若干个作业（Job）构成，一个作业由多个阶段（Stage）构成，一个阶段由多个任务（Task）组成。 Spark 生态系统组件 Spark Core：内存计算、任务调度、部署模式、故障恢复、存储管理等，主要面向批数据处理 Spark SQL：允许开发者直接处理RDD，也可查询 Hive、Hbase等外部数据源。统一处理数据关系表和RDD，开发者无需自己编写Spark程序，即可用 SQL 命令查询。 Spark Streaming： 实时流处理。支持多种数据输入源，如 Kafka、Flume、HDFS 或 TCP套接字。 MLlib（机器学习）：提供机器学习算法实现，包括聚类、分类、回归、协同过滤。 GraphX（图计算） 无论哪个组件，都可以用 Core 的API处理问题。 Spark 的安装在 Spark 官网下载 tgz 压缩包 1wget http://mirrors.tuna.tsinghua.edu.cn/apache/spark/spark-2.3.1/spark-2.3.1-bin-hadoop2.7.tgz 注：以上是 2.3.1 版本的清华大学镜像，最新版本在 spark 官网 找 将 spark 解压到当前目录 1tar -zxvf spark-2.3.1-bin-hadoop2.7.tgz -C . Spark 三种部署方式 standalone Spark on Mesos（官方推荐） Spark on YARN 使用 Spark Shell 进行交互式编程Spark 官方提供了命令行交互式编程，也就是一边输入一边输出。 安装完 spark 后， 运行 ./bin/spark-shell 即可启动 scala 语言的 spark shell， 运行 ./bin/pyspark即可启动 Python 语言的 spark shell (pyspark)。 独立 spark 应用程序但是我们一般都是在 IDE 里编写独立的应用程序（Self-Contained Applications），再部署打包运行。 我这里根据官方示例，使用 IDEA，编写一个统计文本中包含字母 ‘a’ 的行数和包含字母 ‘b’的行数的 spark 应用程序。 新建 Maven 工程首先新建一个 Maven 工程，然后在 pom.xml 中添加依赖 1234567891011&lt;properties&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;dependency&gt; &lt;!-- Spark dependency --&gt; &lt;groupId&gt;org.apache.spark&lt;/groupId&gt; &lt;artifactId&gt;spark-sql_2.11&lt;/artifactId&gt; &lt;version&gt;2.3.0&lt;/version&gt; &lt;/dependency&gt; properties标签里的内容目的是让我们的工程基于 jdk 1.8 dependencies标签里的内容表示依赖，需要哪些依赖一般 Spark 官方文档 在相应的地方都会有标注，然后可以到MVN仓库去搜，上面会告诉你对应版本的dependency该怎么写。 编写java代码SimpleApp.java 12345678910111213141516171819202122232425/* SimpleApp.java */import org.apache.spark.sql.SparkSession;import org.apache.spark.sql.Dataset;public class SimpleApp { public static void main(String[] args) { // 定义文件路径 （可以说 file:// 也可以是 hdfs://） String logFile = \"file:///home/jerrysheh/spark-2.3.0/README.md\"; //定义 spark 会话 SparkSession spark = SparkSession.builder().appName(\"Simple Application\").getOrCreate(); // 定义数据集（ spark读 logfile 文本文件，缓存） Dataset&lt;String&gt; logData = spark.read().textFile(logFile).cache(); // 数据集过滤，包含 a / b 的就进行统计 long numAs = logData.filter((FilterFunction&lt;String&gt;) s -&gt; s.contains(\"a\")).count(); long numBs = logData.filter((FilterFunction&lt;String&gt;) s -&gt; s.contains(\"b\")).count(); //输出 System.out.println(\"Lines with a: \" + numAs + \", lines with b: \" + numBs); spark.stop(); }} 配置运行环境点击edit configuration，在左侧点击该项目。在右侧 VM options中 输入-Dspark.master=local，指示本程序本地单线程运行。 spark 支持的 master URL 有： local 本地单线程 local[K] 本地多线程（指定K个内核） local[*] 本地多线程（指定所有可用内核） spark://HOST:PORT 连接到指定的 Spark standalone cluster master，需要指定端口。 mesos://HOST:PORT 连接到指定的 Mesos 集群，需要指定端口。 yarn-client 客户端模式 连接到 YARN 集群。需要配置 HADOOP_CONF_DIR。 yarn-cluster 集群模式 连接到 YARN 集群。需要配置 HADOOP_CONF_DIR。 配置完以后，就可以直接在 IDEA 运行，开发阶段不必打包后在命令行运行。 打包使用 mvn 命令打包安装 maven 1sudo apt install maven 打包 jar 1mvn package 这样 out 目录就生成了 一个 jar 文件，这就是我们的 spark 应用程序了。 使用 IDEA 打包用 maven 打包的 jar 非常大，因为把很多依赖都打包进去了，我们可以用 IDEA 删除我们不需要的组件，这样打包出来的 jar 就很小了。 使用 IDEA 打包的方法可以参考：利用开发工具IntelliJ IDEA编写Spark应用程序 如果需要 sql 驱动，可以这样写： 12345678910// 从数据库读 DataFramedef readFromMySQL(spark: SparkSession, tableName:String): DataFrame = { val prop=new java.util.Properties prop.setProperty(\"driver\", \"com.mysql.cj.jdbc.Driver\") prop.setProperty(\"user\",\"root\") prop.setProperty(\"password\",\"YOURPASSWORD\") val df = spark.read.jdbc(jdbcURL, tableName, prop) df} 这样当提交到 spark-submit 的时候会读取你的驱动，否则报 Driver not found 运行在 spark 安装目录下 1./bin/spark-submit --class &quot;SimpleApp&quot; --master local[4] simple-project.jar 输出： 123......Lines with a: 46, Lines with b: 23 这样，一个简单的 spark 应用程序就运行成功了。 只输出 WARN 和 ERROR 不输出 INFO把 SPARK_HOME/conf 下的 log4j.properties.template 复制到 工程 Resource Root 下面（我这里是 Scala 包），重命名为 log4j.properties 。 打开，修改其中的 1log4j.rootCategory=INFO, console 将 INFO 改成 WARN 或者 ERROR 即可","link":"/post/a08d78bf.html"},{"title":"Head First HTML","text":"HTML是HyperText Markup Language 超文本标记语言的缩写。 HTML是由一套标记标签 （markup tag）组成，通常就叫标签。 基本元素普通元素 元素 简介 &lt;h1&gt; 标题 &lt;p&gt; 段落（paragraph），自带换行效果 &lt;b&gt; 或 &lt;strong&gt; 粗体，推荐用 &lt;strong&gt; &lt;br /&gt; 空行 &lt;i&gt; 或 &lt;em&gt; 斜体 &lt;pre&gt; 预格式，用来显示代码 &lt;del&gt; 删除线 &lt;ins&gt; 下划线(尽量不用，因为会跟超链接混淆) &lt;a&gt; 定义超链接，用于从一张页面链接到另一张页面。 例子 1234567891011&lt;html&gt; &lt;head&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=GB2312\"&gt; &lt;/head&gt; &lt;body&gt; &lt;h1&gt;大标题&lt;/h1&gt; &lt;br/&gt; &lt;h2&gt;二级标题&lt;/h2&gt; &lt;p&gt;Hello World&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; &lt;meta&gt;解决了中文编码问题，如果 GB2312 不行，就用UTF-8 在标签中可以加入属性，比如居中 123&lt;h1 &gt;未设置居中的标题&lt;/h1&gt;&lt;h1 align=\"center\"&gt;居中标题&lt;/h1&gt; 图片元素 元素 简介 &lt;img src=”http://example.com/hello.png&quot;/&gt; 图片（链接可以是本地也可以是联网） &lt;img width=”200” height=”200” src=”http://example.com/hello.png&quot;/&gt; 设置图片宽高 &lt;img src=”http://example.cn/not_exist.gif&quot; alt=”加载失败” /&gt; alt用来显示图片加载失败时的提示语 让图片显示在页面左边 123&lt;div align=\"left\"&gt; &lt;img src=\"http://example.com\"/&gt;&lt;/div&gt; 超链接文字超链接 1&lt;a href=\"http://www.12306.com\" title=\"跳转到http://www.12306.com\"&gt;www.12306.com&lt;/a&gt; 图片超链接 123&lt;a href=\"http://www.12306.com\"&gt;&lt;img src=\"http://how2j.cn/example.gif\"/&gt;&lt;/a&gt; 表格三行二列的表格 &lt;tr&gt; 表示 行 &lt;td&gt; 表示 列 border属性表示边框 width表示宽度（屏幕是1920*1080，那横向就有1920像素） 1234567891011121314151617&lt;table border=\"1\" width=\"800px\"&gt; &lt;tr&gt; &lt;td&gt;1&lt;/td&gt; &lt;td&gt;2&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;3&lt;/td&gt; &lt;td&gt;4&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;a&lt;/td&gt; &lt;td&gt;b&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; align水平对齐，valign垂直对齐，bgcolor背景颜色 colspan属性表示，这一行横跨了 第一列和第二列 rowspan属性表示，这一列纵跨了 第一行和第二行 列表无序列表1234&lt;ul&gt;&lt;li&gt;DOTA&lt;/li&gt;&lt;li&gt;LOL&lt;/li&gt;&lt;/ul&gt; 效果： DOTA LOL 有序列表1234&lt;ol&gt;&lt;li&gt;地卜师&lt;/li&gt;&lt;li&gt;卡尔&lt;/li&gt;&lt;/ol&gt; 效果： 地卜师 卡尔 字体和颜色&lt;font&gt;标签表示字体 可用 color 属性 和 size 属性 12345&lt;font color=\"green\"&gt;绿色默认大小字体&lt;/font&gt;&lt;br&gt;&lt;font color=\"blue\" size=\"+2\"&gt;蓝色大2号字体&lt;/font&gt;&lt;br&gt;&lt;font color=\"red\" size=\"-2\"&gt;红色小2号字体&lt;/font&gt; &lt;div&gt; 和 &lt;span&gt;这两种标签都是布局用的，本身没有任何显示效果，通常是用来结合css进行页面布局 div是块元素，即自动换行，常见的块元素还有h1,table,p span是内联元素，即不会换行，常见的内联元素还有img,a,b,strong 例子 123456789&lt;img style=\"margin-left:50px\" src=\"http://how2j.cn/example.gif\"/&gt; &lt;br/&gt; &lt;img style=\"margin-left:50px\" src=\"http://how2j.cn/example.gif\"/&gt;&lt;div style=\"margin-left:100px\" &gt; &lt;img src=\"http://how2j.cn/example.gif\"/&gt; &lt;br/&gt; &lt;img src=\"http://how2j.cn/example.gif\"/&gt;&lt;/div&gt; 转义有时候我们确实想输入 &lt;h&gt; 这几个符号，但是HTML渲染的时候会自动把他们渲染成元素，而使我们看不到，这时候就要用转义。 显示 转义 空格 &amp;nbsp; &lt; &amp;lt; &gt; &amp;gt; &amp; &amp;amp; &quot; （引号） &amp;quot; &apos; （撇号）(IE不支持) &amp;apos; 文本框&lt;input&gt;标签中的 type 属性，设置为 text 是文本框， password 是密码框 属性disabled=&quot;disabled&quot;可以让文本框只输出，不能输入 属性id='id'可以给这个标签添加唯一id号 有初始值的文本框1&lt;input type=\"text\" value=\"666\"&gt; 效果： 获取文本框的值1document.getElementById(id).value; 如果需要类型转换，对整体做 parseInt(); 方法 给文本框赋值12var d = 66;document.getElementById(id).value = d; 有提示语的文本框（HTML5 only）1&lt;input type=\"text\" placeholder=\"请输入账号\"&gt; 效果： 密码框1&lt;input type=\"password\"&gt; 效果： 选择框&lt;input&gt;标签中的 type 属性，设置为 radio 是单选， checkbox是复选。 单选框 checked属性表示默认选中 name属性表示同一组 123是&lt;input type=\"radio\" name=\"yesOrNo\" value=\"是\" &gt;&amp;nbsp;否&lt;input type=\"radio\" checked=\"checked\" name=\"yesOrNo\" value=\"否\" &gt; 是 &nbsp;&nbsp; 否 复选框12345&lt;input type=\"checkbox\" name=\"Ojbk\" value=\"jerry\" &gt;&amp;nbsp;&lt;input type=\"checkbox\" checked=\"checked\" name=\"Ojbk\" value=\"calm\" &gt; &amp;nbsp;&lt;input type=\"checkbox\" name=\"Ojbk\" value=\"superman\" &gt; jerry &nbsp; calm &nbsp; superman 下拉列表&lt;select&gt;标签表示一个下拉列表， &lt;option&gt;标签是下拉列表的每个项 multiple=&quot;multiple&quot; 属性表示可以多选，按ctrl或shift进行多选 selected=&quot;selected&quot; 属性表示默认选中 12345&lt;select multiple=\"multiple\" selected=\"selected\" &gt; &lt;option &gt;jerry&lt;/option&gt; &lt;option &gt;calm&lt;/option&gt; &lt;option &gt;superman&lt;/option&gt;&lt;/select&gt; 单选 jerry calm superman&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;多选（按住ctrl） jerry calm superman 按钮使用&lt;input&gt;标签&lt;input&gt;标签中的 type 属性，设置为 button是 按钮 1&lt;input type=\"button\" value=\"我是按钮\"&gt; 注意：普通按钮不具备在表单中提交的功能，如要提交，用type=&quot;submit&quot;，见下文。 &lt;input&gt;标签中的 type 属性，设置为 reset，可以把输入框的改动复原 1&lt;input type=\"reset\" value=\"重置\"&gt; 使用&lt;button&gt;标签&lt;button&gt;&lt;/button&gt;即按钮标签，与&lt;input type=&quot;button&quot;&gt;不同的是，&lt;button&gt;标签功能更为丰富。按钮标签里的内容可以是文字也可以是图像 如果&lt;button&gt;的type=&quot;submit&quot; ，那么它就具备提交form的功能 1&lt;button&gt;&lt;img src=\"http://how2j.cn/example.gif\"/&gt;&lt;/button&gt; 效果： 表单(form)&lt;form&gt; 用于向服务器提交数据，比如账号密码 action属性表示要提交的服务器页面地址 method属性表示HTTP方法（get or post） 123456&lt;form method=\"get\" action=\"http:/127.0.0.1/login.jsp\"&gt;账号：&lt;input type=\"text\" name=\"name\"&gt; &lt;br/&gt;密码：&lt;input type=\"password\" name=\"password\" &gt; &lt;br/&gt;&lt;input type=\"submit\" value=\"登录\"&gt;&lt;input type=\"reset\" value=\"重置\"&gt;&lt;/form&gt; 账号： &nbsp; 密码： &nbsp; &nbsp; > 通常，我们提交一些文本数据，可以用 get 方法，而且数据会在浏览器地址栏显示出来。但是假若我们想提交二进制数据，比如上传文件，就必须用post。此外，为了安全起见，登录功能也要用post 如果要提交图片，把 input 标签的type属性改为 image 表单中 id 跟 name 的区别name是传到服务器被服务器识别的 id是HTML中该元素的唯一标识 文本域&lt;textarea&gt;标签表示文本域 cols 和 rows表示宽高 123&lt;textarea cols=\"15\" rows=\"5\"&gt;abcdef&lt;/textarea&gt; hello world, and hello again 如何去除两个紧邻元素的空格？当我们想让两张图片紧挨着，如： 12&lt;img id=\"1\" src=\"../static/icon/star_hollow_hover.png\"&gt;&lt;img id=\"2\" src=\"../static/icon/star_hollow_hover.png\"&gt; 却发现中间多了一个空格。去除方法是：在父div上添加font-size: 0 1234&lt;div id=\"img_group\" style=\"font-size: 0;\"&gt; &lt;img id=\"1\" src=\"../static/icon/star_hollow_hover.png\"&gt; &lt;img id=\"2\" src=\"../static/icon/star_hollow_hover.png\"&gt;&lt;/div&gt;","link":"/post/65acdb59.html"},{"title":"JavaScript（三）Document Object Model","text":"前面提到，完整的 Javascript 由以下三个部分组成： 语言基础 BOM（Browser Object Model 浏览器对象模型） DOM（Document Object Model 文档对象模型） 这一篇主要讲讲 DOM ，DOM 其实就是把 html 里面的各种数据当作对象进行操作的一种思路。 那么 DOM 有什么作用呢？ 通过可编程的对象模型，JavaScript 获得了足够的能力来创建动态的 HTML。 能够改变页面中的所有 HTML 元素或属性 能够改变页面中的所有 CSS 样式 能够对页面中的所有事件做出反应 改变HTML元素和属性改变元素内容把 Hello World 替换成了 WTF 1234567891011&lt;html&gt;&lt;body&gt;&lt;p id=\"p1\"&gt;Hello World!&lt;/p&gt;&lt;script&gt;document.getElementById(\"p1\").innerHTML=\"WTF\";&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 改变元素属性把 smiley.gif替换成了 landscape.jpg 123456789101112&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;img id=\"image\" src=\"smiley.gif\"&gt;&lt;script&gt;document.getElementById(\"image\").src=\"landscape.jpg\";&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 当用户点击按钮时，改变CSS属性 123&lt;h1 id=\"id1\"&gt;My Heading 1&lt;/h1&gt;&lt;button type=\"button\" onclick=\"document.getElementById('id1').style.color='red'\"&gt;点击这里&lt;/button&gt; 效果： My Heading 1 点击这里 使用onmouseover= 来让鼠标移到上面时发生事件，onmouseout=来让鼠标移除时发生事件 使用onclick=来让鼠标点击时发生事件 使用onchange=来让 onmousedown, onmouseup 以及 onclick 构成了鼠标点击事件的所有部分。首先当点击鼠标按钮时，会触发 onmousedown 事件，当释放鼠标按钮时，会触发 onmouseup 事件，最后，当完成鼠标点击时，会触发 onclick 事件。 改变元素的 class 1document.getElementById(\"btn_1\").className = 'btn btn-light btn-margin'; 删除前提示12345678910111213141516171819202122232425262728293031323334353637&lt;script&gt; function deleteRow(link) { var c = confirm(\"确定删除吗？\"); if (!c) return; var table = document.getElementById(\"nameTable\"); var td = link.parentNode; var tr = td.parentNode; var index = tr.rowIndex; table.deleteRow(index); }&lt;/script&gt;&lt;table border=\"1\" id=\"nameTable\"&gt; &lt;tr&gt; &lt;td&gt;名字&lt;/td&gt; &lt;td&gt;操作&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Jerry&lt;/td&gt; &lt;td&gt; &lt;a href=\"#\" onclick=\"deleteRow(this)\"&gt;删除&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Calm&lt;/td&gt; &lt;td&gt; &lt;a href=\"#\" onclick=\"deleteRow(this)\"&gt;删除&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;Superman&lt;/td&gt; &lt;td&gt; &lt;a href=\"#\" onclick=\"deleteRow(this)\"&gt;删除&lt;/a&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/table&gt; 通过document.getElementById(&quot;nameTable&quot;)获取到这张表 link就是this，通过link.parentNode和td.parentNode获取到所在的这一行 通过tr.rowIndex获取到这一行的下标index 通过 table.deleteRow(index) 删除这一行 登录前判断用户名或密码是否为空123456789101112131415161718192021222324252627&lt;body&gt;&lt;script&gt; function login() { var name = document.getElementById(\"name\"); if (name.value.length === 0){ alert(\"用户名不能为空\"); return false; } var psw = document.getElementById(\"password\") if (psw.value.length === 0){ alert(\"密码不能为空\") return false; } return true; }&lt;/script&gt;&lt;form method=\"get\" action=\"https://www.google.com\" onsubmit=\"return login()\"&gt; 账号：&lt;input type=\"text\" name=\"name\" id=\"name\" &gt; &lt;br/&gt; 密码：&lt;input type=\"password\" name=\"password\" id=\"password\" &gt; &lt;br/&gt; &lt;input type=\"submit\" value=\"登录\"&gt; &lt;input type=\"reset\" value=\"重置\"&gt;&lt;/form&gt;&lt;/body&gt; 效果: function login() { var name = document.getElementById(\"name\"); if (name.value.length === 0){ alert(\"用户名不能为空\"); return false; } var psw = document.getElementById(\"password\") if (psw.value.length === 0){ alert(\"密码不能为空\") return false; } return true; } 账号： 密码： 用document.getElementById(&quot;name&quot;)来获取账号输入框的内容 在表单中，用onsubmit=&quot;return login()&quot;来验证登录 注册时验证年龄必须是数字 / 整数123456789101112131415var age = document.getElementById(\"age\");if(age.value.length==0){ alert(\"年龄不能为空\"); return false;}if(isNaN(age.value)){ alert(\"年龄必须是数字\"); return false;}if(parseInt(age.value)!=age.value){ alert(\"年龄必须是整数\"); return false;}return true; 验证 Email 格式12345678var Regex = /^(?:\\w+\\.?)*\\w+@(?:\\w+\\.)*\\w+$/; if (!Regex.test(email.value)){ alert(\"email格式不正确\"); return false;} return true;} 隐藏和显示12345678910111213141516&lt;div id=\"d\"&gt; 一个普通的div&lt;/div&gt;&lt;script&gt;function hide(){ var d = document.getElementById(\"d\"); d.style.display=\"none\";}function show(){ var d = document.getElementById(\"d\"); d.style.display=\"block\";}&lt;/script&gt; 用document.getElementById(&quot;d&quot;)来获取对象 用d.style.display来设置对象的隐藏和显示","link":"/post/f75e92e9.html"},{"title":"JavaScript（二）Browser Object Model","text":"浏览器对象模型(Brower Object Model)浏览器对象模型(Brower Object Model) 就是所谓的 BOM 浏览器对象包括： Window(窗口) Navigator(浏览器) Screen (客户端屏幕) History(访问历史) Location(浏览器地址) windows 用window.innerWidth和window.innerHeight获取浏览器的文档显示区域的宽和高 用window.outerWidth和window.outerHeight获取浏览器外部窗体的宽和高 用window.open(&quot;/&quot;)打开一个新页面，这里的/指本站的根目录。只能打开本站网页。（不建议在用户不知情的情况下随意打开新页面，影响用户体验） 体验一下： function openNewWindow(){ myWindow=window.open(\"/\"); } 回到主页 NavigatorNavigator提供浏览器相关的信息 属性 简介 navigator.appName 浏览器产品名称 navigator.appVersion 浏览器版本号 navigator.appCodeName 浏览器内部代码 navigator.platform 操作系统 navigator.cookieEnabled 是否启用Cookies navigator.userAgent 浏览器的用户代理报头 弹出框 用alert显示一个警告窗 用confirm显示一个确认框，根据用户选择，返回true or false 用prompt显示一个输入框 确认框例子 12345678&lt;script&gt;function del(){var d = confirm(\"是否要删除\"); // d 是 boolean 类型}&lt;/script&gt;&lt;br&gt;&lt;button onclick=\"del()\"&gt;删除&lt;/button&gt; 输入框例子 123456789&lt;script&gt;function p(){var name = prompt(\"请输入用户名:\"); // name 是 string 类型alert(\"您输入的用户名是:\" + name);}&lt;/script&gt;&lt;br&gt;&lt;button onclick=\"p()\"&gt;请输入用户名&lt;/button&gt; LocationLocation 对象包含有关当前 URL 的信息。 1234567&lt;script&gt;// url的值为当前URLvar url = location.href// 跳转到谷歌location.href = \"https://www.google.com\"&lt;/script&gt; 参考： Location 对象 下一篇介绍Javascript中的DOM（文档对象模型）","link":"/post/8a9941f1.html"},{"title":"MyBatis大批量数据处理","text":"前言最近项目里需要跨数据库同步大批量数据（百万到千万级别），以前都是用 JDBC 来实现。在 JDBC 里，我们能灵活地使用流查询来批次摄取处理，避免OOM，但 JDBC 这玩意儿写多了，谁都会嫌它既啰嗦又繁琐（但性能真香）。于是这次决定用 Springboot + Mybatis 框架来试试。因为涉及到多个数据源和不同的数据库产品（Oracle、PostgreSQL、MySQL），所以在项目里使用了动态数据源。 关于 Springboot 多数据源方案，我参考过最好的文章为下面的3连载，推荐一看。 搞定SpringBoot多数据源(1)：多套源策略 搞定SpringBoot多数据源(2)：动态数据源 搞定SpringBoot多数据源(3)：参数化变更源 至于使用 Mybatis 做大批量数据读取和插入，先前也是阅读了大量的参考资料和文档。总体思想跟 JDBC 是一致的，即：流式查询、批量插入。但在讲 Mybatis 之前，先回顾一下 JDBC 时代是怎么做的吧。 JDBC 驱动的那些坑以前写 JDBC 时，通常是通过设置 fetchsize 来控制每次读取的数据量。fetchsize 并不是分页查询，而是数据库一次缓存到客户端的数量。所以在查询大量数据时，并不需要在SQL里手动写 limit n offset m 这样的分页语法。 JDBC 返回的数据类型是 ResultSet，这个玩意特别有意思，它是动态的。意思就是说，在你发起查询时，客户端与数据库的连接会一直保持打开，之后我们通过 while(rs.next()) 逐条操作 ResultSet 里的每一条记录。 等缓存的数据量都遍历完了， 数据库会通过 TCP 连接发送下一批次的数据放到 ResultSet 里。全程对我们无感，我们要做的，只是不断地 rs.next() 就行了。 但是，不同的数据库产品对 fetchsize 的支持不一样。像 Oracle 这种标准的商业数据库，对 fetchsize 的支持就比较好，无脑使用即可。而 MySQL 和 PostgreSQL 就没那么简单了。 MySQL 流查询查阅 MySQL 的官方文档，里面提到： By default, ResultSets are completely retrieved and stored in memory. In most cases this is the most efficient way to operate and, due to the design of the MySQL network protocol, is easier to implement. If you are working with ResultSets that have a large number of rows or large values and cannot allocate heap space in your JVM for the memory required, you can tell the driver to stream the results back one row at a time. To enable this functionality, create a Statement instance in the following manner: 123stmt = conn.createStatement(java.sql.ResultSet.TYPE_FORWARD_ONLY, java.sql.ResultSet.CONCUR_READ_ONLY);stmt.setFetchSize(Integer.MIN_VALUE); The combination of a forward-only, read-only result set, with a fetch size of Integer.MIN_VALUE serves as a signal to the driver to stream result sets row-by-row. After this, any result sets created with the statement will be retrieved row-by-row. 也就是说，默认情况下，MySQL会一次性返回所有数据，fetchsize 并不起作用。如果想一条一条处理，必须在创建 prepareStatement 时指定参数，同时设置 fetchsize 的值为 Integer.MIN_VALUE 作为流式查询的标志。 这种操作很有意思。之前在阅读《高性能MySQL》时，看到书里面打过一个比喻，说 MySQL 的服务器和客户端，就像是水管的两端。一旦发起查询，水便源源不断地从进水口灌向出水口，此时出水口只能被动地被灌水，做什么也无济于事。既然通信协议都设计成这样了，为什么还可以实现做到流式查询，一条一条地处理呢？查阅了一些资料后得知，其奥妙在于借助了 TCP 的阻塞策略。即服务器向客户端发送 TCP 流，而客户端 TCP buffer 满了，在客户端没消费之前， TCP 连接会一直阻塞。这就像你把水管出水口用塞子塞住了，一次只允许流一滴水出来。 MySQL 默认情况下，创建 prepareStatement 时，就已经是 ResultSet.TYPE_FORWARD_ONLY 和 ResultSet.CONCUR_READ_ONLY ，所以这两个参数可加可不加。 PostgreSQL 流查询PostgreSQL 默认情况下， fetchsize也是无效的。官方文档里提到，要让 fetchsize 生效，连接必须是非自动提交 。即： 123conn.setAutoCommit(false);Statement statement = conn.createStatement();statement.setFetchSize(500); MyBatis 流查询Mybatis 也是支持流数据查询的，主要是用了 ResultHandler 回调，对结果集的每一条进行处理，处理完即丢弃（释放内存），所以不会内存溢出。 1void query(ResultHandler&lt;?&gt; handler); 12345productMapper.query( resultContext -&gt; { Product p = (Product) resultContext.getResultObject() // 处理单条记录 // ...}); 如果是 MySQL， fetchSize 要设置成 -2147483648，即Integer.MIN_VALUE 的值。 PostgreSQL 或 Oracle 则设置 fetchSize=1000 ，fetchSize 大小可以自行调整。 123&lt;select id=\"query\" fetchSize=\"-2147483648\" resultSetType=\"FORWARD_ONLY\" resultType=\"me.jerrysheh.demo.entity.Product\"&gt; SELECT product_id, product_name, product_price FROM fun_product&lt;/select&gt; 在 PostgreSQL 测试时，发现不起作用，PostgreSQL 驱动还是一次性把几十万数据拉到了内存里，导致了 OOM。 结合刚刚上面提到的 PostgreSQL 需要把自动提交关闭才会启用 fetchsize，初步判断是自动提交的原因。但我们的 productMapper 是自动注入进来的，如果要改，还得从底层的 datasource -&gt; SqlSessionFactory -&gt; Sqlsession -&gt; mapper 一层一层地手动注入进来。实际使用中根本不方便。 所以另辟蹊径，这里我给这个查询加了个事务，事务当中的SQL，肯定是手动提交的，只不过Spring帮我们管理了： 1234567891011transactionTemplate.execute( status -&gt; { productMapper.query( resultContext -&gt; { Product p = (Product) resultContext.getResultObject() // 处理单条记录 // ... }); return null;} ) 这下查询就搞定了！ MyBatis 批量插入批量插入没什么好说的，就是在查询过程中，积累了1000条，统一提交插入，用的 mybatis 的 &lt;foreach&gt; 标签。 1234567891011121314151617181920212223242526272829List&lt;Product&gt; list = new ArrayList&lt;&gt;();// 切换数据源datasourceContentHolder.setDatasource(\"my_pg\")transactionTemplate.execute( status -&gt; { productMapper.query( resultContext -&gt; { Product p = (Product) resultContext.getResultObject() // 处理单条记录 // ... list.add(p); if (list.size &gt;= 1000){ DatasourceContentHolder.setDatasource(\"my_oracle\") productMapper.batchUpdate(list); // 插入完记得把 list 清掉 list.clear(); } }); return null;} )// 记得处理最后不足1000条的数据if (list.size &gt; 0){ DatasourceContentHolder.setDatasource(\"my_oracle\") productMapper.batchUpdate(list); list.clear();} 但是在实际操作中，发现数据源无论如何都切换不过去。查阅资料发现，在 Spring 的动态数据源（AbstractRoutingDataSource）中，如果使用到了事务，那么当前线程默认拿事务的数据源，除非拿不到，才会去 ThreadLocal 里面拿。所以我们的DatasourceContentHolder.setDatasource(&quot;my_oracle&quot;) 不起作用。 解决方法也很简单粗暴，将productMapper.batchUpdate(list)封装到另一个 public 方法去，加上注解将插入操作排除在事务之外即可。 1234567@Transactional(propagation=Propagation.NOT_SUPPORTED)public void doUpdate(List&lt;Product&gt; list){ DatasourceContentHolder.setDatasource(\"my_oracle\") productMapper.batchUpdate(list); // 插入完记得把 list 清掉 list.clear();}","link":"/post/7969a482.html"},{"title":"JavaScript（一）基础语法","text":"JavaScript用于网页和用户之间的交互，比如提交的时候，进行用户名是否为空的判断。 完整的 Javascript 由以下三个部分组成： 语言基础 BOM（Browser Object Model 浏览器对象模型） DOM（Document Object Model 文档对象模型） 基本语法标签JavaScript 必须写在 &lt;script&gt; 里 1234567&lt;html&gt; &lt;head&gt; &lt;script&gt; document.write(\"这是 javascript\"); &lt;/script&gt; &lt;/head&gt;&lt;/html&gt; 在文档加载结束后使用 document.write，会覆盖整个HTML的内容 也可以在HTML中引用 .js 文件 123&lt;html&gt; &lt;script src=\"http://jerrysheh.com/study/hello.js\"&gt;&lt;/script&gt;&lt;/html&gt; 变量用 var 声明变量，关键字var 也可以省略。但省略就是全局变量，所以不建议省略。 1234&lt;script&gt; var x = 10; document.write(\"变量x的值:\"+x);&lt;/script&gt; 基本数据类型 关键字 简介 undefined 声明了但未赋值 Boolean 布尔 Number 数字 String 字符串 var 动态类型 typeof 变量类型判断 null 空对象/对象不存在 JavaScript 中单引号和双引号都表示字符串 JavaScript 中，即使是基本数据类型，也有属性和方法 当不确定某个变量是什么类型的时候，可以用使用typeof来进行判断数据类型 12var name = 'jerry'typeof name // string JavaScript中的变量类型是动态的 123var x // x 为 undefinedvar x = 6; // x 为数字var x = \"Bill\"; // x 为字符串 类型转换使用内置函数toString()转换为字符串。 比如说，我们可以对 Number 或者 Boolean 执行 toString()方法。 将a转换为16进制字符串 12var a = 18a.toString(16) 对于有Null值的情况，用String()会返回null，用toString()报错。 使用内置函数 parseInt()、parseFloat()或 Number()转换为数字 parseInt会一直定位数字，直到出现非字符。 所以10abc会被转换为10。但是abc10返回NaN，如果没有数字，也返回NaN。 Number()必须为纯数字，如果参杂其他字符，直接返回NaN。 使用内置函数Boolean()转换为Boolean值 当转换字符串时：非空即为true 当转换数字时： 非0即为true 当转换对象时：非null即为true 绝对等运算符JavaScript的运算符跟 Java 区别不大，但是有一点要注意： ==是等于运算符，表示：值相等（类型不一定相等） ===是绝对等运算符，表示：类型相等，值也相等 例如，数字1和字符串1，值都是1，但是类型是不一样的 函数和语句函数定义了函数，必须调用才能执行。return、作用域等跟 Java 类似。不再赘述。 12345678&lt;script&gt;function print(message){ document.write(message);}print(\"hello\");print(\"&lt;br&gt;\");print(\"world\");&lt;/script&gt; 输出 12helloworld 在写前端文件的时候，通常把 JavaScript 脚本写在最后面，以提高网页的加载速度。当需要在加载时立即执行 JavaScript 代码，可以用 onload=&quot;jfun()&quot; 属性。其中 jfun() 是 JS 函数名称。 语句跟Java类似， JavaScript也支持 条件语句、循环语句、try-catch语句 其中循环语句还支持 forEach 循环。 但是跟 Java 的 forEach 有点不一样 1234567var strs = [\"America\",\"Greece\",\"Britain\",\"Canada\",\"China\",\"Egypt\"];var count = 0;for (var str in strs) { if (strs[str].match(\"a\") != null) { count++; }} 这里的str，是strs的下标，因此要表达数组的每个元素，用strs[str] continue、break 什么的当然也是存在的啦 事件用户任何对网页的操作，都会产生一个事件。 事件有很多种，比如鼠标移动，鼠标点击，键盘点击等等。 鼠标点击事件1234567&lt;script&gt;function showHello(){ alert(\"Hello JavaScript\");}&lt;/script&gt;&lt;button onclick=\"showHello()\"&gt;点击一下&lt;/button&gt; 效果如下 function showHello(){ alert(\"Hello JavaScript\"); } 点击有惊喜 对象对象是有属性和方法的一种特殊数据类型。 常见的对象有数字Number，字符串String，日期Date，数组Array等。 跟 Java 一样，可以通过 new 来创建一个对象 1234&lt;script&gt; var x = \"5\"; var y = new String(x);&lt;/script&gt; 常用的数字方法 关键字 简介 new Number 创建一个数字对象 属性MIN_VALUE 最小值 属性MAX_VALUE 最大值 属性NaN 表示不是数字 方法toFixed 返回一个数字的小数表达 方法toExponential 返回一个数字的科学计数法表达 方法valueOf 返回一个数字对象的基本数字类型 常用的字符串方法 关键字 简介 new String() 创建字符串对象 属性 length 字符串长度 方法 charAt charCodeAt 返回指定位置的字符 方法 concat 字符串拼接 方法 indexOf lastIndexOf 子字符串出现的位置 方法 localeCompare 比较两段字符串是否相同 方法 substring 截取一段子字符串 方法 split 根据分隔符，把字符串转换为数组 方法 replace 替换子字符串 常用的数组方法 关键字 简介 new Array 创建数组对象 属性 length 数组长度 for / for in 遍历一个数组 方法 concat 连接数组 方法 join 通过指定分隔符，返回一个数组的字符串表达 方法 push pop 分别在最后的位置插入数据和获取数据(获取后删除) 方法 unshift shift 分别在最开始的位置插入数据和获取数据(获取后删除) 方法 sort 对数组的内容进行排序 方法 sort(comparator) 自定义排序算法 方法 reverse 对数组的内容进行反转 方法 slice 获取子数组 方法 splice 删除和插入元素 常用的数学方法 关键字 简介 属性E PI 自然对数和圆周率 方法 abs 绝对值 方法 min max 最小最大 方法 pow 求幂 方法 round 四舍五入 方法 random 随机数 自定义对象直接定义对象1234567var person={firstname : \"Bill\",lastname : \"Gates\",id : 5566};var n = person.lastname; 函数封装对象123456789101112function Hero(name){ this.name = name; this.go = function(){ document.write(this.name + \"正在前进&lt;br&gt;\"); }}var gareen = new Hero(\"盖伦\");gareen.go();var teemo = new Hero(\"提莫\");teemo.go(); 用 prototype 实现为已存在的对象增添新的方法，例如为 Hero 增添 back 方法 12345Hero.prototype.back = function(){ document.write(this.name + \"正在后退&lt;br&gt;\");}gareen.back(); 日期格式化函数1234getDate:function (strDate) { var d = new Date(strDate); return d.getFullYear() + '-' + (d.getMonth() + 1) + '-' + d.getDate() + ' ' + d.getHours() + ':' + d.getMinutes() + ':' + d.getSeconds();}","link":"/post/21eaf7cd.html"},{"title":"使用 Mybatis 简化 JDBC 操作","text":"在 Java简明笔记（十三）JDBC 中，使用 JDBC 来操作数据库，并把查询到的数据库信息进行 java 对象的映射（ORM），但是 JDBC 除了需要自己写SQL之外，还必须操作Connection, Statment, ResultSet，显得繁琐和枯燥。于是我们对 JDBC 进行封装，以简化数据库操作。mybatis就是这样的一个框架。 以下简介摘自官方文档： MyBatis是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生信息，将接口和 Java 的 POJOs(Plain Old Java Objects,普通的 Java对象)映射成数据库中的记录。 IDEA 实战创建数据库和表使用 MYSQL ： 创建数据库，库名: myball 创建表，表名：category_ 表分为 id 列 和 name 列， name 列填充category1 和 category2 新建工程使用 IDEA 新建一个 maven 工程，在 pom.xml 中写入依赖 pom.xml 12345678910111213&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.4.6&lt;/version&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.9-rc&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; mybatis依赖从官方文档中找，版本信息从 github 找 mysql依赖从 mvn 仓库找 准备实体类 Category这个类用来映射数据库信息为java对象（数据库 category_ 表 -&gt; java 的 category对象） 注意：java对象要和数据库信息对应上。比如表category_有 id 和 name，对象category就要有 int id 和 String name。 src/main/java/com.jerrysheh.pojo/Category.java 12345public class Category { private Long id; private String name; // 省略 getter setter} 创建配置文件 mybatis-config.xml在 src/main/java 目录下 创建 mybatis-config.xml，填入以下内容： （SpringBoot 免此配置） 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE configuration PUBLIC \"-//mybatis.org//DTD Config 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-config.dtd\"&gt;&lt;configuration&gt; &lt;typeAliases&gt; &lt;package name=\"com.jerrysheh.pojo\"/&gt; &lt;/typeAliases&gt; &lt;environments default=\"development\"&gt; &lt;environment id=\"development\"&gt; &lt;transactionManager type=\"JDBC\"/&gt; &lt;dataSource type=\"POOLED\"&gt; &lt;property name=\"driver\" value=\"com.mysql.cj.jdbc.Driver\"/&gt; &lt;property name=\"url\" value=\"jdbc:mysql://localhost:3306/myball?characterEncoding=UTF-8&amp;amp;serverTimezone=GMT%2B8&amp;amp;useSSL=false\"/&gt; &lt;property name=\"username\" value=\"root\"/&gt; &lt;property name=\"password\" value=\"123456\"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource=\"com/jerrysheh/pojo/Category.xml\"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; &lt;dataSource&gt;主要提供连接数据库用的驱动，数据库名称，编码方式，账号密码以及别名 &lt;typeAliases&gt; 写明包后，就会自动扫描这个包下面的类型 &lt;mappers&gt;是映射 创建配置文件 Category.xml在包 com.jerrysheh.pojo 下创建 Category.xml 12345678910&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.jerrysheh.pojo\"&gt; &lt;select id=\"listCategory\" resultType=\"Category\"&gt; select * from category_ &lt;/select&gt;&lt;/mapper&gt; namespace指明哪个包 resultType指映射出来的java对象类型，因为在上一个配置文件已经在&lt;typeAliases&gt;写明包名，所以这里不用给出全名（com.jerrysheh.pojo.Category） 测试类 TestTest.java 12345678910111213public class Test { public static void main(String[] args) throws IOException { String resource = \"mybatis-config.xml\"; InputStream inputStream = Resources.getResourceAsStream(resource); SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); SqlSession session = sqlSessionFactory.openSession(); List&lt;Category&gt; cs = session.selectList(\"listCategory\"); for (Category c : cs) { System.out.println(c.getName()); } }} 事实上，Mybatis 做了以下几件事: 应用程序找 Mybatis 要数据 Mybatis从数据库中找来数据(通过 mybatis-config.xml 定位哪个数据库，通过 Category.xml 执行对应的select语句) 基于 Category.xml 把返回的数据库记录封装在 Category 对象中 把多个 Category 对象装在一个 Category 集合中 返回一个 Category 对象的集合 使用 mybatis 增删查改修改 Category.xml 文件，添加增删查改的SQL语句。 1234567891011121314151617181920212223242526&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt;&lt;mapper namespace=\"com.jerrysheh.pojo\"&gt; &lt;insert id=\"addCategory\" parameterType=\"Category\" &gt; insert into category_ ( name ) values (#{name}) &lt;/insert&gt; &lt;delete id=\"deleteCategory\" parameterType=\"Category\" &gt; delete from category_ where id= #{id} &lt;/delete&gt; &lt;select id=\"getCategory\" parameterType=\"_int\" resultType=\"Category\"&gt; select * from category_ where id= #{id} &lt;/select&gt; &lt;update id=\"updateCategory\" parameterType=\"Category\" &gt; update category_ set name=#{name} where id=#{id} &lt;/update&gt; &lt;select id=\"listCategory\" resultType=\"Category\"&gt; select * from category_ &lt;/select&gt;&lt;/mapper&gt; 增在测试类Test中通过session将对象映射为数据库信息，插入表 12345678910111213// 这四句是固定写法String resource = \"mybatis-config.xml\";InputStream inputStream = Resources.getResourceAsStream(resource);SqlSessionFactory sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);SqlSession session = sqlSessionFactory.openSession();// 实例化一个Category对象Category c = new Category();c.setName(\"category3\");//通过session，将该对象映射为数据库信息，插入到表中//第一个参数是 Category.xml 中的 idsession.insert(\"addCategory\",c); 删删除 id 号为 2 的category 123456// 实例化一个Category对象Category c = new Category();c.setId(2);//通过session，将该对象映射为数据库信息，从表中删除session.delete(\"deleteCategory\", c); 改123456789// 通过session.selectOne取出一个Category对象// 第二个参数是 Category.xml 的 getCategory 行的 parameterType，这里对应 int ，也就是 id 号Category c= session.selectOne(\"getCategory\",3);//修改对象c.setName(\"修改了的Category名稱\");//通过session，将该对象映射为数据库信息，从表中更新session.update(\"updateCategory\",c); 查123456789101112listAll(session);// 提交和关闭 sessionsession.commit();session.close();private static void listAll(SqlSession session) { List&lt;Category&gt; cs = session.selectList(\"listCategory\"); for (Category c : cs) { System.out.println(c.getName()); }} 模糊查询在 Category.xml 中添加模糊查询语句： 123&lt;select id=\"listCategoryByName\" parameterType=\"string\" resultType=\"Category\"&gt; select * from category_ where name like concat('%',#{0},'%')&lt;/select&gt; concat是一个 SQL 函数，表示字符串连接。在这个例子中，concat(‘%’,#{0},’%’) 表示 [零个或多个字符] + 参数{0} + [零个或多个字符]， 比如参数{0}是 cat，可以匹配 hellocatWTF 在 测试类 Test.java 中 12345678listbyName(session,\"gory\");private static void listbyName(SqlSession session, String param) { List&lt;Category&gt; cs = session.selectList(\"listCategoryByName\", param); for (Category c : cs) { System.out.println(c.getName()); }} session.selectList()提供第二个参数，这个参数就是Category.xml 中的 param #{0} 多条件查询在 Category.xml 中添加多条件查询语句： 查询 id 号大于某个参数的 123&lt;select id=\"listCategoryByIdAndName\" parameterType=\"map\" resultType=\"Category\"&gt; select * from category_ where id&gt; #{id} and name like concat('%',#{name},'%')&lt;/select&gt; 因为是多个参数，而selectList方法又只接受一个参数对象，所以需要把多个参数放在Map里，然后把这个Map对象作为参数传递进去 12345678910111213Map&lt;String,Object&gt; params = new HashMap&lt;&gt;();// id号大于 4 的params.put(\"id\", 4);// name 包含 cat的params.put(\"name\", \"cat\");listbyIdAndName(session,params);private static void listbyIdAndName(SqlSession session, Map&lt;String,Object&gt; param) { List&lt;Category&gt; cs = session.selectList(\"listCategoryByIdAndName\", param); for (Category c : cs) { System.out.println(c.getName()); }} 动态SQLif我们前面提供了 listCategory 全部查询 和 listCategoryByName 模糊查询 两种方式。要写两个 SQL 语句。可以看到 session.selectList() 既能接受一个参数，也能接受两个参数。 那么可不可以，只写一个 SQL 语句， 当session.selectList()只有一个参数的时候，进行全部查询，提供第二个参数的时候，提供模糊查询呢？答案是肯定的。 假如我们要查询的表是 Product_ 表，对应的java对象类为 Product 类。 Product.xml 修改前： 123456789101112131415&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.how2java.pojo\"&gt; &lt;select id=\"listProduct\" resultType=\"Product\"&gt; select * from product_ &lt;/select&gt; &lt;select id=\"listProductByName\" resultType=\"Product\"&gt; select * from product_ where name like concat('%',#{name},'%') &lt;/select&gt; &lt;/mapper&gt; Product.xml 修改后： 1234567891011121314&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\"&gt; &lt;mapper namespace=\"com.how2java.pojo\"&gt; &lt;select id=\"listProduct\" resultType=\"Product\"&gt; select * from product_ &lt;if test=\"name!=null\"&gt; where name like concat('%',#{name},'%') &lt;/if&gt; &lt;/select&gt; &lt;/mapper&gt; 其他动态SQL语句除了 if 以外，还有 where、choose、foreach、bind等动态SQL语句，具体用法可以到网上查找。","link":"/post/f251f1b.html"},{"title":"Java并发编程之AQS","text":"什么是 AQS同步工具类 也叫同步器（Synchronizer）。在使用同步器时，我们发现不同的同步器存在许多共同点，例如 ReentrantLock 和 Semaphore 都支持每次允许一定数量线程通过/等待/取消，也都支持让等待线程执行公平或非公平的队列操作等。 事实上，很多同步工具类在实现时都使用了共同的基类，这就是 AbstractQueuedSynchronizer（AQS），抽象队列同步器。 从字面上理解 AQS: Abstract：抽象类，说明只实现一些通用逻辑，有些方法由子类实现； Queue：使用先进先出（FIFO）队列存储数据； Synchronizer：实现了同步的功能。 说白了，AQS就是一个用来构建锁和同步器的框架，我们可以使用 AQS 简单且高效地构造出应用广泛的同步器。在《Java并发编程实战》一书中，AQS是放在“构建自定义的同步工具”这一章讲解的。当然，JDK里有很多并发工具类也都是基于AQS，包括： ReentrantLock ReentrantReadWriteLock Semaphore CountDownLatch FutureTask AQS 的 stateAQS 是一个同步器，同步器的本质作用是协调资源。我们把资源是否可用称为资源的状态。在 AQS 中用一个 int 变量表示资源状态。 不同的实现对 state 的意义不尽相同，例如： ReentrantLock 的 state 表示锁持有者重入的次数，每重入一次就加一，当 state 降为 0 才表示资源可用； Semaphore 的 state 则表示剩余的可用资源数量； FutureTask 的 state 用来表示任务的状态（尚未开始、正在运行、已完成、已取消等）。 12345678910111213141516// volatile 确保了它的修改对任何线程都是及时可见的private volatile int state;// protected 意味着可由子类重写具体实现protected final int getState() { return state;}protected final void setState(int newState) { state = newState;}protected final boolean compareAndSetState(int expect, int update) { // See below for intrinsics setup to support this return unsafe.compareAndSwapInt(this, stateOffset, expect, update);} 资源有两种模式： 独占模式（Exclusive）：一次只能一个线程获取，如 ReentrantLock。 共享模式（Share）：同时可以被多个线程获取，具体的资源个数可以通过参数指定，如 Semaphore。 一般一种同步器只会用到一种模式，但也有两种模式同时使用的，如 readWriteLock。 acquire 获取资源有了对资源状态的表示，便可通过 acquire(int arg) 方法来获取资源。参数 arg 表示要获取的资源的个数。 12345public final void acquire(int arg) { if (!tryAcquire(arg) &amp;&amp; acquireQueued(addWaiter(Node.EXCLUSIVE), arg)){ selfInterrupt(); }} 获取资源时，由同步器判断是否成功，如果是，则线程获得资源，此时会将该线程当作一个节点放入队列头表示占用资源，然后更新同步器的状态；如果否，在把该线程节点放入队列等待的同时，线程将阻塞。该队列是一个先进先出（FIFO）的双端队列，使用两个指针head和tail用于标识队列的头部和尾部。 队列并不是直接储存线程，而是储存拥有线程的Node节点。 1234567891011121314151617181920212223242526272829303132333435static final class Node { // 标记一个结点（对应的线程）在共享模式下等待 static final Node SHARED = new Node(); // 标记一个结点（对应的线程）在独占模式下等待 static final Node EXCLUSIVE = null; // waitStatus的值，表示该结点（对应的线程）已被取消 static final int CANCELLED = 1; // waitStatus的值，表示后继结点（对应的线程）需要被唤醒 static final int SIGNAL = -1; // waitStatus的值，表示该结点（对应的线程）在等待某一条件 static final int CONDITION = -2; /*waitStatus的值，表示有资源可用，新head结点需要继续唤醒后继结点（共享模式下，多线程并发释放资源，而head唤醒其后继结点后，需要把多出来的资源留给后面的结点；设置新的head结点时，会继续唤醒其后继结点）*/ static final int PROPAGATE = -3; // 等待状态，取值范围，-3，-2，-1，0，1 volatile int waitStatus; volatile Node prev; // 前驱结点 volatile Node next; // 后继结点 volatile Thread thread; // 结点对应的线程 Node nextWaiter; // 等待队列里下一个等待条件的结点 // 判断共享模式的方法 final boolean isShared() { return nextWaiter == SHARED; } Node(Thread thread, Node mode) { // Used by addWaiter this.nextWaiter = mode; this.thread = thread; } // 其它方法忽略，可以参考具体的源码} acquire 方法里的 addWaiter(Node.EXCLUSIVE) 也在 Node 里面实现。 123456789101112131415161718// AQS里面的addWaiter私有方法private Node addWaiter(Node mode) { // 生成该线程对应的Node节点 Node node = new Node(Thread.currentThread(), mode); // 将Node插入队列中 Node pred = tail; if (pred != null) { node.prev = pred; // 使用CAS尝试，如果成功就返回 if (compareAndSetTail(pred, node)) { pred.next = node; return node; } } // 如果等待队列为空或者上述CAS失败，再自旋CAS插入 enq(node); return node;} 线程节点以CAS的方式加入队列后，除头结点外，其余节点都处于阻塞状态。而头结点的下一个结点会不断通过 acquireQueued 尝试获取资源。 获取资源的方法除了acquire外，还有： acquireInterruptibly：申请可中断的资源（独占模式） acquireShared：申请共享模式的资源 acquireSharedInterruptibly：申请可中断的资源（共享模式） 值得注意的是，这些 acquire 前缀的方法，内部都会再调用 tryAcquire 方法来判断是否能执行，以防止并发操作带来的安全性问题。 release 释放资源释放资源时，首先用 tryRelease 判断能否释放，如果能，则进入 unparkSuccessor 进行释放。 123456789public final boolean release(int arg) { if (tryRelease(arg)) { Node h = head; if (h != null &amp;&amp; h.waitStatus != 0) unparkSuccessor(h); return true; } return false;} 释放时先更新同步器的状态，如果新的状态允许队列中某个被阻塞的线程结点获取资源，则解除它的阻塞。 1234567891011121314151617181920private void unparkSuccessor(Node node) { // 如果状态是负数，尝试把它设置为0 int ws = node.waitStatus; if (ws &lt; 0) compareAndSetWaitStatus(node, ws, 0); // 得到头结点的后继结点head.next Node s = node.next; // 如果这个后继结点为空或者状态大于0 // 通过前面的定义我们知道，大于0只有一种可能，就是这个结点已被取消 if (s == null || s.waitStatus &gt; 0) { s = null; // 等待队列中所有还有用的结点，都向前移动 for (Node t = tail; t != null &amp;&amp; t != node; t = t.prev) if (t.waitStatus &lt;= 0) s = t; } // 如果后继结点不为空， if (s != null) LockSupport.unpark(s.thread);}","link":"/post/eecbf398.html"},{"title":"Java并发编程之对象共享","text":"对象数据共享要实现多个线程之间的数据共享，需要考虑两个问题： 通信：通信是指消息在两条线程之间传递 同步：既然要传递消息，那 接收线程 和 发送线程 之间必须要有个先后关系。此时就需要用到同步，即控制多条线程之间的执行次序。 如何通信一般有两种通信的方式： 共享内存：共享内存指的是多条线程共享同一片内存，发送者将消息写入内存，接收者从内存中读取消息，从而实现了消息的传递。 消息传递：顾名思义，消息传递指的是发送线程直接将消息传递给接收线程。 Java选择哪种通信方式？（Java内存模型）Java使用共享内存的方式实现多线程之间的通信。使用这种方式，程序员需要编写额外的代码用于线程之间的同步。在 Java 中，所有线程都共享一片主内存（Main Memory），用于存储共享变量。此外，每条线程都有各自的存储空间，存储各自的局部变量、方法参数、异常对象。 可见性和失效数据可能你不会相信，在 Java 中，一个线程修改了共享对象的状态后，其他线程可能不能及时看到发生的状态变化。为什么其他线程有可能会看不到变化呢？可以从两个角度理解： 从 Java内存模型（JMM）的角度看，正因为每条线程都有各自的存储空间，在多线程中，假设没有加入同步，如果一个线程修改了一个值，储存在自己的线程内存里，另一个线程就会看不到。又或者，你看到的是一个已经失效的值。 从计算机的角度看，现代多核计算机中，每个 CPU 都有自己的寄存器，为了和主存读写速度匹配，CPU寄存器和主存中间往往有一层 Cache 缓冲，当一个 CPU 修改了一个共享变量，放在自己的寄存器或 Cache 缓冲中，还未写回主存，另一个 CPU 就可能读不到最新修改的数据。 从 JVM 的角度来看，虚拟机会对源代码做一些重排序或优化。 考虑下面的例子， 12345678boolean asleep = false;// 线程Awhile(!asleep) countSomeSheep();// 线程Basleep = true; 线程A不断检查 asleep 的值，直到它变成 true 就停止数羊，线程B将 asleep 设置成true，如果不解决可见性问题，线程B的改动，线程A可能永远都看不到。像这样，一个线程不能及时看到另一个线程对共享变量的修改这种情况，叫做可见性问题。 在这里例子中，JVM可能会把 while 循环优化成： 123if (!asleep) while(true) countSomeSheep(); 解决可见性问题使用 synchronized解决可见性问题，可以用 synchronized ，因为 synchronized 的语义规定，对一个变量执行 unlock 操作前，必须先把此变量同步回主内存中。但是 synchronized 每次加锁解锁都需要额外的开销，显得太“重”了，会影响性能。 使用 final我们也可以用 final 解决可见性问题，被 final 修饰的字段在构造器中一旦初始化完毕（且 this 引用没有逃逸），其他线程立即可以看到 final 字段的值。可惜 final 字段不可再次被修改，有时不满足我们的需求。 使用 volatile第三种方法是将变量声明为 volatile 类型。声明为 volatile 的变量，在写操作时，底层的汇编指令会多出一行 Lock 前缀指令。这个指令在多核处理器中引发了两件事情：第一，将当前处理器缓存行的数据写回到系统内存。第二，该操作使在其他CPU里缓存了该内存地址的数据无效。 volatile 保证了变量每次读写时都是最新的值，但不要太过于依赖 volatile，满足以下条件时，才用 volatile： 对变量的写入操作不依赖变量的当前值（因为会产生竞争条件引发安全性问题，i++就不满足），或者你的程序只有一个线程更新该变量的值(其他线程可访问但不可修改)； 访问变量时不需要加锁； 该变量不会与其他状态变量一起纳入不变性条件中。 也就是说， volatile 是解决 可见性 问题的，并不能解决所有原子性问题。另外，当想禁止编译器的重排序功能时，也可以用 volatile。 重排序问题当我们写一个单线程程序时，总以为计算机会一行行地运行代码，然而事实并非如此。编译器、处理器会在不改变程序执行结果的前提下，重新排列指令的执行顺序，以达到最佳的运行效率，这就是重排序。多线程环境下，重排序可能带来一些问题。考虑下面的例子： 1234567891011121314151617class Reorder{ int a = 0; boolean flag = false; // 线程A public void writer(){ a = 2; flag = true; } // 线程B public void reader(){ if (flag) { int i = a*a; } }} 假设有两个线程，A线程先执行writer方法，之后B线程执行reader方法。按理说，B会将 i 设置成 4，然而事实却不一定，i还可能是0。原因是，编译器和处理器会对没有依赖关系的语句进行一定程度的重排序。在线程A中，可能 flag 先被设置成 true，然后线程B执行reader，发现flag 为 true，执行赋值语句，i = 0 * 0，最后，A线程的 a 才被赋值为 2。 解决重排序问题，也可以使用 volatile， volatile 本身包含禁止指令重排序的语义。 深入：为什么 volatile 能解决重排序问题？声明为 volatile 的变量，实际上相当于程序员显式地告诉编译器和处理器不要使用重排序。汇编指令中多出来的 Lock，实际上也就是一道内存屏障。处理器遇到内存屏障时，就会知道不要对此处乱序执行。事实上，Linux 或 Windows 作为操作系统，也只是调用 CPU 所实现的内存屏障指令而已，归根结底这个不是操作系统或者编译器去实现，而是硬件实现了然后供软件调用。 线程封闭不共享数据是避免使用同步最好的办法，这称为线程封闭（Thread Confinement）。线程封闭包括 Ad-hoc 、栈封闭、ThreadLocal类，这里只探讨ThreadLocal。 ThreadLocal 类在单线程 JDBC 程序中，我们通常在程序启动时初始化一个 Connection 连接，从而避免在调用每个方法时都传递一个 Connection 对象。在多线程 JDBC 程序中，我们希望每个线程建立自己的 Connection 对象连接，不互相干扰。这种场景就可以通过 ThreadLocal 来解决。 ThreadLocal提供了一些比如set、get等来访问接口和方法，每个使用该变量的线程都有一份独立的副本，线程之间互不影响。 ThreadLocal 类简单例子声明一个 ThreadLocal 对象 1234567891011private ThreadLocal myThreadLocal = new ThreadLocal();// orprivate ThreadLocal&lt;String&gt; myThreadLocal = new ThreadLocal&lt;String&gt;();//or// 在声明ThreadLocal对象时，即给初值，而不是第一次调用private ThreadLocal myThreadLocal = new ThreadLocal&lt;String&gt;() { @Override protected String initialValue() { return \"This is the initial value\"; }}; 使用set()放置线程封闭变量，使用get()将其取出。 12345// 往对象里放置变量myThreadLocal.set(\"aStringValue\");// 将 ThreadLocal 里存放的变量取出来String threadLocalValue = (String) myThreadLocal.get(); 除了 ThreadLocal 类之外，还有一个 InheritableThreadLocal 是可继承的 ThreadLocal ，只有声明的线程及其子线程可以使用 InheritableThreadLocal 里面存放的变量。 在 JDK 1.7 之后，还有一个 java.util.concurrent.ThreadLocalRandom 类。 12// 返回特定于当前线程的 Random 类实例static ThreadLocalRandom current() 发布与逸出发布（publish）的意思是，在当前作用域之外的代码中使用对象，例如将对象的引用传递到其他类的方法中。在多线程环境下，如果一个对象在构造完成之前就被发布，会破坏线程安全性。而当某个不应该发布的对象被不小心发布出去，就叫逸出（escape）。考虑下面的例子： 1234567class status{ private String[] s = new String[] {\"AK\",\"AL\",\"AJ\"}; public String[] get(){ return this.s; }} 外部可以通过 get() 方法获取数组 s 的引用，而 s 是一个 private 数组，外部现在就有权力修改这个数组里面的所有元素，这就是逸出。逸出使得我们的封装变得没有意义。 还有一种逸出的情况就是发布一个类的内部类实例，因为内部类是隐式持有外部类引用的。 安全地构造在构造方法中启动一个线程，this引用会被新创建的线程共享，此时还没构造完毕，会导致线程安全问题。好的做法是，等构造方法结束时，this引用才逸出。在构造方法中创建一个线程，然后通过一个 start() 方法来启动线程。永远不要在构造过程中使 this 引用逸出。如果想在构造函数中注册一个事件监听或者启动线程，好的办法是使用静态工厂方法（私有构造函数+公共工厂方法）。 安全发布有 Holder 这么一个类 12345678910111213public class Holder { private int n; public Holder(int n){ this.n = n; } public void assertSanity(){ if (n != n) { thorw new AssertionError(\"statement false\") } }} 假设线程1对Holder类进行了发布 12345public Holder holder;public void initialize(){ holder = new Holder(42);} 然后线程2调用assertSanity()方法，很有可能出现 n != n，抛出 AssertionError 。 原因：存在可见性问题，线程1的 new 指令使 holder 对象开始构造，构造到一半时线程2即调用assertSanity()方法了,线程2看到的 holder 对象可能是一个空引用，或者是初始化了一半的值。 安全地发布要安全地发布一个对象，对象的引用和对象的状态必须同时对其他线程可见。 一般可以通过以下几种方式： 在静态初始化函数中初始化一个对象的引用 将对象的引用保存到 volatile 类型的域或者 AtomicReferance 对象中 将对象的引用保存到某个正确构造的 final 类型域中 将对象的引用保存到一个由锁保护的域中(如线程安全容器) 参考： 操作系统漫游（二）进程 volatile是怎么实现防止指令重排序的？ 剖析Disruptor:为什么会这么快？(三)揭秘内存屏障 《Java并发编程实战》 《Java并发编程的艺术》","link":"/post/959bfd05.html"},{"title":"JDBC + MySQL 如何正确地批量删除","text":"问题的来源一张2亿数据的 MySQL InnoDB大表，现要对 c_date 时间字段的的某时间区间内，将 client_name 为 null 的数据进行删除。c_date 已建索引。 分析显然，最简单的方式是写一个大的 DELETE 语句，类似这样： 123DELETE FROM tableWHERE c_date between '2019-10-01' and '2020-03-10'AND client_name is NULL 但这种方式是不建议的，因为会对 MySQL 服务器造成一定影响，参考《高性能MySQL》： 书中给我们的建议是，每次删除1万条数据： 1234DELETE FROM tableWHERE c_date between '2019-10-01' and '2020-03-10'AND client_name is NULLLIMIT 10000 我们在应用层JDBC循环删除： 123456for (int i= 0;i &lt; 1000000 ;i++ ) { delCount = prepareStatement.executeUpdate(); if (delCount &lt;= 0) { break; }} 这种方式看似没毛病，但经过实践我们发现，MySQL越删越慢，到最后删了24个小时都没删完。究其原因，是 MySQL 每次执行 DELETE 时，总要先去查一遍： 1234SELECT id FROM tableWHERE c_date between '2019-10-01' and '2020-03-10'AND client_name is NULLLIMIT 10000 这就导致一个问题，由于 InnoDB 是以 B+树 数据结构存放数据的，在 c_date 上建立索引，MySQL可以很快定位到 c_date = 2019-10-01 的第一条数据，之后往右边逐条检索，直到凑足1万条符合条件的数据再返回。随着 for 循环的进行，越往后要凑满1万条需要检索的数据就越多（因为前面符合的已经在前几次循环删除了）。 改进找到删除慢的根源后，优化思路如下： 1.先查出每一天、每一小时大概有多少数据，我这边查询大概一小时在1万-5万不等 1234567SELECT count(*) c, t.dateFROM (SELECT date_format(c_date, '%Y-%m-%d %H') date FROM table WHERE c_date between '2019-10-01' and '2020-03-10' AND client_name is NULL) tGROUP BY t.date 2.按每一小时递进删除，每次删1万，直至该小时全部删完，再继续删除下一小时 1234567891011121314151617181920final long ONE_HOUR = 60 * 60 * 1000TimeStamp start = getStart(); // 2019-10-01 00:00:00TimeStamp end = getStart() + ONE_HOUR;TimeStamp finish = getFinish(); // 2020-03-10 23:59:59for (long i = start.getTime(); i&lt; finish.getTime() ;i = i + ONE_HOUR ) { prepareStatement.setTimeStamp(1, start); prepareStatement.setTimeStamp(2, end); // 只要该小时内还有需要删除的数据，则重复做删除动作 do { int delCount = prepareStatement.executeUpdate(); } while (delCount &gt; 0); // 设置下一个小时 start = end.getTime(); end = start.getTime() + ONE_HOUR;} DB 层如下: 1234DELETE FROM tableWHERE c_date between ? and ?AND client_name is NULLLIMIT 10000","link":"/post/f215e4e1.html"},{"title":"Java并发编程之并发工具","text":"Java自带的平台类库（java.util.concurrent）里面包含了很多有用的工具，来帮助我们更好地处理并发问题。这一篇主要介绍一下几类工具： atomic原子类：AtomicLong 同步容器类：Vector、Hashtable 并发容器类：concurrentHashMap、ConcurrentLinkedQueue、BlockingQueue（阻塞队列） 并发工具类：闭锁（Latch）、栅栏（Barrier）、信号量（Semaphore） atomic原子类为什么要用atomic原子类像 i++ 这样的操作并不是原子操作，多线程访问可能出现问题，在 Java并发编程之安全性 就提到可以用 java.util.concurrent.atomic 包的 atomic原子类 来将 i++ 封装成原子操作。 原理非阻塞并发算法。典型的算法有compare-and-swap（CAS），即一个线程在修改一个变量时，先将当前值（当前内存地址值）跟预期值进行比较，如果一致，则进行修改，如果不一致，说明这个变量被其他线程改了，就不进行修改。 但是 CAS 也不是完美的，比如经典的ABA问题：一个变量 V 初次读取的时候是 A值，之后被其他线程修改为 B，然后又修改为 A，那 CAS 会认为它从来没有变过。 参考：http://tutorials.jenkov.com/java-concurrency/compare-and-swap.html 原子类的更新问题用 Atomiclong 的 incrementAndGet() 方法或者 set() 方法更新值。 12345private Atomiclong count = new AtomicLong(10);count.incrementAndGet(); // 11long value = 2L;count.set(value); // 2 当 value 是一个方法的返回值时，如Math.max(count.get(), observed) (选择两者中比较大的)，这个操作也并不安全。 正确的做法是用compareAndSet(old, new)方法： 1234do{ oldValue = count.get(); newValue = Math.max(count.get(), observed);} while(!count.compareAndSet(oldValue,newValue)) 在Java 8中，上述样板代码可以简化为： 123count.updateAndGet(x-&gt;Math.max(count.get(), observed));// orcount.accumulateAndGet(observed, Math::max); 用 LongAdder 优化高并发性能问题如果在高并发情况下 Atomiclong 的 CAS 乐观锁需要太多次重试，这会带来一定的性能下降。Java 8 提供了 LongAdder 类。其思想跟JDK 1.7的 concurrenthashmap类似，采用分段的思想。LongAdder 内部包含多个值，每个线程只更新其中的一个，然后返回所有值的和。 LongAdder 适用于统计求和计数的场景，例如计算qps。在高并发场景下，qps这个值会被多个线程频繁更新的，所以 LongAdder 很适合。但 LongAdder 并不能替代 Atomiclong。 123456789final LongAdder adder = new LongAdder();// thread 1adder.increment();// thread 2adder.increment();// main threadadder.sum(); LongAccumulator 将这种思想推广到任意的累加操作，而不仅仅是+1 同步容器类同步容器类包括 Vector 和 Hashtable。 它们实现线程安全的方式十分简单粗暴：对每个公有方法进行同步，使得每次只有一个线程能够访问容器的状态。这种线程安全方式对于容器自身来说是安全的，但在调用方可能会出现问题，因此使用时要注意调用方可能需要做一些额外的协调。例如： 1234567891011// 获取 Vector 最后一个元素public static Object getLast(Vector list){ int lastIndex = list.size() - 1; return list.get(lastIndex);}// 删除 Vector 最后一个元素public static void deleteLast(Vector list){ int lastIndex = list.size() - 1; list.remove(lastIndex);} 从 Vector 的角度，无论你用多少个线程调用多少次deleteLast()方法，都不会让 Vector 内部出问题。然而，从调用者的角度，线程A调用getLast，线程A先观察到size为10，然后时间片切换到线程B调用deleteLast，B也观察到size为10，然后B删除了最后一个元素，然后A获取最后一个元素，发现这个元素不存在，于是抛出ArrayIndexOutOfBoundsException。 另一个例子是，用一个 for 循环迭代 Vector，循环到一半时，另一个线程删除了后面某些元素，迭代到后面时就会找不到元素抛出ArrayIndexOutOfBoundsException。 1234// 如果迭代到一半，另一个线程删除了后面的元素，导致 get(i) 取不到for (int i=0; i &lt; vector.size() ;i++ ) { doSomething(vector.get(i));} 我们通常会用 Iterator 可以对集合进行遍历，但是却 不能在遍历过程对原集合做增、删、改，会抛出 ConcurrentModificationException。这是 Java 的一种并发预警警示器，叫 fail-fast。告知我们集合在遍历过程中被修改了。 有时候，我们看起来好像没有迭代，但仍然抛出了ConcurrentModificationException。是因为有些方法隐式地进行了迭代，如打印一个Hashset，事实上会调用 toString 方法，这个方法不断调用 StringBuilder.append 把各个元素转为字符串，这其实就是迭代了。同理，hashCode方法、equals方法、containAll、removeAll、retainAll等方法都是如此。 因此，使用同步容器类时，需要在调用方加 synchronized 同步。 并发容器类同步容器简单粗暴地对公有方法加同步，实际上是强行将对容器状态的访问串行化了，这对并发性能带来了很大影响。在 Java 5 之后，增加了如 ConcurrentHashMap、ConcurrentLinkedQueue 这样的并发容器，天生为并发程序设计。在多线程中应该尽可能用并发容器，而不是同步容器。 ConcurrentHashMapConcurrentHashMap 采用了细粒度的加锁机制，称为分段锁（Lock Striping）。分段锁的原理是，容器内部有多个锁，每一把锁只锁住容器内一部分数据。在 JDK 1.7 里，一个 ConcurrentHashMap 内部是一个 Segment 数组， Segment 数组每个元素都是一个 Entry 数组，Entry 数组每个元素都是 Entry 链表对象。加锁时，不是加锁整个 ConcurrentHashMap，而是加锁 Segment 数组上的每个 Segment 对象。 但是在JDK 1.8中，取消了基于 Segment 的分段锁思想，改用 CAS + synchronized 控制并发操作。 ConcurrentHashMap 迭代时不会抛出 ConcurrentModificationException，是 fail-safe 的。它实现了 ConcurrentMap 接口，如下： 1234567891011121314public interface ConcurrentMap&lt;K, V&gt; extends Map&lt;K, V&gt; { // 仅当 K 没有相应的映射值时才插入 V putIfAbsent(K key, V value); // 仅当 K 被映射到 value 时才插入 boolean remove(Object key, Object value); // 仅当 K 被映射到 oldValue 时才替换为 newValue boolean replace(K key, V oldValue, V newValue); // 仅当 K 被映射到某个值时才替换为 newValue V replace(K key, V value);} concurrentHashMap有两个带参构造器 123456// initialCapacity - 初始容量（默认16）concurrentHashMap&lt;K, V&gt;(int initialCapacity);// loadactor - 如果每一个桶的平均负载超过这个值，会重新调整大小（默认0.75）// concurrencyLevel - 并发写线程的估计数concurrentHashMap&lt;K, V&gt;(int initialCapacity, float loadactor, int concurrencyLevel) 使用 concurrentHashMap 做词频统计的例子考虑下面的例子，我们需要在每次访问时将 map 里面的值+1，虽然 concurrentHashMap 内部是线程安全的，但是这段代码并非线程安全，另一个线程可能也正在更新数值。 1234ConcurrentHashMap&lt;String,Long&gt; map = new ConcurrentHashMap();long oldValue = map.get(word);long newValue = oldValue == null ? 1 : oldValue+1;map.put(word, newValue); 一般的改进如下，用到了CAS的思想，使用 replace 方法，如果替换不成功就不断尝试。 1234do { oldValue = map.get(word); newValue = oldValue == null ? 1 : oldValue+1;} while (!map.replace(word, oldValue, newValue)); 但是我们太讨厌这样的样板代码了，进一步改进如下： 1234567891011// 把 Long 换成了 LongAdderConcurrentHashMap&lt;String,LongAdder&gt; map = new ConcurrentHashMap();// 如果为空，新建map.putIfAbsent(word, new LongAdder());// 获取再+1，实际上是把 do while 封装到 increment() 里面map.get(word).increment();// 上面两句可以合并为一句map.putIfAbsent(word, new LongAdder()).increment(); 但如果我不是想 +1，而想做其他计算，就无法用 increment() 了。Java 8 中，compute 方法传入一个 key 和一个计算新值的函数，用于完成原子更新，推荐使用： 1map.compute(word, (k,v)-&gt; v == null? 1:v+1); CopyOnWriteArrayList这是一个写入时复制（Copy-On-Write）并发容器，用于替代SynchronizedList。在每次修改时，都会创建并重新发布一个新的容器副本。迭代器不会抛出ConcurrentModificationException，是 fail-safe 的。当迭代操作远远多于修改操作时，应该考虑使用Copy-On-Write容器。例如事件监听系统，接收事件通知的操作远远多于注册或注销监听器的操作。 类似的，有CopyOnWriteArraySet。 BlockingQueue（生产者消费者模式）BlockingQueue 是一个阻塞队列接口。其 put 方法将一个元素放进队列头端，如果队列已满，就一直阻塞，直到队列空出位置。同理，take 方法将从队列尾端取出一个元素，如果队列未空，就一直阻塞，直到队列有元素。 BlockingQueue非常适合用来做生产者-消费者模式。其优点是，将生产数据的过程与使用数据的过程解耦。 BlockingQueue 也提供了一个 offer 方法，如果数据不能添加进队列，返回一个失败状态。offer 方法可以带时间参数，表示在一段时间内尝试添加元素。poll 同理。 1boolean success = queue.offer(x, 100, TimeUnit.MILLSECONDS); BlockingQueue 的实现类有 LinkedBlockingQueue 和 ArrayBlockingQueue，以及按优先级排序的 PriorityBlockingQueue。还有一个比较特殊的 SynchronousQueue，它没有存储空间，只是维护一组线程。例如，一个线程 put 会被阻塞，直到另一个线程 take，才算成功交付。 方法 正常动作 特殊情况动作 add 添加元素 队列满抛出 IllegalStateException offer 添加元素并返回true 队列满返回false put 添加元素 队列满阻塞 element 返回队列头元素 队列空抛出NoSuchElementException peek 返回队列的头元素 队列空返回null poll 移出并返回队列头元素 队列空返回null remove 移出并返回队列头元素 队列空抛出NoSuchElementException take 移出并返回队列头元素 队列空阻塞 同步工具类BlockingQueue 阻塞队列不仅能作为保存对象的容器，而且能根据其自身的状态来协调线程的控制流。所以它既是并发容器，也是一个同步工具。我们把能 根据其自身的状态来协调线程的控制流的工具称为同步工具。 同步工具类的特点是：封装了一些状态，这些状态决定执行同步工具类的线程是继续执行还是等待，此外还提供一些方法对状态进行操作。常见的同步工具类有：闭锁（Latch）、栅栏（Barrier）、信号量（Semaphore）。 闭锁（Latch）闭锁相当于一个门，且有一个开门的条件。未开门前，所有线程都不能通过，当门打开后才允许所有线程通过。闭锁打开之后将不能再关上。使用闭锁的场景有： 确保某个计算在其需要的所有资源都被初始化后才继续执行。 确保某个服务在其依赖的其他服务都被启动之后才启动。 等待某个操作的参与者都就绪再继续执行（多人在线游戏）。 CountDownLatch 是一种闭锁的实现。包括一个计数器，一开始为正数，表示需要等待的事件数量。以及 countDown 方法，每当一个等待的事件发生了，计数器就减一。直到为零闭锁打开。如果计数器不为零，那 await 会一直阻塞直到计数器为零，或者等待中的线程中断，或者等待超时。 栅栏（Barrier）栅栏跟闭锁类似，不同点在于，所有线程必须同时到达栅栏位置，才能继续执行。闭锁用于等待事件，而栅栏用于等待其他线程，当所有线程到达 barrier.await(); 的位置，栅栏放开。 12// param 1 参与的线程数量 ， param 2 栅栏放开后执行的 runnableCyclicBarrier barrier = new CyclicBarrier(2, myRunnable); CyclicBarrier 与 CountDownLatch 的区别在于 CyclicBarrier 是可以重用的。 CyclicBarrier 可以使一定数据的参与方反复地在栅栏位置汇集，通常用于并行迭代算法。 信号量（Semaphore）计数信号量（Counting Semaphore）用来控制同时访问某个特定资源的操作数量，或者同时执行某个指定操作的数量。 Semaphore 与 CountDownLatch 的区别在于 Semaphore 的计数器减少之后，还可以再增加，表示可用的资源数量。Semaphore 可以用来实现资源池，如数据库连接池。 123456789Semaphore semaphore = new Semaphore(1);//资源被使用代码semaphore.acquire(); // 资源被获取// 资源使用完毕代码semaphore.release(); // 资源被释放 显式锁可重入锁（ReentrantLock）ReentrantLock 是 Lock 接口的默认实现。实现了锁的基本功能。作用跟 Synchronized 一样，都是用于线程同步的。但 ReentrantLock 多了三个高级特性： 等待可中断：如果持有锁的线程长期不释放锁，正在等待的线程可以放弃等待，改为处理别的事情。 可实现公平锁：公平锁是指按照申请锁的时间顺序依次获得锁，而非随机获得。可以通过带 boolean 值的构造函数要求使用公平锁。 锁可以绑定多个条件：一个 ReentrantLock对象可以绑定多个 Condition 对象。 可重入读写锁（ReentrantReadWriteLock）ReentrantReadWriteLock 是 ReadWriteLock 接口的默认实现。实际上是结合了可重入锁和读写锁的特性。内部维护了两个锁，ReadLock 和 WriteLock，其中ReadLock 是线程共享的，而 WriteLock 是独占的。 可重入读写锁有一个小弊端，就是在“写”操作的时候，其它线程不能写也不能读。我们称这种现象为“写饥饿”。 StampedLockStampedLock 是 JDK 1.8 才发布的，作者依然是 Doug Lea。功能跟 ReentrantReadWriteLock 一样，但是性能更高，且不会发现写饥饿。其原理是，在读的时候如果发生了写，应该通过重试的方式来获取新的值，而不应该阻塞写操作。这种模式也就是典型的无锁编程思想，和CAS自旋的思想一样。这种操作方式决定了StampedLock在读线程非常多而写线程非常少的场景下非常适用，同时还避免了写饥饿情况的发生。 StampedLock的性能非常优异，基本上可以取代ReentrantReadWriteLock的作用。 参考： 《Java并发编程实战》 第十四章 锁接口和类","link":"/post/a23f9c20.html"},{"title":"Java并发编程之异步任务","text":"有时候，我们想在主线程之外执行一些异步任务，不难想到，可以开一个新线程专门去处理某个任务。 最简单的异步任务执行RunnableRunnable 用于一个异步执行的任务，没有参数和返回值。实现 Runnable 接口，把我们想要执行的任务写在 run 方法里，即可表示任务内容。 12345package java.lang;@FunctionalInterfacepublic interface Runnable { public abstract void run();} CallableCallable 与 Runnable 类似，区别是，Callable有返回值，且可以抛出异常。 12345package java.util.concurrent;@FunctionalInterfacepublic interface Callable&lt;V&gt; { V call() throws Exception;} 一个简易Web服务器例子无论是 Runnable 还是 Callable，想要放到独立的线程中去运行，都是需要借助 Thread 类的。 12new Thread(runnable).start();new Thread(callable).start(); 我们可以编写一个简易的Web服务器，当一个请求进来时，新建一个线程去服务这个请求。（不要在生产环境使用这种方式） 123456789101112public static void main(String[] args) throws IOException { ServerSocket socket = new ServerSocket(80); for (;;){ final Socket conn = socket.accept(); Runnable task = () -&gt; handleRequest(conn); new Thread(task).start(); }}private static void handleRequest(Socket conn){ // do something} 由我们手动去 new 线程执行任务，有一些缺点： 随着新任务一个个的到来，旧任务一个个结束，线程不断创建销毁，开销很大； 线程数量不可控，如果一下子有大量任务到来，将无限制创建线程，即使没有OOM，也会因线程数量太多而导致性能降低（CPU在线程之间切换也是有开销） 所以通常我们不会手动去 new 线程执行任务，而是借助 Executor 接口帮助我们执行。 Executor 接口Executor 接口用来执行一个 Runnable： 123public interface Executor { void execute(Runnable command);} 为什么要把线程放到 Executor 里面执行呢？ Executor 提供了一种标准的方法将任务的 提交过程 和 执行过程 解耦。这是一种生产者-消费者模式。 我们可以在 Executor 的实现类里，添加一些方法，用于 管理生命周期和做其他监控，便于我们调度异步任务。 不仅应该尽量不要编写自己的工作队列，而且还应该尽量不直接使用线程。 ——《Effective Java》 借助 Executor 的简易Web服务器这一次，我们不再 new 线程，而是把 task 放到 Executor 里面去执行。 123456789101112131415161718public class ExecutorExample { private static final int THREAD_NUMBER = 100; private static final Executor exec = Executors.newFixedThreadPool(THREAD_NUMBER); public static void main(String[] args) throws IOException { ServerSocket socket = new ServerSocket(80); for (;;){ final Socket conn = socket.accept(); Runnable task = () -&gt; handleRequest(conn); exec.execute(task); } } private static void handleRequest(Socket conn){ // do something }} Executors 工具类Executor 的实现类多种多样，我们可以把 Executor 实现为单线程，或者实现为跟每次都自己 new 线程一样，也可以实现为限制最大线程数量等。通常情况下不同的实现类参数复杂，状态较多，所以我们通常不自己 new Executor，而是借助工具类 Executors 帮助我们创建 Executor。 12345678// 单线程执行器，如果该线程异常，将创建另一个来替代Executor exec1 = Executors.newSingleThreadExecutor();// 固定线程数量，提交一个任务就创建一个，直至最大值Executor exec2 = Executors.newFixedThreadPool(10);// 多线程调度执行器Executor exec3 = Executors.newScheduledThreadPool(10); ExecutorService 接口事实上，我们用 Executors 创建出来的执行器是 Executor 的子接口 ExecutorService。既然已经有了 Executor 了，为什么还要 ExecutorService 呢？前面说到，我们不只是把任务丢到线程里让他去执行就完了，有时候，我们还想获取异步任务的状态，以及管理 Executor 执行器本身。 因此，ExecutorService 继承了 Executor ，再添加几个方法，主要是submit方法，用于向线程提交异步任务，然后返回一个 Future，我们再用 Future 来判断异步任务结束没有，或者获取结果。 123456public interface ExecutorService extends Executor { &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); // ... 其他方法见下面生命周期部分} ExecutorService 接口的默认实现是 ThreadPoolExecutor，用于启动一个线程池，另一个实现是 Fork/Join 框架（JDK1.7）。 submit 和 execute 的区别execute() 是 Executor 接口的方法，表示执行一个 Runnable， submit() 是 ExecutorService 接口的方法，内部调用了 execute() ，但还会返回一个异步计算结果 Future 对象（也意味着可以做异常处理）。 ScheduledExecutorService 接口看起来已经够用了，JUC的设计者Doug Lea大佬觉得哪里还不太够，于是劈里啪啦又写了一个 ScheduledExecutorService 接口，继承 ExecutorService 接口，再添加几个 schedule 方法： 12public ScheduledFuture&lt;?&gt; schedule(Runnable command, long delay, TimeUnit unit);public &lt;V&gt; ScheduledFuture&lt;V&gt; schedule(Callable&lt;V&gt; callable, long delay, TimeUnit unit); ScheduledExecutorService 的功能和 Timer/TimerTask 类似，解决那些需要任务重复执行的问题。这包括延迟时间一次性执行、延迟时间周期性执行以及固定延迟时间周期性执行等。 Executor 生命周期既然 ThreadPoolExecutor 是 ExecutorService 的实现，而 ExecutorService 又继承 Executor 接口。所以，线程池的生命周期即是 Executor 的生命周期啦。 12345678910111213public interface ExecutorService extends Executor { // 用于提交异步任务和获取结果 &lt;T&gt; Future&lt;T&gt; submit(Callable&lt;T&gt; task); &lt;T&gt; Future&lt;T&gt; submit(Runnable task, T result); Future&lt;?&gt; submit(Runnable task); // 用于管理执行器本身 void shutdown(); List&lt;Runnable&gt; shutdownNow(); boolean isShutdown(); boolean isTerminated(); boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException;} CREATE &amp; RUNNING当我们 new 一个 Executor 或者通过 Executors 静态工厂构造一个 Executor，线程池即进入了 RUNNING 状态，在此之前是 CREATE 状态。严格意义上讲线程池构造完成后并没有线程被立即启动，只有进行“预启动”或者接收到任务的时候才会启动线程。但是无论如何，构造完后，线程池已经在运行，随时准备接受任务来执行。 SHUTDOWN &amp; STOP通过shutdown()和shutdownNow()来将线程关闭。 shutdown()平缓关闭，线程池停止接受新的任务，同时等待已经提交的任务执行完毕，包括那些进入队列还没有开始的任务，这时候线程池处于SHUTDOWN状态。 shutdownNow()是一个立即关闭过程，线程池停止接受新的任务，同时尝试取消所有正在执行的任务和已经进入队列但是还没有执行的任务，这时候线程池处于STOP状态。 TERMINATED一旦shutdown()或者shutdownNow()执行完毕，线程池就进入TERMINATED状态，此时线程池就结束了。 isTerminating()描述的是SHUTDOWN和STOP两种状态。 isShutdown()描述的是非RUNNING状态，也就是SHUTDOWN/STOP/TERMINATED三种状态。 可以调用 awaitTermination() 来等待 ExecutorService 到达 TERMINATED 状态。 FutureCallable 的 call() 方法可以执行一个异步任务并获取一个返回值，但假设异步任务要执行很久，调用方就会阻塞。这就失去了异步的意义。 1234AsyncTask task1 = new MyTask(64);// 调用即阻塞long result1 = (Long) task1.call(); Future是一个接口，用来判断异步计算是否已完成以及帮助我们获取异步计算的结果。 在没有Future之前我们检测一个线程是否执行完毕通常使用Thread.join()或者用一个死循环加状态位来描述线程执行完毕。Future是一种更好的方法，能够阻塞线程，检测任务执行完毕，甚至取消执行中或者未开始执行的任务。 123456789101112public interface Future&lt;V&gt; { boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); // 调用 get 时，如果还没计算完，将阻塞 V get() throws InterruptedException, ExecutionException; // 如果过了设定的时间还没计算完，抛出超时异常 V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException;} RunnableFuture&lt;V&gt; 是一个继承了 Runnable 和 Future&lt;V&gt; 的接口，再添加一个 run() 方法。而 FutureTask&lt;V&gt; 是它的实现，包含以下四个field： 12345678/** The underlying callable; nulled out after running */private Callable&lt;V&gt; callable;/** The result to return or exception to throw from get() */private Object outcome; // non-volatile, protected by state reads/writes/** The thread running the callable; CASed during run() */private volatile Thread runner;/** Treiber stack of waiting threads */private volatile WaitNode waiters; 其构造器传入一个Callable，所以，当我们有一个异步任务 Callable ，可通过 FutureTask&lt;V&gt; 来获取返回值，如： 12345678910111213FutureTask&lt;Long&gt; future = new FutureTask&lt;Long&gt;( () -&gt; { Thread.sleep(1000); return 5L;});new Thread(future).start();// 此时主线程可以去做别的事// ...// 执行get时，若异步任务还未结束，主线程将阻塞Long result = future.get();System.out.println(result); ExecutorService 的 submit() 方法，就是返回一个 future。所以，一般我们都是 FutureTask 和 Executor 结合起来用： 1234567ExecutorService executor = Executors.newFixedThreadPool(4);// MyTask implements CallableCallable&lt;String&gt; mytask = new MyTask();// 提交任务,同时获得一个 Future 对象:Future&lt;String&gt; future = executor.submit(task);// 从 Future 获取异步执行返回的结果:String result = future.get(); // 可能阻塞 CompletableFutureFuture 其实还不够好，因为主线程迟早要主动去调用 future.get() 来获取结果的。我们希望异步任务结束后，主动回调，而不是主线程去isDone()或get() 。 JDK 1.8 引入了 CompletableFuture，用法如下： 123456789101112131415161718192021222324// 定义一个异步任务Supplier&lt;String&gt; myTask = () -&gt; { try { Thread.sleep(3000); } catch (InterruptedException e) { e.printStackTrace(); } return \"hello world\";};// 定义 CompletableFutureCompletableFuture&lt;String&gt; myTaskFuture = CompletableFuture.supplyAsync(myTask);// 设置 CompletableFuture 执行结束时做什么myTaskFuture.thenAccept(System.out::println);// 设置 CompletableFuture 抛出异常时做什么myTaskFuture.exceptionally( e -&gt; { e.printStackTrace(); return null;});// 主线程可以做其他事// ... 使用 CompletableFuture 的好处是异步任务结束或异常时，会自动回调某个对象的方法，且主线程设置好回调后，不再关心异步任务的执行。 多个 CompletableFuture 串行执行1234567891011// 定义任务 f1CompletableFuture&lt;String&gt; f1 = CompletableFuture.supplyAsync(myTaskHello);f1.thenAccept(System.out::println);// 定义任务 f2 为 f1 执行完后执行，第一个任务的结果会作为第二个任务的参数// 所以 thenApplyAsync 接收的是一个 Function&lt;T,T&gt;CompletableFuture&lt;String&gt; f2 = f1.thenApplyAsync(myTaskName);f2.thenAccept(System.out::println);// 主线程可以做其他事// .. 多个 CompletableFuture 并行执行用 anyOf() 或 allOf() 可以将两个 CompletableFuture 合并为一个新的 CompletableFuture ，实现并行执行。 anyOf()：只要有一个成功 allOf()：需所有的都成功 想象一个场景：需要一个人搬砖，用异步任务呼叫 jerry 和 calm 两个人，只要任意一个人回应了，就由他去搬砖。 1234567891011121314// f1： 呼叫 jerry// f2： 呼叫 calm// f3： 搬砖CompletableFuture&lt;String&gt; f1 = CompletableFuture.supplyAsync( () -&gt; callSomebody(\"jerry\"));CompletableFuture&lt;String&gt; f2 = CompletableFuture.supplyAsync( () -&gt; callSomebody(\"calm\"));// 用anyOf合并为一个新的CompletableFuture:CompletableFuture&lt;Object&gt; f3 = CompletableFuture.anyOf(f1, f2);f3.thenAccept( r -&gt; System.out.println(String.format(\"%s去搬砖\", r)));// 主线程可以做其他事// .. Fork/Join前面提到 ExecutorService 接口的默认实现是 ThreadPoolExecutor，用于启动一个线程池，另一个实现是 Fork/Join ，Fork/Join 用来将一个大的任务分解成多个小的任务，并行执行。其原理跟排序算法的归并排序类似。 例如，要计算一个超大数据的和，可以把数组拆成两个中等组数，两个中等数组又分别拆成两个小数组，现在我们有4个小数组了，可以用4个线程并行执行求和。最后再汇总。 使用方法： 12345public static void main(String[] args) { long[] largeArrays = getLargeArrays(); ForkJoinTask&lt;Long&gt; calculateSumTask = new SumTask(largeArrays,0, largeArrays.length); Long result = ForkJoinPool.commonPool().invoke(calculateSumTask);} 其中，SumTask 的实现如下，继承RecursiveTask&lt;Long&gt;，并重写compute()方法，在compute()里面，判断如果任务足够小，就直接计算，否则一分为二。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546class SumTask extends RecursiveTask&lt;Long&gt; { static final int THRESHOLD = 500; long[] array; int start; int end; SumTask(long[] array, int start, int end) { this.array = array; this.start = start; this.end = end; } @Override protected Long compute() { // 如果任务足够小,直接计算: if (end - start &lt;= THRESHOLD) { long sum = 0; for (int i = start; i &lt; end; i++) { sum += this.array[i]; // 故意放慢计算速度: try { Thread.sleep(1); } catch (InterruptedException e) { } } return sum; } // 任务太大,一分为二: int middle = (end + start) / 2; System.out.println(String.format(\"split %d~%d ==&gt; %d~%d, %d~%d\", start, end, start, middle, middle, end)); SumTask subtask1 = new SumTask(this.array, start, middle); SumTask subtask2 = new SumTask(this.array, middle, end); // invokeAll会并行运行两个子任务: invokeAll(subtask1, subtask2); Long subresult1 = subtask1.join(); Long subresult2 = subtask2.join(); Long result = subresult1 + subresult2; System.out.println(\"result = \" + subresult1 + \" + \" + subresult2 + \" ==&gt; \" + result); return result; }} 参考： 《Java并发编程实战》","link":"/post/377edbcb.html"},{"title":"Effective Java（一）创建和销毁对象","text":"《Effective Java》这本书算得上有口皆碑了，去年发现出了第三版，趁某东活动入手了一本英文版，粗略了过了一下，这本书给我最大的体会就是它教你如何成为一个真正的 Java 程序员，而不是 CRUD 程序员或 Spring 程序员，读这本书，能让你站在更高的角度和更深层次的视角去剖析 Java 的细节，让人豁然开朗。然而，上半年因为各种原因，瞎忙活了大半年，这本书一直没机会捡起来仔细看。好在最近工作不忙，想起来有这本书，决定一天看两个 Item 。 系列目录： Effective Java（一）创建和销毁对象 Effective Java（二）对象通用的方法 Effective Java（三）类和接口 Effective Java（四）泛型 Effective Java（五）枚举和注解 Effective Java（六）Lambdas and Streams Effective Java（七）方法 Effective Java（八）General Programming Effective Java（九）异常 Effective Java（十）并发 Item 1 使用静态工厂方法替代构造器我们平时编写一个类的构造方法，然后用 new 去获取一个对象。 123456789101112public class Student { String name; String age; Student(String name, String age){ this.name = name; this.age = age; }}// clientStudent jerry = new Student(\"jerry\", 18); 有时候我们还可以把构造器私有化，禁止 new，取而代之的是用一个静态方法 newInstance 来获取对象： 12345678910111213141516public class Student { String name; int age; private Student(String name, int age){ this.name = name; this.age = age; } public static Student newInstance(String name, int age) { return new Student(name, age); }}// clientStudent jerry = Student.newInstance(\"jerry\", 18); 这么做的好处有五个： 有名字，构造方法有多个时容易搞混，静态工厂方法就不会； 静态工厂方法不要求每次都返回一个新对象，可以用来做单例（singleton）和不可实例化保证； 静态工厂方法可以返回一个对象的子类作为返回类型，而构造器不行，如 java.util.Collections； 静态工厂方法返回对象的类可以根据输入参数的不同而不同； 在编写包含该方法的类时，返回的对象的类不需要存在； 使用静态工厂方法，主要的不足是，没有 public 或 protected 构造器，因此也无法被子类化。但从另一个角度来说，这也是优点，因为这样做鼓励程序员 多用组合，而不是继承，这是好的习惯。第二个不足是程序员可能比较难找到他们，以下是静态工厂方法常用的名字： from of valueOf instance / getInstance create / newInstance getType newType type 例如 jdk 里，获取 Boolean 对象： 123public static Boolean valueOf(boolean b){ return b ? Boolean.TRUE : Boolean.FALSE;} Item 2 当构造器参数过多，考虑使用 Builder 模式这里的 Builder 模式不是指设计模式。假设你要组装一台电脑，有品牌、价格、CPU、是否防水、屏幕尺寸等参数，有些是必选的，有些是可选的，如果用构造器，看起来会像是这样： 12345678910111213141516171819202122public class Computer { private String brand; // required private double price; // required private int cpuGeneration; // optional private boolean isWaterproof;// optional private int screenSize; // optional Computer(String brand, double price){ // something here } Computer(String brand, double price, int cpuGeneration){ // something here } Computer(String brand, double price, int cpuGeneration, boolean isWaterproof){ // something here } // ...} 你会发现，你要写好多好多不同的构造方法，而且还容易搞混。 最好使用内部 builder 类，在调用方根据需要进行组合，如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class Computer { private String brand; // required private double price; // required private int cpuGeneration; // optional private boolean isWaterproof;// optional private int screenSize; // optional public static class Builder{ private String brand; private double price; // Optional parameters - initialized to default values private int cpuGeneration = 3; private boolean isWaterproof = false; private int screenSize = 12; // constructor public Builder(String brand, double price) { this.brand = brand; this.price = price; } public Builder cpuGeneration(int value){ cpuGeneration = value; return this; } public Builder isWaterproof(boolean value){ isWaterproof = value; return this; } public Builder screenSize(int value){ screenSize = value; return this; } public Computer build(){ return new Computer(this); } } private Computer(Builder builder) { this.brand = builder.brand; this.price = builder.price; this.cpuGeneration = builder.cpuGeneration; this.isWaterproof = builder.isWaterproof; this.screenSize = builder.screenSize; }} 调用方： 1234567891011public static void main(String[] args) { Computer computer = new Computer.Builder(\"MicroSoft\", 6500.00) .cpuGeneration(7) .isWaterproof(false) .screenSize(24) .build(); System.out.println(computer.toString());} Item 3 使用私有构造器或枚举实现单例（Singleton） 注意: 不适用于多线程情况。 单例用于一个类只允许一个实例对象的情况，通常有两种方法实现单例：公有域 和 公有静态方法。两种方式都是通过 私有构造器 + 公开静态成员 来实现的。 第一种方法：公有域，客户端通过 Elvis.INSTANCE 来获取唯一对象。 12345// Singleton with public final fieldpublic class Elvis { public static final Elvis INSTANCE = new Elvis(); private Elvis() { ... }} 第二种方法：公有静态工厂方法。 123456// Singleton with static factorypublic class Elvis { private static final Elvis INSTANCE = new Elvis(); private Elvis() { ... } public static Elvis getInstance() { return INSTANCE; }} 需要注意的是，有特权的客户端可以通过反射AccessibleObject.setAccessible的方式来调用私有构造方法。如果需要避免这个潜在的问题，可以修改构造函数，使其在请求创建第二个实例时抛出异常。 当需要序列化单例类对象时，仅仅用 implements Serializable 是不够的，因为每一次反序列化都会创建一个新的实例，解决办法是声明所有成员为 transient，然后用以下方法来返回实例。 123456// readResolve method to preserve singleton propertyprivate Object readResolve() { // Return the one true Elvis and let the garbage collector // take care of the Elvis impersonator. return INSTANCE;} 最后还有一种用枚举实现单例的方式： 123456// Enum singleton - the preferred approachpublic enum Elvis { INSTANCE; public void leaveTheBuilding() { ... }} 用这种方式无需担心序列化问题和反射攻击，但是如果单例类需要继承除 enum 外的其他父类，就不能使用这种方法。 Item 4 使用私有构造器实现不可实例化（Noninstantiable）有些类（如工具类）只包含静态域和静态方法，为了避免被误用，可以将其构造器设置为私有，从而不可实例化。 12345678// Noninstantiable utility classpublic class UtilityClass { // Suppress default constructor for noninstantiability private UtilityClass() { throw new AssertionError(); } ... // Remainder omitted} 为什么不用抽象类来实现不可实例化呢？因为抽象类可以被继承，其子类可以被实例化，并且会误导用户认为该类是为继承而设计的。 Item 5 使用依赖注入，而不是硬编码所需资源有些工具类或单例对象，依赖于一些底层资源。如单词拼写检查器，依赖于字典。 123456789101112131415161718192021222324// 静态工具类// Inappropriate use of static utility - inflexible &amp; untestable!public class SpellChecker { // 依赖直接生成 private static final Lexicon dictionary = ...; private SpellChecker() {} // Noninstantiable public static boolean isValid(String word) { ... } public static List&lt;String&gt; suggestions(String typo) { ... }}// 单例对象// Inappropriate use of singleton - inflexible &amp; untestable!public class SpellChecker { // 依赖直接生成 private final Lexicon dictionary = ...; private SpellChecker(...) {} public static INSTANCE = new SpellChecker(...); public boolean isValid(String word) { ... } public List&lt;String&gt; suggestions(String typo) { ... }} 然而，不同语言的单词拼写检查器，依赖于不同的字典，因此在 SpellChecker 直接依赖 dictionary，既不够灵活，又不便于测试（测试依赖其他字典时需要修改代码）。也就是说，静态工具类和单例类都不适合直接引用底层资源。 解决办法是 依赖注入（Dependency injection）。将 dictionary 依赖通过构造器，或静态工厂方法，或 item 2 中的 builder 传入 SpellChecker，从而实现解耦。 123456789101112// Dependency injection provides flexibility and testabilitypublic class SpellChecker { private final Lexicon dictionary; // 依赖由构造器传入 public SpellChecker(Lexicon dictionary) { this.dictionary = Objects.requireNonNull(dictionary); } public boolean isValid(String word) { ... } public List&lt;String&gt; suggestions(String typo) { ... }} 一个更好的实践建议是，将资源工厂传递给构造器，再让工厂造资源。这也是设计模式中 工厂方法模式（Factory Method pattern） 的体现。Java 8 中引入的 Supplier&lt;T&gt; 接口非常适合代表工厂。 尽管依赖注入提高了灵活性和可测试性，但在大型项目中会让依赖变得十分混乱。使用依赖注入框架（如 Dagger、Guice 或 Spring）可以消除这些混乱。 Item 6 避免创建不必要的对象重用不可变对象更多的时候，我们尽量要重用一个对象，而不是创建一个新的相同功能的对象，以节省资源。如果对象是不可变的（immutable, item 17），它就总是可以被重用。 一个反面例子： 1String s = new String(\"bikini\"); // DON'T DO THIS! 用 new 构造一个 String 时，其参数本身就是一个String，这样白白创建了一个 bikini 对象。正确的做法应该像下面这样，使用单个 String 实例，而不是每次执行时创建一个新实例。此外，它可以保证对象运行在同一虚拟机上的任何其他代码重用。 1String s = \"bikini\"; // DO THIS ! 使用静态工厂方法避免创建不需要的对象使用静态工厂方法（static factory methods, item 1），可以避免创建不需要的对象。构造方法每次调用时都必须创建一个新对象，而工厂方法则不会。 缓存（预编译）实例有些对象的创建很“昂贵”，例如检查一个字符串是否是一个有效的罗马数字： 12345// Performance can be greatly improved!static boolean isRomanNumeral(String s) { return s.matches(\"^(?=.)M*(C[MD]|D?C{0,3})\" + \"(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$\");} 我们发现，每次调用都要去匹配一次。s.matches在内部为正则表达式创建一个 Pattern 实例，并且只使用它一次，之后就可能被垃圾回收。然而，创建 Pattern 实例是昂贵的。解决方法是，将正则表达式显式编译为一个 Pattern 实例（不可变），缓存它，并在 isRomanNumeral 方法的每个调用中重复使用相同的实例： 12345678910// Reusing expensive object for improved performancepublic class RomanNumerals { private static final Pattern ROMAN = Pattern.compile( \"^(?=.)M*(C[MD]|D?C{0,3})\" + \"(X[CL]|L?X{0,3})(I[XV]|V?I{0,3})$\"); static boolean isRomanNumeral(String s) { return ROMAN.matcher(s).matches(); }} 自动装箱导致的创建不必要对象注意自动装箱导致的创建不必要对象。如下面的代码，用 Long 会比 long 额外创建 2^31个不必要的 Long 实例。所以，优先使用基本类型而不是装箱的基本类型，也要注意无意识的自动装箱。 1234567// Hideously slow! Can you spot the object creation?private static long sum() { Long sum = 0L; for (long i = 0; i &lt;= Integer.MAX_VALUE; i++) sum += i; return sum;} 最后，避免创建不必要的对象这并不是说对象创建是昂贵的，应该避免创建对象。现代JVM可以很轻松应对廉价的对象，但是像数据库连接这样的重量级对象，就应该考虑重用的问题。 Item 7 消除过期的对象引用Java自带垃圾收集机制，但有时候得手动清除不需要的引用。 在一个栈的实现中，弹栈时我们返回 pop 之后的栈顶元素，但刚刚被弹出去的元素，其实已经不再被需要了，然而它的引用还在，垃圾收集器不会回收它。所以这个栈存在「内存泄漏」。 12345public Object pop() { if (size == 0) throw new EmptyStackException(); return elements[--size];} 如下图所示，一个数组实现的栈，尽管 s[5] 已经被 pop 出去，但垃圾回收器不知道，它会认为 s[0] - s[7] 都是有用的。 解决办法很简单，对弹出去的元素置为 null 即可： 1234567public Object pop() { if (size == 0) throw new EmptyStackException(); Object result = elements[--size]; elements[size] = null; // Eliminate obsolete reference return result;} 请注意，清空对象引用应该是例外而不是规范。当一个类自己管理内存时，程序员才应该警惕内存泄漏问题。 Item 8 避免使用 Finalizer 和 Cleaner 机制 Finalizer 被设计用来当垃圾回收时关闭一些特殊的资源，可能有点像 C++ 的析构函数，但它并不稳定，因为我们无法确定什么时候垃圾回收。从 Java 9 开始，Finalizer 已被弃用，但仍被 Java 类库所使用。 Java 9 中 Cleaner 机制代替了 Finalizer 机制。但是 Cleaner 仍然是不可预测的。一般不要轻易尝试 Finalizer 和 Cleaner 。 需要关闭一般资源时，请使用 try-with-resource。只有在使用 JNI(Java Native Interface) 调用non-Java程序（C或C++）时，才使用 finalize() 来回收这部分的内存。 Item 9 使用 try-with-resource 代替 try-finally像 InputStream，OutputStream 和 java.sql.Connection 这些资源时需要关闭的，通常我们用 try-finally 来关闭，但如果有多个资源需要关闭，情况会变得很糟糕： 1234567891011121314151617// try-finally is ugly when used with more than one resource!static void copy(String src, String dst) throws IOException { InputStream in = new FileInputStream(src); try { OutputStream out = new FileOutputStream(dst); try { byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) &gt;= 0) out.write(buf, 0, n); } finally { out.close(); } } finally { in.close(); }} 内层的try块喝finally块都可能抛出异常，然而外层的 finally 块会吃掉内层的异常，导致在异常堆栈跟踪中没有第一个异常的记录，这会让调试变得非常复杂。 因此，在 Java 7 引入了 try-with-resources 语句，只要资源实现了 AutoCloseable接口就可以使用。当前， Java 类库和第三方类库中的许多类和接口现在都实现或继承了 AutoCloseable，所以无需担心。 12345678910// try-with-resources on multiple resources - short and sweetstatic void copy(String src, String dst) throws IOException { try (InputStream in = new FileInputStream(src); OutputStream out = new FileOutputStream(dst)) { byte[] buf = new byte[BUFFER_SIZE]; int n; while ((n = in.read(buf)) &gt;= 0) out.write(buf, 0, n); }}","link":"/post/39fc1edf.html"},{"title":"Effective Java（七）方法","text":"Item 49 检查参数有效性在 Java 7 之后，可以用 requireNonNull 来判空，如果为空，自动抛出空指针异常。 1this.strategy = Objects.requireNonNull(strategy, \"strategy\"); 其内部实现 12345public static &lt;T&gt; T requireNonNull(T obj) { if (obj == null) throw new NullPointerException(); return obj;} Item 50 防御性复制假设你编写一个 final 的类 Period ，其中包含两个 final 的 Date 字段。乍一看，这个类似乎是不可变的，然而 Date 里面的成员却是可以变的。这就像声明了一个 final 数组，数组本身不能变，然而数组里面的元素却可以改变一样。 12345// Attack the internals of a Period instanceDate start = new Date();Date end = new Date();Period p = new Period(start, end);end.setYear(78); // Modifies internals of p! 解决这一问题的办法是使用 Instant（或 LocalDateTime 或 ZonedDateTime）代替Date，因为 Instant 和其他 java.time 包下的类是不可变的（Item 17）。Date 已过时，不应再在新代码中使用。 如果实在要用像 Date 这样的可变类，在构造器和访问器做拷贝： 1234567891011121314public Period(Date start, Date end) { this.start = new Date(start.getTime()); this.end = new Date(end.getTime()); //... // 防御性拷贝 public Date start() { return new Date(start.getTime()); } public Date end() { return new Date(end.getTime()); }} Item 51 设计APITips 1：设计API时避免参数过长，三种方式解决参数过长： 将方法分解为多个方法，每个方法只需要参数的一个子集。 创建辅助类来保存参数组（通常是静态成员类） 使用 Builder 模式 Tips 2：设计API时，参数类型优先选择接口而不是类。 Tips 3：与布尔型参数相比，优先使用两个元素枚举类型，例如： 1public enum TemperatureScale { FAHRENHEIT, CELSIUS } Item 52 重载重载方法的选择是在 编译期，如下所示会打印两次 Unknown Collection，即使运行时第一次传入的是 List，但传入 Collection 的重载方法仍然会被使用。 12345678910111213141516171819public class CollectionClassifier { public static String classify(List&lt;?&gt; lst) { return \"List\"; } public static String classify(Collection&lt;?&gt; c) { return \"Unknown Collection\"; } public static void main(String[] args) { Collection&lt;?&gt;[] collections = { new ArrayList&lt;BigInteger&gt;(), new HashMap&lt;String, String&gt;().values() }; for (Collection&lt;?&gt; c : collections) System.out.println(classify(c)); }} 记住，重载（overloaded）方法之间的选择是静态的，而重写（overridden）方法之间的选择是动态的。 修复这一问题的办法如下： 1234public static String classify(Collection&lt;?&gt; c) { return c instanceof Set ? \"Set\" : c instanceof List ? \"List\" : \"Unknown Collection\";} JDK 里面为了避免这一问题，例如 ObjectOutputStream 类，会用 writeBoolean(boolean)、writeInt(int)和writeLong(long)，而不是重载write方法。 当然，也有一些违反常规的，需要特别注意。例如，TreeSet 的 remove 选择的是重载 remove(E) 方法，而 ArrayList 的 remove 却是 remove(int i)，一个是元素值，一个是元素下标。可能会带来混乱。 Item 53 可变参数可变参数机制：首先创建一个数组（数组大小为传入的可变参数数量），然后将参数值放入数组中，最后将数组传递给方法。 尽量不要使用可变参数。 Item 54 返回空的数组或集合，不要返回 null如果你有一个数组或集合，它可能为空，请直接返回一个空的容器，不要返回null 123456789//The right way to return a possibly empty collectionpublic List&lt;Cheese&gt; getCheeses() { return new ArrayList&lt;&gt;(cheesesInStock);}//The right way to return a possibly empty arraypublic Cheese[] getCheeses() { return cheesesInStock.toArray(new Cheese[0]);} 如果担心每次都 new 会影响性能，考虑优化如下，跟上面的区别在于 Collections.emptyList() 永远是同一个，不同每次都 new 一个新的空集合。 123456789101112// Optimization - avoids allocating empty collectionspublic List&lt;Cheese&gt; getCheeses() { return cheesesInStock.isEmpty() ? Collections.emptyList() : new ArrayList&lt;&gt;(cheesesInStock);}// Optimization - avoids allocating empty arraysprivate static final Cheese[] EMPTY_CHEESE_ARRAY = new Cheese[0];public Cheese[] getCheeses() { return cheesesInStock.toArray(EMPTY_CHEESE_ARRAY);} Item 55 OptionalJava 8 加入了 Optional&lt;T&gt;，本质上是一个集合（但没有实现Collection&lt;T&gt;接口）。例如，本来应该返回 Student 的，但如果 Student 可能为空，那么就有返回 Student 或返回 null 两种情况。 Optional把两种情况变成一种，统一返回 Optional&lt;Student&gt;。 12345678public static Optional&lt;Student&gt; getFirstStu(Collection&lt;Student&gt; c) { // 如果为空，返回 empty if (c.isEmpty()) return Optional.empty(); // 非空返回 else return Optional.of(c.get(0));} 并不是所有的返回类型都适合用 Optional。容器类型，包括集合、映射、Stream、数组和 Optional，不应该封装在 Optional 中。与其返回一个空的Optional&lt;List&lt;T&gt;&gt;，还不如返回一个空的 List&lt;T&gt; Item 56 编写文档注释这一条还是直接翻原书吧。","link":"/post/387fb533.html"},{"title":"Effective Java（二）对象通用的方法","text":"对象通用的方法，指的是 Object 类下的方法，即 toString、equals、hashCode 等等，合理地使用跟重写它们，可以避免很多坑。 Item 10 重写 equals 时请遵守约定重写 equals 很容易犯错，最好不要去重写，比如下面的情形： 类的每个实例都是唯一的。显而易见，像 Thread 这样表示活动而不是值的类来说，每个实例都是不一样的。 类不需要「逻辑相等（logical equality）」 父类已经重写了 equals 方法，除非有必要，否则子类就不用再去重写了。例如，大多数 List 从 AbstractList 继承了 equals 实现，Map 从 AbstractMap 的 Map 继承了 equals 实现。 如果你不想这个类的 equals 方法被调用，可以给它抛异常 1234@Overridepublic boolean equals(Object o) { throw new AssertionError(); // Method is never called} 那什么时候需要重写 equals 方法呢？如果一个类需要逻辑相等，而不是引用相同的对象，那么需要重写 equals ，重写 equals 请遵守以下5个规则： 自反性： 对于任何非空引用 x，x.equals(x) 必须返回 true。 对称性： 对于任何非空引用 x 和 y，如果且仅当 y.equals(x) 返回 true 时 x.equals(y) 必须返回 true。 传递性： 对于任何非空引用 x、y、z，如果x.equals(y) 返回 true，y.equals(z) 返回 true，则 x.equals(z) 必须返回 true。 一致性： 对于任何非空引用 x 和 y，如果在 equals 比较中使用的信息没有修改，则 x.equals(y) 的多次调用必须始终返回 true 或始终返回 false。 对于任何非空引用 x，x.equals(null) 必须返回 false。 如何正确地使用 equals ： 使用 == 运算符检查参数是否为该对象的引用。如果是，返回 true。这只是一种性能优化，但是如果这种比较可能很昂贵的话，那就值得去做。 使用 instanceof 运算符来检查参数是否具有正确的类型。 如果不是，则返回 false。 通常，正确的类型就是 equals 方法所在的那个类，但有时是这个类实现的接口。 如果类实现了一个接口，且该接口允许实现接口的类进行比较，那么就使用接口。集合接口（如 Set，List，Map 和 Map.Entry）具有此特性。 将参数转换为正确的类型。因为转换操作在 instanceof 中已经处理过，所以它肯定会成功。 对每个需要比对的属性，都去检查该参数属性是否与该对象对应的属性相匹配。如果都匹配，返回 true，否则返回 false。如果步骤 2 中的类型是一个接口，那么必须通过接口方法访问参数的属性;如果类型是类，则可以直接访问属性，这取决于属性的访问权限。 JDK String 重写 equals 的例子就很值得学习： 12345678910111213141516171819202122232425262728293031public boolean equals(Object anObject) { // 如果是同一个对象，返回 true if (this == anObject) { return true; } // 如果 anObject 可以向下转型为 String if (anObject instanceof String) { // 转型为 String 类型 String anotherString = (String)anObject; // 原字符串长度 int n = value.length; // 如果原字符串长度和要比较的字符串长度一致 if (n == anotherString.value.length) { char v1[] = value; char v2[] = anotherString.value; int i = 0; // 逐个字符比较 while (n-- != 0) { if (v1[i] != v2[i]) return false; i++; } return true; } } return false;} Item 11 重写 equals ，必须重写 hashCode重写 hashCode 的规范如下： 在一个应用执行过程中，如果 equals 没有做任何修改，那么多次调用 hashCode 必须返回相同的值。 如果 equals() 返回 true ，那么 hashcode 值必然相同，反之则不一定。 重写 equals 如果没有重写 hashCode，可能导致对象在集合（如 HashSet、HashMap）中出问题。因为两个逻辑相等 equals 的对象，若是不同的实例，会返回不同的 hashCode，如果一个实例插入到 HashMap 中，另一个作为判断相等的实例用来检索，put 方法把实例保存在了一个哈希桶（hash bucket）中，但 get 方法却是从不同的哈希桶中去查找，即使恰好两个实例放在同一个哈希桶中，get 方法几乎肯定也会返回 null。因为 HashMap 做了优化，缓存了与每一项（entry）相关的哈希码，如果哈希码不匹配，则不会检查对象是否相等了。 解决办法就只有重写 hashCode 方法，那么如何重写呢？去翻《Effective Java》原书吧，讲得很详细。也可以参考Guava 框架的 com.google.common.hash.Hashing [Guava] 方法，AutoValue 框架，或者 IDEA 的自动生成。 一个建议是不要试图从哈希码计算中排除重要的属性来提高性能，因为这样哈希质量会降低。 Item 12 始终重写 toString 方法toString 方法应该返回对象中包含的所有需要关注的信息。而 Object 类的 toString 却只返回 类名@十六进制数。因此我们最好重写它。例如当你把一个字符串放进 Map 里，输出时会 toString 方法会自动被调用， 输出 {Jenny=707-867-5309} 总比 {Jenny=PhoneNumber@163b91} 好吧？ 附上阿里巴巴Java开发规范 【强制】关于 hashCode 和 equals 的处理，遵循如下规则： 只要重写 equals ，就必须重写 hashCode 。 因为 Set 存储的是不重复的对象，依据 hashCode 和 equals 进行判断，所以 Set 存储的对象必须重写这两个方法。 如果自定义对象作为 Map 的键，那么必须重写 hashCode 和 equals 。 说明： String 重写了 hashCode 和 equals 方法，所以我们可以非常愉快地使用 String 对象作为 key 来使用。 Item 13 谨慎地重写 clone 方法Cloneable 接口是一个标记接口，只有实现该接口才可以调用 clone 方法。 clone的规范为： x.clone() != x，并且 x.clone().getClass() == x.getClass() ，通常情况下 x.clone().equals(x)。 但是请注意，clone() 是浅复制。也就是说只会复制对象本身，而对象引用的其他对象并不会被复制。考虑一个栈里面的元素，clone()出来的栈和原始栈引用的是相同的元素，因此改变克隆栈的某个元素，原始栈也会跟着改变，这是一个坑。要解决这个问题，要使用深复制，简而言之就是重写 clone() ，使对象中对其引用对象再使用clone()。 Item 14 考虑实现 Comparable 接口Comparable接口： 123public interface Comparable { int compareTo(T other);} 如果你正在编写具有明显自然顺序（如字母顺序，数字顺序或时间顺序）的值类，那么就应该实现 Comparable 接口。如果一个对象按重要顺序要比较不同的属性，还可以递归调用： 12345678910// Multiple-field `Comparable` with primitive fieldspublic int compareTo(PhoneNumber pn) { int result = Short.compare(areaCode, pn.areaCode); if (result == 0) { result = Short.compare(prefix, pn.prefix); if (result == 0) result = Short.compare(lineNum, pn.lineNum); } return result;} 在 Java 8 中，还能用 比较器 Comparator 来定义比较行为： 123456789// Comparable with comparator construction methodsprivate static final Comparator&lt;PhoneNumber&gt; COMPARATOR = comparingInt((PhoneNumber pn) -&gt; pn.areaCode) .thenComparingInt(pn -&gt; pn.prefix) .thenComparingInt(pn -&gt; pn.lineNum);public int compareTo(PhoneNumber pn) { return COMPARATOR.compare(this, pn);} 第三版中的建议是，比较 compareTo 方法的实现中的字段值时，请避免使用「&lt;」和「&gt;」运算符。相反，使用包装类中的静态 compare 方法或 Comparator 接口中的构建方法。","link":"/post/f754c291.html"},{"title":"Effective Java（三）类和接口","text":"Item 15 最小化类和成员的可访问性一个设计良好的组件，应该隐藏其内部细节，将 API 与它的实现分离开来，外界只与 API 通信。这也是软件设计的基本原则。 Java中的四种访问级别： private —— 该成员只能在声明它的顶级类内访问。 package-private —— 成员可以从被声明的包中的任何类中访问。从技术上讲，如果没有指定访问修饰符（接口除外，它默认是公共的），这是默认访问级别。 protected —— 成员可以从被声明的类的子类中访问，以及它声明的包中的任何类。 public —— 该成员可以从任何地方被访问。 能用 private 的，绝不用 protected，能用 protected 的，绝不用 public。 如果子类方法重写父类方法，子类方法不能有比父类方法更大的访问级别，但可以更小。但如果是实现接口，则实现类方法必须只能是 public。 带有 public 的可变字段的类通常不是线程安全的。 请注意下面的写法，数组 Thing[] 本身是 final 的，但是 Thing[] 里面的元素却是可以变的 12// Potential security hole!public static final Thing[] VALUES = { ... }; 解决办法如下： 12private static final Thing[] PRIVATE_VALUES = { ... };public static final List&lt;Thing&gt; VALUES = Collections.unmodifiableList(Arrays.asList(PRIVATE_VALUES)); Item 16 使用 public 方法来访问属性，而不是 public 属性对于一个 public类 来说，应该用 private域 + getter setter 方法来访问属性。这体现了封装和面向对象。 但是，如果一个类是 package-private 的，或者是一个 private 内部类，那么暴露它的数据属性就没有什么本质上的错误——假设它们提供足够描述该类提供的抽象。 Item 17 最小化可变性immutable class 简单来说就是实例不能被修改的类。包含在每个实例中的所有信息在对象的生命周期中是固定的，因此不会观察到任何变化。比如 String，BigDecimal 等。 设计一个 immutable class 的原则如下： 没有修改对象的方法（mutators） 不能继承 所有属性 private final 如果有引用的可变对象，确保它无法被客户端访问到 immutable class 的优点是简单，本质上是线程安全的，不需要同步。缺点是是对于每个不同的值都需要一个单独的对象。 总原则： 坚决不要为每个属性编写一个 get 方法后再编写一个对应的 set 方法，除非有充分的理由使类成为可变类，否则类应该是不可变的。 除非有足够的理由把属性设置为非 final ，否则每个属性都应该设置为 final 的。 构造方法应该创建完全初始化的对象，并建立所有的不变性。 Jdk 中一个好的示范是 CountDownLatch 类，它本身是可变的，但它的状态空间有意保持最小范围。创建一个实例，使用它一次直到完成，一旦 countdown 锁的计数器已经达到零，就不能再重用它。 Item 18 多用组合少用继承如果软件设计之初，专门为了继承而设计的类，并且有文档说明，使用继承是安全的。但是跨越到 package 之外去继承，就很危险。它打破了封装。 不要继承一个现有的类，而应该给你的新类增加一个私有属性，该属性是现有类的实例引用，这种设计称为 组合（composition）。 什么时候用继承？《Effective Java》作者 Joshua Bloch 的建议： 只有在子类真的是父类的子类型的情况下，继承才是合适的。 换句话说，只有在两个类之间存在「is-a」关系的情况下，B 类才能继承 A 类。 如果你试图让 B 类继承 A 类时，问自己这个问题：每个 B 都是 A 吗？ 如果你不能如实回答这个问题，那么 B 就不应该继承 A。如果答案是否定的，那么 B 通常包含一个 A 的私有实例，并且暴露一个不同的 API ：A 不是 B 的重要部分 ，只是其实现细节。 Item 19 为继承编写文档，否则就不要用继承如果一个类没有设计和文档说明，那么「外来」类去继承是危险的。 测试为继承而设计的类的唯一方法是编写子类。 构造方法绝不能直接或间接调用可重写的方法，因为父类构造方法先于子类构造方法运行，导致在子类构造方法运行之前，子类中的重写方法就已被调用。 如果不想你的类被继承，将类设计为 final，或者让构造器私有，用静态工厂来实例化你的类。 Item 20 接口优于抽象类Java 8 对接口引入了默认实现，抽象类和接口都允许有实现。 因为 Java 只允许单一继承，所以继承抽象类会有一些限制，而一个类实现多个接口。接口允许构建非层级类型的框架。 Item 21 接口的默认实现Java 8 提供了接口的默认实现，本质上是为了不改变接口设计的条件下，向接口加入更多方法。其用途主要在接口演化。 考虑一个旧接口有一些旧的实现，后来新需求需要对该接口添加新方法，但是又不想改旧实现，此时就就可以用默认实现。但 应该尽量避免使用默认实现，因为默认实现可能会破坏接口的功能。例如 Collection 接口的 removeIf 方法，在很多集合类上都工作正常，但对于 org.apache.commons.collections4.collection.SynchronizedCollection ，如果这个类与 Java 8 一起使用，它将继承 removeIf 的默认实现，但实际上不能保持类的基本承诺：自动同步每个方法调用。 默认实现对同步一无所知，并且不能访问包含锁定对象的属性。 如果客户端在另一个线程同时修改集合的情况下调用 SynchronizedCollection 实例上的 removeIf 方法，则可能会导致 ConcurrentModificationException 异常或其他未指定的行为。 Item 22 接口仅用来定义类型，不用于导出常量客户端可以直接用接口引用具体实现类，这是接口的正确使用方式。 糟糕的使用方式是常量接口（constant interface），即只为接口定义常量属性。类在内部使用一些常量，完全属于该类的实现细节，实现一个常量接口会导致这个实现细节在外部可见（因为接口是public的），不符合隐藏实现的原则。 如果你确实想暴露一些常量给外部，用不可实例化的工具类： 12345678910// Constant utility classpackage com.effectivejava.science;public class PhysicalConstants { private PhysicalConstants() { } // Prevents instantiation public static final double AVOGADROS_NUMBER = 6.022_140_857e23; public static final double BOLTZMANN_CONST = 1.380_648_52e-23; public static final double ELECTRON_MASS = 9.109_383_56e-31;} 客户端调用： 12345678910// Use of static import to avoid qualifying constantsimport static com.effectivejava.science.PhysicalConstants.*;public class Test { double atoms(double mols) { return AVOGADROS_NUMBER * mols; } ... // Many more uses of PhysicalConstants justify static import} Item 23 为类设计层次结构，不要混杂类如果有一个图形类，即可以表示圆又可以表示矩形，那么应该把这个类抽成两个类，共同继承于抽象图形类，而不是在类里用一个标签判断类型，再用 Switch 去走分支。 不好的设计： 123456789101112131415class Figure { enum Shape { RECTANGLE, CIRCLE }; double area() { switch(shape) { case RECTANGLE: return length * width; case CIRCLE: return Math.PI * (radius * radius); default: throw new AssertionError(shape); } }} 好的设计： 123456789101112131415161718abstract class Figure { abstract double area();}class Circle extends Figure { final double radius; @Override double area() { return Math.PI * (radius * radius); }}class Rectangle extends Figure { final double length; final double width; @Override double area() { return length * width; }} Item 24 尽量使用静态成员内部类建议：如果你声明了一个不需要访问宿主实例的成员类，最好把 static 修饰符放在它的声明中，使它成为一个静态成员类，而不是普通成员类。 如果忽略了这个修饰符，每个实例都会有一个隐藏的外部引用给它的宿主实例。存储这个引用需要占用时间和空间。更严重的是，会导致即使宿主类在满足垃圾回收的条件时却仍然驻留在内存中。由此产生的内存泄漏可能是灾难性的。由于引用是不可见的，所以通常难以检测到。 Item 25 一个.java源文件只定义一个顶级类永远不要将多个顶级类或接口放在一个源文件中。 遵循这个规则保证在编译时不能有多个定义。 这又保证了编译生成的类文件以及生成的程序的行为与源文件传递给编译器的顺序无关。","link":"/post/20ef17da.html"},{"title":"Effective Java（九）异常","text":"Item 69 异常只用于异常异常只用于异常的情况，不要用 try-catch 捕获 ArrayIndexOutOfBoundsException 并且不做任何处理这种方式来跳出数组遍历。为什么不用 for-each 循环呢？ 设计良好的 API 不应该强迫它的客户端为了正常的控制流程而使用异常。 例如： 1234for ( Iterator&lt;Foo&gt; i = collection.iterator(); i.hasNext(); ){ Foo foo = i.next(); ...} hasNext方法是一个状态测试机。如果 Iterator API 没有设计 hasNext 方法，那么客户端代码将会变得很丑： 123456789/* Do not use this hideous code for iteration over a collection! */try { Iterator&lt;Foo&gt; i = collection.iterator(); while ( true ) { Foo foo = i.next(); ... }} catch ( NoSuchElementException e ) {} Item 70 对可恢复的情况使用checked exception，对编程错误使用unchecked exception（runtime exception）使用 checked exception 还是 unchecked exception 的一个基本原则是，你是不是想让程序恢复。如果是，使用 checked exception。 像 ArrayIndexOutOfBoundsException、NullPointerException 这类 unchecked exception 异常，可以通过优化代码实现来避免，不应该捕获。而像 IOException 是不可避免的，应当捕获并处理。 Item 71 避免对 checked exception 不必要的使用正如前面所说的，异常只用于异常情况。有些 try-catch 实际上可以分解重构成 if-else，对于真正有异常的部分才进入 try-catch 块。不要过度使用 try-catch。 Item 72 优先使用标准的异常Java 平台类库提供了一组基本的 unchecked exception，它们满足了绝大多数 API 的异常抛出需求。应该尽可能使用。 异常 使用场合 IllegalArgumentException 非 null 的参数值不正确（如接收非负数的方法传入了-1） IllegalStateException 不适合方法调用的对象状态（如对象未被正确初始化前就被调用） NullPointerException 在禁止使用 null 的情况下参数值为 null IndexOutOfBoundsExecption 下标参数值越界 ConcurrentModificationException 在禁止并发修改的情况下，检测到对象的并发修改 UnsupportedOperationException 对象不支持用户请求的方法 Item 73 异常转译和异常链高层的实现应该捕获底层的异常，同时抛出可以按照高层抽象进行解释的异常。这种做法称为 异常转译 （exception translation）。 例如下面的例子，高层的将 get(i) 将底层 i.next() 的 NoSuchElementException 转译成 IndexOutOfBoundsException 并抛出。 12345678910111213/** * Returns the element at the specified position in this list. * @throws IndexOutOfBoundsException if the index is out of range * ({@code index &lt; 0 || index &gt;= size()}). */public E get(int index) { ListIterator&lt;E&gt; i = listIterator(index); try { return(i.next() ); } catch (NoSuchElementException e) { throw new IndexOutOfBoundsException(\"Index: \" + index); }} 在转译时，可以形成 异常链（exception chaining），将底层异常带出去。如果低层的异常对于调试导致高层异常的问题非常有帮助，使用异常链就很合适。 123456// Exception Chainingtry {... // Use lower-level abstraction to do our bidding} catch (LowerLevelException cause) { throw new HigherLevelException(cause);} 但也不能滥用异常链，使用原则是：优先处理异常，无法处理时才向上抛出或转译抛出，如果底层异常对高层调试有帮助，才用异常链。 Item 74 每个方法抛出的异常都需要创建文档使用 Javadoc 的 ＠throws 标签记录一个方法可能抛出的每个unchecked exception，但是不要使用 throws 关键字将 unchecked exception 包含在方法的声明中。 123456789101112// do this/** * @throws may cause NullPointerException **/public String foo(){}// don't do thispublic String foo thorws NullPointerException(){} Item 75 异常输出输出异常的细节信息应该包含有用的所有参数和字段的值。例如 IndexOutOfBoundsException 应该包含下界、上界以及实际使用的下标值。 1234Exception in thread &quot;main&quot; java.lang.IndexOutOfBoundsException: Index: 5, Size: 2 at java.util.ArrayList.rangeCheck(ArrayList.java:657) at java.util.ArrayList.get(ArrayList.java:433) at test.Test.main(Test.java:18) Tips：千万不要在细节消息中包含密码、密钥以及类似的信息！ Item 76 failure atomic一般而言，失败的方法调用应该使对象保持在被调用之前的状态。具有这种属性的方法被称为具有 失败原子性（failure atomic）。也就是说，出现异常并捕获，之后程序恢复，不会因此有其他任何状态的改变。 最简单的方法是用不可变对象。不可变对象的状态永远是一致的。对于在可变对象，获得失败原子性最常见的办法是，在执行操作之前检查参数的有效性 （Item 49）。这可以使得在对象的状态被修改之前，先抛出适当的异常。 1234567public Object pop() { if ( size == 0 ) throw new EmptyStackException(); Object result = elements[--size]; elements[size] = null; /* Eliminate obsolete reference */ return(result);} 如果取消对初始大小（size）的检查，当这个方法试图从一个空栈中弹出元素时，它仍然会抛出异常。然而，这将会导致 size 字段保持在不一致的状态（负数）之中，从而导致将来对该对象的任何方法调用都会失败。 总而言之，想办法让在异常抛出前后，对象的状态保持一致。你可以提前检查（像上面那样），可以调整计算处理的顺序，可以在对象的一份临时拷贝上执行操作，操作完再去代替对象本身。或者是，编写恢复对象状态的代码（不常用）。 虽然一般情况下都希望实现失败原子性，但并非总是可以做到。如果两个线程企图在没有适当的同步机制的情况下，并发地修改同一个对象，这个对象就有可能被留在不一致的状态之中。因此，在捕获了 ConcurrentModificationException 异常之后再假设对象仍然是可用的，这就是不正确的。 Item 77 不要忽略异常忽略一个异常非常容易，只需将方法调用通过 try 语句包围起来，并包含一个空的 catch 块。但是，最好不要这么做。空的 catch 块会使异常达不到应有的目的。 12345// Empty catch block ignores exception - Highly suspect!try { ...} catch ( SomeException e ) {} 即使确实不需要做任何处理，把异常记录下来还是明智的做法，因为如果这些异常经常发生，你就可以调查异常的原因。 如果异常确实也不需要记录下来，才选择忽略异常，catch 块中应该包含一条注释，说明为什么可以这么做，并且变量应该命名为 ignored。 12345try { numColors = f.get( 1L, TimeUnit.SECONDS );} catch ( TimeoutException | ExecutionException ignored ) { // Use default: minimal coloring is desirable, not required}","link":"/post/4e34dae4.html"},{"title":"Java并发编程之安全性","text":"并发编程显然有很多优势，然而，多线程也带来了一定的风险。例如安全性问题、活跃性问题、性能问题等。 安全性问题： 含义是“永远不发生糟糕的事情”，例如多个线程同时修改一个共享变量，导致结果跟预期不符。 活跃性问题： 关注“某件正确的事情最终会发生”，假若不能，就会产生活跃性问题。例如死锁，A、B进程互相等待对方释放某资源，结果谁也执行不下去。 性能问题： 在解决安全性问题和活跃性问题的时候会带来额外开销，我们必须想办法减少开销。 并发编程的问题，在Java简明笔记（十一） 并发编程中就有提及，这一篇，主要就安全性问题，详细谈谈Java并发编程的问题。 线程安全性一个对象是否需要是线程安全的，取决于它是否被多个线程访问。那什么是安全性呢？说白了，就是要保证结果正确！《Java并发编程实战》的作者Brain Goetz对线程安全的定义是：当多个线程访问某个对象时，不管运行时环境采用何种调度方式或者如何交替执行，并且调用方不需要任何额外的同步操作，调用这个对象的行为都能获得正确的结果，那么就称这个对象是线程安全的。 无状态对象 - 安全无状态对象一定是线程安全的。比如一个 Servlet , 从 Request 从提取数值，执行计算，然后封装到 Response 中。每个收到要计算的 Servlet 线程实例都是自己算自己的，没有跟其他线程的 Servlet 实例共享状态。因此，它是线程安全的。 有状态对象 - 原子性问题（竞争条件）但假设多个 Servlet 之间，要处理共享的一个变量，由于这个变量值是会变的，我们称之为“状态”，又由于这个“状态”可以被多个线程同时读写，我们称之为“共享状态”。这时候多个 Servlet 实例就会产生竞争条件。所谓竞争条件，是指由不恰当的执行时序导致的出现不正确的结果，最常见的竞态条件就是“先观察后执行”，问题就出在观察的值可能是错的。 竞争条件例子1：计数器例如要统计网站访问总人数，用一个 count 共享变量来表示。如下所示： 12345678910// count 是共享变量private static long count = 0;public long getCount(){ return count; }public void service (ServletRequest req, ServletResponse resp) { //do something ++count; // 线程不安全 //do something} 使用 Intellij IDEA 的 jclasslib 插件，可以看到上述 service 方法翻译成JVM字节码后如下： 123450 getstatic #2 &lt;Test/AtomicTest.count&gt; // 获取常量3 lconst_1 //将 long 类型的常量添加进操作栈4 ladd // +15 putstatic #2 &lt;Test/AtomicTest.count&gt; // 常量写回8 return 可见 ++count 并非原子操作，它实际上包含 读取 count 的值、计算加一、计算结果写回 count 三个操作（即复合操作）。因此，有可能出现当线程A观察 count 的值，发现为 5，并对其加一，此时线程B观察 count 的值，也发现为 5，并对其加一，之后线程A计算结果将6写回count，线程B也将6写回count。我们预期结果是7，但实际上却是6。这就是竞争条件带来的原子性问题。 竞争条件例子2：延迟初始化延迟初始化是指将对象的初始化操作推迟到实际被使用时才进行。 1234567891011121314public class lazyInitRace{ // 当类被加载，先不初始化 private ExpensiveObject instance = null; //当第一次被使用时，才初始化 public ExpensiveObject getInstance(){ // 如果第一次被使用发现为 null，先初始化 if (instance == null){ this.instance = new ExpensiveObject(); } // 第二次之后直接返回该对象 return instance; }} 假如线程A和线程B同时执行getInstance()方法，线程A观察到 instance 为 null，于是 new 一个实例，由于 new 不是一个原子操作，在 new 还没完成时，instance仍然为null，此时时间片切换到线程B，B也观察到 instance 为 null，又 new 了一个实例。 竞争条件并不总会发生错误，但在某种不恰当的执行时序下，可能会出错。因此是线程不安全的。 使用 atomic 原子类解决原子性问题在 java.util.concurrent.atomic 包中包含了一些原子变量类，可以提供原子操作。只需把 count 的类型从 long 改为 Atomiclong。在程序员的角度，可以认为 Atomiclong 把上述 读取 count 的值、计算加一、计算结果写回 count 这三个操作，合并成一个原子操作。这跟数据库的事务有点类似。 12345678910 // count 是共享变量private Atomiclong count = new AtomicLong(0);public long getCount(){ return count.get(); }public void service (ServletRequest req, ServletResponse resp) { //do something count.incrementAndGet(); // 线程安全 //do something} 像这样，当一个对象只有一个“状态”时，将该状态交给如 Atomiclong 这类线程安全对象来管理，那么这个类仍然是线程安全的。但并不是添加多个这样的安全对象，程序就线程安全了。当对象不止有一个“状态”时，或者说，涉及多个状态变量时，各个变量之间有时候并不是彼此独立，而是某个变量的值会对其他变量产生影响。这时候修改一个原子变量的同时，也要更新另一个原子变量。这种情况 Atomic 原子类是无法解决的，只能用下文将提到的加锁机制了。 深入：atomic原子类为什么可以保证原子性？atomic原子类底层是用非阻塞并发算法实现的。具体是用了 CAS 算法。CAS指的是比较并交换(compare and swap)。它包含三个数：需要读写的内存位置V、进行比较的值A、拟写入的新值B。当 V 和 A 相等时，才将 V 的值更新为 B。无论是否更新成功，都返回当前内存位置 V 值。 可以这样理解CAS：我认为 V 的值应该为 A，如果是，那么将 V 的值更新为 B，否则不修改并告诉 V 的值实际为多少。 因此，当多个线程并发修改atomic原子变量时，可能的情况为： 123456789线程A：观察 V 的值，发现为 5线程A：进行加一操作（得到6）线程B：观察 V，也发现为 5线程B：进行加一操作（得到6）线程A：再次观察 V 的值，看看是不是预期值5，发现是，就把加一后的值 6 写回 V线程B：再次观察 V 的值，看看是不是预期值5，发现不是，不写回，重试线程B：观察 V 的值，发现为 6线程B：进行加一操作（得到7）线程B：再次观察 V 的值，看看是不是预期值6，发现是，就把加一后的值 7 写回 V 关于atomic原子类可参考另一篇：Java并发编程之并发工具 使用 加锁机制 解决原子性问题前面提到，Atomic 原子类可以保证一个“状态”是安全的。但是当对象中存在多个“状态”，并且互相影响。那 Atomic 原子类就不再适用。Java 提供了一种内置的锁机制来支持原子性，即 同步代码块（Synchronized Block）。 1234// synchronized 可用在独立的代码片段，也可以修饰方法synchronized (obj) { // do something .. (访问或修改共享变量和状态)} synchronized 修饰符表示一个锁。括号里是要锁住的对象（称为对象锁，对象锁是Java的内置锁或者叫监视锁，隐式存在于每个对象中）。当线程A进入了 synchronized 块，它就持有了某个对象的锁，当CPU时间片从线程A切换到其他线程，也执行到这里，就会阻塞在 synchronized 块之外，直到线程A退出synchronized块，释放该锁。需要注意，当对一个父类加了对象锁，子类是不会受到影响的，相反也是如此。 对于有多个状态并且相互影响的对象才使用锁。否则 Atomic 原子类已经足够。此外，synchronized 最好仅仅包含需要互斥同步的临界区代码片段，包含在整个方法的做法有点极端。因为就 Servlet 的例子来说，锁住整个 service 方法，每次只有一个客户端能够响应，多个客户端无法同时使用和计算，服务的响应性能非常低，这就变成一个性能问题了。 重入一个线程请求其他线程持有的锁时，发出请求的线程会被阻塞。但是，如果一个线程试图获得一个 自己 持有的锁，则会请求成功。因为 synchronized 内置锁是可重入的。 重入如何实现？重入的一种实现方式是，为每个锁关联一个获取计数值和一个所有者线程。当计数值为0时，锁没有被任何线程持有。当一个线程获取该锁，JVM将记下锁的持有者，并把计数值+1，这个线程第二次请求该锁，计数值再+1。第二次请求的操作执行完毕后，计数值-1，第一次请求的操作执行完毕后，计数值再-1，便恢复到0，锁被释放。 为什么要重入？考虑下面的例子, 如果不可重入，那么会发生死锁。在 LoggingWidget 的 doSomething 方法中，跳出去执行父类 Widget 的 doSomething 方法，之后，调用栈返回，又回到子类 LoggingWidget 的 doSomething 方法，会发现锁已经被占用，然而占用锁的人正是它自己。 1234567891011public class Widget{ public synchronized void doSomething(){ //... }}public class LoggingWidget extends Widget{ public synchronized void doSomething(){ super.doSomething(); }} 好在 synchronized 是可重入的，有了重入，我们就可以在上述 Servlet 的例子中，把需要原子操作的代码片段用 synchronized 封装起来，缩小锁的范围，从而提高并发性了。至于同步代码块的范围要缩小多少，就需要在设计需求之间进行权衡了，包括安全性、简单性和性能等方面。 深入：synchronized 原理同步代码块基于 monitorenter 和 monitorexit 字节码指令来实现。编译后的代码，monitorenter 指令会被插入到同步代码块的开始位置，而 monitorexit 会被插入到代码块结束处和异常处。线程执行到 monitorenter 指令时，将会尝试获取对象所对应的 monitor 所有权。 1234567static int count = 0;public static void service(){ synchronized (go.class){ count++; }} 12345678910111213141516170 ldc #2 &lt;Test/go&gt;2 dup3 astore_04 monitorenter // 获得锁5 getstatic #3 &lt;Test/go.count&gt;8 iconst_19 iadd10 putstatic #3 &lt;Test/go.count&gt;13 aload_014 monitorexit // 正常结束 释放锁15 goto 23 (+8)18 astore_119 aload_020 monitorexit // 发生异常 释放锁21 aload_122 athrow23 return 参考： 操作系统漫游（二）进程 volatile是怎么实现防止指令重排序的？ 剖析Disruptor:为什么会这么快？(三)揭秘内存屏障 《Java并发编程实战》 《Java并发编程的艺术》","link":"/post/b4ed848b.html"},{"title":"Effective Java（八）General Programming","text":"Item 57 最小化局部变量的作用域 好的编程习惯：在首次使用的地方声明它。 如果循环终止后不需要循环变量的内容，那么优先选择 for 循环而不是 while 循环。 如果变量需要在 try-catch 之外使用，那就必须在外面提前声明，这是一个例外。其他情况都应该遵循在首次使用的地方声明。 每个行为对应一个方法。保持方法小而集中。 Item 58 for-each 循环优于 for-i 循环如果你只是需要容器里的元素，而不需要下标，for-i循环显然增加出错的可能性。最好用 for-each。for-each还可以用来遍历实现 Iterable 接口的任何对象。 但也有不能用for-each的情况： 过滤删除：如果需要遍历集合，并删除指定选元素，则需要使用显式iterator，以便可以调用其 remove 方法。 通常可以使用在 Java 8 中添加的 Collection 类中的 removeIf 方法，来避免显式遍历。 12List&lt;String&gt; li = new ArrayList&lt;&gt;(Arrays.asList(\"aa\",\"bb\",\"cc\"));li.removeIf( a -&gt; \"aa\".equals(a)); 转换：如果需要遍历一个列表或数组并替换其元素的部分或全部值，那么需要 iterator 或数组索引来替换元素的值。 并行迭代 Item 59 了解并使用库 使用标准库，等于站在巨人肩膀上。 例如，生成随机数，自己写有很大的不确定性，但是直接使用 Random.nextInt(int) 可以直接得到期望的结果。Java 7 更应该用 ThreadLocalRandom，它能产生更高质量的随机数，而且速度比Random快。对于 fork 连接池和并行流，使用 SplittableRandom。 每个程序员都应该熟悉 java.lang、java.util 和 java.io 的基础知识及其子包。其他库的知识可以根据需要学习。此外，Collections 框架和 Streams 库应该是每个程序员的基本工具包的一部分，java.util.concurrent 中的并发实用程序也应该是其中的一部分。 如果你在 Java 平台库中找不到你需要的东西，你的下一个选择应该是寻找高质量的第三方库，比如谷歌的优秀的开源 Guava 库 [Guava]。 不要重复造轮子！ Item 60 精确数字就应避免 float 和 double ，使用 BigDecimal《阿里巴巴Java开发手册》提到： 【强制】小数类型为 decimal ，禁止使用 float 和 double 。说明： float 和 double 在存储的时候，存在精度损失的问题，很可能在值的比较时，得到不正确的结果。如果存储的数据范围超过 decimal 的范围，建议将数据拆成整数和小数分开存储。 float 和 double 类型特别不适合进行货币计算。 12// 输出：0.6100000000000001System.out.println(1.03 - 0.42); 使用 BigDecimal 能解决这个问题，注意：使用 BigDecimal 的 String 构造函数而不是它的 double 构造函数。 12final BigDecimal TEN_CENTS = new BigDecimal(\".10\");BigDecimal funds = new BigDecimal(\"1.00\"); Item 61 基本数据类型优于包装类基本数据类型和其包装类两者之间有真正的区别！！自动装箱和自动拆箱模糊了基本类型和包装类型之间的区别，但不会消除它们的区别。 基本类型只有它们的值，而包装类型有方法，引用，对象。 基本类型只有值，而包装类型还能是 null。 基本类型比包装类型更节省时间和空间。 如果你不小心的话，这三种差异都会给你带来真正的麻烦。例如，将 == 操作符应用于包装类型，这几乎都会带来错误。因为包装类同值可不同对象。 混合使用基本类型和包装类型，包装类型就会自动拆箱。如果一个空对象引用自动拆箱，将导致 NullPointerException。 还有一个问题，在 for 循环中声明包装类，可能会产生很多对象，或者反复装箱和拆箱，从而导致性能下降。 那什么时候应该用包装类呢？ 作为集合中的元素、键和值：不能将基本类型放在集合中，因此必须使用包装类型。 泛型：不能将变量声明为 ThreadLocal&lt;int&gt; 类型，只能用 ThreadLocal&lt;Integer&gt;。 反射：在进行反射方法调用时，必须使用包装类型 Item 62 当使用其他类型更合适时应避免使用字符串略 Item 63 当心字符串连接引起的性能问题不要使用 + 连接大量字符串，除非性能无关紧要。因为用 + 连接两个字符串时，本质上会复制这两个字符串的内容。一般这种需求最好使用 StringBuilder 的 append 方法。 Item 64 通过接口引用对象如果存在合适的接口类型，那么应该使用接口类型声明参数、返回值、变量和字段。除非具体类要使用的方法是接口没有的。 12345// Good - uses interface as typeSet&lt;Son&gt; sonSet = new LinkedHashSet&lt;&gt;();// Bad - uses class as type!LinkedHashSet&lt;Son&gt; sonSet = new LinkedHashSet&lt;&gt;(); Item 65 接口优于反射用反射调用方法比普通调用要慢得多，可能会造成性能损失。而且不能在编译时做类型检查。 通常在代码分析工具或依赖注入框架里会看到反射。仅仅在需要使用编译时不存在的类时才会用到反射。除此之外最好都用接口来声明类。 Item 66 谨慎使用 Native 方法JNI 允许 Java 程序调用本地方法，这些方法是用 C 或 C++ 等本地编程语言编写的。由于本地语言比 Java 更依赖于平台，因此使用本地方法的程序的可移植性较差，也更难调试。 Item 67 谨慎优化 编写好的程序，而不是快速的程序 很多计算上的过失都被归昝于效率。不要去计较效率上的一些小小的得失，在 97% 的情况下，不成熟的优化才是一切问题的根源。​ —William A. Wulf [Wulf72] —Donald E. Knuth [Knuth74] 在优化方面，我们应该遵守两条规则： 规则 1：不要进行优化。 规则 2 （仅针对专家）：还是不要进行优化，也就是说，在你还没有绝对清晰的未优化方案之前，请不要进行优化。​ —M. A. Jackson [Jackson75] 但是在设计系统时一定要考虑性能，特别是在设计API、线路层协议和持久数据格式时。 Item 68 遵守被广泛认可的命名约定参考《阿里巴巴Java开发手册》 Identifier Type Example Package or module org.junit.jupiter.api, com.google.common.collect Class or Interface Stream, FutureTask, LinkedHashMap,HttpClient Method or Field remove, groupingBy, getCrc Constant Field、 MIN_VALUE, NEGATIVE_INFINITY Local Variable i, denom, houseNum Type Parameter T, E, K, V, X, R, U, V, T1, T2 特别提一下容易被忽略的参数类型：T 表示任意类型，E 表示集合的元素类型，K 和 V 表示 Map 的键和值类型，X 表示异常。函数的返回类型通常为 R。任意类型的序列可以是 T、U、V 或 T1、T2、T3。","link":"/post/7d5810ff.html"},{"title":"Effective Java（六）Lambdas and Streams","text":"Item 42 lambda 表达式优于匿名类Java 的 Lambda 表达式本质上就是一个匿名类。而什么是匿名类？就是在使用的时候现场 new 并实现的类。 只有一个方法的接口称为 函数式接口（functioning interface），Lambda 表达式本质上就是对这样子的接口做现场实现。可以参考我之前写的：Java简明笔记（八）Lambda和函数式编程 然而 lambda 也不是万能的，它只对函数是接口有用，如果一个接口有多个方法需要重写，那只能用匿名类。this 关键字在 lambda 中引用封闭实例，在匿名类中引用匿名类实例。如果你需要从其内部访问函数对象，则必须使用匿名类。 Lambdas 与匿名类都无法可靠地序列化和反序列化。因此，尽量少去 (如果有的话) 序列化一个 lambda (或一个匿名类实例)。如果有一个想要进行序列化的函数对象，比如一个 Comparator，那么使用一个私有静态嵌套类的实例（见 Item 24 ）。 作者建议：一行代码对于 lambda 说是理想的，三行代码是合理的最大值。 如果违反这一规定，可能会严重损害程序的可读性。 Item 43 方法引用优于 lambda 表达式lambda 比 匿名类 简洁，方法引用比 lambda 简洁。 考虑一个例子： 1map.merge(key, 1, (count, incr) -&gt; count + incr); 第三个参数是一个 lambda，就只是求两数之和，而求和这个方法在 Integer 类中是存在的。所以可以直接用方法引用： 1map.merge(key, 1, Integer::sum); Method Ref Type Example Lambda Equivalent Static Integer::parseInt str -&gt; Integer.parseInt(str) Bound Instant.now()::isAfter Instant then = Instant.now();t -&gt; then.isAfter(t) Unbound String::toLowerCase str -&gt; str.toLowerCase() Class Constructor TreeMap&lt;K, V&gt;::new () -&gt; new TreeMap&lt;K, V&gt; Array Constructor int[]::new len -&gt; new int[len] 原则：如果方法引用看起来更简短更清晰，请使用它们；否则，还是坚持 lambda。 Item 44 优先使用标准的函数式接口java 8 提供了很多标准函数式接口（java.util.Function 有 43 个接口），其中有 6 个基本接口。当我们编写函数对象时，应该优先考虑标准接口，而不是自己定义函数式接口。 接口 方法 示例 UnaryOperator T apply(T t) String::toLowerCase BinaryOperator T apply(T t1, T t2) BigInteger::add Predicate boolean test(T t) Collection::isEmpty Function&lt;T,R&gt; R apply(T t) Arrays::asList Supplier T get() Instant::now Consumer void accept(T t) System.out::println 这 6 个标准接口接收相应不同的参数，返回相应不同的对象。参考：Java简明笔记（八）Lambda和函数式编程 Item 45 使用 StreamJava 8 提供了 Stream API，其中有两个关键抽象：流(Stream)表示有限或无限的数据元素序列，流管道(stream pipeline)表示对这些元素的多级计算。常见的流的来源包括集合，数组，文件，正则表达式模式匹配器，伪随机数生成器和其他流。流中的数据可以是引用对象，或 int，long 和 double 这三种基本数据类型。 流包括转换和规约，转换把一个流转换成另一个流，规约把流转换成非流（集合，数组，数字）。流是惰性计算的，遇到规约操作才会开始计算。 流虽然简化了代码，但过度使用流也可能使程序难于阅读和维护。最好是迭代跟流结合着使用。如果不确定一个任务是通过流还是迭代更好地完成，那么尝试这两种方法，看看哪一种效果更好。 关于流的用法，参考：Java简明笔记（九）Stream API Item 46 优先考虑流中无副作用的函数流不仅仅是一个 API，它是函数式编程的范式（paradigm）。函数式编程应该尽可能使用纯函数（pure function）。纯函数的结果仅取决于其输入，不依赖于任何可变状态，也不更新任何状态。为此，传递给流操作的任何函数对象（中间操作和终结操作）都应该没有副作用。 一个建议是 forEach 操作应仅用于报告流计算的结果，而不是用于执行计算。考虑下面的代码，它只是伪装成流代码的迭代代码，并没有享受到流带来的好处。 1234567// Uses the streams API but not the paradigm--Don't do this!Map&lt;String, Long&gt; freq = new HashMap&lt;&gt;();try (Stream&lt;String&gt; words = new Scanner(file).tokens()) { words.forEach(word -&gt; { freq.merge(word.toLowerCase(), 1L, Long::sum); });} 好的做法： 123456// Proper use of streams to initialize a frequency tableMap&lt;String, Long&gt; freq;try (Stream&lt;String&gt; words = new Scanner(file).tokens()) { freq = words .collect(groupingBy(String::toLowerCase, counting()));} Item 47 优先使用 Collection 而不是 Stream 来作为方法的返回类型如果在返回一些序列元素的方法里返回了一个流，而你想迭代，（或相反），可以用适配器将流和 iterator 互相转换。但这样会降低效率。 123456789// Adapter from Stream&lt;E&gt; to Iterable&lt;E&gt;public static &lt;E&gt; Iterable&lt;E&gt; iterableOf(Stream&lt;E&gt; stream) { return stream::iterator;}// Adapter from Iterable&lt;E&gt; to Stream&lt;E&gt;public static &lt;E&gt; Stream&lt;E&gt; streamOf(Iterable&lt;E&gt; iterable) { return StreamSupport.stream(iterable.spliterator(), false);} 在实践中，最好优先考虑返回集合，而不是返回一个流。如果返回集合是不可行的，则返回流或可迭代对象。 Item 48 谨慎使用流并行让我们回顾一下java的并发历史： 1996 年 java 发布 1.0 时就内置了对线程的支持，包括同步和 wait / notify 机制，java 5 加入了 java.util.concurrent 类库，提供了并发集合和执行器框架。Java 7 引入了 fork-join 包，这是一个用于并行分解的高性能框架。 Java 8 引入了流，可以通过对 parallel 方法的单个调用来并行化。用 Java 编写并发程序变得越来越容易，但编写正确快速的并发程序还像以前一样困难。 通常，并行在 ArrayList、HashMap、HashSet 和 ConcurrentHashMap 实例、数组、int 类型和 long 类型的流上性能提升是最好的。因为它们都可以精确而廉价地分割成任意大小的子程序。 Java 8 的 parallel 本质上是 fork-join 的封装，适合用少量线程执行大量任务的情况。本质上，是通过分治归并实现并行的。但这并不适合所有情况。只有在充分测试确实没有安全隐患和性能问题时，才考虑使用 parallel 。","link":"/post/cc85a16e.html"},{"title":"Java虚拟机（一）JVM 基础和类的加载","text":"什么是Java虚拟机Java的理念是“一次编译，到处运行”。我们平时编写的 Java 代码，经过Java编译器编译后会生成一种 .class 文件，称为字节码文件。Java虚拟机（Java Virtual Machine，JVM）就是负责将字节码文件翻译成特定平台下的机器码然后运行的软件，其本身是由C/C++编写。 JVM 如何让 Java 程序跨平台？JVM 将字节码翻译成机器码然后运行，也就是说，只要在不同平台上安装对应的 JVM，就可以运行字节码文件，运行我们编写的 Java 程序。 而这个过程，我们编写的 Java 程序没有任何改变，仅仅是通过 JVM 这一 “中间层” ，就能在不同平台上运行，真正实现了 “一次编译，到处运行” 的目的。 需要注意的是，JVM 本身是用 C/C++ 开发的，是编译后的机器码，不能跨平台，不同平台下需要安装不同版本的 JVM。 JVM的“无关性”JVM 是 平台无关的，即不同的操作系统安装的是不同的JVM，但作用一样。JVM 还是 语言无关的。Java 源代码通过javac编译器编译成 .class 文件，之后 JVM 执行 .class 文件从而程序开始运行。也就是说，JVM 只认识 .class 文件，而不管何种语言生成了 .class 文件，只要 class 文件符合 JVM 的规范就能运行。因此，除了 Java 之外，像 Scala、Kotlin、Jython 等语言也能够运行在 JVM 上。 JVM的组成JVM由四个部分组成： 类加载器：负责在 JVM 启动时或者类运行时将需要的类加载到 JVM 中 内存区域：将内存划分为几个区域，模拟实际机器上的存储、记录和调度 执行引擎：执行字节码指令，相当于实际机器上的 CPU 本地方法调用：调用 C/C++ 实现的本地方法 类加载器类加载器的作用编译器生成的许多 .class 字节码文件，其实就是一个个的 Java 类。类加载器负责读取这些字节码，加载进JVM的方法区，并在内存中生成 java.lang.Class 类的一个实例对象作为外界访问这个类的接口。每个这样的实例用来表示一个 Java 类。通过此实例的 newInstance() 方法就可以创建出该类的一个对象。实际的情况可能更加复杂，比如 Java 字节代码可能是通过工具动态生成的，也可能是通过网络下载的。 在 JDK 6 中，java.lang.Class 类的实例对象是放在方法区的，但是在 JDK 7 和 8 中放在堆里面。 类加载器如何加载 class 文件？（即把一个类装入JVM）在Java中，类加载是在程序运行期间完成的 ，ClassLoader 把一个类装入JVM的步骤如下： 加载 获取二进制字节流：根据一个类的全限定名来获取其定义的二进制字节流（找到对应的 .class 文件） 转换数据结构：将二进制字节流所代表的静态存储结构转化为方法区的运行时数据结构。同时进行初步校验（cafebabe、常量池、文件长度、是否有父类等） 生成Class类对象：在内存中生成一个代表这个类的 java.lang.Class 对象，作为这个类的访问入口 在加载阶段，开发人员既可以使用系统提供的类加载器来完成加载，也可以自定义自己的类加载器来完成加载。加载阶段完成后，虚拟机外部的二进制字节流就按照虚拟机所需的格式存储在方法区之中，而且在 Java 内存中也创建一个 java.lang.Class 类的对象，这样便可以通过该对象访问方法区中的这些数据。 从哪里加载？一般二进制字节流都是从已经编译好的本地 .class 文件中读取，但其实还可以从 .jar / .war / JSP动态生成的class类 / 数据库 或 网络 中读取。 类加载 和 数组加载 过程有什么区别？当我们声明一个数组，例如： 1String[] str = new String[10]; 这个数组也是有类型的，称为数组类型。在 Java 层面，我们说这个数组的类型是 String[]， 但在 JVM 层面，类型是[Ljava.lang.String (二维数组是 [[Ljava.lang.String ) ，而 java.lang.String 只是数组里面元素的类型。 当程序在运行过程中遇到 new 关键字创建一个数组时，由 JVM 直接创建数组类，再由类加载器创建数组中的元素类。而普通类的加载由类加载器完成，既可以使用系统提供的引导类加载器，也可以使用用户自定义的类加载器。 链接在这个阶段，JVM需要完成三件事： 校验：检查载入的Class文件正确性，包含文件格式验证、元数据验证、字节码验证和符号引用验证。 准备：给类的 静态变量 分配内存并设置零值（此时还未赋值）。但被 final 修饰的除外。 解析：将符号引用（Symbolic References）转化成直接引用。（符号引用就是一组符号来描述目标，可以是任何字面量。直接引用就是直接指向目标的指针、相对偏移量或一个间接定位到目标的句柄。） 准备阶段静态变量我们在 java 中编写： 123// 在准备阶段， str1 是 null， str2 是 \"zxc\"public static str1 = \"jerry\";public static final str2 = \"zxc\"; 在准备阶段， str1 会先被赋初值 null，此时还没有被赋予 jerry 这个值。但假如是 final 修饰，在编译阶段就会将初始值存入 constantValue 属性中，在准备阶段就将 constantValue 的值赋给该字段，所以此时str2已经是 zxc 了 ，而不是 null 。 初始化对类的静态变量和静态代码块进行赋值。例如我们在程序中编写： 12// 在初始化阶段，str1 被赋值为 jerrypublic static str1 = \"jerry\"; 在链接阶段， str1 还是 null， 在初始化阶段，str1 就被赋值为 jerry 了。 初始化的步骤 假如这个类还没有被加载和链接，则程序先加载并链接该类 假如该类的直接父类还没有被初始化，则先初始化其直接父类 假如类中有静态初始化语句，则系统依次执行这些初始化语句 什么时候初始化？(初始化的条件) 在运行过程中遇到 new、getstatic、putstatic、invokestatic 这四个字节码指令时，如果类尚未初始化，那就要进行初始化。getstatic 和 putstatic 用于读取、设置一个类的静态成员变量(不包括final修饰的静态变量)，invokestatic用于调用一个类的静态成员函数。 使用java.lang.reflect进行反射调用的时候，如果类没有初始化，那就需要初始化； 当初始化一个类的时候，若其父类尚未初始化，那就先要让其父类初始化，然后再初始化本类； 当虚拟机启动时，虚拟机会首先初始化带有main方法的类，即主类； 直接满足初始化的这4个条件的情况叫做主动引用；间接满足上述初始化过程的情况叫做被动引用。下文有举例。 双亲（父类）委派模型在 JDK 8 和之前的版本中，类加载器可分为三层： BootStrap ClassLoader：启动类加载器，由C++实现，属于JVM一部分，负责加载 &lt;JAVA_HOME&gt;/lib 目录下的类，如 rt.jar、tools.jar Extensioon ClassLoader：扩展类加载器，由Java实现，负责加载 &lt;JAVA_HOME&gt;/lib/ext 目录下的类，如 javax.XXX Application ClassLoader：应用类加载器，由Java实现，负责加载用户类路径（Classpath）下的所有类库。 虚拟机装载类时，使用了双亲委派机制： 全盘负责：当一个 ClassLoader 加载一个类时，除非显式地使用另一个ClassLoader，否则该类所依赖及引用的类也由当前 ClassLoader 负责加载。 双亲委派：加载一个类时，先委托父类装载器寻找目标类，找不到时才从自己的类路径找。 举个栗子，像 java.lang.Object 这些存放在 rt.jar 中的类，无论使用哪个类加载器加载，最终都会委派给最顶端的 RootClassLoader 加载，从而使得不同加载器加载的 Object 类都是同一个。之所以这样设计，是从安全角度考虑的，试想如果有人恶意编写了一个 java.lang.String 类并装载到 JVM 中，我们使用 String 的时候就可能执行了恶意的 String 而不是 Java 提供的 Stirng。有了全盘负责委托机制，java.lang.String 永远是由 RootClassLoader 来加载，避免了上述安全隐患。 双亲委派过程 首先检查类是否被加载； 若未加载，则调用父类加载器的 loadClass 方法； 若该方法抛出 ClassNotFoundException 异常，则表示父类加载器无法加载，则当前类加载器调用 findClass 加载类； 若父类加载器可以加载，则直接返回Class对象； 类加载器如何判断两个 Java 类是相同的 ？Java 虚拟机不仅要看类的全名是否相同，还要看加载此类的类加载器是否一样。只有两者都相同的情况，才认为两个类是相同的。即便是同样的字节代码，被不同的类加载器加载之后所得到的类，也是不同的。 什么时候需要自定义类加载器？ 需要隔离加载类的时候。在某些框架中，应用和中间件依赖的jar包要隔离开来，用不同的类加载器确保不会互相影响。 需要修改类的加载方式时 需要扩展加载源时，例如从网络、数据库等地方加载 防止源码泄露，用自己的类加载器还原加密的字节码 主动引用与被动引用直接满足初始化4个条件的情况叫做主动引用；间接满足上述初始化过程的情况叫做被动引用。 被动引用的例子示例一1234567891011121314151617public class Father{ public static String name = \"jerry\"; static{ System.out.println(\"父类被初始化！\"); }}public class Son extends Father{ static{ System.out.println(\"子类被初始化！\"); }}public static void main(String[] args){ System.out.println(Son.name);} 输出结果： 12父类被初始化！jerry 在这个例子中，似乎满足初始化条件的第一条：读取、设置一个类的静态成员变量。那为什么调用的是子类的name，子类却没有被初始化呢？ 原因是：这个静态成员变量属于父类，子类只是间接调用，因此属于被动引用，JVM只会初始化父类。 示例二修改 main 方法，new 一个父类数组 123public static void main(String[] args){ Father[] fArr = new Father[10];} 执行结果并没有输出父类被初始化！。在这个例子中，也似乎满足第一条：遇到 new 指令新建对象，那为什么父类没有被初始化呢？原因是：现在通过 new 要创建的是一个数组对象，而非父类对象，因此也属于间接引用，不会初始化父类。 示例三修改 Father 类，用 final 修饰 name 1234567891011121314public class Father{ public static final String name = \"jerry\"; static{ System.out.println(\"父类被初始化！\"); }}public class Go{ public static void main(String[] args){ System.out.println(Father.name); }} 输出： 1jerry 这个例子中，只输出了 jerry，却并没有初始化父类。原因是：Father.name 被 final 修饰。被 final 修饰的已经是一个常量，在 Java 代码编译的过程中就会被放入它被引用的class文件的常量池中(这里是Go类的常量池)。所以程序在运行期间如果需要调用这个常量，直接去当前类的常量池中取，而不需要初始化这个类。 参考： 深入理解JVM(十)——类加载器 Java 面试知识点解析(三)——JVM篇","link":"/post/3ebede8.html"},{"title":"Effective Java（四）泛型","text":"Java 5 加入了泛型。在有泛型之前，你必须转换从集合中读取的每个对象。如果有人不小心插入了错误类型的对象，则在运行时可能会失败。使用泛型，你告诉编译器在集合中允许存放哪些类型的对象。编译器会自动插入强制转换，并在编译时告诉你是否尝试插入错误类型的对象。 Item 26 使用泛型，不要使用原始类型如果使用原始类型的集合，在一个字符串集合里插入一个数字是合法的，可能到运行时才出现问题。 123456List names = ...;names.add(\"jerry\");names.add(1.0);for (Iterator i = names.iterator(); i.hasNext(); ) String s = (String) i.next(); // Throws ClassCastException 但是如果使用泛型，当你向字符串集合插入数字或其他类型时，编译器会报错。使得问题在编译器被发现。 123List&lt;String&gt; names = ...;names.add(\"jerry\");names.add(1.0); // 编译出错 Item 27 消除 unchecked 警告使用泛型编程时，会看到许多编译器警告：未经检查的强制转换警告，未经检查的方法调用警告，未经检查的参数化可变长度类型警告以及未经检查的转换警告。 例如，如果你写： 1Set&lt;Lark&gt; exaltation = new HashSet(); 编译器会发出 unchecked conversion 警告，修改如下即可消除（JDK 1.7）： 1Set&lt;Lark&gt; exaltation = new HashSet&lt;&gt;(); 尽可能的消灭这些警告，以保证安全。如果你无法消除，但可以确定代码是安全的，可以用 @SuppressWarnings(&quot;unchecked&quot;) 来抑制警告。使用时，请添加注释，说明为什么是安全的。 Item 28 List 优于 数组你不能把一个 String 放到一个 Long 类型的容器中，会编译出错。但是同样的情况在数组里却可以编译通过，要等到运行时才会抛出ArrayStoreException。 数组和泛型不能混用。new List&lt;E&gt;[]，new List&lt;String&gt;[]，new E[]，这些将在编译时导致泛型数组创建错误。因为泛型数组不是类型安全的。泛型会在编译时被擦除。而数组是具体化的。 Item 29 优先编写泛型元素如果你要写一个栈 Stack 类，如下： 123456789101112131415161718192021222324// Object-based collection - a prime candidate for genericspublic class Stack { private Object[] elements; private int size = 0; private static final int DEFAULT_INITIAL_CAPACITY = 16; public Stack() { elements = new Object[DEFAULT_INITIAL_CAPACITY]; } public void push(Object e) { ensureCapacity(); elements[size++] = e; } public Object pop() { if (size == 0) throw new EmptyStackException(); Object result = elements[--size]; elements[size] = null; // Eliminate obsolete reference return result; }} 请考虑把它变成泛型的 123456789101112131415161718192021222324// Initial attempt to generify Stack - won't compile!public class Stack&lt;E&gt; { private E[] elements; private int size = 0; private static final int DEFAULT_INITIAL_CAPACITY = 16; public Stack() { elements = new E[DEFAULT_INITIAL_CAPACITY]; } public void push(E e) { ensureCapacity(); elements[size++] = e; } public E pop() { if (size == 0) throw new EmptyStackException(); E result = (E) elements[--size]; elements[size] = null; // Eliminate obsolete reference return result; } ... // no changes in isEmpty or ensureCapacity} 这样一来，客户端可以创建一个 Stack&lt;Object&gt;，Stack&lt;int[]&gt;，Stack&lt;List&lt;String&gt;&gt; 或者其他任何对象的 Stack 引用类型。 Item 30 优先使用泛型方法使用泛型方法的好处是类型安全，把运行时可能的错误提前到编译期。 before： 123456// Uses raw types - unacceptable! [Item 26]public static Set union(Set s1, Set s2) { Set result = new HashSet(s1); result.addAll(s2); return result;} after： 1234567// Generic methodpublic static &lt;E&gt; Set&lt;E&gt; union(Set&lt;E&gt; s1, Set&lt;E&gt; s2) { Set&lt;E&gt; result = new HashSet&lt;&gt;(s1); result.addAll(s2); return result;}","link":"/post/53a4cf82.html"},{"title":"Java虚拟机（五）JVM参数和调优","text":"本地线程分配缓冲（TLAB）Java虚拟机遇到 new 指令时，需要在堆内存上为新对象分配内存空间。如果堆是规整的，一边是分配过的内存，一边是空闲内存，那只要在中间用一个指针隔开，为新对象分配内存时，指针往后移动相应的空间距离即可。 然而，在多线程环境下，线程A和线程B同时为新对象分配内存，线程A还没来得及改指针位置，线程B也使用了这个位置来分配内存，就会出现问题。有两种方法解决这个问题，第一是采用同步，事实上虚拟机采用的 CAS 失败重试的方式来保证更新内存的原子性。第二种是本地线程分配缓冲（Thread Local Allocation Buffer）。 本地线程分配缓冲会在 Java 堆内存里预先分配一小块内存专门给某个线程用来分配空间，所以不同的线程分配内存是在不同的位置。这样就不会导致冲突。只有当 TLAB 用完并分配新的缓冲区时，才需要同步锁定。 在 Java 中，用以下参数来设定是否要开启TLAB 12345678// 启用TLAB（默认）-XX:+UseTLAB// 禁用TLAB-XX:-UseTLAB// 设置TLAB空间所占用Eden空间的百分比大小(默认1%)-XX:TLABWasteTargetPercent 参考：https://blog.csdn.net/zyc88888/article/details/80361635 持续更新","link":"/post/a3255dff.html"},{"title":"Effective Java（五）枚举和注解","text":"Item 34 使用枚举类型替代整型常量如果你需要一组常量，比如球的红绿蓝三种颜色，四则运算的加减乘除操作，用枚举类会比用 final static int 或 String 好。枚举更具可读性，更安全，更强大。 12345678910111213// Enum type with constant-specific method implementationspublic enum Operation { PLUS {public double apply(double x, double y){return x + y;}}, MINUS {public double apply(double x, double y){return x - y;}}, TIMES {public double apply(double x, double y){return x * y;}}, DIVIDE{public double apply(double x, double y){return x / y;}}; public abstract double apply(double x, double y);}public static void main(String[] args) { double d = Operation.PLUS.apply(1.2,3.4);} Item 35 使用实例属性替代序数永远不要从枚举的序号中得出与它相关的值; 请将其保存在实例属性中。 12345678910111213141516171819// Abuse of ordinal to derive an associated value - DON'T DO THISpublic enum Ensemble { SOLO, DUET, TRIO, QUARTET, QUINTET, SEXTET, SEPTET, OCTET, NONET, DECTET; public int numberOfMusicians() { return ordinal() + 1; }}// goodpublic enum Ensemble { SOLO(1), DUET(2), TRIO(3), QUARTET(4), QUINTET(5), SEXTET(6), SEPTET(7), OCTET(8), DOUBLE_QUARTET(8), NONET(9), DECTET(10), TRIPLE_QUARTET(12); private final int numberOfMusicians; Ensemble(int size) { this.numberOfMusicians = size; } public int numberOfMusicians() { return numberOfMusicians; }} 枚举类的 ordinal 方法被设计用于基于枚举的通用数据结构，如 EnumSet 和 EnumMap。除此之外避免使用 ordinal 方法。 Item 36 使用 EnumSet 替代位属性java.util.EnumSet 类可以有效地表示从单个枚举类型中提取的值集合。 1234567891011121314// EnumSet - a modern replacement for bit fieldspublic class Text { public enum Style { BOLD, // 1 &lt;&lt; 0 1 ITALIC, // 1 &lt;&lt; 1 2 UNDERLINE, // 1 &lt;&lt; 2 4 STRIKETHROUGH // 1 &lt;&lt; 3 8 } // Any Set could be passed in, but EnumSet is clearly best public void applyStyles(Set&lt;Style&gt; styles) { ... }}text.applyStyles(EnumSet.of(Style.BOLD, Style.ITALIC)); Item 37 使用 EnumMap 替代序数索引java.util.EnumMap 类可以用作从枚举到值的映射。 12345678910111213141516171819class Plant { enum LifeCycle { ANNUAL, PERENNIAL, BIENNIAL } final String name; final LifeCycle lifeCycle;}// Using an EnumMap to associate data with an enumMap&lt;Plant.LifeCycle, Set&lt;Plant&gt;&gt; plantsByLifeCycle = new EnumMap&lt;&gt;(Plant.LifeCycle.class);for (Plant.LifeCycle lc : Plant.LifeCycle.values()){ plantsByLifeCycle.put(lc, new HashSet&lt;&gt;());}for (Plant p : garden){ plantsByLifeCycle.get(p.lifeCycle).add(p);}System.out.println(plantsByLifeCycle); Item 38 使用接口模拟可扩展的枚举枚举类型的扩展性不好，因为它可能要修改类定义。例如加减乘除操作的枚举类 Operation ，有时需要让 API 的用户提供他们自己的操作，从而有效地扩展 API 提供的操作集。这个时候，让你的枚举类 BasicOperation 实现 Operation 接口。这样用户可以自己去实现扩展的运算。 12345678910111213141516171819202122232425262728// Emulated extensible enum using an interfacepublic interface Operation { double apply(double x, double y);}public enum BasicOperation implements Operation { PLUS(\"+\") { public double apply(double x, double y) { return x + y; } }, MINUS(\"-\") { public double apply(double x, double y) { return x - y; } }, TIMES(\"*\") { public double apply(double x, double y) { return x * y; } }, DIVIDE(\"/\") { public double apply(double x, double y) { return x / y; } }; private final String symbol; BasicOperation(String symbol) { this.symbol = symbol; } @Override public String toString() { return symbol; }} 用户的实现： 1234567891011121314151617181920212223// Emulated extension enumpublic enum ExtendedOperation implements Operation { EXP(\"^\") { public double apply(double x, double y) { return Math.pow(x, y); } }, REMAINDER(\"%\") { public double apply(double x, double y) { return x % y; } }; private final String symbol; ExtendedOperation(String symbol) { this.symbol = symbol; } @Override public String toString() { return symbol; }} Item 39 注解优于命名模式命名模式指的是以某些格式规范命名的方法，如 JUnit4 之前，测试框架要求其用户通过以 test[Beck04] 开始名称来指定测试方法。这很容易犯错。JUnit4 之后提供了 @Test 注解，更不容易犯错。 有时候，我们一个注解有多个值，通常是： 123@ExceptionTest({ IndexOutOfBoundsException.class, NullPointerException.class })public static void doublyBad() { ... } 在 Java 8 之后，如果注解有元注解@Repeatable，那么我们可以多次使用同一个注解。 1234// Code containing a repeated annotation@ExceptionTest(IndexOutOfBoundsException.class)@ExceptionTest(NullPointerException.class)public static void doublyBad() { ... } 除了特定的开发者（toolsmith）之外，大多数程序员都不需要定义注解类型。 但所有程序员都应该使用 Java 提供的预定义注解类型。 Item 40 始终使用 Override 注解@Override 注解可以减少很多低级错误。如重写一个方法，不小心把参数类型写错了，如果有 @Override ，编译器会提示你。但如果不写注解，也可以编译通过，然而这是一个重载而不是重写。 Item 41 使用标记接口定义类型标记接口（marker interface），是没有任何方法和属性的接口，只起到标记作用，表示一个类实现了具有某些属性的接口。 例如 Serializable 接口。实现这个接口，表示实现这个接口的类的实例可以被序列化（即写入 ObjectOutputStream）。 虽然我们也可以用标记注解，但标记接口类型的存在允许在编译时捕获错误，如果使用标记注解，则直到运行时才能捕获错误。编译时错误检测是标记接口的意图。然好笑的是，JDK 里面 ObjectOutputStream.writeObject 却没有利用 Serializable ，它的参数被声明为 Object 类型，所以尝试序列化一个不可序列化的对象直到运行时才会失败。 所以什么时候应该使用标记注解，什么时候应该使用标记接口？如果标记是应用于 除类或接口以外 的任何元素（如方法、域），则必须使用注解。如果标记是大量使用注解的框架的一部分，则标记注解是明确的选择。 如果只需要标记类和接口，那么问自己问题：「我是不是想编写一些接收被标记的对象作为参数的方法？」如果是这样，则应该优先使用标记接口而不是注解。因为这样你可以将接口作为参数，而不是具体的实现类。这将带来编译时类型检查的好处。 总之，标记接口和标记注释都有其用处。 如果你想定义一个没有任何关联的新方法的类型，一个标记接口是一种可行的方法。 如果要标记除类和接口以外的程序元素，或者将标记符合到已经大量使用注解类型的框架中，那么标记注解是正确的选择。 参考 41. 使用标记接口定义类型","link":"/post/acf36022.html"},{"title":"Java虚拟机（二）内存模型和对象创建","text":"运行时数据区域Java 程序执行的过程中，虚拟机所管理的内存划分为如下几个不同的数据区域： 程序计数器（线程隔离）类似于操作系统里的 PC 计数器，程序计数器可以看做是当前线程所执行的字节码的行号指示器。 如果线程正在执行的是一个 Java 方法，这个计数器 记录的是正在执行的虚拟机字节码指令的地址；如果正在执行的是 Native 方法，这个计数器值则为空（Undefined）。 程序计数器的作用 字节码解释器通过改变程序计数器来依次读取指令，从而实现代码的流程控制，如：顺序执行、选择、循环、异常处理。 在多线程中，程序计数器用于记录当前线程执行的位置，当线程被切换回来的时候能够知道该线程上次运行到哪儿了。 程序计数器的特点 此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 情况的区域； 是一块较小的存储空间； 线程私有； 生命周期随着线程的创建而创建，随着线程的结束而死亡。 为什么每个线程都要有一个程序计数器，不能多个线程共享一个吗？JVM的多线程是通过线程轮流切换、分配处理器时间片的方式实现。一个时刻处理器只会执行一条指定。为了线程切换后能恢复到上次的位置，每条线程都需要有一个单独的程序计数器。 虚拟机栈（栈内存）（线程隔离）虚拟机栈描述的是 Java 方法执行的内存模型。 虚拟机栈是由一个个栈帧组成。每个 Java 方法即将执行的时候，JVM都会创建一个栈帧用于存储该方法的 局部变量表、操作数、动态链接、方法出口等信息。 每个方法调用都对应了一个栈帧在虚拟机栈中入栈到出栈的过程。一个方法被调用了，即创建了一个“栈帧”，一个方法返回了，“栈帧”出栈，释放内存。 虚拟机栈的组成1. 局部变量表(Local Variable Table)存储方法参数、局部变量（基本数据类型 + 引用对象指针）、方法返回地址。局部变量表所需的内存空间在编译期就完全确定。 2. 操作数栈(Operand Stack)进行运算的地方 3. 动态链接.Class文件中有很多符号引用，一部分在类加载的时候转化为直接引用（称为静态链接），另一部分在每一次运行期间转化为直接引用，这部分被称为动态链接。 什么是符号引用和直接引用？符号引用是无歧义的可以定位到这个目标的字面量。在编译时，java类并不知道所引用的类的实际地址，因此只能使用符号引用来代替。而直接引用可以理解为直接指向目标的指针。 在类加载的链接（的解析）阶段，符号引用被转换为直接引用。 4. 方法出口当一个方法执行的时候，只有两种可以退出方法的方法。第一种是JVM碰到任意一个方法返回的字节码指令，被称为正常完成出口。另一种是在执行方法中抛出异常并且未对异常进行处理，被称为异常完成出口。方法退出的时候相当于把栈帧出栈。 虚拟机栈的特点 局部变量表随着栈帧的创建而创建，其大小在编译时期就已确定，创建时直接分配该大小的空间。方法运行过程中，局部变量表大小并不会改变； 每个线程都有各自的Java虚拟机栈。生命周期随着线程的创建而创建，随着线程的结束而死亡。 StackOverFlowError 和 OutOfMemoryError虚拟机栈会抛出两种异常： StackOverFlowError： 表示当前线程申请的栈超过了事先定好的栈的最大深度，但内存空间可能还有很多。 OutOfMemoryError： 当线程申请栈时发现栈已经满了，而且内存也全都用光了。 本地方法栈（线程隔离）和Java虚拟机栈的作用类似，区别是：该区域服务的是 native 方法，而不是 Java 方法。 什么是本地方法？（Native方法）Native 方法指的是 java 代码调用非 java 代码的接口。在 Java 中，被 native 关键字修饰的方法称为 Native 方法，Native 方法只在 Java 中声明，而具体实现是由其他编程语言实现的（比如C/C++）。 JVM 如何让 Native 方法跑起来？我们知道，当一个类第一次被使用到时，这个类的字节码会被加载到内存，并且只会加载一次。在这个被加载的字节码的入口维持着一个该类所有方法描述符的list，这些方法描述符包含这样一些信息：方法代码存于何处，它有哪些参数，方法的描述符（public之类）等等。 如果一个方法描述符内有 native ，这个描述符块将有一个指向该方法的实现的指针。这些实现在一些DLL文件内，但是它们会被操作系统加载到 java 程序的地址空间。当一个带有本地方法的类被加载时，其相关的DLL并未被加载，因此指向方法实现的指针并不会被设置。当本地方法被调用之前，这些DLL才会被加载，这是通过调用 java.system.loadLibrary() 实现的。 堆内存（线程共享）堆是用来存放对象的内存空间，几乎所有的对象都存储在堆中。 从回收内存的角度看，堆内存还可以进一步细分为：新生代、老年代。新生代又可被分为：Eden、From Survior、To Survior。不同的区域存放具有不同生命周期的对象。这样可以根据不同的区域使用不同的垃圾回收算法，从而更具有针对性，更高效。《深入理解Java虚拟机》第三版提到，堆内存中的无论哪个区域，存放的都只能是对象的实例，将堆内存细分的目的只是为了更好地回收或分配内存。 堆的特点 堆内存是垃圾收集器管理的主要区域； 堆内存是所有线程共享的； 在虚拟机启动时创建； 堆的大小既可以固定也可以扩展，但主流的虚拟机堆的大小是可扩展的，因此当线程请求分配内存，但堆已满，且内存已满无法再扩展时，就抛出 OutOfMemoryError。 方法区（线程共享）方法区用于 存储虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码。虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却又一个别名叫做 Non-Heap（非堆），目的是与 Java 堆区分开来。 方法区中的信息一般需要长期存在，而且它又是堆的逻辑分区，因此以前人们用堆的划分方法，喜欢把方法区称为永久代，但是永久代和方法区其实并不等价。只不过说为了方便像管理堆内存一样管理方法区，HotSpot虚拟机采用了永久代的方式来实现方法区。 到了 JDK 8 ，永久代的概念被放弃了。以前放在永久代的字符串常量池、静态变量等，被搬运到了在本地内存中实现的元空间（meta space）里面。 总的来说，方法区是Java虚拟机规范里的一个概念定义，而永久代和元空间是两种具体实现方式。 方法区的特点 所有线程共享； 内存回收效率低：方法区中的信息一般需要长期存在，回收一遍内存之后可能只有少量信息无效。对方法区的内存回收的主要目标是： 对常量池的回收 和 对类型的卸载。 运行时常量池运行时常量池是方法区的一部分。方法区就是借助运行时常量池来存储常量的。 一般我们声明常量的方式是： 12345public class A{ public static final double PI = 3.1415926; //...} 这个类被编译后便生成class文件，这个类的所有信息都存储在这个class文件中。当这个类被Java虚拟机加载后，class文件中的常量就存放在方法区的运行时常量池中。 而且在运行期间，可以向常量池中添加新的常量。如：String类的 intern() 方法就能在运行期间向常量池中添加字符串常量。当运行时常量池中的某些常量没有被对象引用，同时也没有被变量引用，那么就需要垃圾收集器回收。 直接内存直接内存是除Java虚拟机之外的内存，但也有可能被Java使用。 在NIO中引入了一种基于通道和缓冲的IO方式。它可以通过调用本地方法直接分配Java虚拟机之外的内存，然后通过一个存储在Java堆中的DirectByteBuffer对象直接操作该内存，而无需先将外面内存中的数据复制到堆中再操作，从而提升了数据操作的效率。 直接内存的大小不受Java虚拟机控制，但既然是内存，当内存不足时就会抛出 OutOfMemoryError 对象的创建过程当虚拟机遇到 new 指令时，就会创建一个对象。创建的过程大致为：检查常量池 - 检查类是否被加载 - 准备内存大小 - 划分空间 - 初始化 1.检查静态常量池静态常量池(constant_pool)指的是在编译期被确定，并被保存在已编译的 .class文件 中的一些数据。它包括了类、方法、接口等中的常量、字符串常量、符号引用。 虚拟机遇到 new 指令时，首先会检查常量池是否有表示该类的符号引用，若没有说明还没被classloader加载，则先进行类的加载、链接、初始化。 2.检查是否已经被JVM加载找到符号引用后，虚拟机检查该符号引用所代表的类是否已经被类加载器加载。若还没有，先将该类的 .class 文件加载进方法区。 3.准备所需的内存大小JVM在一个类被加载进方法区的时候，就知道该类生产的每一个对象所需要的内存大小。JVM将准备这个对象所需的内存。 为什么类加载完毕后就可以确定该类对象的大小？不同的虚拟机，对象在内存中的布局略有不同。以 HotSpot虚拟机为例，对象在内存中可以分为三部分：对象头（Obejct Header）、实例数据（Instance Data）、对齐填充（Padding）。 对象头官方叫做 Mark Word，用于存储对象自身的运行时数据（hashcode、GC age等）和指向方法区对象类型数据的指针（如果是数组还有数组大小）。为了节省空间，这个对象头（32bit或64bit）的存储空间是复用的。它有一个标志位，01时表示未锁定，存储hashcode、GC age等，00时表示轻量级锁定，10时表示重量级锁定，11是GC标记，01时是可偏向。不同标志位下这 32bit 存储的东西也都不一样。 实例数据就是我们程序代码中定义的各种类型字段。一般从父类继承的变量会出现在子类之前，相同宽度（如long和double）的会出现在一起。 对齐填充没有实际意义。因为 HotSpot 虚拟机的自动内存管理系统规定对象的起始地址必须是 8 字节的整倍数，所以当没有对齐时，就用对齐填充来补上。 从对象的内存布局中可以看到，一个对象所需的所有数据，都是完全可以被统计的，因而类加载完毕后，虚拟机也就知道了该类对象所需的内存空间了。 4. 划分空间知道应该为这个类划分多少内存空间后，虚拟机于是从堆中划分一块对应大小的内存空间给新的对象。划分的方式有 指针碰撞 和 空闲列表 两种。 如果堆是规整的，一边是分配过的内存，一边是空闲内存，那只要在中间用一个指针隔开，为新对象分配内存时，指针往后移动相应的空间距离即可。这种划分方式叫指针碰撞。 如果堆不是规整的，虚拟机就必须维护一个列表，记录堆中哪些空间是可用的。这种划分方式叫空闲列表。 虚拟机采用哪种划分方式取决于堆是否规整，堆是否规整又取决于垃圾回收算器是否带有压缩整理功能。 5. 初始化划分完内存空间之后，虚拟机会为对象中的成员变量赋上初始零值（例如 int 初始化为 0）。之后，为对象设置其对象头中的信息（对象是哪个类的实例、对象的hashcode、对象的GC分代年龄等）。 至此，站在虚拟机的角度，new指令已经执行完毕，一个新的对象已经产生。但是站在程序员的角度，对象创建才刚刚开始。因为方法还没有执行，所有字段都还为零。紧接着new指令之后，通常会执行方法，即调用对象的构造函数，根据程序员的需要，进行应用程序角度的初始化。 引用类型如何访问对象Java程序通常都是在方法中声明一个引用类型（引用存放在Java方法栈上），然后通过引用来操作堆内存里的具体对象。引用可以有两种访问对象的方式。 句柄访问方式堆中需要有一块叫做“句柄池”的内存空间，用于存放两个指针，一个指针指向堆中对象实例数据，另一个指针指向方法区中对象类型数据。 引用先找到句柄，再根据句柄中对象指针所指的地址再去访问对象。 直接指针访问方式引用直接存放对象的地址。这种方式省去了句柄“转发”。但堆中必须有一种方式，让我们能够去访问方法区的中对象类型数据。 HotSpot虚拟机采用什么方式HotSpot采用直接指针方式访问对象。因为它只需一次寻址操作，从而性能比句柄访问方式快一倍。但它需要额外的策略存储对象在方法区中类信息的地址。","link":"/post/7a1af8ce.html"},{"title":"Java中的 String","text":"String 的本质在 Java8 中，分析 java.lang.String 类的源码，可以发现 String 内部维护的是一个 char 数组。同时可以发现，String类被 final 修饰，即不可变的。 1234567public final class String implements java.io.Serializable, Comparable&lt;String&gt;, CharSequence { /** The value is used for character storage. */ private final char value[]; //...} 在 Java9 中，将 char 数组优化成了 byte 数组。 1private final byte value[]; 为什么要将 char[] 改成 byte[] ？char 占用16位，即两字节。每个 byte 占用8位，即1字节。如果我们要存储字符A，则为0x00 0x41，用 char 的话，前面的一个字节空间浪费了。 为什么要设计成不可变类 ？ 优缺点？ 优点：只读，所以 多线程并发访问也不会有任何问题。 缺点：每个不同的状态都要一个对象来代表，可能会造成性能上的问题。（所以 Java 标准类库还提供了一个可变版本，即 StringBuffer） 具体到 String 类中，原因如下： 字符串常量池的需要维护一个字符串池，可以节省堆内存空间。不同的字符串变量都指向池中的同一个字符串。即字符串常量池数据共享。 线程安全考虑 类加载器要用到字符串，不可变性提供了安全性，以便正确的类被加载。 支持hash映射和缓存因为字符串是不可变的，所以在它创建的时候hashcode就被缓存了，不需要重新计算。这就使得字符串很适合作为Map中的键，字符串的处理速度要快过其它的键对象。这就是HashMap中的键往往都使用字符串。 String str = new String(“abc”)创建了几个对象？答案是：最多创建2个，最少创建1个。 在Java虚拟机（JVM）中存在着一个字符串池，其中保存着很多String对象，并且可以被共享使用，因此它提高了效率。由于String类是final的，它的值一经创建就不可改变，因此我们不用担心String对象共享而带来程序的混乱。 当我们执行： 1String str = \"abc\"; String类会先去字符串池寻找abc这个对象，如果abc存在，则把它的引用给str，如果&quot;abc&quot;不存在，则先创建abc对象。 看String类源码的构造方法中，其中一个是： 1234567891011121314151617// 源码第 151 行/* * 初始化一个新创建的 String 对象，使其表示一个与参数相同的字符序列； * 换句话说，新创建的字符串是该参数字符串的副本。 * Initializes a newly created {@code String} object so that it represents * the same sequence of characters as the argument; in other words, the * newly created string is a copy of the argument string. Unless an * explicit copy of {@code original} is needed, use of this constructor is * unnecessary since Strings are immutable. * * @param original * A {@code String} */public String(String original) { this.value = original.value; this.hash = original.hash;} 可以发现，被调用的构造器方法接受的参数也是一个String对象。也就是说，当我们执行： 1String str=new String(\"abc\"); String类会先去字符串池寻找abc，发现abc不存在，于是创建abc这个对象，然后把abc作为构造方法的参数，传给String构造器new String(&quot;abc&quot;)相当于新创建了参数字符串的副本，于是又创建了一个对象。 只是，第一个abc对象存在于字符串池当中，第二个跟其他对象一样存在于内存的堆当中。 String 的 intern 方法String.intern()是一个 native 方法。如果字符串常量池里面已经包含一个等于此 String 对象的字符串，则返回池中的这个字符串String对象，否则，先将该String对象包含的字符串添加进常量池，然后返回此String对象的引用。 在 jdk 1.6 的实现里，intern会把首次出现的该实例内容复制进永久代里面的常量池，而在 jdk 1.7 以上的实现中，intern 方法只是在常量池记录首次出现该实例的引用，并不会把它复制一份。 12345678910111213// base on jdk 1.8public static void main(String[] args) { String str1 = new StringBuilder(\"oj\").append(\"bk\").toString(); // \"ojbk\"是首次出现，记录的是 str1 的引用，因此返回 true System.out.println(str1.intern() == str1); String str2 = new StringBuilder(\"ja\").append(\"va\").toString(); // \"java\"肯定在其他地方出现过了，记录的是别的引用，不是str2，因此返回 false System.out.println(str2.intern() == str2);} String 的 “+” 号是怎么连接字符串的 ？当我们在程序中输入： 12345public static void main(String[] args) { String hello = \"hello\"; String world = \"world\"; String hw = hello + world;} 编译之后，如果我们把 .class 文件反编译回 .java 文件，可以看到代码变成了： 12345public static void main(String[] args) { String hello = \"hello\"; String world = \"world\"; String hw = (new StringBuilder()).append(hello).append(world).toString();} 编译器自动引入了一个 java.lang.StringBuilder 类。虽然我们在源代码中并没有使用 StringBuilder 类，但是编译器却自作主张地使用了它，因为它更高效。这就是所谓的编译器优化。 如果字符串操作比较简单，那就可以信赖编译器，它会为你合理地构造最终的字符串结果。但如果你还使用循环，多次地改变字符串的内容，那就更适合StringBuilder对象。 参考：Java学习笔记（3）—— String类详解 String 的比较== 和 equals 两种比较12345String s1 = \"AAA\";String s2 = new String(\"AAA\");System.out.println(s1 == s2); // 输出 falseSystem.out.println(s1.equals(s2)); // 输出 true ==比较的是引用的内存地址，而equals方法比较的是字符串的内容。 探究 String 类 equals 方法源码12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * Compares this string to the specified object. The result is {@code * true} if and only if the argument is not {@code null} and is a {@code * String} object that represents the same sequence of characters as this * object. * * @param anObject * The object to compare this {@code String} against * * @return {@code true} if the given object represents a {@code String} * equivalent to this string, {@code false} otherwise * * @see #compareTo(String) * @see #equalsIgnoreCase(String) */public boolean equals(Object anObject) { // 如果是同一个对象，返回 true if (this == anObject) { return true; } // 如果 anObject 可以向下转型为 String if (anObject instanceof String) { // 转型为 String 类型 String anotherString = (String)anObject; // 原字符串长度 int n = value.length; // 如果原字符串长度和要比较的字符串长度一致 if (n == anotherString.value.length) { char v1[] = value; char v2[] = anotherString.value; int i = 0; // 逐个字符比较 while (n-- != 0) { if (v1[i] != v2[i]) return false; i++; } return true; } } return false;} 从源码中可以知道，类型不同是返回 false 的，因此考虑下面的例子： 123String s = \"hello\";String t = \"hello\";char c[] = {'h', 'e', 'l', 'l', 'o'}; 显然，s==t和 s.equals(t) 返回 true ，因为 s 和 t 都指向了同一个 String 常量池里面的常量，类型相同且值相同。但是，t.equals(c) 返回 false ， 因为类型不同。 引申，在 Java 9 中， String 的实现已经从 char[] 变成 byte[] 了。因此就更应该是 false 了。 字符串比较的几点建议建议一：文字串和String对象比较的时候，好的习惯是把文字串放在前面，这样可以避免某些空指针异常。 1if (\"World\".equals(location)) 建议二：不要用 == 符号来判断字符串相等！！在Java虚拟机中，每个文字串只有一个实例，&quot;World&quot; == &quot;World&quot; 确实会返回真，但是如果前后比较的字符串是用分割提取等方法获取到的，它将会被存入一个新的对象当中，这时用==判断会出现假，因为不是同一个对象。 建议三：测试一个字符串对象是否为null，可以用==。例如： 1String middlename == null; null不是字符串，null说明该变量没有引用任何对象。而空字符串 &quot;&quot;是长度为零的字符串。 建议四：如果想忽略大小写比较字符串，使用equalsIgnoreCase方法： 1myStr.equalsIgnoreCase(\"world\"); String 的用法使用 join 连接字符串join并不是用来取代“+”连接符的，更多是用于分隔符拼接。（参考：stackoverflow） 1String name = String.join(\"-\",\"hello\",\"and\",\"again\"); 输出 hello-and-again 。 第一个参数是连接符，第二到n个参数是需要连接的字符串 使用 substring 提取子串12String str = \"Hello, World!\";String str2 = str.substring(7,12); 提取出第 7（包括）到第12（不包括）位，即World这个单词。注意是从 0 开始的。 使用 split 分割字符串1String[] subs = str.split(\" \"); 以空格为分隔符，将子字符串提取出来。split的最终结果为一个字符串数组。 使用 format 格式化输出1234567String fs;fs = String.format(\"浮点型变量为%f, 整型变量为%d, 字符串变量为%s\", floatVar, intVar, stringVar);String hello;hello = String.format(\"Hello, %s. Next year you will be %d.\", name, age); 使用 toString 将数字转为字符串1str = Integer.toString(n,2); toString接受2个参数，第一个参数是数字n，第二个参数是进制（默认为10进制，范围在[2,36]）。在这个例子中，如果n是42，则把42转为二进制字符串 “101010”。 使用 parseInt 将字符串转化为数字1n = Integer.parseInt(str，2) 这实际上是Integer的方法而不是String的方法。这个例子将字符串 str 转化成二进制的 Integer 。 使用 replace 和 replaceAll 取代12public String replace(char oldChar, char newChar)public String replaceAll(String regex, String replacement) 注意，replaceAll 方法的第一个参数是一个正则表达式 String 和 Char[] 之间的转换String的底层就是 Char数组（JDK1.9之后是 Byte 数组），转换方式如下： 123456//将 String 转换为 char[]char[] cs = str.toCharArray();//将 char[] 转换为 StringString str = String.valueOf(cs); // 方法一String str2 = new String(cs); // 方法二 StringBuffer 和 StringBuilder当需要对字符串进行修改，可以使用 StringBuffer 和 StringBuilder 类。 和 String 类不同的是，StringBuffer 和 StringBuilder 类的对象能够被多次的修改，并且不产生新的未使用对象。 StringBuilder 类在 Java 5 中被提出，它和 StringBuffer 之间的最大不同在于 StringBuilder 的方法不是线程安全的（不能同步访问）。但是速度快。 由于 StringBuilder 相较于 StringBuffer 有速度优势，所以多数情况下建议使用 StringBuilder 类。然而在应用程序要求线程安全的情况下，则必须使用 StringBuffer 类。 （摘自菜鸟教程） 总结起来就是： StringBuilder 比 StringBuffer 快，但涉及线程安全必须用StringBuffer。它们两者与 String 的不同点在于对象能被多次修改。 StringBuffer 的用法StringBuffer有跟String类似的方法： 使用 append 追加字符串1234StringBuffer s = new StringBuffer(\"hello world，\");s.append(\"I am \");s.append(\"Jerry.\");System.out.println(s); 输出：hello world，I am Jerry. 扩展： String 的 “+” 和 StringBuffer的 append问: 有没有哪种情况用 + 做字符串连接比调用 StringBuffer / StringBuilder 对象的 append 方法性能更好？ 答：如果连接后得到的字符串在 静态存储区中是早已存在的，那么用+做字符串连接是优于 StringBuffer / StringBuilder 的 append 方法的。 使用 reverse 进行反转123StringBuffer s = new StringBuffer(\"hello\");s.reverse;System.out.println(s); 输出：olleh 使用 delete 删除字符串中间的字符12345public delete(int start, int end)StringBuffer s = new StringBuffer(\"hello\");s.delete(1,3);System.out.println(s); 输出：ho 使用 insert 插入123StringBuffer s = new StringBuffer(\"hello\");str.insert(1,\"ang\");System.out.println(s); 输出：“hangello” 使用 replace 取代不举例了，给出原型: 1replace(int start, int end, String str) 参考： 互联网面试笔记","link":"/post/689b9445.html"},{"title":"Java虚拟机（三）Class文件结构","text":"class 文件简介class 文件是javac编译器编译后生成的二进制文件,全部是连续的0/1。可以把 class 文件中的内容分为两种类型： 无符号数：表示class文件中的值，没有符号，但有长度。u1、u2、u4、u8 （u1表示1字节的无符号数） 表：无符号数要么单独存在，要么多个组合成为二维表。 总而言之，class文件中的数据要么是单个值，要么是二维表。 class 文件的组织结构一览 魔数 本文件的版本信息 常量池 访问标志 类索引 父类索引 接口索引集合 字段表集合 方法表集合 魔数class文件的头4个字节，具体的值是16进制表示的“CAFEBABE”。 魔数的作用就相当于文件后缀名，只不过后缀名容易被修改，不安全，因此在class文件中标示文件类型比较合适。 版本信息紧接着魔数的4个字节是版本号。它表示本class中使用的是哪个版本的JDK。 在高版本的JVM上能够运行低版本的class文件，但在低版本的JVM上无法运行高版本的class文件，即使该class文件中没有用到任何高版本JDK的特性也无法运行！ 常量池常量池存放两种类型的常量： 字面值常量：字面值常量即我们在程序中定义的被final修饰的值。 符号引用：符号引用就是我们定义的各种名字。包括：类和接口的全限定名、字段的名字和描述符、方法的名字和描述符。 常量池的大小是不固定的，因此常量池开头放置一个u2类型的无符号数，用来存储当前常量池的容量。JVM根据这个值就知道常量池的头尾。（注意：这个值是从1开始的，若为5表示池中有4个常量。） 访问标志在常量池之后是2字节。 访问标志是用来表示这个class文件是类还是接口、是否被public修饰、是否被abstract修饰、是否被final修饰等。 由于这些标志都由是/否表示，因此可以用0/1表示。 访问标志为2字节，可以表示16位标志，但JVM目前只定义了8种，未定义的直接写0。 类索引、父类索引、接口索引集合表示当前class文件所表示类的名字、父类名字、接口们的名字。 由于一个类的接口可能有好多个，因此需要用一个集合来表示接口索引，它在类索引和父类索引之后。 字段表集合存储本类所涉及到的成员变量，包括实例变量和类变量，但不包括方法中的局部变量。 每一个字段表只表示一个成员变量，本类中所有的成员变量构成了字段表集合。 方法表集合所有的方法以二维表的形式存储，每张表来表示一个函数，一个类中的所有方法构成方法表的集合。","link":"/post/d15ce8f0.html"},{"title":"Java虚拟机（四）垃圾回收策略","text":"在 Java虚拟机（二）内存模型和对象创建 这一篇中，我们知道 Java 虚拟机的内存模型包含五个部分：程序计数器、Java虚拟机栈、本地方法栈、堆、方法区。这五个区域也叫运行时数据区域（Runtime Data Area），他们是数据的存储空间。既然是存储空间，那就有可能达到存满的时候，因此，JVM必须配备一个垃圾回收器（Garbage Collection, GC），用于不定期地回收不再需要的内存空间。 事实上，Java的动态内存分配和回收技术已经相当成熟，作为开发者的我们无需手动去分配和释放内存，一切都交给Java虚拟机。那为什么我们还要去了解 GC 和 内存放配呢？原因是：当需要排查各种内存溢出、泄露等问题，或当垃圾收集称为系统达到更高并发量的瓶颈时，我们有必要对这些“自动化”的技术进行监控和调节。 线程私有区域程序计数器、Java虚拟机栈、本地方法栈都是线程私有的，这三个区域会随着线程的创建而创建，随着线程的结束而销毁。 此外，Java虚拟机栈、本地方法栈中的栈帧会随着方法的开始而入栈，随着方法的结束而出栈，每个栈帧中的本地变量表都是在类被加载的时候就确定的。 正是因为这些确定性，垃圾回收器能够清楚地知道何时该回收这部分内存空间。 线程共享区域堆和方法区是所有线程共享的，并且都在JVM启动时创建，一直运行到JVM停止。 堆中存放JVM运行期间的所有对象，虽然每个对象的内存大小在加载该对象所属类的时候就确定了，但究竟创建多少个对象实例只有在程序运行期间才能确定。 方法区中存放类信息、静态成员变量、常量。类的加载是在程序运行过程中，当需要创建这个类的对象时才会加载这个类。因此，JVM究竟要加载多少个类也需要在程序运行期间确定。 因此，堆和方法区的内存回收具有不确定性，因此垃圾收集器在回收堆和方法区内存的时候就不那么容易了。 堆内存的回收判断哪些对象需要回收一个对象不被任何对象或变量引用，那么就是无效对象，就需要被回收。可以用 引用计数法 和 可达性分析法 来找到无效对象。 引用计数法（Reference Counting）每个对象都有一个计数器，每当有一个地方引用了它，计数器加一；若引用失效，计数器减一。当计数器为 0 时，就认为该对象是无效对象。这个方法虽然简单，但存在一个严重的问题：无法解决循环引用的问题。 在下面的例子中，虽然把 objA 和 objB 都置为 null ，但其两者内部某个属性还持有对方的引用，因此采用引用计数法不会被回收。 1234567Ref objA = new Ref();Ref objB = new Ref();objA.instance = objB;objB.instance = objA;objA = null;objB = null; 因此，目前主流语言均使用可达性分析方法来判断对象是否有效。 可达性分析法(Reachability Analysis)GC把以下几种对象称为 GC-Roots： Java虚拟机栈所引用的对象(栈帧中局部变量表中引用类型的变量所引用的对象) 本地方法栈JNI(Native)所引用的对象 方法区中 静态属性 和 常量 引用的对象 可达性分析法的规则是：所有和 GC Roots 直接或间接关联的对象都是有效对象，和 GC Roots 没有关联的对象就是无效对象。 GC Roots并不包括堆中对象所引用的对象！这样就不会出现循环引用。 无论采用上述哪种方法，都与引用相关。关于引用的定义，在JDK1.2之后分为 强引用、软引用、弱引用、虚引用 四种引用类型，参考：refjava 如何回收可达性分析法中，不可达的对象并不是“非死不可”，他还有最后一次机会：finalize() 方法可以复活。 finalize() 方法Object 类中定义的方法，Java 中允许使用 finalize() 方法在垃圾收集器将对象从内存中清除出去之前做必要的清理工作。这个方法是由垃圾收集器在销毁对象时调用的，通过重写 finalize() 方法可以整理系统资源或者执行其他清理工作。 这个方法一个对象只能执行一次，只能在第一次进入被回收的队列，而且对象所属于的类重写了finalize方法才会被执行。第二次进入回收队列的时候，不会再执行其finalize方法，而是直接被二次标记，在下一次GC的时候被杀死。 回收过程 判断该对象是否 Override 了 finalize() 方法，若有 Override，将 finalize() 扔进F-Queue队列中；若无 Override，直接释放对象内存； 执行F-Queue队列中的 finalize() 方法； 如果在执行 finalize() 方法时，将 this 赋给了某一个引用，那么该对象就重生了。如果没有，那么就会被垃圾收集器清除。 使用建议 一般不要使用 finalize，最主要的用途是回收特殊渠道申请的内存。Java程序有垃圾回收器，所以一般情况下内存问题不用程序员操心。但有一种JNI(Java Native Interface)调用non-Java程序（C或C++），finalize()的工作就是回收这部分的内存。 强烈不建议使用 finalize() 函数进行任何操作！如果需要释放资源，请使用try-finally。因为 finalize() 不确定性大，开销大，无法保证顺利执行。 方法区的回收方法区中主要清除两种垃圾： 废弃常量 无用的类 如何判断一个常量是否废弃？清除废弃的常量和清除对象类似，只要常量池中的常量不被任何变量或对象引用，那么这些常量就会被清除掉。举个例子，常量池中有”abc”这个常量，但是当前系统已经没有任何引用指向 “abc” 了，这时候如果发生 GC 且有必要，”abc” 这个方法区中的常量就会被回收。 如何判断一个类是否无用？ 该类的所有对象都已被清除（堆中已经没有该类的对象） 该类的 java.lang.Class 对象没有在任何地方被引用（无法通过反射访问该类的方法） 加载该类的 ClassLoader 已经被回收 垃圾回收算法1. 标记-清除（Mark-Sweep）算法首先判断需要清除哪些数据，并给它们做上标记，然后清除被标记的数据。这种方法虽然简单，但是效率比较低，而且清除完后存在大量碎片空间，导致后续无法存储大对象，降低了空间利用率。 2. 复制算法（针对新生代）将内存分成两份，只将数据存储在其中一块上。当需要回收垃圾时，也是首先标记出废弃的数据，然后将有用的数据复制到另一块内存上，最后将第一块内存全部清除。这种算法避免了碎片空间，但内存被缩小了一半。而且每次都需要将有用的数据全部复制到另一片内存上去，效率不高。 复制算法如何解决空间利用率问题？在新生代中，由于大量的对象都是“朝生夕死”（98%），也就是一次垃圾收集后只有少量对象存活，因此我们可以将内存划分成三块：Eden、Survior1、Survior2，内存大小分别是8:1:1。分配内存时，只使用Eden和一块Survior1。当发现 Eden+Survior1 的内存即将满时，JVM会发起一次GC，将所有存活下来的对象复制到另一块Survior2中，然后清除掉整个 Eden+Survior1。那么，接下来就使用 Survior2+Eden 进行内存分配。 通过这种方式，只需要浪费10%的内存空间即可实现带有压缩功能的垃圾收集方法，避免了内存碎片的问题。 但是，当一个对象要申请内存空间时，发现Eden+Survior中剩下的空间无法放置该对象，此时需要进行Minor GC，如果 Minor GC 过后空闲出来的内存空间仍然无法放置该对象，此时需要将 Eden+Survior 中的所有对象都转移到老年代中，然后再将新对象存入Eden区。这个过程称为“分配担保”。 3. 标记-整理（Mark-Compact）算法（针对老年代）在回收垃圾前，首先将所有废弃的对象做上标记，然后将所有未被标记的对象移到一边，最后清空另一边区域即可。这是一种针对老年代的算法，因为老年代中的对象一般寿命比较长，因此每次垃圾回收会有大量对象存活。其清空的是标记的废弃对象区域。 标记-整理和标记-清除的区别在于，标记-清除是直接清除掉需要需要回收的对象，而标记-整理是先将存活的对象往一端移动，然后清除端边界以外的内存。 4. 分代收集算法将内存划分为老年代和新生代。老年代中存放寿命较长的对象，新生代中存放“朝生夕死”的对象。然后在不同的区域使用不同的垃圾收集算法。 Minor GC 和 Full GCMinor指的是发生在新生代的垃圾收集，因对Java对象大多具有“朝生夕死”的特征，所以 Minor 发生得非常频繁，回收速度也快。Full GC 也叫做 Major GC，指的是发生在老年代的垃圾收集，一次 Full GC 通常伴随一次 Minor GC（非绝对），Full GC的回收速度一般比 Minor GC 慢 10 倍以上。 参考： 深入理解JVM(三)——垃圾收集策略详解 Java中跟垃圾回收密切相关的就是引用的类型了，这一部分之前专门有写了一篇 Java中的引用类型，现在回过头来看，好像又加深了一些理解。 周志明，《深入理解Java虚拟机》","link":"/post/2191536a.html"},{"title":"Java中的引用类型","text":"什么是引用类型引用类型（reference type）是一种基于类的数据类型。Java中，除去基本数据类型外，其它类型都是引用类型。包括Java提供的或者自己定义的class类。 当我们对某个对象声明一个变量的时候，例如 1Ball b1 = new Ball(); 变量 b1 事实上指向了这个对象的引用，而不是对象本身。 1Ball b2 = b1; b2 和 b1 都指向了 ball 类的同一个实例。 Java中有四种引用： 强引用（Strong Reference） 软引用（Soft Reference） 弱引用（Weak Reference） 虚引用（Phantom Reference） 强引用（Strong Reference）如果一个对象具有强引用，那垃圾回收器(GC)绝不会回收它。 比如上面 Ball 的例子，就是一个强引用。 1Ball b1 = new Ball(); 当内存空间不足，Java虚拟机宁愿抛出OutOfMemoryError错误，使程序异常终止，也不会靠随意回收具有强引用的对象来解决内存不足的问题。如果不使用时，可以通过 b1=null;的方式来弱化引用，帮助GC回收对象。 ArrayList 中的强引用12345678private transient Object[] elementData;public void clear() { modCount++; // Let gc do its work for (int i = 0; i &lt; size; i++) elementData[i] = null; size = 0;} 可以看到，clear()方法不是直接对 elementData 置空，而是对elementData[i] 置空，这样elementData就不会被 GC 回收，避免在后续调用 add()等方法添加元素时进行重新的内存分配。 软引用（Soft Reference）如果一个对象只具有软引用，则内存空间足够，垃圾回收器就不会回收它；如果内存空间不足了，就会回收这些对象的内存。 只要垃圾回收器没有回收它，该对象就可以被程序使用。软引用可用来实现内存敏感的高速缓存。 软引用可以和一个引用队列（ReferenceQueue）联合使用，如果软引用所引用的对象被垃圾回收器回收，Java虚拟机就会把这个软引用加入到与之关联的引用队列中。 12345// 强引用String str=new String(\"abc\"); // 软引用SoftReference&lt;String&gt; softRef=new SoftReference&lt;String&gt;(str); 软引用在网页中的应用: 如果一个网页在浏览结束时就进行内容的回收，则按后退查看前面浏览过的页面时，需要重新构建 如果将浏览过的网页存储到内存中会造成内存的大量浪费，甚至会造成内存溢出这时候就可以使用软引用 12345678910111213// 获取页面进行浏览Browser prev = new Browser(); // 浏览完毕后置为软引用SoftReference sr = new SoftReference(prev); // 还没有被回收器回收，直接获取if(sr.get()!=null){ rev = (Browser) sr.get(); }else{ // 由于内存吃紧，所以对软引用的对象回收了 prev = new Browser(); sr = new SoftReference(prev); // 那么就重新构建} 弱引用（Weak Reference）弱引用与软引用的区别在于： 只具有弱引用的对象拥有更短暂的生命周期。 在垃圾回收器线程扫描它所管辖的内存区域的过程中，一旦发现了只具有弱引用的对象，不管当前内存空间足够与否，都会回收它的内存。 弱引用可以和一个引用队列（ReferenceQueue）联合使用，如果弱引用所引用的对象被垃圾回收，Java虚拟机就会把这个弱引用加入到与之关联的引用队列中。 123StringBuilder sb = new StringBuilder();SoftReference&lt;StringBuilder&gt; sbSoftRef = new SoftReference&lt;&gt;(sb); 当你想引用一个对象，但是这个对象有自己的生命周期，你不想介入这个对象的生命周期，这时候你就是用弱引用。这个引用不会在对象的垃圾回收判断中产生任何附加的影响。 比如说Thread中保存的ThreadLocal的全局映射，因为我们的Thread不想在 ThreadLocal 生命周期结束后还对其造成影响，所以应该使用弱引用，这个和缓存没有关系，只是为了防止内存泄漏所做的特殊操作。 虚引用（Phantom Reference）虚引用主要用来跟踪对象被垃圾回收器回收的活动。 虚引用与软引用和弱引用的一个区别在于：虚引用必须和引用队列 （ReferenceQueue）联合使用。当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在回收对象的内存后，把这个虚引用加入到与之关联的引用队列中。也就是说，为一个对象设置虚引用的唯一目的是能在这个对象被收集器回收时受到一个系统通知。 12345StringBuilder sb = new StringBuilder();ReferenceQueue&lt;StringBuilder&gt; refQ = new ReferenceQueue&lt;&gt;();PhantomReference&lt;StringBuilder&gt; sbPhantomRef = new PhantomReference&lt;&gt;(sb, refQ); 程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存回收后采取必要的行动。 如果引用队列中出现了你的虚引用，说明它已经被回收，那么你可以在其中做一些相关操作。","link":"/post/ae9388fa.html"},{"title":"Java简明笔记（一） 基础知识","text":"Java 与 C++ 的区别 C++支持多重继承，Java不支持，但可以实现多接口。（引申：多重继承菱形问题） 自动内存管理 java不支持goto语句 引用与指针：在Java中不可能直接操作对象本身，所有的对象都由一个引用指向，必须通过这个引用才能访问对象本身，包括获取成员变量的值，改变对象的成员变量，调用对象的方法等。而在 C++ 中存在引用，对象和指针三个东西，这三个东西都可以访问对象。其实，Java中的引用和C++中的指针在概念上是相似的，他们都是存放的对象在内存中的地址值，只是在Java中，引用丧失了部分灵活性，比如 Java 中的引用不能像 C++ 中的指针那样进行加减运算。 数据类型在 Java 中，数据类型分为两类：基本数据类型（primitive type） 和 引用类型（reference type）。 八（九）种基本数据类型 基本类型 大小(字节) 默认值 封装类 byte 1 (byte)0 Byte short 2 (short)0 Short int 4 0 Integer long 8 0L Long float 4 0.0f Float double 8 0.0d Double boolean - false Boolean char 2 \\u0000(null) Character void - - Void 在数字后面加 L 后缀即表示long类型（如 400000000L），在数字前面类型转换即可表示Byte或short类型 （如 (byte)127） 在浮点数后面加 f 后缀表示 float，否则默认为double 关于 void，有些书认为不属于基本数据类型，虽然 Java api 中并未说明，但有些书籍如《Thinking in Java》将其也划进去。 数据类型转换数据类型转换分为 自动转换 和 强制转换。 自动转换程序在执行过程中 “悄然” 进行的转换，不需要用户提前声明，一般是从位数低的类型向位数高的类型转换。 Java中的 byte，short，char 进行计算时都会提升为 int 类型。 int &lt; long &lt; float &lt; double， 如果有一个操作数是 double 型，计算结果是double型。 12345byte b = 1;short s = 2;int i = b + s; // b 和 s 会自动转换为 intdouble d = i + 3.0; // i 会被自动转换为 double 强制转换必须在代码中声明，转换顺序不受限制。使用 括号（） 来声明要转换的类型。 12Person p = new Student();Student s = (Student) p; 基本数据类型的 ++ 操作1234567891011public static void main(String[] args) { int i = 0; int j = i++; System.out.println(\"i: \" + i); System.out.println(\"j: \"+ j); int m = 0; int n = ++m; System.out.println(\"m: \" + m); System.out.println(\"n: \"+ n);} 输出： 1234i: 1j: 0m: 1n: 1 这个例子中，i++ 先把 i 的值赋给 j，然后 i 自增。 ++m，先把 m + 1 的值赋给 n， 然后 m 自增。 也就是说，无论是 i++ 还是 ++i ，都是先赋值，后自增。 左移右移 &lt;&lt;表示左移位 &gt;&gt;表示带符号右移位 &gt;&gt;&gt;表示无符号右移 没有 &lt;&lt;&lt; 运算符 右移要特别注意一下，由于计算机数据位以补码表示，正数符号位位0，负数符号位位1，因此，正数的右移（&gt;&gt;）前面补0，负数的右移（&gt;&gt;）前面补1（称为算术右移）。但是，如果是无符号右移（&gt;&gt;&gt;），符号位失去特权，一律补0（称为逻辑右移）。 拆箱和装箱什么是装箱？一般我们要创建一个类的对象实例的时候，我们会这样： 1Class a = new Class(parameter); 当我们创建一个Integer对象时，却可以这样： 1Integer i = 100; //(注意：不是 int i = 100; ) 实际上，执行上面那句代码的时候，系统为我们执行了： 1Integer i = Integer.valueOf(100); 这就是基本数据类型的自动装箱功能。 同理，拆箱就是把基本数据类型从 Integer 对象取出的过程。 考虑下面这个例子： 1234int i02 = 59;Integer i04 = new Integer(59);System.out.println(i02 == i04); // 输出 true 输出 true 是因为，虽然 i04 是对象，但是跟基本数据类型比较时，会自动拆箱。 数据类型 -&gt; Object可以把任何一种数据类型的变量赋给 Object 类型的变量。基本类型也是可以的，会自动装箱。 基本数据类型的包装类，即 Integer、Double、Float 等，都继承于 Number 类。 基本数据类型及其包装类的区别1.java是面向对象语言，但基本数据类型不是对象，为了让基本数据类型有对象的特征，java设计了一套包装类。基本数据类型没有可调用的方法，而包装类型有方法调用。比如： 12int t = 1; // t. 后面没有方法Integer u = 1;// u. 后面就有很多方法可以调用了 2.基本数据类型初始化值为0（char为\\u0000）,if 判断时要用 if(i == 0)，而包装类要用 if(i==null) 3.当需要往ArrayList，HashMap中放东西时，基本类型是放不进去的，因为容器都是装object的，包装类可以。 1List&lt;Integer&gt; list = new ArrayList&lt;Integer&gt;(); equals() 和 “==” equals()：比较的是两个对象的值（内容）是否相同。 ==：比较的是两个引用所指的对象（或者说内存地址）是否相同，也用来比较两个基本数据类型的变量值是否相等。 123456789101112131415public static void main(String[] args) { int i = 5; long j = 5L; // 虽然类型不一样，但基本数据类型是可以比较的，返回 true System.out.println( i == j ); Integer ii = 5; Long jj = 5L; // 编译错误，类型不一样，无法比较 System.out.println( ii == jj ); // 类型不一样，返回 false System.out.println( ii.equals(jj));} 前面说过，int 的自动装箱，是系统执行了 Integer.valueOf(int i)，看看Integer.java的源码（在IDEA中，按住Ctrl键，鼠标点击 Integer）： 1234567public static Integer valueOf(int i) { // 没有设置的话，IngegerCache.high 默认是127 if(i &gt;= -128 &amp;&amp; i &lt;= IntegerCache.high) return IntegerCache.cache[i + 128]; else return new Integer(i);} 对于–128到127（默认是127）之间的值，Integer.valueOf(int i) 返回的是 缓存的Integer对象！！！ 所以下面的现象也就不难理解了： 12345678910//在-128~127 之外的数Integer i1 = 200; Integer i2 = 200; System.out.println(\"i1==i2: \"+(i1==i2)); // 输出 false// 在-128~127 之内的数Integer i3 = 100; Integer i4 = 100; System.out.println(\"i3==i4: \"+(i3==i4)); // 输出 true 《阿里巴巴Java开发手册》中提到，对于 Integer var =? 在 -128 至 127 之间的赋值， Integer 对象是在IntegerCache.cache 产生，会复用已有对象，这个区间内的 Integer 值可以直接使用 == 进行判断，但是这个区间之外的所有数据，都会在堆上产生，并不会复用已有对象，这是一个大坑，因此推荐使用 equals 方法进行判断。 增强 for 循环 (forEach)两个例子： 如果 numbers 是一个 int[] 数组列表，则使用 forEach 输出所有int 1234int sum = 0;for ( int n : numbers){ sum += 0;} 如果 friends 是一个 String[] 数组列表，则使用 forEach 输出所有String 123for (String name : friends) { System.out.println(name);} foreach与正常for循环效率对比 循环ArrayList时，普通for循环比foreach循环花费的时间要少一点； 循环LinkList时，普通for循环比foreach循环花费的时间要多很多。 当将循环次数提升到一百万次的时候，循环ArrayList，普通for循环还是比foreach要快一点；但是普通for循环在循环LinkList时，程序直接卡死。 结论： 需要循环数组结构的数据时，建议使用普通for循环，因为for循环采用下标访问，对于数组结构的数据来说，采用下标访问比较好。 需要循环链表结构的数据时，一定不要使用普通for循环，这种做法很糟糕，数据量大的时候有可能会导致系统崩溃。 原因：foreach使用的是迭代器 零碎知识数学运算相关 最小整数：Integer.MIN_VALUE 最大整数：Integer.MAX_VALUE long不够用，用 BigInteger 类 1_000_000 = 1000000，编译器会自动删掉下划线（方便阅读） Double.POSITIVE_INFINITY表示无穷大，Double.NEGATIVE_INFINITY表示负无穷大 Double.NaN表示非数值 用 if (Double.isNaN(x))来检查 x 是否为 NaN，但不可以用if (x == Double.NaN)，因为NaN都是彼此不同的 浮点数不适合金融计算，用 BigDecimal 类，且要用它的 String 参数构造器，否则还是会发生精度丢失的问题。 BigDecimal.ValueOf(n,e);，其中n是一个整数数，e是小数位，如(588888,3)，就是 588.888 17/5 的结果是3， 而 17.0/5 的结果是3.4 整数除以零会导致异常，浮点数除以零会产生无限值或NaN 负数慎用 % Math类让算数运算更安全（p15） Math.round方法获得数字四舍五入的整数，int n = (int) Math.round(x)，若x=3.75，则n=4 ( n!=0 &amp;&amp; s+(100-s) / n ) &lt; 50，第二个条件除数等于零可能会报错，但第一个条件排除了这种可能性，所以第一个条件满足时，第二个条件不予评估，也就不会发生错误 time &lt; 12 ? &quot;am&quot; : &quot;pm&quot;， 若time&lt;12，结果为am，否则为pm n &amp; 0xF的结果为n的最低四位 在 32 位的 int 类型中，1&lt;&lt;35 的结果跟 1&lt;&lt;3 相同 Java不允许对象直接使用加减乘除等操作符，所以 BigDecimal 和 BigInteer 类需要用方法 1BigDecimal next = bd.multiply(bd.add(BigDecimal.valueOf(\"l\"))); 变量相关 最好每个变量名都有各自单独的声明 变量名建议用驼峰式命名，如 countOfInvalidInputs 刚好正在首次需要变量的前一刻声明 常量用大写字母，如DAYS_PRE_WEEK = 7; 在其他类中使用 Calendar 类的常量，只需要前面加上类名，如Calendar.DAYS_PRE_WEEK 格式化输出使用 %0.0 输出浮点数%8.2f指明输出的浮点数宽度为8，精度为小数点后两位。 12// 输出：333.33System.out.printf(\"%8.2f\", 1000.0 / 3.0); 使用 %s 输出字符串，%d 输出纯数字12System.out.printf(\"Hello, %s. Next year you will be %d.\", name, age);String.format(\"Hello, %s. Next year you will be %d.\", name, age); 类型转换String 转 其他1Integer.parseInt(Str); 其他 转 String123456//取数字的值，转换为字符串，比如 3.10 转换为 \"3.1\"//如果要格式化为 \"3.10\"，应该用下面的 DecimalFormat 类String n = String.ValueOf(num);// Integer 转 StringString s = Integer.toString(num); 使用 DecimalFormat 类将数字格式化为字符串 1234567double d = 3.1;// 预定格式DecimalFormat df = new DecimalFormat(\"0.00\");// 把 3.10 格式化，返回 String，s = \"3.10\"String s = df.format(d); 数组声明数组12//声明一个有100个元素的字符串数组String[] names = new String[100]; 使用 new 构造数组时的默认值：数字（0）， Boolean（flase）, 对象（空引用） 遍历数组12// 使用 stream 遍历Arrays.stream(names).forEach(System.out::println); 数组元素比较== 和 != 比较的是对象引用，而不是对象的内容。所以比较数组不同下标元素内容是否相同时，不要用 == 应该用 equals。 12345// DON'Tif (numbers.get(i) == numbers.get(j));// DOif (numbers.get(i).equals(numbers.get(j))); 使用 ArrayList 代替数组构造数组时，需要知道数组的长度，一旦构造出来长度便不能改变。在许多实际应用中很不方便。所以需要 Java.util 包中的 ArrayList 类来根据需求随时增长或者缩减数组的长度。ArrayList是泛型类。 12345678ArrayList&lt;String&gt; friends;friend = new ArrayList&lt;&gt;();friend.add(\"Peter\");friend.add(\"Paul\");friend.remove(1);String first = friends.get(0);friends.set(1, \"Mary\"); 二维数组在 Java 中，二维数组的每一个元素都是一个一维数组。 当我们声明一个二维数组： 1Integer[][] num = new Integer[2][3]; 也就声明了这个二维数组里面有 2 个一维数组，这 2 个一维数组里面每个一维数组都有 3 个元素。 123456789101112131415161718192021222324// 初始化二维数组Integer[][] num = new Integer[2][3];// 另一种初始化int[][] numbers = { {1,2,3}, {4,5,6}};// 遍历 fori 二维数组for (int i = 0; i &lt;numbers.length ; i++) { for (int j = 0; j &lt;numbers[i].length ; j++) { System.out.print(numbers[i][j] + \" \"); } System.out.println();}// 使用 foreach 遍历二维数组for (int[] number : numbers) { for (int aNumber : number) { System.out.print(aNumber + \" \"); } System.out.println();} 遍历结果输出： 121 2 34 5 6 注意：二维数组的声明中， [][] 其中第一个括号必须有值。代表的是在该二维数组中有多少个一维数组。 可变长参数使用 … 声明可变长参数12345public static double average(double... values) { double sum = 0; for(double v: values) sum+= v; return values.length == 0 ? 0 : sum / values.length;} 注意：可变参数必须是方法的最后一个参数","link":"/post/b3088ac5.html"},{"title":"Java简明笔记（七） 异常和断言","text":"异常处理在Java异常处理中，一个方法可以通过 抛出(throw) 异常来发出一个严重问题的信号。调用链中的某个方法，负责 捕获（catch） 并处理异常。捕获到的异常不仅可以在当前方法中处理，还可以将异常抛给调用它的上一级方法去处理。 异常处理的根本优点是：将错误检测和错误处理的过程解耦。 Java 的异常都派生自 Throwable 类，Throwable 又分为 Error 和 Exception。Error 不是我们的程序所能够处理的，比如系统内存耗尽。我们能预知并处理的错误属于 Exception。Exception又分为 unchecked exception 和 checked exception。 unchecked exception 属于 RuntimeException 。 当然，所有的异常都发生在运行时（Runtime），但是 RuntimeException 派生的子类异常在编译时不会被检查。 checked exceptions跟上下文环境有关，即使程序设计无误，仍然可能因使用的问题而引发。通常是从一个可以恢复的程序中抛出来的，并且最好能够从这种异常中使应用程序恢复。 我们所要关注的是一般情况下错误可被提前预知的 checked exception，什么是可被提前预知？比如IO操作文件可能损坏或不存在，网络操作的时候网络可能会断开… 许多异常类派生自 IOException，我们应该尽可能用准确合适的异常类来报告错误。比如在某个路径查找指定文件时，却无法找到，此时应该抛出 FileNotFoundException。 unchecked exceptions通常是如果一切正常的话本不该发生的异常，但是的确发生了。发生在运行期，具有不确定性，主要是由于程序的逻辑问题所引起的。 unchecked exception 我们完全可以在程序中避免。比如遇到空指针异常，我们完全可以在代码中确保没有引用null值，通过修改代码来避免抛出这个异常。但是文件不存在或网络断开这种就不是我们逻辑代码的问题了，应该抛出异常。 checked exception的声明假如有一个方法，我们能够预料到它 可能 会抛出 IOException 和 ReflectiveOperationException 这两种异常，那么我们可以在方法中这样声明： 123public void write (Object obj, String filename) throws IOException, ReflectiveOperationException { ...} Override覆盖的方法不能抛出超出父类异常范围的异常，如果父类没有throws异常，则子类不可以抛出checked exception 当一个方法抛出异常时，可以用javadoc的 @throws 标签来文档化 不可能指定 lambda 表达式的异常类型 异常捕获示例1：可以捕获多个异常1234567891011try { //statements} catch (ExceptionClass1 ex) { //handler1} catch (ExceptionClass2 ex) { //handler2} catch (ExceptionClass3 ex) { //handler3} finally { //statements} 有多个捕获器的时候，第一个捕获后下面的捕获器就不会再捕获了，因此范围小的写在前面。 注意，如果 try 里面某一行抛出异常了，那一行接下去的代码不会接着执行。 示例2：多个捕获共享一个handler1234567try { //statements} catch (ExceptionClass1 | ExceptionClass2 | ExceptionClass3 ex) { //handler3} finally { //statements} 示例3：带资源的异常捕获（try-with-resource）(Java 7+)try后面接资源，在正常执行完之后或者当发生异常时，try-with-resources语句会自动关闭资源。 这样我们不用写out.close()，但却能够保证每个资源的out.close()都会被触发。 12345678910ArrayList&lt;String&gt; lines ...;try (PrintWriter out = new PrintWriter(\"output.txt\")) { for (String line:lines ) { out.println(line.toLowerCase()); }} catch (IOException ex) { //handler} finally { //statements} 如果没有 try-catch 的话，如果其中一个 line 抛出异常，那么所有的 line 的 out.close() 不能被正常执行，导致out结果丢失。 如果用常规的 try-catch 语句，如果要打开两个资源，那么就要嵌套 try-catch 了。try-with-resources的一个好处在于只需要写一个 try-catch 语句。 更多关于异常的内容 异常重抛和链接、堆栈踪迹、Objects.requireNonNull方法参考 《core java for the impatient》p186 Throw 和 Throws 的区别Throws 写在方法后面，表示这个方法可能向上抛出的异常。 Thorw 写在程序里面，直接抛出异常。注意，抛出后程序便不再往下执行。这一点跟 try-catch 语句不一样， catch 捕获异常并处理过后，程序还会往下执行，而 throw 是向上一级调用栈抛出，本身程序不再继续执行。 try里有return，finally还执行么？答：执行，并且 finally 的执行早于 try 里面的 return 不管有没有出现异常，finally块中代码 都会执行； 当 try 或 catch中有 return 时，finally 仍然会执行；finally 是在 return 后面的表达式运算后执行的（此时并没有返回运算后的值，而是先把要返回的值保存起来，不管finally中的代码怎么样，返回的值都不会改变，任然是之前保存的值），所以函数返回值是在 finally 执行前确定的； finally 中最好不要包含 return，否则程序会提前退出，返回值不是 try 或 catch 中保存的返回值。 一句话总结: 先执行return后面的表达式，把结果保存起来，但不返回，然后执行finally，最后才返回。不要在finally中包含return，更不要在 finally 修改返回值。 若是在try语句块或catch语句块中执行到 System.exit(0) 语句，则直接退出程序。 使用 Optional 类解决空指针异常一个对象如果可能是null，我们通常要写类似下面的代码来避免空指针异常： 1234567if (obj == null){ // do something..}if (obj != null){ // go ahead..} 在 Java 8 中，我们有了更好的方法来判断空指针——Optional 类。它是一个可以为 null 的容器对象。如果值存在则 isPresent() 方法会返回 true，调用 get() 方法会返回该对象。Optional 容器可以保存类型 T 的值，或者仅仅保存null。Optional提供很多有用的方法，这样我们就不用显式进行空值检测。 java.util.Optional&lt;T&gt; 的声明如下： 1234public final class Optional&lt;T&gt;extends Object{ //...} 用法： 12345678public User findUser(String email){ Optional&lt;User&gt; optUser = userRepository.findById(email); // returns java8 optional if (optUser.isPresent()) { return optUser.get(); } else { // handle not found, return null or throw }} 断言（assert）断言机制允许我们在测试时加入检测条件，并且在生产代码中自动移除它们。在Java中，断言用于调试目的以验证内部假设。 为了断言 x 是一个非负数 1assert x &gt;= 0; 或者将 x 的实际值传进 AssertionError 对象，这样后面就可以现实它： 1assert x &gt;=0 : x; 默认情况下断言是被禁用的，在运行程序时加上 -ebableassertion 或者 -es可以启用断言 1$ java -ea MainClass 不必重新编译程序，当断言被禁用时，类加载器会清除断言代码，所以断言不会降低运行速度。","link":"/post/a3bb075d.html"},{"title":"Java简明笔记（三） 接口","text":"什么是接口假设有一种整数序列服务，这种服务可以计算前n个整数的平均值。就像这样： 1234public static double average(IntSequence seq, int n){ ... return average} 我们传入一个序列seq，以及我们想计算这个序列的前n个数，它返回平均数。 然而，这样的序列可以有很多种形式，比如用户给出的序列、随机数序列、素数序列、整数数组中的元素序列…… 现在，我们想实现一种单一机制，来处理所有的这些序列。要做到这一点，就得考虑上面序列的共性。 不难知道，我们需要两个方法。 判断是否还有下一个元素 获得下一个元素 我们暂时不去想这两个方法具体怎么实现，只是知道需要有这两个方法。于是，我们的average计算平均数服务可以是这样： 123456789public static double average(IntSequence seq, int n) { int count = 0; double sum = 0; while (seq.hasNext() &amp;&amp; count &lt; n){ count ++; sum += seq.next(); } return count == 0 ? 0 : sum / count;} 在Java中，我们把这两种方法声明出来，但不实现，这就是接口了。 1234public interface IntSequence{ boolean hasNext(); int next();} 接口中所有的方法默认为public 实现接口一个实现现在有一个类，它的序列是一组无限平方数（0,1,4,9,16,25…），我们要用上面的average方法来计算这组平方数前n个数的平均值。那么，这个类必然有hasNext()和next()这两个方法的具体实现。我们就称这个类实现了上面的IntSequence接口。 123456789101112public class SquareSequence implements IntSequence { private int i; public boolean hasNext() { return true; } public int next() { i++; return i * i; }} 获得前100个平方数的平均值： 12SquareSequence squares = new SquareSequence();double avg = average(squares, 100); squares是SquareSequence类的一个对象，先new一个squares对象。然后在average方法中传入了这个对象作为序列，并且传入100表示前100个平方数。 又一个实现现在又有一个类，它是一个有限序列。是正整数从个位开始每个位的值。比如1729，那么序列就是9，2，7，1。这个序列必然也有hasNext()和next()这两个方法的具体实现。因此，这个类也实现了上面的IntSequence接口。 123456789101112131415161718192021public class DigitSequence implements IntSequence { private int number; public DigitSequence(int n) { number = n; } public boolean hasNext() { return number !=0; } public int next() { int result = number % 10; number /= 10; return result; } public int rest() { return number; }} 计算1729位数序列的平均值 12IntSequence digits = new DigitSequence(1729);double avg = average(digits, 100); //虽然这里传入100，但实际只有4个数 值得注意的是，IntSequence接口是DigitSequence类的父类，所以我们可以指定digits变量的类型为IntSequence接口类型。 从父类转换为子类，用cast。 你只能将一个对象强制转换为它的实际类或者它的父类之一。 可以用instanceof测试对象是否期望的类型 1234// 如果DigitSequence是sequence的父类，if语句为trueif (sequence instanceof DigitSequence) { DigitSequence digits = (DigitSequence) sequence;} 一个接口可以继承(extend)另外一个接口，在原有方法上提供额外的方法。 一个类可以实现多个接口，用逗号隔开。 定义在接口中的任何变量自动为 public static final。 接口中可以有哪些方法修饰符？Java8 的接口方法可以有如下方法定义： public, abstract, default, static，strictfp public接口中所有的方法都是public的，不可以是 protected 或者 private。 接口中写 abstract 有什么意义？其实接口中所有的方法都是 public abstract 的（静态方法除外），不写也默认是 abstract。只是可以省略而已。写了也不会错。 static接口可以有静态方法（Java 8新特性），但必须提供实现。 default （默认方法）可以给接口一个默认实现（默认方法），用default修饰。（Java 8新特性） 12345678public interface IntSequence { default boolean hasNext(){ return true; } int next();} 默认方法的一个重要用途：接口演化 有一个旧接口，一个类实现了这个接口。新版Java中对旧接口增加了一个方法，那么这个类就无法编译了，因为这个类没有实现新增加的方法。这时，如果新增加的方法设为默认方法。那么在类的实例中调用这个方法时，执行的是接口的默认方法，即使这个类没有该方法也得以编译和运行。 解决冲突 如果一个类实现了两个接口，其中一个接口有默认方法，另一个接口有同名同参数的方法（默认或非默认），那么编译器会报错。可以用父类.super.方法()来决定要执行哪个方法。 123456//返回 Identified 接口的 getID，而不是 Persons 接口的public class Employee implements Persons, Identified { public int getID() { return Identified.super.getID(); }} strictfpstrictfp, 即 strict float point (精确浮点)，这个用得比较少，暂时不深入研究。 Java标准类库的几个常用接口Comparable接口如果一个类想启用对象排序，它应该实现 Comparable 接口。 123public interface Comparable&lt;T&gt; { int compareTo(T other);} String类实现Comparable&lt;String&gt;，它的 compareTo 方法是 1int compareTo(String other) Employee类实现Comparable&lt;Employee&gt;，它的compareTo方法可以这样写： 123456public class Employee implements Comparable&lt;Employee&gt; { ... public int compareTo(Employee other) { return getID() - other.getID(); }} 返回正整数（不一定是1），表示x应该在y后面；返回负整数（不一定是-1），表示x应该在y前面；返回0，说明相等。 如果返回负整数，有可能溢出，导致结果变成一个大正整数，用Interger.compare方法解决。 比较浮点数时，应该用静态方法Double.compare，不能用两数之差。 实现了Comparable后，如何使用？我们的 Employee 类实现了 Comparable 接口，说明这个类的不同实例之间是可以比较的，比较的方法如下 123Employee s1 = new Employee(18,\"Xiaoming\");Employee s2 = new Employee(20,\"Luohao\");s1.compareTo(s2); 可以将这些实例放到一个数组中，然后用Arrays.sort()进行排序。 1234567891011// 一个Employee数组Employee[] eArr = {e1,e2,e3};// 对Employee数组进行排序，如何排序？根据上面我们写的compareTo方法Arrays.sort(eArr);//遍历输出for (Employee ei: eArr) { System.out.println(ei.getID());} Comparator接口我们比较字符串的时候，通常是 123String s1 = \"hello\";String s2 = \"world\";s1.compare(s2); 这样会以首字母大小顺序对 s1,s2 进行比较。 但如果我们要比较的是字符串的长度，而不是根据首字母。就无法用Comparable接口的compareTo方法来实现。这时候就需要Comparator接口： 123public interface Comparator&lt;T&gt; { int compare(T first, T second); } 我们可以写一个类，叫LenthComparator，这个类实现了 Comparator&lt;&gt; 接口。 然后重写compare方法。 比较字符串长度的实现 12345class LenthComparator implements Comparator&lt;String&gt; { public int compare(String first, String second) { return first.lenth() - second.lenth() }} 然后对这个类进行实例化，再应用在两个字符串中，这样就实现了对字符串的长度的比较。 1234Comparator&lt;String&gt; comp = new LenthComparator();if (comp.compare(words[i],words[j]) &gt; 0){ //...} 可以看到，这种调用是compare对象上的调用，而不是字符串自身。 扩展当我们要对某个对象数组（比如student对象）进行排序的时候，不按comparable实现的比较方法来排序，而是要以另一种方式排序。这时候Arrays.sort()提供第二个参数，是一个 Comparator，意思是：以第二个参数（Comparator）制定的规则来对第一个参数（数组）进行排序。 1234567student[] sArr = {s1,s2,s3};Arrays.sort(sArr, new Comparator&lt;student&gt;(){ @Override public int compare(student o1, student o2) { return o1.getAge() - o2.getAge(); }}); 这样的代码比较啰嗦，我们可以用 lambda 表达式替代： 12// lambda 表达式会自动进行类型判断Arrays.sort(sArr, (o1,o2)-&gt;(o1.getAge() - o2.getAge())); 如果你要比较的不是数组，而是一个集合，用Collections.sort代替Arrays.sort 12345678// 第一种写法，IDEA会提示你可以用方法引用替代Collections.sort(studentList, ((o1, o2) -&gt; o1.getAge() - o2.getAge()));// 用方法引用，IDEA会提示你可以用 实例.sort 替代Collections.sort(studentList, Comparator.comparing(student::getAge));// finestudentList.sort(Comparator.comparing(student::getAge)); 继续扩展123456789//按照名字进行排序Arrays.sort(arr, Comparator.comparing(Person::getName));//按照名字长度进行排序Arrays.sort(arr,Comparator.comparing(Person::getName,(s,t)-&gt;Integer.compare(s.length(),t.length())));Arrays.sort(arr,Comparator.comparingInt(p-&gt;p.getName().length()));//先按照名字进行排序,如果名字相同,再按照地址比较Arrays.sort(arr,Comparator.comparing(Person::getName).thenComparing(Person::getAddress)); Runable接口Runable接口用来定义任务。比如我们想把特定的任务丢给一个单独的线程去做。 1234567891011class HelloTask implements Runnable { public void run { // how to run }}{Runnable task = new HelloTask();Thread thread = new Thread(task);thread.start();} 这样，run方法就在一个单独的线程中去执行了，当前线程可以做别的事。 Serializable 标记接口什么是序列化对象流是指将对象的内容进行流化。之后，我们就可以对流化后的对象进行读写操作或网络传输。序列化就是一种用来处理对象流的机制，为了解决在对对象流进行读写操作时所引发的问题。 Serializable 接口的作用将需要被序列化的类实现 Serializable 接口，该接口没有需要实现的方法，implements Serializable 只是为了标注该对象是可被序列化的。 之后，使用一个输出流(如：FileOutputStream)来构造一个 ObjectOutputStream(对象流) 对象，接着，使用 ObjectOutputStream 对象的 writeObject(Object obj) 方法就可以将参数为obj的对象写出(即保存其状态)，要恢复的话则用输入流。 UI回调在GUI中，当用户单击按钮、选择菜单项、拖动滑块等操作时，我们必须指定需要执行的行为。这种行为称为回调。 在Java GUI类库中，用接口来回调。如在JavaFX中，报告事件的接口： 123public interface EventHandler&lt;T&gt; { void handle (T event);} 一个CancelAction类实现上面的接口，指定按钮单击事件的行为ActionEvent，然后创建该类的对象。 12345678class CancelAction implements EventHandler&lt;ActionEvent&gt; { public void handle (ActionEvent event) { System.out.println(\"Oh shit!\"); }}Button cancelButton = new Button(\"Cancel!\");cancelButton.setOnAction(new CancelAction()); 接口(Interface)和抽象类(abstract class)的区别接口是对动作(行为)的抽象，表示的是”like-a”关系。 抽象类是对类的抽象，表示的是”is-a”关系。 接口注重的是方法，而抽象类注重属性和方法。 抽象类 接口 可以有构造函数 没有构造函数 可以有普通成员变量 没有普通成员变量，只能有常量 可以有实现方法和抽象方法 有抽象方法，可以有静态方法（java8），如果方法被default修饰就可以实现（java8） 一个类只能继承一个抽象类 接口可以有多个实现 什么时候使用接口，什么时候使用抽象类如果你想实现多继承，那么就用接口，Java不支持多继承，但是可以实现多个接口 接口主要用于模块与模块之间的调用 抽象类主要用于当做基础类使用，即基类 举个简单的例子，飞机和鸟是不同类的事物，但是它们都有一个共性，就是都会飞。那么在设计的时候，可以将飞机设计为一个类Airplane，将鸟设计为一个类Bird，但是不能将 飞行 这个特性也设计为类，因此它只是一个行为特性，并不是对一类事物的抽象描述。此时可以将 飞行 设计为一个接口Fly，包含方法fly( )，然后Airplane和Bird分别根据自己的需要实现Fly这个接口。然后至于有不同种类的飞机，比如战斗机、民用飞机等直接继承Airplane即可，对于鸟也是类似的，不同种类的鸟直接继承Bird类即可。从这里可以看出，继承是一个 “是不是”的关系，而 接口 实现则是 “有没有”的关系。如果一个类继承了某个抽象类，则子类必定是抽象类的种类，而接口实现则是有没有、具备不具备的关系，比如鸟是否能飞（或者是否具备飞行这个特点），能飞行则可以实现这个接口，不能飞行就不实现这个接口。 (例子出处)","link":"/post/32811f1d.html"},{"title":"Java中的回调机制","text":"什么是回调（CallBack）呢？有一个经典的打电话例子。 有一天小王遇到一个很难的问题，问题是“1 + 1 = ?”，就打电话问小李，小李一下子也不知道，就跟小王说，等我办完手上的事情，就去想想答案，小王也不会傻傻的拿着电话去等小李的答案吧，于是小王就对小李说，我还要去逛街，你知道了答案就打我电话告诉我，于是挂了电话，自己办自己的事情，过了一个小时，小李打了小王的电话，告诉他答案是2 所谓回调：就是A类中调用B类中的某个方法C，然后B类中反过来调用A类中的方法D，D这个方法就叫回调方法。 回调让模块与模块之间解耦，也实现了异步调用。 异步回调首先定义一个回调接口 12345public interface Callback { public void solve();} A 类实现了回调接口，并持有B类的引用 A 类去调用 B 类的方法来处理 A类 自身的问题 B 类处理A类的问题，并通过回调把结果告知A类 Android 中的回调在 Android 中，我们开启一个 AsyncTask 获取网络数据， 然后在 onPostExecute() 方法中进行视图绑定。 由于 AsyncTask 可能造成的内存泄漏问题，因此我们一般都用静态内部类来规避这个问题。但是静态内部类又不能持有外部类的成员，因此我们可以用回调函数(Callback Function)来解决。 定义回调接口首先定义一个回调接口 1234public interface OnDataFinishedListener { public void onDataSuccessfully(String data); public void onDataFailed();} AsyncTask 内部类在 AsyncTask 里面实例化，并添加一个方法用来传引用 1234OnDataFinishedListener onDataFinishedListener; public void setOnDataFinishedListener(OnDataFinishedListener onDataFinishedListener) { this.onDataFinishedListener = onDataFinishedListener; } 然后在 onPostExecute() 方法里面，根据doInBackground()返回的内容不同，选择合适的回调方法。 12345678@Overrideprotected void onPostExecute(String respResults) { if (respResults != null) { onDataFinishedListener.onDataSuccessfully(respResults); } else { onDataFinishedListener.onDataFailed(); }} 外部类在外部类中调用内部类的setOnDataFinishedListener()方法，重写接口。 123456789101112getDetailTask.setOnDataFinishedListener(new OnDataFinishedListener() { @Override public void onDataSuccessfully(String json) { // do something } @Override public void onDataFailed() { // do something } }); 这样就实现了内部类AsyncTask执行结束后，异步把结果传回外部类。 未完待续","link":"/post/98aa81f1.html"},{"title":"Java简明笔记（九）Stream API","text":"StreamJava 中的 Stream 提供了数据源，让你可以在比集合类更高的概念层上指定操作。使用 Stream，只需要指定做什么，而不是怎么做。你只需要将操作的调度执行留给实现。 简单地说，流就是一组数据，经过某种操作，产生我们所需的新流，或者输出成非流数据。 流的来源，可以是集合，数组，I/O channel， 生成器（generator）等。流的聚合操作类似 SQL 语句，比如filter, map, reduce, find, match, sorted等。 例如，从文件从获取流： 123try (Stream&lt;String&gt; lines = Files.lines(Paths.get(\"/path/to/file.txt\"))) { ...} 从迭代到 Stream 操作假设现在有一本电子书alice.txt在我们的硬盘里，我们想统计这本书中所有的长单词（超过12个字母），我们可以用迭代的方法。 第一步，先将 alice.txt 所有内容读到字符串里 第二步，创建一个List列表，以非字母为分隔符存放每一个单词字符串 第三步，foreach循环开始迭代 12345678910// 读文件，放到 String 里String contents = new String(readAllBytes((Paths.get(\"alice\"))), StandardCharsets.UTF_8);// 以非字母为分隔符List&lt;String&gt; words = Arrays.asList(contents.split(\"\\\\PL+\"));int count = 0;// 在 List 里面迭代，如果找到长度＞12的，计数器+1for (String w : words) { if (w.length() &gt; 12) count++; } 在 java 8 中，可以用 stream 来实现相同的功能： 1234567// 读文件，放到 String 里String contents = new String(readAllBytes((Paths.get(\"alice.txt\"))), StandardCharsets.UTF_8);// 以非字母为分隔符List&lt;String&gt; words = Arrays.asList(contents.split(\"\\\\PL+\"));// 把 List 转换成 流，用 flilter 方法对流的每一个元素进行判断，筛选出＞12的，并计数long count1 = words.stream().filter(w -&gt; w.length() &gt; 12).count(); words.stream()创建的是串行流，words.parallelStream()创建的是并行流。 只需要一行，就把过滤字母长度大于12的单词和统计实现出来了。 Stream就是这样遵循 做什么，而不是怎么去做 的原则。 聚合操作（Aggregation）简单介绍filter, map, reduce, find, match, sorted filter: 过滤符合的条件,如在集合里面过滤长度大于5的元素.filter(w -&gt; w.length() &gt; 5) map：用于映射每个元素到对应的结果，如将每个元素乘方.map( i -&gt; i*i) reduce：把结果继续和序列的下一个元素做累积计算（第一个参数是起始值） find：查找 anyMatch：匹配，判断的条件里，任意一个元素成功，返回true allMatch：判断条件里的元素，所有的都是，返回true noneMatch：跟 allMatch 相反 sorted：排序 limit：取集合的前 n 个元素 关于聚合操作，可参考： runoob.com 一个例子: 将alice.txt的内容读入 String， 以非字母为分隔符存入 List， 通过流取前20个值，过滤出这20个值长度大于5的，并排序，最后存到新的 List 里 12345678910public static void streamTest() { try { String contents = new String(readAllBytes((Paths.get(\"alice.txt\"))), StandardCharsets.UTF_8); List&lt;String&gt; words = Arrays.asList(contents.split(\"\\\\PL+\")); List&lt;String&gt; newwords = words.stream().limit(20).filter(w -&gt; w.length() &gt; 5).sorted().collect(Collectors.toList()); System.out.println(newwords); } catch (IOException e) { System.out.println(\"IO problem\"); };} 另一个例子：为每个订单加上12%的税 12345678910// 不使用lambda表达式List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);for (Integer cost : costBeforeTax) { double price = cost + .12*cost; System.out.println(price);}// 使用lambda表达式List costBeforeTax = Arrays.asList(100, 200, 300, 400, 500);costBeforeTax.stream().map((cost) -&gt; cost + .12*cost).forEach(System.out::println); 可见 Lambda 表达式非常地优雅。 规约方法（reduction）有时候我们使用聚合操作，操作完成后还是一个流。但有时会转换成非流值，我们把转换完毕后是非流值的方法称为规约方法。 比如上面例子的.count()，就把流转换成了数字，.collect(Collectors.toList()转换成 List 集合， .max()和.min()获取成流中最大或最小的值。findFirst()返回非空集合的第一个值，findAny()返回任何符合的值。anyMatch()、noneMatch()和allMatch()返回匹配。 例子：流中是否有以Q开头的元素？有返回True，没有返回False 1boolean aWordStartWithQ = words.parallel().anyMatch( s -&gt; s.startWith(\"Q\")); CollectorsCollectors实现了很多规约操作，例如 .collect(Collectors.toList()把流转换成 List .collect(Collectors.joining(&quot;,&quot;)把流转换成以逗号分割的 String parallel streamparallelStream是并行执行的流，是以多线程的方式运行的。其原理是ForkJoinPool（实现了Executor和ExecutorService接口），主要用分治法(Divide-and-Conquer Algorithm)来解决需要使用相对少的线程处理大量的任务的问题（比如使用4个线程来完成超过200万个任务，任务之间有父子关系），这一点是 ThreadPoolExecutor 做不到的。 提示：当需要处理递归分治算法时，考虑使用ForkJoinPool。 stream or parallelStream使用串行流还是并行流，主要考虑： 考虑1：是否需要并行？在回答这个问题之前，你需要弄清楚你要解决的问题是什么，数据量有多大，计算的特点是什么？并不是所有的问题都适合使用并发程序来求解，比如当数据量不大时，顺序执行往往比并行执行更快。毕竟，准备线程池和其它相关资源也是需要时间的。但是，当任务涉及到I/O操作并且任务之间不互相依赖时，那么并行化就是一个不错的选择。通常而言，将这类程序并行化之后，执行速度会提升好几个等级。 考虑2：任务之间是否是独立的？是否会引起任何竞态条件？对于问题2，如果任务之间是独立的，并且代码中不涉及到对同一个对象的某个状态或者某个变量的更新操作，那么就表明代码是可以被并行化的。 考虑3：结果是否取决于任务的调用顺序？对于问题3，由于在并行环境中任务的执行顺序是不确定的，因此对于依赖于顺序的任务而言，并行化也许不能给出正确的结果。 参考： 《写给大忙人看的Java核心技术》 Java Functional Programming 深入浅出parallelStream","link":"/post/372345f.html"},{"title":"Java简明笔记（八）Lambda和函数式编程","text":"函数式编程我们平时所采用的 命令式编程（OO也是命令式编程的一种）关心解决问题的步骤。你要做什么事情，你得把达到目的的步骤详细的描述出来，然后交给机器去运行。 而函数式编程关心数据的映射，或者说，关心类型（代数结构）之间的关系。这里的映射就是数学上“函数”的概念，即一种东西和另一种东西之间的对应关系。所以，函数式编程的“函数”，是数学上的“函数”（映射），而不是编程语言中的函数或方法。 函数式编程的思维就是如何将这个关系组合起来，用数学的构造主义将其构造出你设计的程序。用计算来表示程序，用计算的组合来表达程序的组合。 函数式编程思想函数式编程有三个关键点： 函数第一（Functions as first class objects）：函数跟其他对象一样，一个引用变量可以指向一个函数，就像我们声明一个引用 s 指向一个字符串 String 一样。可惜的是，在 Java 中，函数不是第一的，但 Scala、Kotlin 里面是。 纯函数（Pure functions）：函数内部不依赖于外部变量。 高阶函数（Higher order functions）：函数可以作为参数传递进来，也可以作为返回值返回。在 Java 中，一个方法可以接受一个 lambda 表达式，也可以返回一个 lambda 表达式。 纯函数的四个关键点： 无状态(No state)：函数内部不能使用外部变量。 无副作用（No side effects）：函数内部不能修改外部变量。 对象不可变（Immutable variables）：使用不可变对象来避免副作用。如果要修改一个传进来的参数对象，那修改完毕后返回一个新的对象，而不是修改后的该对象本身。 递归（Favour recursion over looping）：使用递归，而非循环。 Java 中的 Lambda 表达式Lambda 表达式，也可称为闭包，或者匿名函数，它是推动 Java 8 发布的最重要新特性。Lambda 允许把函数作为参数传递进方法中，也可以在方法中返回一个函数。 使用 Lambda 表达式可以使代码变的更加简洁紧凑。 语法我们用 -&gt; 来表达 Lambda 表达式，-&gt;之前是输入的参数，-&gt;之后是输出的结果。 1(parameters) -&gt; expression 简单例子比较字符串长度 1(String first, String second) -&gt; first.length() - second.length() 给出两个数字，求和 1(int a, int b) -&gt; a + b; 如果结果无法用一个表达式写出，则用大括号，并明确 return 1234(int a, int b) -&gt; { if (a &gt; b) return a * b; else return a / b;} 如果没有参数，-&gt;前面的参数给出空括号 1Runnable task = () -&gt; { for (int i = 0; i &lt; 100; i++) do(); }; 实际例子替代匿名类12345678910111213141516171819202122232425class jump implements Runnable { public void run(){ System.out.println(\"jump now\"); }}public class test { public static void main(String[] args) { //不使用匿名类 Runnable r = new jump(); Thread t1 = new Thread(r); t1.start(); //使用匿名类 new Thread(new Runnable() { @Override public void run() { System.out.println(\"swim now\"); } }).start(); //使用 lambda 表达式 new Thread( () -&gt; System.out.println(\"go away now\")).start(); }} 事件处理12345678910111213// Java 8之前：JButton show = new JButton(\"Show\");show.addActionListener(new ActionListener() { @Override public void actionPerformed(ActionEvent e) { System.out.println(\"Event handling without lambda expression is boring\"); }});// Java 8方式：show.addActionListener((e) -&gt; { System.out.println(\"Light, Camera, Action !! Lambda expressions Rocks\");}); 对列表进行迭代12345678910111213// Java 8之前：List features = Arrays.asList(\"Lambdas\", \"Default Method\", \"Stream API\", \"Date and Time API\");for (String feature : features) { System.out.println(feature);}// Java 8之后：List features = Arrays.asList(\"Lambdas\", \"Default Method\", \"Stream API\", \"Date and Time API\");features.forEach(n -&gt; System.out.println(n));// 使用Java 8的方法引用更方便，方法引用由::双冒号操作符标示，// 看起来像C++的作用域解析运算符features.forEach(System.out::println); Java中的函数式接口lambda背后的奥秘在于，lambda表达式本质上是一个匿名类，这个匿名类实现了某个只有一个方法的接口。 自定义函数式接口只有一个未实现的抽象方法的接口称为函数式接口，static 和 default 不影响。之所以规定不能有多个抽象方法，是因为 lambda 表达式只能接受一个方法。用@FunctionalInterface注解检查是否符合函数式接口规范。 12345// 函数式接口@FunctionalInterfacepublic interface Cal { int cal(int n1, int n2);} Cal是一个函数式接口，只有一个 cal 方法。使用的时候可以用 lambda 表达式定义方法做什么。 12345678910111213public static void main(String[] args) { // 做加法 Cal sum = (n1, n2) -&gt; n1 + n2; int r1 = sum.cal(10, 20); System.out.println(r1); // 30 // 做减法 Cal sub = (n1, n2) -&gt; n1 - n2; int r2 = sub.cal(10, 20); System.out.println(r2); // -10} 当然，我们可以再做一层封装，提供 calculator 方法，接收两个数字和一个表示如何计算的 lambda，返回计算结果。 1234567public static int calculator(int num1, int num2, Cal c){ return c.cal(num1, num2);}public static void main(String[] args) { int n = calculator(10, 20, (n1, n2)-&gt; n1 + n2); // 30} 可以看到，calculator 方法传入了一个 lambda 表达式，事实上，这个 lambda 就是 Cal 接口的一个匿名实现，在传参的时候“现场”声明罢了。 Java预置的函数式接口jdk 1.8 预置了一些函数式接口，在 java.util.function 包里。其中 6 个最常用的基本接口为： ConsumerConsumer的中文意思是消费者，接收一个对象 T， 无返回。 123456789@FunctionalInterfacepublic interface Consumer&lt;T&gt; { void accept(T t); default Consumer&lt;T&gt; andThen(Consumer&lt;? super T&gt; after) { Objects.requireNonNull(after); return (T t) -&gt; { accept(t); after.accept(t); }; }} JDK 例子：System.out::println 12Consumer&lt;Double&gt; cal = (d) -&gt; System.out.println(d*2);cal.accept(3.5); SupplierSupplier的中文意思是提供者，不接收参数，返回一个对象 T JDK例子：Instant::now 1234@FunctionalInterfacepublic interface Supplier&lt;T&gt; { T get();} Predicate我之前很难理解什么是 Predicate，直到看了 知乎这个回答。 其实很简单，接收一个对象T，返回 boolean，这种场景就是 Predicate 。 12345678910111213141516171819202122232425@FunctionalInterfacepublic interface Predicate&lt;T&gt; { boolean test(T t); default Predicate&lt;T&gt; and(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) &amp;&amp; other.test(t); } default Predicate&lt;T&gt; negate() { return (t) -&gt; !test(t); } default Predicate&lt;T&gt; or(Predicate&lt;? super T&gt; other) { Objects.requireNonNull(other); return (t) -&gt; test(t) || other.test(t); } static &lt;T&gt; Predicate&lt;T&gt; isEqual(Object targetRef) { return (null == targetRef) ? Objects::isNull : object -&gt; targetRef.equals(object); }} JDK 例子：Collection::isEmpty Function&lt;T,R&gt;接收一个对象T，返回一个对象R JDK 例子：Arrays::asList UnaryOperator接收一个对象T，返回一个对象T。这个接口实际上继承了 Function&lt;T,T&gt; JDK 例子：String::toLowerCase BinaryOperator接收两个 T 对象，返回一个 T 对象。 这个接口实际上继承了 BiFunction&lt;T,T,T&gt;，在 BiFunction 中，接收 T，U 返回 R。 JDK 例子：BigInteger::add 12345678910111213@FunctionalInterfacepublic interface BinaryOperator&lt;T&gt; extends BiFunction&lt;T,T,T&gt; { public static &lt;T&gt; BinaryOperator&lt;T&gt; minBy(Comparator&lt;? super T&gt; comparator) { Objects.requireNonNull(comparator); return (a, b) -&gt; comparator.compare(a, b) &lt;= 0 ? a : b; } public static &lt;T&gt; BinaryOperator&lt;T&gt; maxBy(Comparator&lt;? super T&gt; comparator) { Objects.requireNonNull(comparator); return (a, b) -&gt; comparator.compare(a, b) &gt;= 0 ? a : b; }} 高阶函数处理或返回函数的函数称为 高阶函数。 返回值为 lambda表达式 的方法Arrays.sort()有第二个参数让我们以某种方式排序 升序排序 1Arrays.sort(sArr, (o1,o2) -&gt; (o1.compareTo(o2))); 降序排序 1Arrays.sort(sArr, (o1,o2) -&gt; ( -1 * o1.compareTo(o2))); 这样比较麻烦，怎么办呢？可以写一个产生比较器的方法： 123public static Comparator&lt;String&gt; compraeInDirection(int direction) { return (x,y) -&gt; direction * x,compareTo(y);} 这个方法返回了一个 lambda 表达式，决定了是采用升序排序还是降序排序。 当需要降序排序的时候，直接： 1Arrays.sort(sArr, compraeInDirection(-1)); compraeInDirection(-1) 返回了一个 lambda 表达式，即 (x,y) -&gt; -1 * x,compareTo(y) ，这个 lambda 表达式又作为 Arrays.sort() 的第二个参数。 操作符 「::」 和方法引用在学习lambda表达式之后，我们通常使用lambda表达式来创建匿名方法。然而，有时候我们仅仅是调用了一个已存在的方法。如下： 1Arrays.sort(stringsArray,(s1,s2)-&gt;s1.compareToIgnoreCase(s2)); 在Java8中，我们可以直接通过方法引用来简写lambda表达式中已经存在的方法。这种特性就叫方法引用： 1Arrays.sort(stringsArray, String::compareToIgnoreCase); 操作符::将 方法名称 与 类或对象名称分隔开。 可用于 类::实例方法 比如，String::comparaToIgnoreCase 等同于 (x,y) -&gt; x.comparaToIgnoreCase(y) 类::静态方法 比如，Objects::isNull 等同于 x -&gt; Objects.isNull(x) 对象::实例方法 比如，System.out::println 等同于 x -&gt; System.out::println(x) 例子打印列表的所有元素，可以这么做 1list.forEach(x -&gt; System.out.println(x)); 但也可以直接这么做 1list.forEach(System.out::println); this也是可以使用的，比如，this::equals 等同于 x -&gt; this.equals(x) 访问闭合作用域的变量注意，lambda 表达式只能引用 final 或 final 局部变量，这就是说不能在 lambda 内部修改定义在域外的局部变量，否则会编译错误。 考虑下面这个例子： 1234567public static void repeatMessage(String text, int count) { Runnable r = () -&gt; { for (int i = 0; i &lt; count; i++) { System.out.println(text); } };} 可以发现，在Lambda表达式里，count和text既不属于Lambda表达式的参数，也不属于Lambda表达式内部定义的变量。但是我们仍然可以使用，原因是Lambda表达式捕获了repeatMessage方法的变量值。注意，是变量值，不是变量本身。 也就是说，Lambda表达式访问闭合作用域的变量，只能访问 final 局部变量。不会被修改的值。当然，我们也不能在Lambda表达式里去修改count和text的值。 假设我们： 123for (int i=0 ; i &lt; n ; i++ ) { new Thread ( () -&gt; System.out.println(i)).start();} 则会编译出错，因为 i 是会变化的。 参考： 函数式编程 Java Functional Programming","link":"/post/68278ec8.html"},{"title":"Java简明笔记（二） 面向对象","text":"Java 创建对象的过程当我们实例化一个对象时，例如： 1Person p = new Person(); Java首先会在堆中开辟一块内存空间用来存放这个新的 Person 对象，然后在栈中创建一个引用 p ， p 指向堆中的 Person 对象。这样，我们通过 p 就能找到 Person 的内存地址。 之后，我们执行： 1Person p2 = p; 我们创建了一个新的引用 p2， p2 跟 p 一样，都是保存在栈中，也指向了 Person 对象。当我们改变 p2 的状态， p 也会跟着改变，因为他们指向同一个对象。 类块加载顺序在一个类中，可能存在： 静态块：用 static{ } 声明，JVM 加载类时执行，仅执行一次（注意：如果在静态块中声明了变量，如 int a = 1;, 它是一个局部变量，在该静态块执行结束后就会失效） 构造块：类中直接用 { } 定义，每一次创建对象时执行 在有继承关系的类中，加载顺序如下： 父类静态块 子类静态块 父类构造块 父类构造方法 子类构造块 子类构造方法 注意：如果 main 在该类下，JVM 先加载类，然后才会执行 main() 方法 示例一1234567891011121314public class Go { { System.out.println(\"blockA\"); } static { System.out.println(\"blockB\"); } public static void main(String[] args) { }} 输出结果： 1blockB main方法什么都不做，但是当我们执行时这个空的main方法，Go类会被JVM加载，因此输出静态块 blockB。 示例二12345678910111213141516public class Go { public static Go t1 = new Go(); { System.out.println(\"blockA\"); } static { System.out.println(\"blockB\"); } public static void main(String[] args) { }} 输出: 12blockAblockB main()依然什么都不做，但是在JVM加载Go类时（只会加载一次），第一行 new 一个新的 Go 对象，new 的时候调用了构造快，因此输出 blockA，之后，Go类继续加载，执行静态块，输出 blockB。 示例三12345678910111213141516public class Go { public static Go t1 = new Go(); { System.out.println(\"blockA\"); } static { System.out.println(\"blockB\"); } public static void main(String[] args) { Go t2 = new Go(); }} 输出： 123blockAblockBblockA JVM 加载 Go类 时（只会加载一次），第一行 new 一个新的 Go 对象，new 的时候调用了构造快，因此输出 blockA，之后，Go类继续加载，执行静态块，输出 blockB。 然后 main 方法执行，new 一个 Go，调用构造块，再次输出blockA。 面向对象的三个特征面向对象的三个特征分别是：封装、继承、多态，如果还有的话，抽象 也算一个。 封装所谓封装，就是将 数据项 与 相关的操作 结合为一个整体，并将其从外部可见性划分为若干级别（private、protected、public），从而 将数据结构的外部特性与其内部实现相分离，提供一致且标准的对外接口，隐藏内部的实现细节。 封装不仅仅是 private + getter/setter ，使用封装可以对 setter 进行更深层次的定制，例如你可以对执行方法的对象做规定，也可以对数据做一定的要求，还可以做类型转换等等。 为什么要使用封装？ 使用封装不仅仅安全，更可以简化操作。 封装还有一个重要的意义，那就是我们可以对程序的正确性进行分析，并且将无意中破坏设计约束的条件变得更难。（《Java并发编程实战》p33） 继承当子类继承父类后，子类是一种特殊的父类，能直接或间接获得父类里的成员。 为什么要使用继承 ？实现软件复用和扩展。 多态多态就是 事物在运行过程中存在不同的状态 多态的三个前提 有继承关系 子类要重写父类的方法 父类引用指向子类对象 多态的例子例如有 Cat 类继承了 Animal 类 ，并重写了 eat()、sleep() 方法(sleep是静态方法，不属于重写，但我们假设 Cat类 也定义了这个方法)，并增加了一个 Animal 没有的 CatchMouse() 方法。 在测试类中实例化： 12345678910// 这个语句在堆内存中开辟了子类(Cat)的对象，并把栈内存中的父类(Animal)引用指向了这个 Cat 对象Animal am = new Cat();//调用实例方法，调的是 Cat 的方法am.eat();//调用静态方法，调的是 Animal 的方法am.sleep(); // 不建议Animal.sleep(); // 建议 可以发现，实例方法 am.eat() 输出的是 Cat 类重写后的方法，而静态方法am.sleep() 输出的是 Animal 类的方法（尽管 Cat 也写了同名的 sleep 方法，但这不算 Override，运行时不被识别） 扩展：有趣的是，当我们用对象实例去调用静态方法，如am.sleep();，IDEA会给我们一个提示：Static member ‘Test.Animal.sleep()’ accessed via instance reference 。意思是说，建议我们使用 Animal.sleep() 来调用静态方法而不要用 am.sleep()。此外，使用静态变量也应如此。 多态的弊端假如我们要执行父类没有而子类特有的CatchMouse()方法。 12Animal am = new Cat();am.CatchMouse(); 结果却编译报错了。 可见，多态 不能使用子类特有的成员属性和子类特有的成员方法。 那怎么办呢？ 这时候就要用到向下转型。可以使用instanceof操作符判断是不是我们需要的引用类型。 1234567Animal am = new Cat();//如果 am 可以向下转型为 Cat 类，则类型转换if (am instanceof Cat) { Cat ca = (Cat) am; ca.CatchMouse();} 为什么要使用多态？当把不同的子类对象都当作父类类型来看，可以屏蔽不同子类对象之间的实现差异，从而写出通用的代码达到通用编程，以适应需求的不断变化。 关于继承和多态，见另一篇：Java简明笔记（四） 继承 public、protected、private public：所有类可以访问 protected： 同一个包可以访问 + 子类可以访问（无论是不是在同一个包中） private： 只有自己能访问 不修饰(friendly)：同一个包内可访问 对象和方法Mutator 方法 和 Accessor 方法如果一个方法改变了调用它的对象，我们就说这是一个Mutator方法（更改器），反之如果不改变调用自己的对象，它就是Accessor方法 （访问器）。比如 plusDays 方法如果改变 Date对象 的状态，不返回结果，就是Mutator方法，如果 plusDays 不改变 Date对象，而是返回一个新构造的 LocalDate对象，就是Accessor方法。 其他 Java中，变量只能持有对象的引用。引用是与实现相关的一种定位对象的方式。 在类的实例上运行的方法称为实例方法。 Java中，所有没有被声明为static的方法都是实例方法。 局部变量和类变量类中的变量可以不用初始化，使用相应类型的默认值即可，方法中的定义的局部变量必须初始化，否则调用的时候，会导致编译不通过。 12345678910111213141516public class Main { // 有默认值 0 和 0.0 public int i; public static double d; public static void main(String[] args) { // 类中定义的变量可以直接使用 System.out.println(Main.d); Main m = new Main(); System.out.println(m.i); // 方法中定义的变量，必须赋初值，否则调用时编译报错 int k; // 这一步是允许的 System.out.println(k); // 报错 }} this用于表示实例变量在对象上调用方法时，this引用 指向该对象。this 清晰地区分了局部变量和实例变量。带有this的是实例对象。 1234public void raiseSalary(double byPercent){ double raise = this.salary * byPercent / 100; this.salary += raise;} 不想给参数起不同的名称时，也可使用this 123public void setSalary(double salary){ this.salary = salary;} 用于构造函数一个类可以有多个构造函数。一个构造函数可以调用另一个构造函数，用this。且只能写在第一行。 12345public Employee (double salary){ // 调用另一个构造器 this(\"\", salary); // ...} 值传递 当你将对象传递给方法，方法获得该对象引用的拷贝。 Java中，所有参数，对象引用以及基本类型值都是值传递。 下面的例子无法工作，因为sales被复制进x,然后x增加，然而x只是局部变量，这并不更改sales 1234567// 无法工作public void increaseRandomly(double x){ double amount = x * generator.nextDouble(); x += amount;}boss.increaseRandomly(sales); 同样的，不可能写出一个方法将对象引用修改成其他东西。下面的例子中，引用fred被复制进变量e，在e被设置成不同的引用之前是会影响 fred 的，因为他们指向同一个内存区域，但是，在e设置成不同的引用之后就不再影响 fred 。 1234567891011121314151617public class EvilManager{ // e 其实是 fred 的拷贝 public void replaceWithZombie(Employee e){ // 现在，e的 name 属性被设为 angle， fred的angle也会被设为angle // 因为 e 和 fred 虽然是不同的引用，但是他们指向了同一个内存区域 e.setName(\"angle\"); // e现在指向了一个新的 Employee ，跟 fred 没有任何关系了 // e 往后的改变都不会影响 fred e = new Employee(\"\",0); e.setName(\"evil\"); }}// 将 fred 传给方法boss.replaceWithZombie(fred); 构造函数 构造函数的名称与类名称相同。并且不返回任何类型！ 构造函数没有返回类型，如果你不小心加了void，那这是一个名称跟类名相同的方法，不是构造函数。 构造函数可以重载。 如果有多个构造函数，将共有代码放在其中一个构造函数里，然后在其他构造函数可以调用另一个构造函数，这时候调用要使用this。且只能作为构造函数方法体的第一条语句。 构造函数不能被static、final、synchronized、abstract、native修饰，但可以被public、private、protected修饰； 1234public Employee (double salary){ this (\"\", salary); //调用构造函数 Employee (String, salary) //... //其他内容} 如果构造函数中没有设置实例变量的值，系统会自动设定：数字为0，boolean为False, 对象引用为null。 尽量不要忘记给对象引用初始化。假设我们没有在构造函数中将变量name设置为空字符串，那么当有人调用getName方法，如if (e.getName().equals(&quot;Jerry&quot;))，就会导致空指针异常。 在调用子类构造器之前，会先调用父类构造器。当子类构造器中没有使用”super(参数或无参数)”指定调用父类构造器时，是默认调用父类的无参构造器，如果父类中包含有参构造器，却没有无参构造器，则在子类构造器中一定要使用“super(参数)”指定调用父类的有参构造器，不然就会报错。 staticstatic方法如果将方法声明为static，该方法就是静态方法，即可以不用运行在对象上的方法。静态方法没有 this 指针。 静态方法要调用实例方法前必须先 new 对象，但静态方法可以直接调用其他静态方法（包括其他类的静态方法）。 static变量（类变量）如果在类中将变量声明为static，那么该变量属于类，而不是属于对象，它在所有的实例中的值是一样的。注意：static静态变量只能在类主体中定义，不能在方法里面定义(无论是静态方法还是实例方法) 像下面这样是错误的： 12345public static void main(String[] args) { // 错误，static不能用在方法里面 // 无论是静态方法还是实例方法都不可以 static int a = 10;} 静态变量和实例变量的区别实例变量属于某个对象的属性，必须创建了实例对象，其中的实例变量才会被分配空间，才能使用这个实例变量。静态变量不属于某个实例对象，而是属于类，所以也称为类变量，只要程序加载了类的字节码，不用创建任何实例对象，静态变量就会被分配空间，静态变量就可以被使用了。 总之，实例变量必须创建对象后才可以通过这个对象来使用，静态变量则可以直接使用类名来引用。 静态方法可以被 Override 吗？不能。因为 Override 是基于运行时动态绑定的，而 static 方法是编译时静态绑定的。static 方法跟类的任何实例都不相关。 静态方法常见用法工厂方法：工厂方法是指返回一个类的新实例的静态方法。 finalfinal 修饰类表示该类不能被继承。此时和 abstract 是反义词。 final 修饰方法表示方法不能被 Override(覆盖)。 final 修饰变量通常用 static final 表示常量，如: 1public static final double PI = 3.14159265358979323846; 注意：当使用可修改对象的引用时，fianl修饰符只是声明该引用永不改变。但修改对象自身是完全合法的。 下面的例子中，ArrayList 集合里面具体的值可以修改，但 friends 这个引用不能改变，尤其是不能变成null。 12345public class Person{ private final ArrayList&lt;Person&gt; friends = new ArrayList&lt;&gt;(); //可以给该数组列表添加元素 ...} 注意：当 final 变量作为类的成员变量时，必须显示初始化或者在构造函数中初始化。 1234567public class A{ // 允许，但是构造函数中必须初始化 i final int i; // 正确 final int j = 4;} abstractabstract指的是抽象，即没有实现，也不能被实例化。此外，接口属于特殊的 abstract 类，也是 abstract 类。 abstract 修饰类抽象类。抽象类中可以有抽象方法，也可以有实现方法。抽象类可以有 private 变量。但最好不要这么干。因为实现类继承了将会无法使用。 abstract 修饰方法抽象方法。abstract 方法必须在 abstract 类或接口中。 内部类Java 中的内部类分为 成员内部类 局部内部类 静态内部类 匿名类 内部类简述成员内部类即在类里面嵌套另一个类，内部类可以直接访问外部类 private 实例属性。也就是说，成员内部类可以无条件访问外部类的成员。 实例化方法： 1内部类名 实例名 = 外部类实例名.new 内部类名(); 局部内部类局部内部类是定义在一个方法或者一个作用域里面的类，它和成员内部类的区别在于局部内部类的访问仅限于方法内或者该作用域内。局部内部类就像是方法里面的一个局部变量一样，不能有public、protected、private 以及 static 修饰符。 静态内部类与非静态内部类不同，静态内部类的实例化 不需要一个外部类的实例为基础，可以直接实例化。 只有静态内部类才可以声明静态方法。静态方法不可以使用非静态变量。 实例化方法： 1内部类名 实例名 = new 内部类名(); 匿名类通常情况下，要使用一个接口或者抽象类，都必须创建一个子类，有的时候，为了快速使用，直接实例化一个抽象类，并“当场”实现其抽象方法。这就是匿名类。 简单地说，匿名类就是声明一个类的同时实例化它。 匿名类可以用 lambda 表达式替代。 在匿名类中使用外部的局部变量，外部的局部变量必须修饰为final （但 jdk 1.8 以后不用声明为 final， jdk 会为你加） 12345678910111213141516171819202122232425class jump implements Runnable { public void run(){ System.out.println(\"jump now\"); }}public class test { public static void main(String[] args) { //不使用匿名类 Runnable r = new jump(); Thread t1 = new Thread(r); t1.start(); //使用匿名类 new Thread(new Runnable() { @Override public void run() { System.out.println(\"swim now\"); } }).start(); //使用 lambda 表达式 new Thread( () -&gt; System.out.println(\"go away now\")).start(); }} 为什么使用内部类 ？ 每个内部类都能独立的继承一个接口的实现，所以无论外部类是否已经继承了某个(接口的)实现，对于内部类都没有影响。内部类使得多继承的解决方案变得完整。 方便将存在一定逻辑关系的类组织在一起，又可以对外界隐藏。 方便编写事件驱动程序 方便编写线程代码 为什么成员内部类可以无条件访问外部类的成员？当我们有一个外部类 Outter，里面包含一个成员内部类 Inner，编译之后会生成两个文件： Outter.class Outter$Inner.class 在 Outter$Inner.class 文件中，可以找到： 1final com.jerrysheh.Outter this$0; 也就是说，编译器会默认 为成员内部类添加了一个指向外部类对象的引用 那么这个引用如何赋初值呢？看一下构造器： 1public com.jerrysheh.Outter$Inner(com.jerrysheh.Outter); 也就是说，内部类对象被构造的时候，自动传入了一个外部类对象的引用，因此可以在成员内部类中随意访问外部类的成员。 为什么局部内部类和匿名内部类只能访问局部final变量？方法 A 中定义了局部内部类 B，当 方法A 执行完毕，已经结束作用域，如果内部类 B 的方法（可能由另一个线程执行）还没结束，但由于 A 结束作用域，方法 A 的变量 a 会不可访问。为了解决这一问题， Java 采用了 复制 的手段，即把方法 A 的变量 a 复制一份到内部类 B 的常量池。 但是复制过后会产生不一致的问题，也就是内部类的方法修改了 a ， 但是外部类的 a 没有改变。 因此，Java 规定，只能访问 final ，以避免上述问题。 引申: Java是如何复制的 ？ 如果局部变量的值在编译期间就可以确定，则直接在匿名内部里面创建一个拷贝。如果局部变量的值无法在编译期间确定，则通过构造器传参的方式来对拷贝进行初始化赋值。 枚举类的用法枚举类有多少个实例，就会调用多少次构造方法。 例子一定义了一个枚举类，成员 KBMH(&quot;hello&quot;) ，如果括号里面是 String 的话，下面相应的要定义一个 String ID 。 12345678910111213141516public enum ComicTypeEnum { KBMH(\"/category/weimanhua/kbmh\"), // 恐怖漫画 GSMH(\"/category/weimanhua/gushimanhua\"), // 故事漫画 QQMH(\"/category/weimanhua/qiqumanhua\"), // 奇趣漫画 GXMH(\"/category/weimanhua/gaoxiaomanhua\"); // 搞笑漫画 String ID; ComicTypeEnum(String ID){ this.ID = ID; } public String getID() { return ID; }} 使用： 1String storyComic = ComicTypeEnum.GSMH.getID(); 例子二定义枚举类型： 123456789enum Weekday { MON, TUE, WED, THU, FRI, SAT, SUN}; 使用： 1Weekday startDay = Weekday.MON; 面向对象的五个基本原则单一职责原则（Single-Resposibility Principle）一个类，最好只做一件事，只有一个引起它的变化。单一职责原则可以看做是低耦合、高内聚在面向对象原则上的引申，将职责定义为引起变化的原因，以提高内聚性来减少引起变化的原因。 开放封闭原则（Open-Closed principle）软件实体应该是可扩展的，而不可修改的。也就是，对扩展开放，对修改封闭的。 Liskov替换原则（Liskov-Substituion Principle）子类必须能够替换其基类。这一思想体现为对继承机制的约束规范，只有子类能够替换基类时，才能保证系统在运行期内识别子类，这是保证继承复用的基础。 依赖倒置原则（Dependecy-Inversion Principle）依赖于抽象。具体而言就是高层模块不依赖于底层模块，二者都同依赖于抽象；抽象不依赖于具体，具体依赖于抽象。 接口隔离原则（Interface-Segregation Principle）使用多个小的专门的接口，而不要使用一个大的总接口","link":"/post/ba7990ce.html"},{"title":"Java简明笔记（十一）并发编程","text":"关于并发的理论基础，见另一篇 聊聊并发和并发模型 在 Java 中创建线程在 Java 中，线程是 java.lang.Thread 或其子类中的实例。通过 new 一个线程实例并调用 start 方法来启动线程。 12Thread thread = new Thread();thread.start(); 但是我们总得指定线程做一些事，可以用两种方式来指定。 方式一：继承 Thread 类123456789public class MyThread extends Thread { @Override public void run(){ System.out.println(\"MyThread running\"); }}Thread myThread = new myThread();myThread.start(); 方式二：实现 Runnable 方法(推荐)创建一个类实现 Runnable 方法 12345678910class MyRunnable implements Runnable { @Override public void run(){ System.out.println(\"MyRunnable running\"); }}MyRunnable myRun = new MyRunnable();Thread thread = new Thread(myRun， \"第二个参数指定线程名字\");thread.start(); 匿名类或lambda表达式方式直接在 runnable 接口上实现匿名类 12345678910// 匿名类Runnable myRunnable = new Runnable(){ @Override public void run(){ System.out.println(\"Runnable running\"); }}// lambdaRunnable myRunable2 = ()-&gt; System.out.println(\"Runnable running\") lambda表达式 1Thread t = new Thread( ()-&gt; System.out.println(\"do something\")); 特别提醒： 调用 .start() 方法才是启动线程，而调用 .run() 方法只是在当前线程上去执行 run 函数，并没有开启新线程。 .stop() 方法已经被标记为 deprecated。因为它无法保证被停止的线程的状态，例如转账方法钱款已经转出，却还没有转入目标账户就被中止了。正确停止线程的方式应该是给定一个 boolean 变量，在方法中将其置 false。可以在 run 方法中加入 while() 循环 ，当主线程将 boolean 置 false， 子线程的 while 不再执行，从而 run 方法结束，线程退出。 .suspend()方法也被标记为 deprecated。因为可能导致死锁：被挂起的线程持有锁，等待恢复，而将其挂起的线程又在等待该锁，导致死锁。 方式三：实现 Callable 方法(可回调)需结合 Future 和 线程池 使用。参见：Java并发编程之并发工具 竞争条件和临界区当多个线程同时访问一块共享区域的时候，就会产生竞争条件。考虑下面的例子： 12345678public class Counter { protected long count = 0; public void add(long value){ this.count = this.count + value; }} 从 Java 虚拟机的角度看，add 方法并不是一个原子操作，而是分为三步： 将 this.count 读进 CPU 寄存器 在寄存器里 + 数值 将寄存器的值写回内存 假如有A、B两个线程同时执行 add 方法，那么可能发生： 12345678this.count = 0;A: 将 this.count 读进 CPU 寄存器 (0)B: 将 this.count 读进 CPU 寄存器 (0)B: 在寄存器里 + 2B: 将寄存器的值 (2) 写回内存， this.count 现在是 2A: 在寄存器里 + 3A: 将寄存器的值 (3) 写回内存， this.count 现在是 3 我们期望的值是5，而结果却是3。如何解决呢？可以用 Java 提供的 synchronized 同步代码块 或者 锁结构 或者 java.util.concurrent.atomic 里面的 原子变量 来解决。 同步代码块 12345678public void add(int val1, int val2){ synchronized(this.sum1Lock){ this.sum1 += val1; } synchronized(this.sum2Lock){ this.sum2 += val2; }} 线程安全和资源共享什么是线程安全？《Java并发编程实战》的作者 Brian Goetz 对线程安全的定义是：当多个线程访问某个对象时，不管运行时环境采用何种调度方式或者如何交替执行，并且调用方不需要任何额外的同步操作，调用这个对象的行为都能获得正确的结果，那么就称这个对象是线程安全的。 如果一段代码是线程安全的，那么就不会发生竞争条件。反过来说，对于非线程安全的代码，多个线程同时修改共享资源的时候，就会发生竞争条件。 因此我们得先知道 Java 中哪些资源是共享的，哪些是不共享的。 局部本地变量（完全线程安全）局部变量存储在每个线程自己的栈内存中，不会共享，是线程安全的。 123456public void someMethod(){ long threadSafeInt = 0; threadSafeInt++;} 引用变量（部分安全）局部引用本身跟局部变量一样，其本身是不共享。但是引用指向的对象就不一定了，因为所有的对象存储在共享的堆里面的，因此不是线程安全的。但如果对象是局部方法里面声明的，那就是安全的。 类成员变量（不安全）很明显成员变量（类变量）不是线程安全的。考虑下面的例子，当两个线程同时执行了 add 方法。结果很难预测。 1234567public class NotThreadSafe{ StringBuilder builder = new StringBuilder(); public add(String text){ this.builder.append(text); }} Thread Control Escape RuleThread Control Escape Rule（线程控制逃逸规则）：如果一个资源从创建、使用、到释放(dispose)这整个过程都由相同的一个线程负责，其控制权不会交给其他线程，那么整个资源就是线程安全的。 这里的资源，可以是一个对象、数组、文件、数据库连接、socket等等。在 Java 中，我们无法手动释放资源，因此释放可以理解为失去该对象的引用或置空(nulling)的过程。 但是注意，有时候尽管一个对象是线程安全的，但是应用不一定是安全的。比如，线程1和线程2分别创建了数据库链接 connection1 和 connection2， connection 本身是安全的，但是通过 connection 去访问数据库，可能造成不安全的后果。比如： 1234Thread 1 checks if record X exists. Result = noThread 2 checks if record X exists. Result = noThread 1 inserts record XThread 2 inserts record X 线程安全和不可变性竞争条件只发生在多个线程同时写一个资源的过程，读的过程并不会造成竞争条件。因此，我们可以用不可变（Immutable）这个特性，来确保线程安全。具体的做法是： 通过构造器传递值，没有 setter 修改时返回一个新的对象，而不是在该对象上变更值 12345678910111213141516171819public class ImmutableValue{ private int value = 0; // 构造器传值 public ImmutableValue(int value){ this.value = value; } public int getValue(){ return this.value; } // 如果要修改，直接返回一个新的ImmutableValue对象，而不是在该对象上变更值 public ImmutableValue add(int valueToAdd){ return new ImmutableValue(this.value + valueToAdd); }} 此时，ImmutableValue对象本身是安全的，但是注意，使用这个对象时，也可能不是安全的。 考虑下面的例子：Calculator 对象使用了 ImmutableValue，当有多个线程同时调用 Calculator 的 setValue 或 add 方法，那 Calculator 的类变量 ImmutableValue 的值无法确定。 123456789101112131415public class Calculator{ private ImmutableValue currentValue = null; public ImmutableValue getValue(){ return currentValue; } public void setValue(ImmutableValue newValue){ this.currentValue = newValue; } public void add(int newValue){ this.currentValue = this.currentValue.add(newValue); }} 需要对 Calculator 类的 getValue(), setValue(), 和 add() 方法添加 synchronized 修饰符，这时候才是真正安全。 从内存模型看并发在冯诺依曼计算机架构中，主存和 CPU 中间，往往有 Cache 缓冲，CPU 内部也有用于临时数据处理的寄存器。在Java虚拟机中，内存模型大致可以分为堆和栈。每个线程都有单独的线程栈，不会共享，而所有的对象都存放在共享的堆里。 正因为对象和变量可以存储在不同的内存区域，因此会导致一些问题。最主要的两个是： 可见性问题：一个线程修改了变量，但是还保存在线程栈中，没有写回内存。另一个线程就看不到这个修改。 竞争条件：两个线程同时修改类变量，结果不可预期。 在 Java 中，竞争条件通过 synchronized 同步代码块解决，可见性问题通过声明 volatile 关键字解决。 使用 Lock 类解决竞争条件问题 在 java.util.concurrent.locks 包里面，有一些锁相关类，用于给程序代码加锁。当多个线程访问加锁代码时，只有一个线程能访问临界区。其中用得最多的是 ReentrantLock。 提醒：解锁操作最好放在 finally 块，这样抛出异常时也能正常解锁。此外，如果使用锁就不能用 try-with-resource 了。 12345678910111213141516class Test{ // 声明一个锁对象 Lock lock = new ReentrantLock(); public void doSomething(){ // 在临界区加锁 lock.lock(); try{ // do something } finally { // 临界区结束释放锁 lock.unlock(); } }} ReentrantLock支持带参构造函数，表示一个公平锁。先申请锁的线程将会先得到执行。但也不是绝对的，因为调度器有可能选择忽略一个线程。使用公平锁比常规锁要慢，必要时才考虑使用。 1ReentrantLock(boolean fair); 条件对象有时候，一个线程拿到锁执行权，进入了临界区，却因为某些条件不满足而无法执行，这时候我们应该及时释放锁，直到条件满足了再重试。这个条件，我们就称为条件对象（或条件变量，conditional variable）。比如说，在银行系统中，一个线程获得了从A账户转出1000元的执行权，但是该线程进入到临界区时发现A账户余额不足1000，无法转账，此时应该释放锁，而不是阻塞死等。 在 Java 中，Condition 类用来表示一个条件对象。 12345678910111213141516171819202122class Bank{ Lock bankLock = new ReentrantLock(); private Condition sufficientFunds; // 在构造器里实例化条件对象 public Bank(){ sufficientFunds = bankLock.newCondition(); } // 转账 public void transfer(){ bankLock.lock(); // 余额不足，释放锁 while(accounts[from] &lt; amount) sufficientFunds.await(); // 余额充足，转账 // ... }} 记住，永远用 while 来判断条件，而不是 if。如果条件满足，调用条件对象的 await() 方法，该线程即释放锁并挂起等待，直到另一个线程调用了 signal() 或 signalAll() 方法。 使用读写锁当很多线程读取数据而很少线程修改数据时，可以考虑使用 ReentrantReadWriteLock（读写锁）。 1234567891011121314151617181920212223242526// 1. 声明一个读写锁private ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();// 2.抽取读锁和写锁private Lock readLock = rwl.readLock();private Lock writeLock = rwl.writeLock();// 3. 读取方法加读锁public double getTotal(){ readLock.lock(); try{ // ... } finally { readLock.unlock(); }}// 4. 修改方法加写锁public void transfer(){ writeLock.lock(); try{ // ... } finally { writeLock.unlock(); }} 使用 synchronizedsynchronized 也是用于解决竞争条件问题。但语法比 ReentrantLock 简单。 123456789// 用于实例方法public synchronized void add(int value){ this.count += value;}// 用于静态方法public static synchronized void add(int value){ count += value; } 同步是一种高开销的操作，应该尽量减少同步的内容。把 synchronized 放在方法里，可能太过于粗粒度了，这样会损失一些并发性，synchronized 也可以单独放在临界区。缩小同步控制的范围。 123456// 用于部分临界区代码块public void add(int value){ synchronized(this){ this.count += value; }} 跟 ReentrantLock 类似，当有条件对象不满足时，进入 synchronized 的线程也是需要立即释放锁并等待条件满足。synchronized 内置了一个条件对象，不用我们显式声明。我们直接在代码中调用 wait() 方法就可让当前线程等待，直到其他线程调用了 notify() 或 notifyAll() 。 12345678public synchronized void add(int value){ // 条件不满足，等待 while(accounts[from] &lt; amount) wait(); // 条件满足，执行业务 this.count -= value;} 我该使用 synchronized 还是 ReentrantLock ？《Java核心技术》的作者 Cay S. Horstmann 给我们的建议是，最好两者都不要用，而是用 java.util.concurrent 包提供给我们的并发工具，如阻塞队列。当 concurrent 并发工具都不能满足时，才考虑用 synchronized 或 ReentrantLock。首选 synchronized 因为它编写简单，而且新版JDK自带锁优化能够减少一些锁开销。 当你需要这三样功能之一时，才考虑用 ReentrantLock： 需要公平锁； 需要有多个条件对象； 线程尝试获得锁失败时可选择放弃而去做别的事情 java.util.concurrent.locks.Lock 12345678// 尝试获得锁，成功返回true，失败返回false(根据返回值用if-else语句)boolean tryLock();// 在给定实践内不断尝试获得锁boolean tryLock(long time, TimeUtil unit);// 获得锁，但不确定地发生阻塞。如果线程被中断，抛出 InterruptedExceptionvoid lockInterruptibly(); 参考：《Java核心技术 卷I》第10版p654 Volatile 关键字可见性问题由于 CPU 有 Cache 缓存，一个线程修改的数据，保存在某CPU核心的 Cache 缓存里，还未写回主存，运行在另一个CPU核心的线程可能看不到修改的值。这就是可见性问题。 Volatile 用于解决可见性问题，被 Volatile 关键字修饰的变量，永远是储存在主存里面的。线程每次都从主存读取或往主存写入，而不是往 CPU Cache 读写。 之前一直有个疑问，如果其他 CPU Cache 已经缓存了数据，那你及时写回主存又有什么用呢？其他 CPU 从 Cache 读的数据还是旧的值呀？ 事实上，对 Volatile 修饰的共享变量进行写操作时，在编译成汇编的代码里会加一个 lock 前缀，这个 lock引发了两件事情： 将当前 CPU Cache 的数据写回主存 使其他 CPU Cache 缓存了该内存地址的数据无效（CPU会嗅探在总线上传播的数据来检查自己的缓存是不是过期了） 有了第二点保证，就能让其他 CPU 下次要用到该值时，不得不去主存里拿，因为之前缓存的已经失效了。 什么时候用 Volatile很多时候，只使用 Volatile 是不够的，通常都要配合 synchronized 。只有当满足以下条件时，才只使用 Volatile： 对变量的写入操作不依赖变量的当前值（count++就不满足），或者你的程序只有一个线程更新该变量的值(其他线程可访问但不可修改)。 访问变量时不需要加锁 该变量不会与其他状态变量一起纳入不变性条件中 线程通信（Signaling）线程通信用于线程与线程之间互相发送信号，或者让线程等待其他线程的信号以协调工作。有两种线程通信的方式，其一是消息队列，其二是共享对象。Java采用的是共享对象的方式。 通过共享对象发送信号线程之间通信最简单的方式就是通过设置一个所有线程都可访问的共享对象变量，通过改变它的值来表示一个信号。例如，线程A对一个共享的 boolean 变量设置为 true，线程B检查该变量值的变化并做出处理。注意，这个共享变量必须要做同步操作，例如 synchronized 12345678910111213public class MySignal{ protected boolean hasDataToProcess = false; public synchronized boolean hasDataToProcess(){ return this.hasDataToProcess; } public synchronized void setHasDataToProcess(boolean hasData){ this.hasDataToProcess = hasData; }} 考虑上面的例子，线程A和线程B分别持有 Mysignal 的引用，线程A 将 hasDataToProcess 设置成 true， 线程B不断查询 hasDataToProcess 的状态，直至其被 线程A 设置成 true 即可开始处理一些事情。线程B不断查询的这个过程，称为 忙等待（busy wait）。 123while(!sharedSignal.hasDataToProcess()){ //do nothing... busy waiting} wait(), notify() 和 notifyAll()忙等待会损耗大量 CPU 资源，因此 Java 提供了一些内置的机制，能够让信号未到来之前使线程处于非活跃（inactive）状态。等信号来了之后再唤醒它。这样就不用一直忙等。 死锁线程A持有 1 资源，同时需要 2 资源， 线程B 持有 2 资源，同时需要 1 资源，但是 1 资源 和 2 资源都是互斥的。此时，A线程 在等待 B线程 释放 2 资源，B线程在等待 A线程 释放 1 资源，结果谁都无法释放，谁也都得不到资源。这就是死锁。","link":"/post/727d207c.html"},{"title":"Java简明笔记（十七）注解","text":"注解魔法注解是一种标记。在 Java 中，随处可见@Override、@Deprecated这样的注解。说实话，Java的注解经常不被重视，以至于学习的时候习惯性略过。在学了Spring框架后发现Spring使用了大量的注解来简化开发和配置，回过头来才发现注解的魅力。 插句题外话，一开始让我感受到注解的强大和优雅的，不是Java，而是在学习 Python 时遇到的 decorator，如下： 1234567891011def draw_lighting_decorator(func): @functools.wraps(func) def wrapper(): func() print(\"lighting\") return wrapper@draw_lighting_decoratordef draw(): print(\"draw\") 只需通过@draw_lighting_decorator标记，就能让draw()函数执行后自动执行print(&quot;lighting&quot;)，而无需修改draw()函数本身。 在 Spring 框架中也是，如下： 1234567@Servicepublic class ProductService { @Autowired private ProductMapper productMapper; //...} 只需使用@Service标记，就能让框架知道这是一个MVC中的Service，只需通过@Autowired 就能实现在Service中自动注入一个mapper组件。 这到底是什么魔法？ Override注解探究Override是一个注解接口，在 java.lang 包下： 1234567package java.lang;import java.lang.annotation.*;@Target(ElementType.METHOD)@Retention(RetentionPolicy.SOURCE)public @interface Override {} 它似乎什么都没干，就能检查父类中有一个同名的方法。然而，不是这样的！Annotations仅仅是元数据，和业务逻辑无关。也就是说，Annotations只是一个标记，而对做了这个标记的地方要做什么业务逻辑，是由其他代码来实现的。就@Override这个注解来说，用户是JVM，它在字节码层面来实现检查重写的业务逻辑。 我们完全可以写自己的注解，在需要的地方标记上，然后在另一个地方提供业务逻辑。 自定义注解定义注解12345@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface IpAddress { String ip() default \"127.0.0.1\";} @Target表示该注解可以作用在哪里（方法、类、属性） @Retention表示该注解的生命周期 RetentionPolicy.SOURCE – 在编译阶段丢弃。这些注解在编译结束之后就不再有任何意义，所以它们不会写入字节码。@Override, @SuppressWarnings都属于这类注解。 RetentionPolicy.CLASS – 在类加载的时候丢弃。在字节码文件的处理中有用。注解默认使用这种方式。 RetentionPolicy.RUNTIME– 始终不会丢弃，运行期也保留该注解，因此可以使用反射机制读取该注解的信息。我们自定义的注解通常使用这种方式。 使用注解1234567891011121314public class AnnotationExample { @IpAddress(ip = \"192.168.1.1\") public void doSomething(){ System.out.println(\"do\"); } public static void main(String[] args) throws NoSuchMethodException { AnnotationExample exam = new AnnotationExample(); IpAddress addr = exam.getClass().getMethod(\"doSomething\").getAnnotation(IpAddress.class); String ip = addr.ip(); // 192.168.1.1 }} 在 doSomething() 方法上的@IpAddress 注解只是标记，真正的业务逻辑在main()方法里做。通过反射的方式，获取类中某个方法的注解，再对注解进行解析。 注解 + AOP 实现业务增强在 Spring 框架中，经常可以见到使用 @Translaction 注解就可以自带事务，叫做 声明式事务。事实上，被 @Translaction 标记的方法，Spring 在另一个地方会通过反射+动态代理的方式，对该方法进行增强，从而加入事务功能，确实很“魔法”。 未完待续 参考： Java中的注解到底是怎么工作的？","link":"/post/b3112bec.html"},{"title":"Java简明笔记（五） 泛型编程","text":"什么是泛型类假设我们现在有一个存储字符串字典键值对的类，就像这样 12345678910111213public class Entry { private int key; private String value; // 构造函数：int 类型的 key， String 类型的 value public Entry(int key, String value) { this.key = key; this.value = value; } public int getKey() { return key; } public String getValue() { return value; }} 在这个类中，我们用 int 类型来存储 key 值， 用 String 类型来存储 value 值。 现在，老板要求，除了 int 类型的 key 和 String 类型的 value之外，还得提供其他类型的 key 和 value 。 比如 double 类型的 key， boolean 类型的value。 我们不可能写很多个相似的类，只是换一下类型。8种基本数据类型或许可以这么干，但是存储的是抽象数据类型呢？我们不可能所有类型都写一个对应的类。 为了解决这个问题，我们可以用 Java 泛型： 只写一个类，实例化的时候再写明是什么类型就好了。这就是泛型类。 泛型仅仅是java的语法糖，它不会影响java虚拟机生成的汇编代码，在编译阶段，虚拟机就会把泛型的类型擦除，还原成没有泛型的代码。 123456789101112public class Entry&lt;K, V&gt; { private K key; private V value; public Entry(K key, V value) { this.key = key; this.value = value; } public K getKey() { return key; } public V getValue() { return value; }} 实例化泛型类 12// new 后面尖括号的类型参数可以省略Entry&lt;String, Integer&gt; entry = new Entry&lt;&gt;(\"Fred\", 42); 泛型方法泛型类是带类型参数的类，同理，泛型方法是带类型参数的方法。 一个普通类的泛型方法的例子，swap方法用于交换任何数组中的元素。声明一个泛型方法时，类型参数放在返回类型之前，在这个例子中是 void 前面的 ，说明 T 是一个泛型类型。 123456789public class Array { public static &lt;T&gt; void swap (T[] array, int i, int j) T temp = array[i]; array[i] = array[j]; array[j] = temp;}String[] friends = ...;Array.swap(friends, 0, 1); 调用泛型方法时，不需要指定类型参数。编译器会自动推断。当然，指定也不会错。如 1Array.&lt;String&gt;swap(friends, 0, 1); 类型限定（extends）假设有一个类对象的ArrayList，该类实现了AutoCloseable接口。里面有一个关闭所有的方法。 123public static &lt;T extends AutoCloseable&gt; void closeAll(ArrayList&lt;T&gt; elems) throws Exception { for (T elem: elems) elem.close();} 观察&lt;T extends AutoCloseable&gt;， 我们用 extends 限制了 T 类型是AutoCloseable的子类型。以防传入了一些奇奇怪怪不可接受的类型。 多个限制可以用 &amp;， 如&lt;T extends Runnable &amp; AutoCloseable&gt; 类型变异和通配符// TODO 遇到相关问题时再补充","link":"/post/76bad10f.html"},{"title":"Java简明笔记（十三）JDBC","text":"假设电脑已经安装有 MySQL，并在里面有一些表。现在，我们想通过 Java，来访问数据库里的表。 JDBC (Java DataBase Connection) 指的就是通过Java访问数据库。 这是我的数据库情况。 JDBC的连接首先到 mySQL 的官网，下载 Connectors/J 驱动，下载完解压出其中的 jar 包，放到项目的依赖里（IDEA - File - Project Structure - Modules - Dependencies - “+” 选择刚刚解压的jar文件）。 初始化驱动在Java中，使用 Class.forName来初始化驱动（这一步在 jdk 1.6 以后已经不是必须） 建立数据库连接建立与数据库的Connection连接，是通过 DriverManager 类的getConnection方法来实现的，因此首先要创建一个Connection实例。 1Connection c = DriverManager.getConnection(url,user,psw); getConnection方法接收三个参数，连接地址，用户名、密码。或者接收一个参数连接地址，该连接地址里已经URL构造了用户名和密码。 连接地址需要提供： 数据库所处于的ip：127.0.0.1 (本机) 数据库的端口号： 3306 （mysql专用端口号） 数据库名称： class_info 编码方式： UTF-8 账号： root 密码： admin 123456789101112131415161718192021222324package com.jerrysheh;import java.sql.*;public class go { public static void main(String[] args) throws SQLException { String base_url = \"jdbc:mysql://127.0.0.1:3306/\"; String DB_name = \"class_info\"; String Encoding = \"UTF-8\"; String user = \"root\"; String psw = \"9501\"; String SSL = \"false\"; String url = String.format(\"%s \\ %s \\ ?characterEncoding=%s \\ &amp;user=%s \\ &amp;password=%s \\ &amp;useSSL=%s\" \\ ,base_url,DB_name,Encoding,user,psw,SSL); Connection c = DriverManager.getConnection(url,user,psw); System.out.println(\"连接成功：\" + c); }} 这样就与数据库连接成功了。 如果没有添加&amp;useSSL=false, IDEA 会报一个 WARN Tue Mar 20 18:39:15 CST 2018 WARN: Establishing SSL connection without server’s identity verification is not recommended. According to MySQL 5.5.45+, 5.6.26+ and 5.7.6+ requirements SSL connection must be established by default if explicit option isn’t set. For compliance with existing applications not using SSL the verifyServerCertificate property is set to ‘false’. You need either to explicitly disable SSL by setting useSSL=false, or set useSSL=true and provide truststore for server certificate verification. 获取执行对象 statement成功连接数据库以后，我们要创建一个可以对数据库进行增删查改等操作的对象，叫做statement。 12// 注意，IDE提示有多个 statement，这里选择java.sql.StatementStatement s = c.createStatement(); 执行 SQL 语句有了可以对数据库进行操作的statement后，我们就可以执行数据库语句了。 如果需要返回结果，需要用ResultSet对象。 12String sql = \"select * from my_table\";ResultSet rs = s.executeQuery(sql); 关于 ResultSet 的用法，可以参考Oracle官方文档 一般我们是用 rs.next()去读取 123456789String sql = \"select * from my_table\";ResultSet rs = s.executeQuery(sql);//如果有数据，rs.next()返回truewhile(rs.next()){ System.out.println(rs.getInt(\"stu_id\") + \"\\t\" + rs.getString(\"stu_name\") + \"\\t\" + rs.getString(\"stu_phone_number\"));} rs.getInt()方法，可以接收 String 参数，列名，如上面例子所示。 也可以接收 Int 参数， 列号。 如rs.getInt(2)就是返回数据库的第二列。 rs.getInt(1) 是 Java 自带 API 里， 唯二的其中一个，1作为起始的，一般都是 0 为起始。 另一个是PreparedStatement，下面将会讲到。 输出 1231 张三 131122995202 李四 132110123453 王五 13711155560 跟我的数据库表正好匹配 关闭数据连接数据库是有限资源，使用完毕需要断开连接 123s.close();rs.close();c.close(); 可以用 java 7 的特性 try-with-resource 来自动管理连接，这样就不用每次都去手动关闭。 1234567891011try ( Connection c = DriverManager.getConnection(url,user,psw); Statement s = c.createStatement(); ) { String sql = \"select * from my_table\"; s.execute(sql); } catch (SQLException e) { e.printStackTrace(); } 增、删、改CRUD 是最常见的数据库操作，即增删改查 C 增加(Create) R 读取查询(Retrieve) U 更新(Update) D 删除(Delete) 增加 123String sql = \"insert into hero values(null,\" + \"'提莫'\" + \",\" + 313.0f + \",\" + 50 + \")\";s.execute(sql); 删除 12String sql = \"delete from hero where id = 5\";s.execute(sql); 修改 12String sql = \"update hero set name = 'name 5' where id = 3\";s.execute(sql); 使用PreparedStatement和 Statement 一样，PreparedStatement 也是用来执行sql语句的。其优点是，能设置参数指定相应的值，而不是Statement那样使用字符串拼接。 123456789101112131415String sql = \"insert into hero values(null,?,?,?)\";try ( Connection c = DriverManager.getConnection(url,user,psw); PreparedStatement ps = c.prepareStatement(sql); ) { // 设置参数 ps.setString(1, \"je\"); ps.setFloat(2, 313.0f); ps.setInt(3, 50); // 执行 ps.execute(); } catch (SQLException e) { e.printStackTrace(); } PreparedStatement用setString(1,&quot;je&quot;)这样的方式，来给每一个参数设置值，比如 1,”je”，就是第一个？的值设为je 为什么使用PreparedStatement使用Statement： 1String sql = \"insert into hero values(null,\"+\"'提莫'\"+\",\"+313.0f+\",\"+50+\")\"; 使用PreparedStatement 1String sql = \"insert into hero values(null,?,?,?)\"; Statement 采用的是字符串拼接，不仅麻烦，还有被SQL注入的风险 execute、executeQuery 和 executeUpdate 的比较executeQuery用于查询，返回单个结果集 execute 和 executeUpdate都可以执行增加，删除，修改 不同点： execute executeUpdate 可以执行查询语句，然后通过getResultSet，把结果集取出来 不能执行查询语句 返回boolean，true表示执行的是查询语句，false表示执行的是insert,delete,update等类型 返回int，表示有多少条数据受到了影响 获取数据表元数据123456789101112131415161718Connection c = DriverManager.getConnection(url,user,psw);DatabaseMetaData dbmd = c.getMetaData();//获取数据库产品名称dbmd.getDatabaseProductName();//获取数据库产品版本dbmd.getDatabaseProductVersion();//获取驱动版本dbmd.getCatalogSeparator();//获取可用的数据库列表ResultSet rs = dbmd.getCatalogs(); while (rs.next()) { System.out.println(\"数据库名称:\\t\"+rs.getString(1)); } 使用事务当我们对数据库进行一组操作时，假若其中一条语句有误，其他正确的语句被执行并提交到数据库了，有误的语句没有被执行，那么会导致结果不可预期。 我们希望，这组操作要么全部成功，要么全部失败。不要部分成功部分失败。 这时候可以使用事务。 用setAutoCommit(false)来关闭自动提交，这时候语句不会被提交到数据库，直至我们用commit()手动提交。 1234567891011121314c.setAutoCommit(false);// 加血的SQLString sql1 = \"update hero set hp = hp +1 where id = 22\";s.execute(sql1);// 减血的SQL// 不小心写错写成了 updata(而非update)String sql2 = \"updata hero set hp = hp -1 where id = 22\";s.execute(sql2);// 手动提交c.commit(); MYSQL 表的类型必须是INNODB才支持事务 使用 ORMORM （Object Relationship database Mapping） 意思是：对象和关系数据库的映射 简单说，一个对象，对应数据库里的一条记录 首先定义一个 student 类，根据我们的数据库表，这个类应该有三个属性： id、name、phonenumber student.java 1234567891011121314151617181920212223package com.jerrysheh;public class student { int student_id; String student_name; long student_phone_number; public void setStudent_id(int student_id) { this.student_id = student_id; } public void setStudent_name(String student_name) { this.student_name = student_name; } public void setStudent_phone_number(long student_phone_number) { this.student_phone_number = student_phone_number; } public String getStudent_name() { return student_name; }} 然后在主类里，定义getStudent()，传入id，返回student 这个 getStudent() 做了什么事情呢？ 他就是把数据库里查到的每一项，映射给我们 student 对象的每一个属性里去。 比如，数据库里，stu_id 为 1 的 同一行 stu_name 为 “张三”。 那getStudent()做的事情就是，把这个1映射给 student对象的 id 属性， 把 “张三” 映射给student对象的 name 属性。 这样，我们就得到一个表示数据库一行的对象实例了。 这就是ORM技术。 test.java 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.jerrysheh;import java.sql.*;public class go { public static student getStudent(int id) throws SQLException{ String base_url = \"jdbc:mysql://127.0.0.1:3306/\"; String db_name = \"class_info\"; String Encoding = \"UTF-8\"; String user = \"root\"; String psw = \"9501\"; String SSL = \"false\"; String url = String.format(\"%s%s?characterEncoding=%s&amp;user=%s&amp;password=%s&amp;useSSL=%s\",base_url,db_name, Encoding,user,psw,SSL); student s = null; String sql = \"select * from my_table\"; try( Connection c = DriverManager.getConnection(url,user,psw); PreparedStatement ps = c.prepareStatement(sql); ResultSet rs = ps.executeQuery(sql) ){ //ps.setInt(1,id); if (rs.next()){ s = new student(); String name = rs.getString(2); long phone_number = Long.parseLong(rs.getString(3)); s.setStudent_id(id); s.setStudent_name(name); s.setStudent_phone_number(phone_number); } } catch (SQLException e){ e.printStackTrace(); } return s; } public static void main(String[] args) throws SQLException { student s = getStudent(1); String name = s.getStudent_name(); System.out.println(name); }} 我们在 main 里实例化了一个 student， 用 getStudent() 方法去获取一个student对象。 然后我们用getStudent_name()来验证是不是对应数据库里的”张三”。 输出： 123张三Process finished with exit code 0 果然如此！ 其他ORM方法根据ORM映射数据库和ORM的思想，我们可以设计其他几个常用的ORM方法： 把一个student对象插入到数据库中 123public static void add(student s) {} 把一个student从数据库中删除 123public static void delete(student s) {} 更新一个student对象的信息 123public static void update(student s) {} 最后，我们把所有的student数据查询出来，转换为student对象后，放在一个集合中返回 1public static List&lt;student s&gt; list(); 这样，我们的 ORM 就封装好了。 使用 DAODAO （DataAccess Object）， 数据库访问对象 DAO其实就是把数据库相关的操作都封装在类里面，其他地方看不到JDBC的代码 1234567891011121314public interface DAO{ //增加 public void add(Hero hero); //修改 public void update(Hero hero); //删除 public void delete(int id); //获取 public Hero get(int id); //查询 public List&lt;Hero&gt; list(); //分页查询 public List&lt;Hero&gt; list(int start, int count);} 封装接口，然后设计类，实现这个接口。 这样，我们需要数据库信息时，直接通过 DAO，获取封装好的对象，我们就能直接对对象进行操作。 在 Java 中，比较常用的 ORM 框架有 Hibernate和 iBatis，我们可以直接拿来用。这样，就不用繁琐地跟 JDBC 打交道了。","link":"/post/f07211ef.html"},{"title":"Java简明笔记（十五）Java NIO","text":"什么是 Java NIOJava NIO， N 可以理解为 New ，也可以理解为 Non-blocking ，是 Java 1.4 之后新的一套区别于标准 Java IO 和 Java Networking 的 API 。NIO 跟传统的 BIO 之间最大的区别在于 NIO 是面向 Channels 和 Buffers 的，一个线程可以通过 Selector 管理多个 Channels ，继而管理多个连接，在线程进行 IO 操作时不会阻塞。 面向 Channels 和 Buffers普通的IO，面向的是 byte streams（字节流，如FileOutputStream） 和 character streams（字符流，如FileReader），但是 NIO 面向的是 channels 和 buffers 。对于 Channel 来说，数据总是从 channel 写进 buffer 里，然后 Java 从 buffer 取出使用，或者 channel 读 buffer 里的数据，传输到外界。 Channel 有点像流（Stream），在 Java NIO 中，有以下几种 channel： FileChannel DatagramChannel （用于通过 UDP 读写数据） SocketChannel （用于通过 TCP 读写数据） ServerSocketChannel 而 Buffer 就是我们熟悉的缓冲区了。包括： ByteBuffer CharBuffer DoubleBuffer FloatBuffer IntBuffer LongBuffer ShortBuffer MappedByteBuffer（不展开讲） 一个线程，可以让 channel 把数据读进 buffer 中（操作者是 channel ），当 channel 正在读的时候，线程可以做其他事。一旦数据已经读进 buffer 了，线程可以回来处理这些数据。写的情况也是类似。 一个简单的例子Channel 和 Buffer 配合的工作流程如下： 开一个文件 获取 Channel 设置 buffer 让 Channel 将数据读到 buffer 里 数据进入 buffer 调用 buffer.flip() 数据从 buffer 出去 调用 buffer.clear() 或 buffer.compact() 123456789101112131415161718192021222324252627// RandomAccessFile 可以自由读写文件的任意位置，不继承字节流或字符流// 1. 开一个文件RandomAccessFile aFile = new RandomAccessFile(\"data/nio-data.txt\", \"rw\");// 2. 获取 ChannelFileChannel inChannel = aFile.getChannel();// 3. 设置 buffer，由于我们要读字节，因此是 ByteBufferByteBuffer buf = ByteBuffer.allocate(48);// 4. 利用 Channel 将数据读到 buffer 里int bytesRead = inChannel.read(buf);while (bytesRead != -1) { System.out.println(\"Read \" + bytesRead); buf.flip(); while(buf.hasRemaining()){ System.out.print((char) buf.get()); } buf.clear(); bytesRead = inChannel.read(buf);}aFile.close(); 注意： buf.flip() 的作用：当你想从 buffer 里获取数据，应该调用 flip 方法。调用这个方法的时候，buffer 将会从 数据写入模式 切换到 数据读出模式 buf.clear()的作用：当数据全部从 buffer 读出去了，应该调用 clear 或 compact 方法，好让 buffer 重写可以写入。 这两个方法的区别是：clear清除整个缓冲区，compact只清除已经读过的部分。 Capacity, Position 和 Limitbuffer 实际上是一块内存区域可以让你往里面写数据，之后再读到程序里。这块内存区域包含在一个 NIO Buffer 对象里。 在 buffer 中，有 Capacity, Position 和 Limit 这三个概念。position 跟 limit 跟 buffer 是读模式还是写模式有关，而 Capacity 与模式无关。 Capacity顾名思义，Capacity 就是容量。也就是 buffer 缓冲区最多能存储多少 bytes （或者 longs，或 chars ，取决于何种类型的 buffer ） Position当你往 buffer 里写一个单位的数据的时候， position 就 +1， position是当前位置指示器。最大值为 Capacity - 1。 当你从 buffer 里读数据时，同样有一个 position 指示器。当调用 flip ，让 buffer 从写模式转换成读模式的时候， position 会被重置为 0 limit在 buffer 写模式中， limit 等于 capacity，决定了你能往 buffer 里写多少数据。 在 buffer 读模式中，limit 告诉你缓冲取最多有多少数据可以让你读取。也就是说，一开始写模式写了多少数据，会记录在 position 中，一旦你调用 flip 切换到读模式，limit 就是刚刚的 position。 Buffer 的方法flip当调用 flip方法， position 会被置0，然后 buffer 会切换模式（读-&gt;写，或 写-&gt;读），limit 也随之改变。 rewindrewind 可以让 position 变为 0， 好让你重新读刚刚读过的数据，但是模式不变。limit 的值也不会变。 clear() 和 compact()clear清除整个缓冲区，compact只清除已经读过的部分。如果你有一些数据还没读，使用 compact， compact 会把未读的数据放到起始位置，然后把 position 放到最后一个数据的右边。 mark() 和 reset()可以用 mark 方法标记 position，然后做一个其他事后，调用 reset， position 会回到刚刚标记的位置。 Scatter（分散） / Gather（聚集）channel “scatters” 是指，多个 buffer 从一个 Channel 里读取数据。分散读取是以数组的形式，总是先填充前面的 buffer，这意味着不支持动态大小。 123456ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);ByteBuffer[] bufferArray = { header, body };channel.read(bufferArray); channel “gathers” 是指，多个 buffer 把数据写进一个 Channel。如果一个 ByteBuffer 的 capacity 有128字节，但实际只存储了58字节。Gather 只会往 channel 里写这58字节。然后继续写下一个。 12345678ByteBuffer header = ByteBuffer.allocate(128);ByteBuffer body = ByteBuffer.allocate(1024);//write data into buffersByteBuffer[] bufferArray = { header, body };channel.write(bufferArray); 在不同 Channel 之间转换Channel 之间可以互相转换，以 FileChannel 为例，提供了 transferFrom() 和 transferTo() 方法。 1234567891011121314RandomAccessFile fromFile = new RandomAccessFile(\"fromFile.txt\", \"rw\");FileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile(\"toFile.txt\", \"rw\");FileChannel toChannel = toFile.getChannel();long position = 0;long count = fromChannel.size();// 从其他channle转到FileChanneltoChannel.transferFrom(fromChannel, position, count);// 从FileChannel转到其他channlefromChannel.transferTo(position, count, toChannel); 在有些 SocketChannel 的实现中，只会转换 channel 当前有的数据（尽管稍后 SocketChannel 会传来更多数据，但会被忽略） SelectorsJava NIO 有一个 “selectors” 的概念。 selector 可以监控多个 channels 事件的状态（例如，连接已建立，数据已到达等）。因此，只需一个线程即可管理多个 channels ，继而管理多个 connection。在并发量特别大时，传统的IO由于一个线程只负责一个连接，因此会创建大量线程。而用 NIO 的 selector，你甚至可以只用一个线程管理所有连接。 然而，不要一贯认为传统IO多线程就不好。我们总说操作系统在线程切换时有一定开销，然而现代CPU都是多核处理器，不用多线程相当于浪费。 123456789101112131415channel.configureBlocking(false);/*第二个参数设置感兴趣的事件，可选项：SelectionKey.OP_CONNECTSelectionKey.OP_ACCEPTSelectionKey.OP_READSelectionKey.OP_WRITE*/SelectionKey key = channel.register(selector, SelectionKey.OP_READ);// 第三个参数设置附加对象（可选）SelectionKey key = channel.register(selector, SelectionKey.OP_READ, theObject); 使用 Selectors 的 channel 必须设置成 non-blocking 模式。FileChannel 无法设置成 non-blocking 因此无法使用 Selectors。 Socketchannels 则可以。channel.register 的第二个参数设定感兴趣的事件，如连接已建立、客户端accept，准备好可读，准备好可写。如果需要设定多个使用，用或语句。 1int interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE; register 之后会返回一个 SelectionKey，通过它来获取有用信息： 12345678Channel channel = selectionKey.channel();Selector selector = selectionKey.selector(); // 附加对象（可选）selectionKey.attach(theObject);Object attachedObj = selectionKey.attachment(); select 方法Selectors 的 select()方法用于返回准备好的 channel 数量。例如，你设置了若干个 SocketChannel 对 read 感兴趣。当你调用 select() ，将返回当前准备好可以读取数据的 channel 数量。 123int select() // 若无，则阻塞int select(long timeout) // 若无，超时时间内阻塞int selectNow() // 立即返回 当 select 返回大于0的数字，说明有 channel 准备好了，实际上内容封装在 Set&lt;SelectionKey&gt; 里，我们可以取出来然后做相应的动作。完整例子： 1234567891011121314151617181920212223242526272829303132333435363738Selector selector = Selector.open();channel.configureBlocking(false);SelectionKey key = channel.register(selector, SelectionKey.OP_READ);while(true) { int readyChannels = selector.selectNow(); if(readyChannels == 0) continue; Set&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys(); Iterator&lt;SelectionKey&gt; keyIterator = selectedKeys.iterator(); while(keyIterator.hasNext()) { SelectionKey key = keyIterator.next(); if(key.isAcceptable()) { // a connection was accepted by a ServerSocketChannel. } else if (key.isConnectable()) { // a connection was established with a remote server. } else if (key.isReadable()) { // a channel is ready for reading } else if (key.isWritable()) { // a channel is ready for writing } keyIterator.remove(); }} wakeup() 和 close()调用 select() 方法的线程会阻塞，用另一个线程调用 Selector.wakeup() 方法可以让它立即返回。 调用Selector.close()可以关闭 Selector 和所有 SelectionKey ，但 channels 不会被关闭。 什么时候用 NIO，什么时候用传统 IO ？NIO可以只使用一个（或几个）单线程管理多个通道（网络连接或文件），但付出的代价是解析数据可能会比从一个阻塞流中读取数据更复杂。 如果需要管理同时打开的成千上万个连接，这些连接每次只是发送少量的数据，例如聊天服务器，实现NIO的服务器可能是一个优势。同样，如果你需要维持许多打开的连接到其他计算机上，如P2P网络中，使用一个单独的线程来管理你所有出站连接，NIO可能是一个优势。 如果你只有少量的连接但是每个连接都占有很高的带宽，同时发送很多数据，传统的IO会更适合。 参考教程：java-nio","link":"/post/44627f59.html"},{"title":"Java简明笔记（十二） IO编程","text":"文件对象 File用过 Linux 的一定知道，“一切皆文件”和“一切皆文本流”的思想。在 Java 中，普通文件和文件夹都是文件对象，用File表示。 文件对象的常用方法new 一个文件对象，用getAbsoluteFile()返回这个File对象形式的路径，用getAbsolutePath()返回字符串形式的路径。 1234567891011121314151617import java.io.File;public class IO { public static void main(String[] args) { //创建文件 File txt = new File(\"D:\\\\JavaTest\\\\t.txt\"); System.out.println(txt.getAbsoluteFile()); //创建目录 File dir = new File(\"D:\\\\JavaTest\"); System.out.println(dir.getAbsolutePath()); //将dir目录作为创建文件的路径 File xml = new File(dir,\"run.bat\"); System.out.println(xml.getAbsolutePath()); }} 我们用 new 创建的文件，并不一定在物理磁盘上存在，用exists()判断是否真实存在。 123//如果物理磁盘上存在t.txt，返回 trueFile txt = new File(\"D:\\\\JavaTest\\\\t.txt\"); System.out.println(txt.exists()); 用isDirectory()判断是否是一个目录，用isFile()判断是否是一个普通文件，用length()获取文件长度。 先在 D:\\JavaTest 创建一个 t.txt 文件，然后里面写 hello， 保存 1234567public static void main(String[] args) { //创建文件 File txt = new File(\"D:\\\\JavaTest\\\\t.txt\"); if (txt.exists()){ System.out.println(txt.length()); }} 输出 5，因为 hello 正好长度是 5 。如果文件在磁盘上不存在，则没有输出。如果是目录，输出 0。 用getParent()以 字符串 形式获取文件所在目录，用getParentFile()以 File对象 形式获取文件所在目录。 用dir.list()以 字符串数组 形式获取目录下所有文件（不包含子文件(夹)），当然，有dir.listFile()，相信你知道如何用。 用f.mkdir()创建文件夹，若父文件夹不存在，则创建无效。用f.mkdirs()创建文件夹，若父文件夹不存在，则先创建父文件夹。 用f.delete()删除文件。用f.deleteOnExit()在JVM结束的时候删除文件（通常是临时文件） 例子：遍历找出最大文件遍历文件夹下的文件和目录，并找出最大的文件 1234567891011121314151617181920212223public static void main(String[] args) { //定义一个文件目录 File folder = new File(\"D:\\\\Documents\"); //列出目录下的所有子文件和子目录，存入File[]数组 File[] foldersAndFiles = folder.listFiles(); long length = 0; String name = \"\"; //空指针异常检查 if (foldersAndFiles != null){ //遍历子目录和子文件，记录最大长度的那个 for (File eachFile : foldersAndFiles) { if (eachFile.length() &gt; length){ length = eachFile.length(); name = eachFile.getName(); } } } System.out.printf(\"最大的文件是：%s \\n 其大小为：%d\",name,length);} 例子：遍历输出目录下的文件（包括子目录里的文件）12345678910111213141516171819202122232425262728import java.io.File;import java.io.IOException;public class IO { public static void main(String[] args) { File parentFolder = new File(\"D:\\\\Documents\"); printSub(parentFolder); } private static void printSub (File parentFolder) throws NullPointerException{ File[] folders = parentFolder.listFiles(); //遍历子目录和子文件 for (File f : folders) { //如果是文件，打印 if (f.isFile()){ System.out.println(f); } //如果是目录，递归调用这个方法 if (f.isDirectory()){ printSub(f); } } }} 输入输出流如果说， File 是表示 文件 的对象， 那么流就是表示 数据在Java程序和文件之间流动 （流动可以是流出，也可以是流入）的对象。 流的概念在 Java API 中，可以从Java程序向外部写入字节序列的对象叫输出流，相反，可以从外部向Java程序读入字节序列的对象叫输入流。 输出流：Java → 外部 输入流：外部 → Java 这里的外部，通常是指文件，当然也可以是网络，甚至内存。 InputStream 和 OutputStreamJava中定义了两个抽象类，InputStream和OutputStream，是 Java IO 的基础。这两个抽象类都有一个抽象方法read()和write()，用于读入和写出一个字节并返回该字节（当遇到结尾时返回-1）。因此，实现这两个抽象类的子类，都必须重写read()或write()方法。 1234567abstract int read(){}abstract void write(int b){} 举个实现的例子，比如 FileInputStream 就实现了从某个文件中读入一个字节。 下面是我们常用的 read()实现方法，它读入一个字节数组，并返回实际读入的字节数。或者在碰到流的结尾时返回-1. 123int read(byte[] b) {} read()和write()方法在执行时是阻塞的（通常是因为网络延迟）。可以用available（）方法检查当前可读入的字节数量。 当我们读写完毕后，切记用close()方法来关闭IO流，以释放系统资源。 例子：向文件写字节创建文件 -&gt; 判断父目录在不在 -&gt; 写入字节 1234567891011121314151617181920public static void main(String[] args) throws IOException { File parentFolder = new File(\"D:\\\\JavaTest\"); writeByte(parentFolder);}private static void writeByte (File parentFolder) throws NullPointerException, IOException{ //创建新文件 File txt = new File(parentFolder,\"how2j\\\\jj\\\\test.txt\"); //判断新文件的父目录在不在，如果不在，用 mkdirs() 创建 if (!txt.getParentFile().exists()){ txt.getParentFile().mkdirs(); } //写入字节 FileOutputStream outputStream = new FileOutputStream(txt); byte[] all = {75,79}; // ASCII 75 = K, 79 = O; outputStream.write(all); outputStream.close();} 不止字节继承于InputStream和OutputStream的实现类可以让我们很方便的读写字节。但是，我们很多文件都是 Unicode 字符编码的，不是单个的字节。因此，Java又定义了Reader和Writer两个抽象类，专门处理 Unicode 字符。 因此，在 Java 中， Stream 结尾的都是字节流， reader 或 writer结尾都是字符流。 两者的区别是：读写的时候一个是按字节读写，一个是按字符。 相比字节，我们更感兴趣的是数字、字符串和对象，而不是一个一个的字节。Java 当然也提供了很多让我们读取常用格式的数据，而不仅仅是字节！ 缓存流如果我们自己从硬盘中读取或写入数据，每次都要读写磁盘。如果读写的频率比较高的时候，其性能表现不佳。为了解决这一问题，Java提供了BufferedReader和BufferedWriter两个缓存流。 当我们要从硬盘读数据的时候，BufferedReader缓存流会先从硬盘中一次性读取较多的数据，然后我们的Java程序直接按需从缓存里取出。这样就不用每次都跟硬盘打交道了。 利用 BufferedWriter 写数据到文件例子 new 一个 BufferedWriter，参数里面 new 一个 FileWriter 用 foreach 循环，遍历集合 如果有必要，做一下类型转换 写数据，写分隔符 刷新 注意，FileWrite 接收第二个参数，为 true 时，不覆盖原有内容。否则原有内容会被覆盖。 123// 文件读写FileWriter fw = new FileWriter(\"C:\\\\Users\\\\JerrySheh\\\\exception.dat\" , true);BufferedWriter bw = new BufferedWriter(fw); 完整例子 产生5555个随机数 写入到文件data.txt中 从文件data.txt中读取这5555个随机数，写入到data2.txt中 randomDoubleNumber.java 123456789101112package com.jerrysheh;import java.math.BigDecimal;public class randomDoubleNumber { // 产生 range 以内的随机数 public static double getRandomDoubleNumber(int range){ BigDecimal b = new BigDecimal(Math.random() * range); return b.setScale(2, BigDecimal.ROUND_HALF_UP).doubleValue(); }} test.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758import java.io.*;import java.text.DecimalFormat;import java.util.ArrayList;import java.util.List;public class main { public static void main(String[] args){ ArrayList&lt;Double&gt; l = addDataToList(new ArrayList&lt;&gt;()); writeToFile(l); readFromFileAndWrite(l); } // 添加随机数数据 public static ArrayList&lt;Double&gt; addDataToList(ArrayList&lt;Double&gt; randomNumberList){ double d; for (int i = 0; i &lt; 5555; i++) { d = com.jerrysheh.randomDoubleNumber.getRandomDoubleNumber(1000); randomNumberList.add(d); } return randomNumberList; } // 数据写入文件 public static void writeToFile(List&lt;Double&gt; randomNumberList){ DecimalFormat df = new DecimalFormat(&quot;0.00&quot;); try (BufferedWriter bw = new BufferedWriter(new FileWriter(&quot;data.txt&quot;))) { for (double dd: randomNumberList) { String s = df.format(dd); bw.write(s); bw.write(&quot;,&quot;); bw.flush(); } } catch (IOException e){ e.printStackTrace(); } } //文件读取数据，写入另一文件 public static void readFromFileAndWrite(List&lt;Double&gt; randomNumberList){ try( BufferedReader br = new BufferedReader(new FileReader(&quot;data.txt&quot;)); BufferedWriter bw = new BufferedWriter(new FileWriter(&quot;data2.txt&quot;)) ){ String s = br.readLine(); String ss[] = s.split(&quot;,&quot;); for (String each: ss) { bw.write(each); bw.write(&quot;\\r\\n&quot;); bw.flush(); } } catch (IOException e){ e.printStackTrace(); } }} 序列化什么是序列化（Serialization）？变量从内存中变成可存储或传输的过程称之为序列化（或持久化）。序列化之后，就可以把序列化后的内容写入磁盘，或者通过网络传输到别的机器上。 Java中的序列化在 Java 中，java.io.Serializable 是一个标记接口。要序列化一个对象，只需要实现该接口。但是，对象中并不是所有字段都可以被序列化，使用时需要注意。 当然，也有一些字段本身是可以被序列化的，但是我们不希望它被序列化，这时可以使用 transient 关键字让它不被序列化。 一个支持序列化的类123456789101112public class Employee implements java.io.Serializable{ public String name; public String address; public transient int SSN; public int number; public void mailCheck() { System.out.println(\"Mailing a check to \" + name + \" \" + address); }} 在 Java 中，我们使用 ObjectOutputStream 类来将一个对象转换成输出流。它的 writeObject(Object x) 方法用于序列化一个对象，并将它发送到输出流。 序列化过程123456789101112131415161718192021222324public class SerializeDemo{ public static void main(String [] args) { Employee e = new Employee(); e.name = \"Reyan Ali\"; e.address = \"Phokka Kuan, Ambehta Peer\"; e.SSN = 11122333; e.number = 101; try { FileOutputStream fileOut = new FileOutputStream(\"/tmp/employee.ser\"); ObjectOutputStream out = new ObjectOutputStream(fileOut); out.writeObject(e); out.close(); fileOut.close(); System.out.printf(\"Serialized data is saved in /tmp/employee.ser\"); }catch(IOException i) { i.printStackTrace(); } }} Java约定序列化的文件后缀名为 .ser ，我们将该对象存入磁盘/tmp/employee.ser文件中 反序列化过程12345678910111213141516171819202122232425262728293031public class DeserializeDemo{ public static void main(String [] args) { Employee e = null; try { // 创建一个文件输入流 FileInputStream fileIn = new FileInputStream(\"/tmp/employee.ser\"); // 创建一个对象输入流，传入文件输入流对象 ObjectInputStream in = new ObjectInputStream(fileIn); // 从对象输入流中获取序列化的数据 e = (Employee) in.readObject(); in.close(); fileIn.close(); }catch(IOException i) { i.printStackTrace(); return; }catch(ClassNotFoundException c) { System.out.println(\"Employee class not found\"); c.printStackTrace(); return; } }} 此时，Employee对象即被“复活”了。但是注意，变量SSN是 transient 的，因此不会被还原。 为什么一个类实现了Serializable接口，它就可以被序列化？查看 ObjectOutputStream 的源码，可以看到，其 writeObject0方法 中，是通过判断该类是否可以转型为 String、Enum 或 Serializable 来为其决定进行何种序列化方式的。实现Serializable接口就用 writeOrdinaryObject 方式。 如果该类没有实现 Serializable 接口，就抛出 NotSerializableException 1234567891011121314151617181920private void writeObject0(Object obj, boolean unshared) throws IOException { ... if (obj instanceof String) { writeString((String) obj, unshared); } else if (cl.isArray()) { writeArray(obj, desc, unshared); } else if (obj instanceof Enum) { writeEnum((Enum) obj, desc, unshared); } else if (obj instanceof Serializable) { writeOrdinaryObject(obj, desc, unshared); } else { if (extendedDebugInfo) { throw new NotSerializableException(cl.getName() + \"\\n\" + debugInfoStack.toString()); } else { throw new NotSerializableException(cl.getName()); } } ...}","link":"/post/779c6006.html"},{"title":"Java简明笔记（十六）网络编程","text":"前言网络编程，顾名思义就是编写通过网络通信的计算机程序。提到网络编程，一般指 socket 编程，之前我写过两篇相关的文章，分别是：浅谈 socket 编程 和 Socket编程实践（Java &amp; Python实现），主要侧重于 socket 编程的理解，而这一篇侧重于使用 Java 进行 socket 编程的要点，作为简明笔记，以备后续用到时方便查阅。 使用Java进行 TCP socket 编程服务器socket编程涉及到多台计算机的连接，一般我们习惯分为服务器和客户端以区分服务提供者和使用者。服务器端首先要建立起一个socket连接服务，之后等待客户端来连接，当连接建立后，两方都用输入输出流来发送和接收数据，就像双向流水管道一样自然。 如何建立连接对于服务器来说，要创建一个服务socket非常简单： 12int SERVER_PORT = 7706;ServerSocket serverSocket = new ServerSocket(SERVER_PORT); 这样就创建了一个服务socket，之后用accept方法开始等待客户端来连接： 1Socket connectSocket = serverSocket.accept(); 在没有客户端连接时，accept方法是一直阻塞的。直到有一个客户端进行连接，connectSocket对象才生成。注意，这里的connectSocket跟刚刚的serverSocket是两个概念，serverSocket用来欢迎并等待客户端的连接，connectSocket则是专门服务于某个连接的客户端的。 连接建立后，我们得到了一个Socket对象（不是ServerSocket对象）。之后我们开一个线程，专门处理与这个客户端的数据传输。 1234while (true){ Socket connectSocket = serverSocket.accept(); new sender(connectSocket).start();} 而主线程的ServerSocket对象则在 while 循环内继续等待欢迎其他客户端来连接。 server.java 完整代码： 123456789101112131415161718192021222324public class server { // 端口号 private static final int SERVER_PORT = 7767; public static void main(String[] args) throws IOException { boolean STOP = false; // 初始化ServerSocket服务 ServerSocket serverSocket = new ServerSocket(SERVER_PORT); System.out.println(\"服务已启动，监听端口：\" + SERVER_PORT); // 不断监听，欢迎客户端来连接 while (!STOP){ // accept方法是阻塞的，一旦有客户端连接，Socket对象才生成 Socket connectSocket = serverSocket.accept(); // 创建一个新的线程来服务特定的客户端 // sender类是我们自定义的用于处理数据的类，继承于 Thread 类，下文介绍 new sender(connectSocket).start(); } }} 如何发送和接收数据接下来关心一下，sender类是如何处理数据的。首先，sender构造时传进了一个 connectSocket 对象，然后在线程的 run 方法里面编写如何跟客户端交互的代码： 123456789101112131415public class sender extends Thread { private Socket connectSocket; // 构造方法，从主线程传入一个 Socket 对象 public sender(Socket connectSocket) { this.connectSocket = connectSocket; } // 在子线程进行处理 @Override public void run(){ // do something }} 首先，用connectSocket.getInputStream()获取来自客户端的输入流，然后封装到 DataInputStream 对象中，最后用readUTF()方法来读取。输出流也是同理： 12345678910111213141516171819202122232425262728293031323334@Overridepublic void run(){ System.out.println(\"远程计算机 \" + connectSocket.getRemoteSocketAddress() + \"已连接\"); try { // 封装接收数据流 InputStream in = connectSocket.getInputStream(); DataInputStream dataIn = new DataInputStream(in); // 封装发送数据流 OutputStream out = connectSocket.getOutputStream() DataOutputStream dataOut = new DataOutputStream(out); // while 循环用于不断接收和发送数据 while (true){ // 接收，该方法阻塞直到有数据接收 String recv = dataIn.readUTF(); System.out.println(\"成功接收来自 \" + connectSocket.getRemoteSocketAddress() + \"的数据：\" + recv); // 数据处理 String send = recv.toUpperCase(); // 发送 dataOut.writeUTF(send); System.out.println(\"向\" + connectSocket.getRemoteSocketAddress() + \"发送转换后的数据：\" + send); } } catch (IOException e) { System.out.println(\"远程计算机 \" + connectSocket.getRemoteSocketAddress() + \"已断开\"); }} 客户端客户端相对来说就简单一些。先创建一个 Socket 对象，然后用同样的方法封装到输入流和输出流中进行处理即可。 创建socket对象 123// 创建Socket对象时需指定服务器的地址和端口String serverNmae = \"192.168.1.187\";Socket client = new Socket(serverName, 7767); 封装输入输出流 1234// 封装输出流DataOutputStream dataOut = new DataOutputStream(client.getOutputStream());// 封装输入流DataInputStream dataIn = new DataInputStream(client.getInputStream()); 数据发送和接收 123456// 发送数据dataOut.writeUTF(send);System.out.println(\"向服务器 \" + client.getRemoteSocketAddress() + \"发送了：\" + send + \"\\n\");String recv = dataIn.readUTF();System.out.println(\"接收来自服务器的数据：\" + recv + '\\n'); 可以使用 Scanner 从键盘多次获取输入。 client.java 完整代码： 1234567891011121314151617181920212223242526272829303132333435363738394041public class client { public static void main(String[] args) { // 从键盘获取服务器地址 Scanner scanner = new Scanner(System.in); System.out.println(\"请输入服务器地址，如 192.168.1.1\"); String serverName = scanner.nextLine(); try { // 创建 Socket 对象 Socket client = new Socket(serverName, 7767); // 封装输出流 DataOutputStream dataOut = new DataOutputStream(client.getOutputStream()); // 封装输入流 DataInputStream dataIn = new DataInputStream(client.getInputStream()); // 循环发送和接收数据 while (true){ // 控制台循环获取输入 System.out.println(\"\\n请输入要发送的数据：(输入exit退出)\"); String send = scanner.next(); if (\"exit\".equals(send)) break; // 发送数据 dataOut.writeUTF(send); System.out.println(\"向服务器 \" + client.getRemoteSocketAddress() + \"发送了：\" + send); // 接收数据 String recv = dataIn.readUTF(); System.out.println(\"接收来自服务器的数据：\" + recv + '\\n'); } } catch (IOException e){ System.out.println(\"服务器连接中断\"); } }} 使用Java进行 UDP socket 编程发送端UDP socket 无需建立连接，但是在发送数据前需要先准备数据报包（packet）。类似于TCP里面我们把输入流封装到 DataInputStream 里，在 UDP 中我们把数据放在数据报包 DatagramPacket 当中，数据报包是载体。65508是每个数据报包可以容纳的最大数据量。 123456789// 数据byte[] buffer = new byte[65508];// 要发送的地址InetAddress address = InetAddress.getByName(\"192.168.1.187\");// 数据报包里面存储包括数据内容、长度、要发送的地址和对方端口DatagramPacket packet = new DatagramPacket( buffer, buffer.length, address, 9797); 有了数据报包之后，我们用 datagramSocket 对象来发送数据。可以这样理解，DatagramPacket 是包裹，用来装数据，而 datagramSocket 是车，用来把包裹运送出去。 12345// 准备车DatagramSocket datagramSocket = new DatagramSocket();// 将数据报包裹装车，并运送出去datagramSocket.send(packet); 完整代码： 12345678910111213141516171819202122232425262728/** * 客户端，发数据 */public class client { public static void main(String[] args) throws UnknownHostException, SocketException { // 要发送的数据 byte[] buffer = \"0123456789\".getBytes(); // 对方地址 InetAddress address = InetAddress.getByName(\"192.168.1.187\"); // 准备包裹 DatagramPacket packet = new DatagramPacket(buffer, buffer.length, address, 9797); // 准备车 DatagramSocket datagramSocket = new DatagramSocket(); try { // 运送出去 datagramSocket.send(packet); } catch (IOException e) { e.printStackTrace(); } }} 接收端接收端一开始需要先创建一个 datagramSocket 对象，用来准备接收数据： 12// 准备卸货车，记下对方包裹的端口DatagramSocket datagramSocket = new DatagramSocket(9797); 然后声明即将接收的数据报包格式： 123// 要接收的包裹长什么样byte[] buffer = new byte[10];DatagramPacket packet = new DatagramPacket(buffer, buffer.length); 接收： 1234567// 接收包裹datagramSocket.receive(packet);// 把接收的内容显示出来byte[] recv = packet.getData();String s = new String(recv);System.out.println(\"接收到：\" + s); 完整代码： 12345678910111213141516171819202122232425262728/** * 服务端，收数据 */public class server { public static void main(String[] args) throws SocketException { // 准备卸货车 DatagramSocket datagramSocket = new DatagramSocket(9797); // 即将接收的包裹特征 byte[] buffer = new byte[10]; DatagramPacket packet = new DatagramPacket(buffer, buffer.length); try { // 接收包裹 datagramSocket.receive(packet); } catch (IOException e) { e.printStackTrace(); } // 显示包裹内容 byte[] recv = packet.getData(); String s = new String(recv); System.out.println(\"接收到：\" + s); }}","link":"/post/bbbc0df0.html"},{"title":"Java简明笔记（十四）反射机制","text":"Java 是完全面向对象语言。事实上，我们创建的每一个类，其实也是对象，称为类对象。类对象提供了类的元信息，比如这个类有几种构造方法，有多少个属性，有哪些普通方法等。 Java反射机制主要提供了以下功能： 在运行时判断任意一个对象所属的类； 在运行时构造任意一个类的对象； 在运行时判断任意一个类所具有的成员变量和方法； 在运行时调用任意一个对象的方法；生成动态代理。 普通对象 VS 类对象假设我们定义两个类， student类和teacher类 1234567891011121314151617181920212223242526272829public class student{ int studentID; String name; String classroom; student(){ //构造方法 } //以及一些其他方法}student Jerry = new student();student Calm = new student();public class teacher{ int teacherID; String name; long phoneNumber; teacher(){ //构造方法 } //以及一些其他方法}teacher Luohao = new teacher();teacher YangLiang = new teacher(); Jerry 和 Calm 都是 student 类的对象，他们的区别在于：有不同的studentID，name… Luohao 和 YangLiang 都是 teacher 类的对象，他们的区别跟 Jerry 和 Calm的区别类似，有不同的teacherID,不同的name… 然后，我们说 student 和 teacher 都是一个类，他们的区别在于，有不同的属性和方法。 所谓类对象，就是用于描述这种类，都有什么属性，什么方法的对象。 获取类对象在 Java 中，获取类对象有三种方法 Class.forName student.class new student().getClass() 通常一个JVM下，只会有一个ClassLoader，因此一种类，只会有一个类对象存在。所以以上三种方式取出来的类对象，都是一样的。 1234Class pClass = Class.forname(\"student\"); //获取一个 student 类的类对象// 实际上内部会调用这个方法，第二个参数true表示要初始化Class.forName(className,true,classloader) 获取类对象的时候，类属性会被初始化。 第三种方法： 1new student().getClass(); getClass() 是 Object 类的方法，返回的是运行时的类的名字（包名+类名），如果要返回父类，用 getClass().getSuperclass() 反射机制正常情况下，我们要获取一个对象，直接new 1student Jerry = new student(); 但是，有一种机制，叫反射机制。反射机制是这样干的：先拿到 student 类的类对象，然后通过类对象获取构造器对象，再通过构造器对象创建一个对象。 通过反射机制创建对象1234567891011121314151617181920public static void main(String[] args) { try { String className = \"student\"; //类对象 Class pClass=Class.forName(className); //构造器 Constructor c= pClass.getConstructor(); //通过构造器实例化 student jerry= (student) c.newInstance(); //给实例对象设置属性 jerry.studentID=\"201501010086\"; } catch (Exception e) { e.printStackTrace(); }} 可以看到，通过反射机制，创建对象的流程为：类对象 -&gt; 构造器对象 -&gt; 实例对象 通过反射机制修改属性的值1234567891011121314151617public static void main(String[] args) { student calm = new student(); // 对象的name属性设置为 calmDu calm.phoneNumber = 13315010086; try { //获取student类中名字叫做phoneNumber的字段 Field f1= calm.getClass().getDeclaredField(\"phoneNumber\"); //修改这个字段的值 f1.set(calm, 189741710000); } catch (Exception e) { e.printStackTrace(); }} 可以看到，我们先用 Field 类，获取 calm 所属类（student类）的 phoneNumber 字段，然后用 Field 的 set方法，修改属性值。 流程为： Field -&gt; set getField 和 getDeclaredField 的区别这两个方法都是用于获取字段。 getField getDeclaredField 只能获取public，包括继承来的字段 可以获取包括private在内的所有字段，但不能获取继承来的字段 getDeclaredField 这里只能获取到private的字段，但并不能访问该private字段的值,除非加上 setAccessible(true) 通过反射机制调用方法首先我们的 student 类里有 setAge 方法和 getAge方法student.java 123456789101112131415161718192021public class student { String studentID; String studentName; String studentPhoneNumber; int age; public student(String studentID, String studentName, String studentPhoneNumber, int age) { this.studentID = studentID; this.studentName = studentName; this.studentPhoneNumber = studentPhoneNumber; this.age = age; } public int getAge() { return age; } public void setAge(int age) { this.age = age; }} 在测试类中调用这个方法 main.java 12345678910111213import java.lang.reflect.Method;public static void main(String[] args) throws Exception{ student jerry = new student(\"201501010086\",\"jerrysheh\",\"13018910086\",20); // 获取名字为setAge，参数类型为int类型的方法 Method m = jerry.getClass().getMethod(\"setAge\", int.class); //对 jerry 对象调用这个方法 m.invoke(jerry,18); System.out.println(jerry.getAge());} 可以看到，用反射机制调用方法的流程是：Method -&gt; invoke 反射机制有什么用？反射机制可以用来创建对象，修改对象属性的值，调用对象的方法。 但是这些我们传统java面向对象编程也能做到，为什么要用反射呢？ 通常来说，需要在学习了 Spring 的依赖注入，反转控制之后，才会对反射有更好的理解。在此之前，我们可以举个栗子简单说明一下反射的强大功能。 没有反射机制假设我们有两个业务类，业务1和业务2，然后我们现在要运行业务1 123456public class Test { public static void main(String[] args) { new Service1().doService1(); }} 好，然后有一天，老板说，全线改到业务2，于是我们不得不改代码 1234567public class Test { public static void main(String[] args) { //new Service1().doService1(); new Service2().doService2(); }} 假如我们的工程非常大，改完代码重新编译运行要1个小时，这有时候是不可接受的。 有了反射机制有了反射机制后，我们可以准备一个配置文件，就叫 spring.txt 吧，在里面写明 12class=reflection.Service1method=doService1 当需要从调用第一个业务方法，切换到调用第二个业务方法的时候，不需要修改一行代码，也不需要重新编译，只需要修改配置文件spring.txt，再运行即可。 此时代码是这样写的 12345678910111213141516171819202122232425public class Test { @SuppressWarnings({ \"rawtypes\", \"unchecked\" }) public static void main(String[] args) throws Exception { //从spring.txt中获取类名称和方法名称 File springConfigFile = new File(\"e:\\\\project\\\\j2se\\\\src\\\\spring.txt\"); Properties springConfig= new Properties(); springConfig.load(new FileInputStream(springConfigFile)); String className = (String) springConfig.get(\"class\"); String methodName = (String) springConfig.get(\"method\"); //根据类名称获取类对象 Class clazz = Class.forName(className); //根据方法名称，获取方法对象 Method m = clazz.getMethod(methodName); //获取构造器 Constructor c = clazz.getConstructor(); //根据构造器，实例化出对象 Object service = c.newInstance(); //调用对象的指定方法 m.invoke(service); }} 事实上，这就是 Spring 框架的最基本原理了。 补充：类装载器 ClassLoaderClassLoader用于寻找字节码文件，并构造出类在 JVM 内部表示对象的组件。在Java中，ClassLoader把一个类装入JVM的步骤如下： 装载：查找和导入Class文件 链接：执行校验（检查载入的Class文件正确性）、准备（给类的静态变量分配存储空间）和解析（将符号引用转化成直接引用）。 初始化：对类的静态变量和静态代码块进行初始化 JVM从安全角度考虑，装载类时，使用了“全盘负责委托机制”： 全盘负责：当一个 ClassLoader装载一个类时，该类所依赖及引用的类也由该 ClassLoader 载入。 委托机制：先委托父装载器寻找目标类，找不到时才从自己的类路径找。 关于类加载器，可参考: Java虚拟机（一）JVM 基础和类的加载 本篇参考教程：how2j - 反射机制","link":"/post/e753fbbb.html"},{"title":"Java简明笔记（四） 继承","text":"什么是继承继承是在现有的类的基础上创建新类的过程。继承一个类，你也就重用了它的方法，而且还可以添加新的方法和域。 举个例子：员工有薪水，管理者有薪水+奖金， 管理者继承员工，增加 bounus 字段和 setBonus 方法即可。这种情况就是管理者类继承了员工类。 12345678public class Manager extends Employee { private double bonus; ... public void setBonus (double bouns) { this.bonus = bonus; }} Manager类继承了Employee类，除了获得Employee类的变量和方法外，还额外添加了bonus变量和setBonus方法。 方法覆盖（Override，重写）Employee类有个getSalary方法，返回员工的总薪水。对于管理层来说，除了工资外，还有奖金，于是Employee的getSalary方法不适用，我们需要重写。这个过程就叫方法覆盖（重写）。 12345678public class Manager extends Employee { //... @Override public double getSalary() { return super.getSalary() + bonus; }} super.getSalary() 是 Employee 类的方法。也就是说，我们可以用 super 来调用父类方法。方法覆盖之后还是可以调用父类方法。 重写一个方法，必须匹配准确的参数类型假如 Employee 类有一个方法 123public boolean workdsFor (Employee supervisor){ ...} 我们现在要在Manager类重写这个方法，如果我们在 Manager 类这样写： 1234@Overridepublic boolean workdsFor (Manager supervisor){ ...} 那这不是一个重写的方法，而是一个新方法，因为类型参数不一样！ 正确的重写应该是： 1234@Overridepublic boolean workdsFor (Employee supervisor){ ...} 因此，为了避免发生这样的失误，最好在我们重写方法的前面加上@Override，以注明这是一个重写方法，当我们失误参数写错时，编译器会报错。 Override 和 Overload 的区别Override 是方法重写，子类对父类方法的重写。需要注意的是，重写方法参数类型不能改，但是返回类型可以改（比父类更小或相等）。 Overload 是方法重载，同一个类中可以有多个名称相同但参数个数、类型或顺序不同的方法。与函数的返回类型无关 。 重写和重载都不要求返回类型，因为 Java 中调用函数并不需要强制赋值。 Overload 和 Overwrite 都与访问控制符（public private protected）无关！但一般不做修改。 初始化：子类构造函数调用父类构造函数Manager的构造函数不能访问Employee的私有变量，所以我们要用super关键字调用父类的构造函数来初始化。 12345678// 子类构造方法public Manager (String name, double salary) { // 调用父类构造方法 super(name, salary); bonus = 0;} 父类赋值在 Java 中，将一个子类对象赋给父类变量是可以的。Java有动态查找（多态），即使是 Employee 类型，执行的时候还是会执行 Manager 的方法。 12345Manager boss = new Manager(...);Employee empl = boss; // it is ok.//执行的是Manager.getSalarydouble salary = empl.getSalary(); 但是这也有一个缺点，那就是只能调用属于父类的方法（getSalary），而不能调用子类方法（getBonus）。 12Employee empl = new Manager(...);empl.setBonus(10010); //编译报错 解决这个问题，可以用instanceof操作符。 1234567Employee empl = new Manager(...);//如果 empl 可以向下转型为 Manager，则类型转换if (empl instanceof Manager) { Manager mgr = (Manager) empl; mgr.setBonus(10010);} 参考：Java简明笔记（二） 面向对象 final、abstract、interface final方法不能被覆盖，final类不能被继承。 abstract方法没有实现，abstract类不能被实例化。 Java中，类比接口优先（class win）。因此一个类继承了另一个类，又实现了某个接口，碰巧父类和接口有同名方法。这时，默认为父类的实现。 注意：声明一个类时，先 extends，再 implements，否则编译错误 123public class A extends B implements C { //...} 终极父类：ObjectObject 是 Java 中所有类的父类。可以把任何一种数据类型的变量赋给 Object 类型的变量（基本数据类型也可以，会自动装箱）。 Object类有几个重要的方法： clone方法1protected Object clone() 用于创建并返回此对象的一个副本，实现对象的浅复制。注意：只有实现了 Cloneable 接口才可以调用该方法，否则抛出 CloneNotSupportedException 异常。 ToString方法1public String toString() 用于返回该对象的字符串表示。许多 toString 方法都采用一种格式： 类名后面跟中括号，里面是实例变量。 例如： Point 类的 toString 输出： 1Java.awt.Point[x=10, y=20] 所以，在我们的Employee方法中，可以重写 toString 为 123public String toString() { return getClass().getName() + \"[name=\" + name + \",Salary=\" + salary + \"]\"} 提示：打印多维数组用 Array.deepToString 方法。 equals方法123public boolean equals(Object obj) { return (this == obj);} 用于判断一个对象是否与另一个对象相等。注意，判断的是对象引用是否相同。 考虑下面的例子： 123456789public static void main(String[] args) {Object o = new Object();Object oo = new Object();System.out.println(o.equals(oo)); // 输出：falseString s = new String(\"aaa\");String ss = new String(\"aaa\");System.out.println(s.equals(ss)); // 输出：true} 为什么同样是 new 对象， 两个 Object 返回 false， 两个 String 却返回 true 呢？ 原因是：String 重写了 equal() 方法，不是用 == 来判断的，而是比较值。具体看：探究 String 类 equals 方法源码 提示： 一般情况下，我们不需要重写equals方法。 对于基本数据类型，用“==”，但是在 double 中，如果担心正负无穷大或NaN，用Double.equals。 对于对象，如果担心对象为null，用Object.equals(x, y)，如果x为空，返回false。而如果你常规的用x.equals(y)则会抛出异常。 equals 方法的注释中提示我们，如果重写了 equals 方法，最好也重写 hashcode 方法。 什么时候需要重写 equals，什么时候需要重写 hashcode ？重写 equals默认的，在 Object 类中比较的是两个对象的地址(==) ，地址相同，即同一个对象， equals 返回真。 但是，当某些类我们希望只要某个或某些属性相同，就认为他们是相同的，这时候就需要重写 equals 。 例如 String ，可能 new 了两个 String 对象，但是存的都是一样的字符数组。他们的地址是不一样的，但是我们也说是 equals 的。 重写 hashcode当重写了 equals 的时候，也必须重写 hashcode。 以免发生 equals 为真，hashcode 却为假的情况。这违背了 hashcode 的性质。 举例来说，HashSet 会用 hashcode 方法得到 hash 值，并以这个 hash 值决定存入 HashSet 的位置。当我们想用 HashSet 存储对象时，两个 equals 的对象都被存入了 HashSet ，这跟 HashSet 储存不重复元素的原则不符。 wait方法123public final void wait() throws InterruptedExceptionpublic final native void wait(long timeout) throws InterruptedExceptionpublic final void wait(long timeout, int nanos) throws InterruptedException wait方法用于让当前线程等待，直到其他线程调用此对象的 notify() 方法或 notifyAll() 方法。 wait() 使当前线程等待该对象的锁。当前线程必须是该对象的拥有者，也就是具有该对象的锁。wait() 方法一直等待，直到获得锁或者被中断。 wait(long timeout) 设定一个超时间隔，如果在规定时间内没有获得锁就返回（继续执行后面的代码），不会抛超时异常。 调用wait(long timeout)后当前线程进入睡眠状态，直到以下事件发生： 其他线程调用了该对象的 notify 方法 其他线程调用了该对象的 notifyAll 方法 其他线程调用了 interrupt 中断该线程 时间间隔到了 此时该线程就可以被调度了，如果是被中断的话就抛出一个 InterruptedException 异常。 notify方法1public final native void notify(); 唤醒在该对象上等待的某个线程 notify()是对对象锁的唤醒操作。但有一点需要注意的是：notify() 调用后，并不是马上就释放对象锁的，而是在相应的 synchronized(){} 语句块执行结束，自动释放锁后，JVM会在 wait() 对象锁的线程中随机选取一线程，赋予其对象锁，唤醒线程，继续执行。这样就提供了在线程间同步、唤醒的操作。 notifyAll方法1public final native void notifyAll(); 唤醒在该对象上等待的所有线程。 hashCode方法1public native int hashCode(); 哈希码是个来源于对象的整数。哈希码应该是杂乱无序的，如果 x 和 y 是两个不相等的对象，他们的hashCode方法很可能不同。 引申：hashcode的作用hashCode用于返回对象的散列值，用于在散列函数中确定放置的桶的位置。 hashCode的存在主要是用于查找的快捷性，如Hashtable，HashMap等，hashCode是用来在散列存储结构中确定对象的存储地址的； 如果两个对象相同，就是适用于equals(java.lang.Object) 方法，那么这两个对象的hashCode一定要相同； 如果对象的equals方法被重写，那么对象的hashCode也尽量重写，并且产生hashCode使用的对象，一定要和equals方法中使用的一致，否则就会违反上面提到的第2点； 两个对象的hashCode相同，并不一定表示两个对象就相同，也就是不一定适用于equals(java.lang.Object) 方法，只能够说明这两个对象在散列存储结构中，如Hashtable，他们“存放在同一个篮子里”。 参考：数据结构（六）查找——哈希函数和哈希表 getClass方法1public final native Class&lt;?&gt; getClass(); native方法，也是 final 方法，用于返回此 Object 的运行时类型。 finalize方法123protected void finalize() throws Throwable { // 没有任何东西} 一般不要使用finalize，最主要的用途是回收特殊渠道申请的内存。Java程序有垃圾回收器，所以一般情况下内存问题不用程序员操心。但有一种JNI(Java Native Interface)调用non-Java程序（C或C++），finalize()的工作就是回收这部分的内存。 当垃圾回收器确定不存在对该对象的更多引用时，由对象的垃圾回收器调用此方法。见 Java虚拟机（四）垃圾回收策略。","link":"/post/2fJava80.html"},{"title":"Java简明笔记（六） 集合","text":"集合和集合框架什么是集合？集合就是一个放数据的容器，准确的说是放数据对象引用的容器。 Java集合主要可以划分为三个部分： Collection（包含 List 和 Set ） Map （键值对） 工具类（Iterator迭代器、Enumeration枚举类、Arrays和VCollections） Java的集合类主要由两个接口派生而来：Collection 和 Map ，这两个是集合框架的根接口，这两个接口又包含了一些 子接口 或 实现类 。如下图： 所有的集合框架都包含如下内容： 接口：是代表集合的抽象数据类型。比如Collection接口，以及子接口List。 实现（类）：是集合接口的具体实现。从本质上讲，它们是可重复使用的数据结构。比如ArrayList是List接口的具体实现。 算法：是实现类对象里的方法，用于执行一些有用的计算，例如：搜索和排序。这些算法被称为多态，因为相同的方法可以在相似的接口上有着不同的实现。比如 Collections 工具类提供了sort()、reverse()等方法。 (参考：菜鸟教程, 极乐科技) 为什么要用集合？使用集合框架的优点之一是：当遇到一些基本算法时，不必重新实现。一些例如addAll、removeIf等基本方法是Collection接口已经定义好的。 Collections工具类包含很多额外的可在集合上操作的算法，你可以对列表进行排序、打乱、旋转、翻转操作；在集合中查询最大或最小元素，或者任意一个元素的位置；生成不含元素或者含一个元素或同一个元素n份拷贝的集合。 有序集合——ListList 指有序的集合，List类是一个抽象类。 实现类 ArrayList 和 LinkedList 实现了 List 接口。所以我们平时用的时候，要指定是 ArrayList 还是 LinkedList。 我应该用 ArrayList 还是 LinkedList ？链表插入操作很快，但遍历很慢。因此当应用需要有序集合时，用 ArrayList 可能会更好。但是注意， ArrayList 和 LinkedList 都是线程不安全的。 ArrayListArrayList的声明 12345//这种是默认创建大小为10的数组，每次扩容大小为1.5倍ArrayList list=new ArrayList(); //这种是指定数组大小的创建，没有扩充ArrayList list=new ArrayList(20); ArrayList使用示例： 123456789101112131415161718192021public static void main(String[] args) { List&lt;String&gt; groupName = new ArrayList&lt;&gt;(); groupName.add(\"jerry\"); groupName.add(\"calm\"); groupName.add(\"Superman\"); //输出：groupName的大小：3 System.out.println(\"groupName的大小：\" + groupName.size()); //输出：groupName原始的内容[jerry, calm, Superman] System.out.println(\"groupName原始的内容\" + groupName); //输出：jerry在容器的位置：0 System.out.println(\"jerry在容器的位置：\" + groupName.indexOf(\"jerry\")); //将下标1的内容替换为 Paul groupName.set(1,\"Paul\"); //输出：groupName替换后的内容[jerry, Paul, Superman] System.out.println(\"\\ngroupName替换后的内容\" + groupName);} 下面是一些常用方法 常用方法 简介 add 增加，支持直接加在末尾，或者指定位置 contain 判断容器中是否存在某个对象（而不是对象值相等） get 获取指定位置的对象（如果越界会报错） indexOf 获取对象所处的位置(从0开始) remove 删除，支持按下标或者按对象 set (index, object) 替换 size 获取大小 toArray 转换为数组 addAll 把另一个容器所有对象都加进来 clear 清空 subList 取子列表 list1 = list2.subList(start, end); LinkedList使用示例： 123456789101112131415List&lt;String&gt; staff = new LinkedList&lt;&gt;();staff.add(\"Amy\");staff.add(\"Bob\");staff.add(\"Carl\");// 使用Iterator来遍历，可删不能增Iterator iter = staff.iterator;String first = iter.next(); // visit first elementString second = iter.next(); //visit second elementiter.remove(); // remove last visited element (second element)// 使用ListIterator可以遍历，也可以增删ListIterator&lt;String&gt; lIter = staff.listlterator();lIter.next(); // visit first elementlIter.add(\"jerry\"); // insert jerry at 2nd position LinkedList.add() 方法将对象添加到链表的尾部。但是，常常需要将元素添加到链表的中间。这就要借助迭代器 Iterrator 来实现。 为什么这里用 ListIterator ，而不是Iterator原因是 Iterator 是适用于包括无序集合 Set 在内的所有集合类的，因此不提供.add()方法。而子接口 ListIterator，仅仅在 List 集合能用。它提供了 .add() 方法，就可以在中间进行插入操作了。 ListIterator 和 Iterator 的区别： 使用范围不同，Iterator 可以应用于所有的集合，Set、List 和 Map 和这些集合的子类型。而 ListIterator 只能用于 List 及其子类型。 ListIterator 有 add 方法，可以向 List 中添加对象，而 Iterator 不能。 ListIterator 和 Iterator 都有 hasNext() 和 next() 方法，可以实现顺序向后遍历，但是 ListIterator 有 hasPrevious() 和 previous() 方法，可以实现逆向（顺序向前）遍历。Iterator 不可以。 ListIterator 可以定位当前索引的位置，nextIndex() 和 previousIndex() 可以实现。Iterator 没有此功能。 都可实现删除操作。但是 ListIterator set() 方法可以实现对象的修改。Iterator 仅能遍历，不能修改。 ArrayList、LinkedList、Vector的区别ArrayList 和 Vector相同点：Arraylist和Vector是采用数组方式存储数据。不同点：Vector由于使用了synchronized方法-线程安全，所以性能上比 ArrayList 要差。但是 ArrayList 是线程不安全的。 ArrayList 和 LinkedList相同点：ArrayList 和 LinkedList 在末尾插入都很快。不同点：LinkedList使用 双向链表 实现存储，按序号索引数据需要进行向前或向后遍历，插入数据时只需要记录本项前后项即可，因此在中间插入数据较快。ArrayList遍历十分快，LinkedList中间插入特别快。 List 如何去重Java 8 使用 Stream: 1list = list.stream().distinct().collect(Collectors.toList()); 无序集合——SetSet 中元素是无序的，且不允许重复的元素， 只能用 Iterator 迭代器取出 Set 中的元素。 Set的 add 方法首先在集合中查找要添加的对象，如果不存在就将这个对象添加进去。 HashSet 和 TreeSet 实现了 Set 接口，但都是线程不安全的。它们的底层数据结构是 哈希表。 哈希表(Hashtable)，也称散列表，是一种数据结构。 哈希表为每个对象计算一个整数，称为 散列码（hash code）。 HashSetHashSet 依靠元素的 hashCode方法 和 euqals方法 来确保元素的唯一性。 HashSet包含敏感词检测的例子 1234567Set&lt;String&gt; badWords = new HashSet&lt;&gt;();badWords.add(\"fuck\");badWords.add(\"drugs\");badWords.add(\"shit\");if (badWords.contain(username.toLowerCase())) { System.out.println(\"please choose a different username\")} TreeSet如果想要按顺序遍历Set集合，或者要对Set集合中的元素进行排序，可以使用TreeSet。 TreeSet通过compareTo或者compare方法中的来保证元素的唯一性。元素是以二叉树的形式存放的，TreeSet使用了红黑树来对元素排序。 队列集合——QueueQueue会记住插入顺序，但只能在尾端插入，头端删除。Deque有两个尾端，头尾都可以插入和删除。上面提到的 LinkedList 就实现了 Deque 接口，是双向链表。 Queue接口的 add(E e)方法 和 offer(E e)方法都是往队列里添加元素，但二者对插入失败时的处理不同，前者在插入失败时抛出异常让你处理，后则则直接返回false。但在优先队列里这两者无区别，都是调用 offer。 PriorityQueue 优先队列PrioriryQueue是 Queue 接口的一个队列实现类。PriorityQueue的排序是基于堆排序的。不允许空值。PrioriryQueue的 add 方法和 offer 方法是一样的。 12345Queue&lt;Integer&gt; p = new PriorityQueue&lt;&gt;(10 , (o1,o2) -&gt; o2 - o1));p.offer(5); // 往堆里添加元素p.offer(8);p.peek(); // 获取堆顶但不删除p.pool(); // 获取堆顶并删除 PriorityQueue构造器支持两个参数，第一个参数是优先队列的大小，第二个参数是一个 Comparator 比较器，可以自己实现比较方法。JDK1.8 可以用 lambda 表达式替代匿名类。 ConcurrentLinkedQueue并发情况下安全的先进先出队列。 BlockingQueue阻塞队列。获取一个元素时，如队列为空，则获取操作一直阻塞，直到队列中出现一个可用元素。插入一个元素时，如果队列已满，则插入操作一直阻塞，直到队列中元素减少。BlockingQueue在“生产者-消费者”模式中非常有用。 键值对集合——MapMap存储键值对。不允许重复的键，但不同键允许有相同的值。用put()方法添加新的键值对或者改变原有的值。 Map的实现类1. Hashtable（遗留类，尽量不用）Map的一个实现是Hashtable，线程安全，速度慢。底层是 哈希表 数据结构。是同步的。不允许null作为键和值。 注意：Hashtable 是一个“遗留的”容器类，应该尽可能不用。在需要并发的场景，使用 ConcurrentHashMap 。或者用 Collections 工具类的的 synchronizedMap 方法。 12HashMap hashMap = new HashMap();Map map = Collections.synchronizeMap(hashMap); 2. HashMap （jdk 1.8实现）Map的另一个实现是HashMap，线程不安全，速度快。其底层也是 哈希表 数据结构（即链表+数组，在Java8中又加入了红黑树）。是不同步的。允许null作为键和值。替代了Hashtable。 为什么 java8 要加入红黑树？HashMap使用 链地址法 来解决冲突。但是使用链地址法会导致 get 的效率从o（1）降至o（n），所以在 Java8 中，链表长度超过阈值（8）时，将链表转换为红黑树，这样大大减少了查找时间。 hashMap的 Hash 过程 hashMap的 put 过程 确定要存入的桶。先使用 hash() 函数获取该对象的 hash 值，高16位和低16位异或后跟 Entry对象数组大小-1 进行与操作，得到应该存入数组的下标。 链表插入。假如该位置为空，就将value值插入，如果该下标不为空，则要遍历该下标上面的对象，使用equals方法进行判断，如果遇到equals()方法返回真则进行替换，否则将其插入。 hashMap的 get 过程 根据 key 对象的 hash 值找到 Entry 对象数组的对应下标。 判断Entry的 key 和 给定的 key 是否相同（equals或==），以及 hash 是否也相同，如果不是，访问链表下一个 Entry ，如果是，返回 Entry 的 value，如果遍历完了也没有，返回 null HashMap的使用例子123456789101112131415Map&lt;String, Integer&gt; counts = new HashMap();counts.put(\"Alice\",1);counts.put(\"Jerry\",2);counts.put(\"Alice\",3); //改变原有值int count = counts.get(\"Alice\"); //获取Alice对应的值，这里是3//如果Alice对应的值不存在，用get方法会得到空指针异常//下面这句避免了空指针异常//获取Alice对应的值，如果值不存在，返回0int count = counts.getOrDefault(\"Alice\", 0);//如果word不存在，将word与1形成键值对，否则将word+1counts.merge(word, 1, Integer::sum); 3. ConcurrentHashMapConcurrentHashMap 是线程安全的 hashMap，其底层也是 哈希表（数组+链表） + 红黑树 实现。 ConcurrentHashMap 如何保证线程安全？JDK1.8 的 ConcurrentHashMap 采用 CAS（compare and swap）+ Synchronized 保证线程安全。 JDK1.7 及以前采用segment的分段锁机制实现线程安全，其中 segment 继承自ReentrantLock，因此采用Lock锁来保证线程安全。 4. LinkedHashMap可以保证HashMap集合有序。存入的顺序和取出的顺序一致。 5. TreeMap可以用来对Map集合中的键进行排序，底层是采用红黑树。 迭代器 Iterator每个集合都提供了某种顺序迭代元素的方式。 Collection的父接口 Iterable 定义了一个方法： 1Iterator&lt;T&gt; Iterator() 这个方法生成一个迭代器，用来访问元素。 迭代 List 和 Set在下面这个例子中，iter是一个迭代器，迭代的对象是 groupName ， while循环用来访问元素。 1234567891011121314public static void main(String[] args) { List&lt;String&gt; groupName = new ArrayList&lt;&gt;(); groupName.add(\"jerry\"); groupName.add(\"calm\"); groupName.add(\"Superman\"); groupName.set(1,\"Paul\"); // 用迭代器 Iterator&lt;String&gt; iter = groupName.iterator(); while (iter.hasNext()){ String name = iter.next(); System.out.println(name); }} 当然这个例子用 foreach 更简单 12345//用 foreachfor (String name : groupName) { System.out.println(name);} 不过 foreach 也有缺点： 无法用来进行ArrayList的初始化 无法得知当前是第几个元素了，当需要只打印单数元素的时候，就做不到了。必须再自定下标变量。 迭代 Map迭代 Map 稍微有点不同，需要先将 map 放到一个 set 里面。 1234567Map&lt;String,Integer&gt; map = new HashMap&lt;String, Integer&gt;();Set&lt;Map.Entry&lt;String, Integer&gt;&gt; entry = map.entrySet();Iterator&lt;Map.Entry&lt;String, Integer&gt;&gt; iter = enrty.iterator();while(iter.hasNext()){ Map.Entry&lt;String, Integer&gt; next = iter.next();} 遍历过程修改集合内容使用 Iterator 可以对集合进行遍历，但是 不能在遍历过程对原集合做增、删、改，会抛出 ConcurrentModificationException。 1234567while(it.hasNext()){ String str = it.next(); if(str.equals(\"abc\")){ // 错误，抛出Concurrent Modification Exception list.remove(str); } } 要对集合进行增删改操作，必须在 Iterrator 对象上操作，而不是原集合 List 上操作，因此，修改如下： 1234567while(it.hasNext()){ String str = it.next(); if(str.equals(\"abc\")){ // 正确 it.remove(); } } 快速失败（fail—fast）和 安全失败（fail—safe）fail—fast在用迭代器遍历一个集合对象时，如果遍历过程中对集合对象的内容进行了修改（增加、删除、修改），则会抛出Concurrent Modification Exception。 原理：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个 modCount 变量。集合在被遍历期间如果内容发生变化，就会改变 modCount 的值。每当迭代器使用 hasNext()/next() 遍历下一个元素之前，都会检测 modCount 变量是否为 expectedmodCount 值，是的话就返回遍历；否则抛出异常，终止遍历。 注意：这里异常的抛出条件是检测到 modCount！=expectedmodCount 这个条件。如果集合发生变化时修改modCount值刚好又设置为了expectedmodCount值，则异常不会抛出。因此，不能依赖于这个异常是否抛出而进行并发操作的编程，这个异常只建议用于检测并发修改的bug。 场景：java.util 包下的集合类都是快速失败（fail—fast）的，不能在多线程下发生并发修改（迭代过程中被修改）。 fail—safe采用安全失败（fail—safe）机制的集合容器，在遍历时不是直接在集合内容上访问的，而是先复制原有集合内容，在拷贝的集合上进行遍历。 原理：由于迭代时是对原集合的拷贝进行遍历，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，所以不会触发Concurrent Modification Exception。 缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。 场景：java.util.concurrent包下的容器都是安全失败（fail—safe），可以在多线程下并发使用，并发修改。 ArrayList 使用 Iterator 的实际例子ArrayList和Iterator的例子，要求初始化50个 hero，名字为 hero0,hero1,hero2…hero50， 然后删除 hero8,hero16,hero24… 可以用 foreach ， 也可以用 Iterator 123456789101112131415161718192021222324252627public static void main(String[] args) { List&lt;String&gt; groupName = new ArrayList&lt;&gt;(); // 初始化 50 个 hero for (int i = 0; i &lt;= 50; i++) { groupName.add(\"hero\" + i); } System.out.println(groupName); //迭代groupName的迭代器 Iterator&lt;String&gt; iter = groupName.iterator(); List&lt;String&gt; waitToRemove = new ArrayList&lt;&gt;(); //开始迭代，把8的倍数记录下来 while (iter.hasNext()){ String name = iter.next(); int i = groupName.indexOf(name); if (i % 8 ==0 ){ waitToRemove.add(name); } } groupName.removeAll(waitToRemove); System.out.println(groupName);} 这里有两个坑: 不能在iterator迭代的过程中，对容器进行增删操作。否则会抛出ConcurrentModificationException 不要在一次迭代中进行多次 iter.next() 操作 解决办法是：用一个waitToRemove容器，来存放待删除的数据，迭代完成再一并删除。或者用 ListIterator。 Collection 和 Collections的区别Collection是集合类的上级接口，子接口主要有Set 和List、Map。 Collections是针对集合类的一个帮助类，提供了操作集合的工具方法：一系列静态方法实现对各种集合的搜索、排序、线程安全化等操作。 例如，对List进行反转： 12List&lt;Blog&gt; blogList = blogService.findAll();Collections.reverse(blogList); 将 数组（Array） 转换为 集合（ArrayList）使用 Arrays.asList()方法将数组转换为ArrayList（注意是 Arrays, 不是 Array） 1234// java.util.Arrays 源码第 3799 行public static &lt;T&gt; List&lt;T&gt; asList(T... a) { return new ArrayList&lt;&gt;(a);} asList 方法 不适用 于基本数据类型（byte,short,int,long,float,double,boolean），但支持它们的包装类 该方法将数组与列表链接起来，当更新其中之一时，另一个自动更新 不支持add和remove，也就是说，转换后不能修改，只能读取 之所以会把原数组和转换后的集合链接起来，还不支持修改的原因是，asList方法返回的是 Arrays 类的内部类 java.util.Arrays.ArrayList，而不是集合里面的 java.util.ArrayList。 Arrays.asList方法使用示例： 123456String[] s = {\"aa\",\"bb\",\"cc\"}; List&lt;String&gt; strlist = Arrays.asList(s); strlist.forEach(n-&gt; System.out.println(n)); for(String str:strlist){ System.out.println(str); } 在 jdk 1.8 以上，可以用 lambda 替代 foreach 循环 12strlist.forEach(n-&gt; System.out.println(n));strlist.forEach(System.out::println); lambda的知识可参考 Lambda表达式 如果你要“真正地”把数组转集合，而不是数组的内部类，应该这么做： 12Object[] arr = {obj1, obj2, obj3};List&lt;Object&gt; objectList = new java.util.ArrayList&lt;Object&gt;(Arrays.asList(arr)); Java集合一览 集合 描述 ArrayList 一种可以动态增长和缩减的索引序列 LinkedList 一种可以在任何位置进行高效地插人和删除操作的有序序列 ArrayDeque 一种用循环数组实现的双端队列 HashSet 一种没有重复元素的无序集合 TreeSet 一种有序集 EnumSet 一种包含枚举类型值的集 LinkedHashSet 一种可以记住元素插入次序的集 PriorityQueue 一种允许高效删除最小元素的集合 HashMap 一种存储键 / 值关联的数据结构 TreeMap 一种键值有序排列的映射表 EnumMap 一种键值属于枚举类型的映射表 LinkedHashMap 一种可以记住键 / 值项添加次序的映射表 WeakHashMap 一种其值无用武之地后可以被垃圾回收器回收的映射表 IdentityHashMap 一种用 = 而不是用 equals 比较键值的映射表 简要介绍其他集合PropertiesProperties类实现了可以很容易地使用纯文本格式保存和加载的映射。是 map 的一种实现。 用于配置文件的定义和操作，使用频率非常高，同时键和值都是字符串。是集合中可以和IO技术相结合的对象。(到了IO在学习它的特有和io相关的功能。) BitSetBitSet（位组）类用来存储一系列比特。 stack、queue、deque、PriorityQueue不支持从中间添加元素。如果需要用stack、queue、deque且不关心线程安全问题，建议用 ArrayDeque WeakHashMapWeakHashMap类用来与垃圾回收器配合，当键的唯一引用来自Hash表条目时，就删除键值对。","link":"/post/f85bb872.html"},{"title":"Spirng（六） IoC容器探究","text":"在 Spring（一）从 传统Java Web到SpirngBoot 中对 Ioc 的概念已经有了初步认识：Spring 通过一个配置文件描述 Bean 与 Bean 之间的依赖关系，利用 Java 的类加载器和反射机制实例化 Bean 并建立 Bean 之间的依赖关系。 我们将调用类对某一接口实现类的依赖关系交由 Spring 容器管理，容器在我们需要的时候，通过注入及时地将对象进行实例化并装配好 bean，无需我们自己 new 。 除此之外，由于JDK提供的访问资源的类对底层资源并不友好，缺少从类路径或者Web容器的上下文获取资源的操作类，Spring重新设计了一个 Resource 接口，用于更强的底层资源访问能力。有了这个资源类，就可以将Spring的配置信息放在任何地方（数据库、LDAP）。而为了访问不同类型的资源，Spring还提供了一个强大的加载资源的机制，定义了一套资源加载的接口 ResourceLoader 及其实现类，可以访问包括classpath:、file:、http://、ftp://等地址前缀资源。 这一篇具体讲讲关于 Spring Ioc的更多内容。 BeanFactory 和 ApplicationContext一般称 BeanFactory 为 IoC 容器，而 ApplicationContext 为应用上下文。 BeanFactoryBeanFactory（com.springframework.beans.factory.BeanFactory）是 Spring Framework 最核心的接口，提供了高级的 Ioc 配置机制，使管理不同类型的 Java 对象成为可能。 在设计模式中有工厂模式，BeanFactory就是一个类工厂，它是一个通用工厂，可以创建并管理各种类的对象。这些对象都是普通的 pojo ，Spring 称这些对象为 bean 。BeanFactory 在启动的时候不会实例化Bean，getBean()的时候才会实例化。 Spring中的 bean 跟 javabean 的区别： javabean 需要满足一定的规范，但 Spring 中只要能被 Spring 容器实例化并管理的对象都称为 bean。 BeanFactory 是 Spring Framework 的基础设施，它是解析、管理、实例化所有容器的 Bean 的入口，BeanFactory 面向 Spring 本身。 ApplicationContextApplicationContext（com.springframework.context.ApplicationContext）在 BeanFactory 的基础上提供更多面向应用的功能：国际化支持、统一的资源文件读取方式、框架事件体系等。 ApplicationContext 面向框架的开发者，几乎所有的应用场合都可以直接使用 ApplicationContext 而非底层的 BeanFactory。ApplicationContext在解析配置文件时会对配置文件所有对象都初始化。 如果把 BeanFactory 比喻成“心脏”，那么 ApplicationContext 就是 “身躯”。 ApplicationContext 类体系结构待补充。 Spring支持类注解的配置方式，主要功能来自 Spring 的一个子项目 JavaConfig。 WebApplicationContext 类体系结构待补充。 父子容器通过 HierarchicalBeanFactory 接口， Spirng IoC 容器可以建立父子层级关联的容器体系。子容器可以访问父容器的 Bean， 但反过来则不行。这种体系增强了 Spring 容器架构的扩展性和灵活性。我们可以通过编程的方式为一个已存在的容器添加一个或多个由特殊用途的子容器。 例如，在 Spring MVC 中，表现层位于一个子容器中， 业务逻辑层 和 数据访问层 位于父容器中。这样，表现层可以引用业务逻辑层和数据访问层的 Bean，而业务逻辑层和数据访问层看不到表现层的 Bean。 IoC容器的初始化IOC容器的初始化的入口是refresh() 先进行 Resource 的定位与载入，由 ResourceLoader 完成 载入 BeanDefinition，这个载入过程就是把用户定义的 Bean 转换成 Bean 容器中的数据结构 BeanDefinition。BeanDefinition 的载入第一步是调用SAX进行解析得到 Document 对象，然后用一个 DocumentReader 进行解析，解析完的结果由个BeanDefinitionHolder对象持有 向IOC容器中注入载入后的 BeanDefinition，这个过程是通过BeanDefinitionRegistry实现的，实际上是注册到一个ConcurrentHashMap中 Bean 的生命周期 实例化：Spring通过一定的策略实例化 Bean。 填入属性：spring 将 值 和 bean 引用注入到 bean 的属性中。 如果 Bean 实现了 BeanNameAware 接口，工厂调用 Bean 的 setBeanName() 方法传递 Bean 的 ID。 如果 Bean 实现了 BeanFactoryAware 接口，工厂调用 setBeanFactory() 方法传入工厂自身。 如果实现了 ApplicationContextAware 接口, spring 将调用 setApplicationContext() 方法，将 bean 所在的上下文的引用进来。 如果 BeanPostProcessor 和 Bean 关联，那么它们的 postProcessBeforeInitialization() 方法将被调用。 如果 Bean 指定了 init-method 方法，该方法将被调用。 如果有 BeanPostProcessor 和 Bean 关联，那么它们的 postProcessAfterInitialization() 方法将被调用 如果配置了 destroy-method 方法则注册 DisposableBean 使用：到这个时候，Bean已经可以被应用系统使用了，并且将被保留在Bean Factory中直到它不再需要。 销毁。如果 Bean 实现了 DisposableBean 接口，销毁时就调用其 destroy 方法。 销毁方法： 如果 Bean 实现了 DisposableBean 接口，destory()方法被调用。 如果指定了订制的销毁方法，就调用这个方法。destory-method() 配置时指定。 Spring Bean 的作用域 singleton: 是 Spring Bean 的默认配置，这个 Bean 在 Spring 容器是 单例 的 prototype: 和 singleton 相反，为每个 Bean 请求提供一个 Bean 实例 request：在请求 Bean 范围内会给每个客户端的网络请求创建一个实例，请求结束之后会回收 session: 在每个 session 中有一个 Bean 的实例，session 结束后回收 global-session: 所有 Portlet 共享的 Bean Spring Boot 如何修改 bean 的作用域 ？加 @Scope() 注解即可 12345@Bean@Scope(\"singleton\")public Person personSingleton() { return new Person();} Spring 自动装配模式Spring容器可以自动配置相互协作beans之间的关联关系。这意味着Spring可以自动配置一个bean和其他协作bean之间的关系，通过检查 BeanFactory 的内容里没有使用和&lt; property&gt;元素。 no：Spring 框架的默认设置，开发者要在 Bean 中明确定义依赖 byName：在配置文件中查找相同名字的 Bean 进行装配 byType：在配置文件中查找相同类型的 Bean 进行装配 constructor：寻找有相同构造参数的 Bean 进行装配 autodetect：先尝试以 constructor 的方法进行装配，失败后 byType 进行装配 在Spring中注入Java集合类Spring 提供如下几种类型的集合配置元素： list元素用来注入一系列的值，允许有相同的值。 set元素用来注入一些列的值，不允许有相同的值。 map用来注入一组”键-值”对，键、值可以是任何类型的。 props也可以用来注入一组”键-值”对，这里的键、值都字符串类型。 12345@Autowiredprivate List&lt;UserService&gt; userServices;@Autowiredprivate Map&lt;String,DemoService&gt; demoServiceMap;","link":"/post/fd78ec01.html"},{"title":"Spring Cloud 微服务漫游","text":"微服务是松耦合的分布式软件服务，这些服务执行 少量的 定义明确的任务。 ——《Spring微服务实战》 对微服务的认识之前做项目，代码都是在一个工程里面，所有代码写完后，打一个 jar 包或 war 包，就放到服务器上面去跑了，这叫做单体架构。如果项目中有一点点需要修改，我们不得不整个工程重新编译打包，再重新部署。现在，我们决定用分布式和集群的方式，把业务功能拆分成多个子项目（服务），子项目可以单独运行，子项目与子项目之间暴露 http 或 rpc 接口，供外部或内部其他服务调用，然后，用一套规范的方式把众多子项目管理起来，这就是微服务架构。 Spring Boot 就是用于快速构建单个微服务的框架，而 Spring Cloud 则是各个微服务的管理者。 Spring Cloud 技术概览采用微服务后，会有很多问题暴露出来。Spring 整合了一套技术用于解决这些问题，这些技术集，即是 Spring Cloud 本身。 如何快速搭建单个微服务？ Spring Boot 快速框架 怎么知道系统中有哪些服务？Eureka 服务发现 多个微服务实例中如何共享配置信息？ Config Server 配置服务 如何让配置信息在多个微服务之间自动刷新？ RabbitMQ 总线 Bus 微服务之间是如何彼此调用的？ Sleuth/zipkin 服务链路追踪 如果某个微服务（集群）不能使用了，调用方如何去处理? 断路器 Hystrix 某个微服务的断路器什么时候开启了？什么时候关闭了？ 断路器监控 Hystrix Dashboard 如果某个微服务本身是个集群，那么如何进行对他们进行聚合监控？ 断路器聚合监控 Turbine Hystrix Dashboard 如何不暴露微服务名称，并提供服务？ Zuul 网关 我的服务在哪里 - 服务发现（Service Discovery）分布式架构中有很多机器，找到机器所在的物理地址即是服务发现。服务发现的一个好处是，调用方只需知道一个逻辑位置（而不是物理地址）即可以请求服务。而服务提供方可以通过水平伸缩（添加服务器）的方式来扩大服务，而不是想着买一台性能更好的服务器。服务发现的第二个好处是，当服务不可用时，服务发现引擎可以将坏掉的服务移除，然后采取一些其他策略。 Spring Cloud Eureka 服务发现Eureka 是 Netflix 开源的一个用来 定位服务 并做 负载均衡 和 故障转移 的服务，Spring 将其集成在 Spring Cloud 里面。其本身也是一个微服务。使用 Eureka，即可获得： 定位、发现服务 服务端负载均衡 故障转移 到 Spring Initializr 起一个 Spring Boot 工程，依赖选择 Eureka Server 。 可以看到 pom.xml 里面有 eureka-server 依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt;&lt;/dependency&gt; 在主类里面使用 @EnableEurekaServer 注解，标记为一个 Eureka 服务发现。 123456789@SpringBootApplication@EnableEurekaServerpublic class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); }} 配置文件，注明服务地址，客户端访问地址，以及服务名 123456789101112eureka: instance: hostname: localhost client: registerWithEureka: false fetchRegistry: false serviceUrl: defaultZone: http://${eureka.instance.hostname}:${server.port}/eureka/spring: application: name: eureka-server 运行，打开127.0.0.1:8761（端口在配置文件里指定），即可看到 Eureka 服务发现界面 当有其他服务注册进来时，可以在这个面板里看到。 拆分服务单体架构在单体架构，所有东西都在一个项目里，举个例子，假设我们有一个提供产品信息的服务。 pojo类 12345public class Product { private int id; private String name; private int price;} service层获取 Product 信息 1234567891011@Servicepublic class ProductService { public List&lt;Product&gt; listProducts(){ List&lt;Product&gt; ps = new ArrayList&lt;&gt;(); ps.add(new Product(1, \"product a\", 50)); ps.add(new Product(2, \"product b\", 150)); ps.add(new Product(3, \"product c\", 250)); return ps; }} Controller 层调用 Service 的数据，最后返回给 product.html 页面渲染。 微服务拆分单体采用微服务，就要把单体架构拆分。现在，我们把项目拆分成两部分：数据微服务 + 视图微服务 数据微服务：从DAO层取数据，通过 REST 返回 JSON 视图微服务：从数据微服务取数据（而不管数据是哪里来），渲染在 html 上 于是，我们现在启两个 Spring Boot 工程。 数据微服务 Spring Boot 工程很简单，就是把单体架构的视图部分去掉，用 @RestController 直接返回 JSON 1234567891011@RestControllerpublic class ProductController { @Autowired ProductService productService; @GetMapping(\"/products\") public Object products() { List&lt;Product&gt; ps = productService.listProducts(); return ps; }} 配置文件，主要注明该服务的名称，以及 Eureka 的地址 1234567spring: application: name: product-data-serviceeureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/ 在启动类注解 @EnableEurekaClient 表示这是一个 Eureka 客户端。（还有另一个注解，@EnableDiscoveryClient 不局限于 Eureka，还能用在类似的服务发现如Zookeeper、Consul） 12345@SpringBootApplication@EnableEurekaClientpublic class ProductDataServiceApplication { //...} 当然，别忘了pom.xml的 eureka-client 依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt;&lt;/dependency&gt; 现在，运行这个工程，可以在 eureka Dashboard 看到该服务已经被注册进来。当然，如果是局域网，我们完全可以在另一台计算机也运行这个工程，可以看到 eureka Dashboard 注册了两个一样的服务，或者在一台计算机两个不同的端口运行同一个服务，这就是简单的负载均衡。 视图微服务 Spring Boot 工程视图微服务将从数据微服务取数据，然后渲染在 products.html 中。 123456789101112@Controllerpublic class ProductController { @Autowired ProductService productService; @RequestMapping(\"/products\") public Object products(Model m) { List&lt;Product&gt; ps = productService.listProducts(); m.addAttribute(\"ps\", ps); return \"products\"; }} 关键是，视图微服务如何从数据微服务中取数据？ 这就需要用到 Ribbon 和 Feign 了。 使用 Ribbon 获取数据并做负载均衡Ribbon 用于调用其他服务，使用 restTemplate，并进行客户端负载均衡。 客户端负载均衡要在 Spring Boot 启动类声明方法 12345@Bean@LoadBalancedRestTemplate restTemplate() { return new RestTemplate();} Service层要取数据，就交代 Ribbon 去数据微服务取 123456789@Servicepublic class ProductService { @Autowired ProductClientRibbon productClientRibbon; public List&lt;Product&gt; listProducts(){ return productClientRibbon.listProdcuts(); }} Ribbon 用 restTemplate 去数据微服务取数据 client/ProductClientRibbon.java 12345678910@Componentpublic class ProductClientRibbon { @Autowired RestTemplate restTemplate; public List&lt;Product&gt; listProdcuts() { return restTemplate.getForObject(\"http://PRODUCT-DATA-SERVICE/products\",List.class); }} 当然，它自己作为一个微服务，也是需要配置的 1234567eureka: client: serviceUrl: defaultZone: http://localhost:8761/eureka/spring: application: name: product-view-service-ribbon 别忘了 pom.xml 的 eureka-client 依赖 使用 Feign 获取数据并做负载均衡Ribbon 用了 restTemplate，实际上还有另一种更优雅的方式 —— Feign pom.xml添加 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt; 在启动类声明@EnableFeignClients，然后在 client/ProductClientFeign.java 写接口 123456@FeignClient(value = \"PRODUCT-DATA-SERVICE\")public interface ProductClientFeign { @GetMapping(\"/products\") public List&lt;Product&gt; listProdcuts();} Service 跟 Controller 跟 Ribbon 方式一样 服务链路追踪随着业务的增加，我们的分布式系统中会有越来越多的微服务，服务与服务之间的调用关系也会越来越复杂，很难直接通过代码观察。因此需要借助 服务链路追踪服务器 来可视化地展示服务链路。zipkin 就是这样一个东西。 在有互相调用的微服务中（不包括eureka-server微服务）添加 zipkin 依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-zipkin&lt;/artifactId&gt;&lt;/dependency&gt; 添加配置项: 1spring.zipkin.base-url: http://localhost:9411 在启动类中加上: 1234@Beanpublic Sampler defaultSampler() { return Sampler.ALWAYS_SAMPLE;} 启动 zipkin 服务 ： 1java -jar zipkin-server-2.10.1-exec.jar 启动所有微服务，并进行一次调用 访问：http://localhost:9411/zipkin/dependency/ 即可看到调用链 断路器服务雪崩效应为了保证微服务高可用，单个服务有时候会集群部署。但由于网络或程序自身的原因，服务并不能保证百分百可靠可用，如果单个服务出现问题，调用这个服务就出现线程阻塞。此时若有大量的请求涌入，servlet容器的线程资源就会被消耗完毕导致服务瘫痪。由于服务与服务之间有依赖，故障会传播，对整个微服务系统造成不可估量的严重后果，这就是常说的服务故障的“雪崩效应”。 为了解决这个问题，有人就提出了一种解决问题的思路，断路器模型。就是每一个调用服务的接口处加一个断路器，默认是关闭的，当对服务调用时，不可用的次数达到一个阀值时，断路器就会打开，通过回调方法迅速返回一个值结束调用，避免出现连锁故障。 hystrix 断路器在 pom.xml 中添加 hystrix 的依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-hystrix&lt;/artifactId&gt;&lt;/dependency&gt; 注解由原来的 1@FeignClient(value = \"PRODUCT-DATA-SERVICE\") 修改为 1@FeignClient(value = \"PRODUCT-DATA-SERVICE\",fallback = ProductClientFeignHystrix.class) 当服务不可用时，就调用 ProductClientFeignHystrix 来进行反馈信息。 ProductClientFeignHystrix 的实现代码如下，实现了断路的 Feign 接口。 12345678@Componentpublic class ProductClientFeignHystrix implements ProductClientFeign{ public List&lt;Product&gt; listProdcuts(){ List&lt;Product&gt; result = new ArrayList&lt;&gt;(); result.add(new Product(0,\"数据微服务不可用\",0)); return result; }} 在配置文件中启用 hystrix 1feign.hystrix.enabled: true 配置中心 ConfigServer一个微服务可能是用集群的方式部署，有多个实例。当需要修改配置信息时，要手动对集群的每一个微服务实例进行修改，显然很麻烦。为了解决这一问题，我们把配置信息放在一个公共的地方，比如 git 上面，然后通过 配置服务器（ConfigServer） 获取。每一个微服务实例再从 ConfigServer 上获取配置。 这样，只要修改 git 上的信息，同一个集群里的所有微服务都立即获取相应信息了。 ConfigServer 本身是一个微服务，启动后，我们还需要对客户端微服务进行修改，才能感应到配置服务器。 消息总线 Bus虽然有了 ConfigServer，但是每次修改配置信息，我们都需要重启 ConfigServer 和客户端微服务实例。我们希望一旦 git 上的配置信息修改之后，就可以自动地刷新到微服务里，而不需要手动重启。 RabbitMQ 是一个消息队列中间件，Spring Cloud 通过 RabbitMQ 来进行消息广播，以达到有配置信息发生改变的时候，广播给多个微服务的效果。 服务网关 Zuul当系统中微服务数量越来越多，而且这些服务实例数通常是动态的，对于客户端而言很难发现动态改变的服务实例的访问地址信息。我们引入 API Gateway 作为轻量级网关，服务调用时是通过网关进行转发，而非直接调用。API Gateway 中也会实现相关的认证逻辑从而简化内部服务之间相互调用的复杂度。 Zuul 是 Netflix 出品的一个基于 JVM 路由和服务端的负载均衡器。Spring Cloud Zuul 是 Spring 提供的 API Gateway 技术，提供动态路由，监控，弹性，安全等的边缘服务。 小结可以看到，我们用 Eureka 做服务发现，将一个单体应用拆分成了 数据微服务 和 视图微服务 两个服务，并复制 数据微服务 的两份 jar 包，分别部署做负载均衡。视图微服务用 Ribbon 或 Feign 方式（推荐）从 数据微服务 取数据。这一切，都要通过服务注册与发现 Eureka。 在微服务集群中，我们用 ConfigServer 共享配置信息，并通过 RabbitMQ 消息总线进行广播刷新。 当系统中的服务越来越多，我们借助 zipkin服务链路追踪器 来观察服务之间的调用关系。且服务之间并不直接调用，而是通过 API Gateway 服务网关进行路由转发。 当 Feign 远程调用取数据发现对方服务不可用时，就会触发 Hystrix 断路器进行反馈，避免了服务雪崩效应。","link":"/post/2a2a41cf.html"},{"title":"Spring（七）深入理解Spring MVC","text":"我们通过 Spring Boot 来创建一个 Web 应用，发挥作用的是 Spring MVC 框架。当我们在IDE里敲入以下代码时，究竟发生了什么呢？ 12345678910111213141516@GetMapping(\"/\")public String hello() { return \"login\";}@PostMapping(\"/login\")public ModelAndView login(LoginData loginData) { if (LOGIN.equals(loginData.getLogin()) &amp;&amp; PASSWORD.equals(loginData.getPassword())) { return new ModelAndView(\"success\", Collections.singletonMap(\"login\", loginData.getLogin())); } else { return new ModelAndView(\"failure\", Collections.singletonMap(\"login\", loginData.getLogin())); }} 从基本的 Servlet 谈起一个 Spring MVC 应用运行后，当我们在浏览器访问 http://localhost:8080/ 时，发生了什么？我们知道，Spring Boot 内置了一个 Tomcat，而 Tomcat 作为应用服务器，它是一个 Servlet 容器，所有发送给 Tomcat 的 HTTP 请求都会被 Java Servlet 进行处理。 Servlet 是 Java Web 应用的核心组件。一个 HTTP servlet 用于处理接收、处理一个 HTTP 请求，并进行响应。 我们自然会猜想，Spring Web 应用程序的入口，应该是一个 Servlet，事实也确实如此。 DispatcherServletDispatcherServlet 就是 Spring Web 应用程序的入口，它就是一个servlet。 为什么需要 DispatcherServlet对于我们开发者来说，我们关心的是业务逻辑，而不是繁琐无聊的样板代码，什么是样板代码呢？例如： 将一个 HTTP request 映射到一个处理该 request 的方法 将 HTTP request 的 data 和 header 转换为 DTO（data transfer objects ）或者 实体类（domain objects） model-view-controller 之间的相互连接 将处理完毕的 DTO 或 实体类转换回 HTTP 的 response 我们需要框架来帮我们简化这些繁琐的工作，而 Spring 的 DispatcherServlet 正是干这件事的。 同时，DispatcherServlet 是可扩展的，它允许我们为许多任务添加适配器（adapters），例如： 将一个 HTTP request映射到到一个可以处理该 request 的方法或类（这部分在 HandlerMapping 接口） 对不同的 request 做不同的处理，包括常规的 Servlet，复杂的 MVC 工作流，或者 POJO bean 里的方法（这部分在 HandlerAdapter 接口） 根据不同的模板引擎做不同的处理（这部分在 ViewResolver 接口） 解析多请求，例如多文件上传，或者你自己写的MultipartResolver解析器 解析 cookie、session、 Accept HTTP header 等（叫做locale） 处理 HTTP request的过程DispatcherServlet 的继承关系： GenericServletGenericServlet 不直接针对 HTTP ，它只是定义了一个 service() 方法，用于接收请求以及产生响应。 12public abstract void service(ServletRequest req, ServletResponse res) throws ServletException, IOException; HttpServletHttpServlet是专注于 HTTP 请求的 Servlet。它是一个抽象类，其中的 service() 方法用于区分不同的 HTTP 方法（如 GET、POST） 1234567891011121314protected void service(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException { String method = req.getMethod(); if (method.equals(METHOD_GET)) { // ... doGet(req, resp); } else if (method.equals(METHOD_HEAD)) { // ... doHead(req, resp); } else if (method.equals(METHOD_POST)) { doPost(req, resp); // ... }} HttpServletBeanHttpServletBean 是 Spring 能够感知的类。它从 web.xml 或 WebApplicationInitializer 等配置文件中获取初始化参数，并注入到 Servlet bean 属性当中，可以理解成为 DispatcherServlet 进行初始化。 FrameworkServletFrameworkServlet 实现了 ApplicationContextAware 接口，在 Web context（上下文）中整合了 Servlet 的功能。 但 FrameworkServlet 自己也能创建一个 web context。 在其父类 HttpServletBean 中，对 Servlet 注入了一些初始化参数。一旦一个类出现在 contextClass 初始化参数当中，这个类的一个实例就会被创建。否则，就用默认的XmlWebApplicationContext。鉴于 XML 配置有点“过时”，在 Spring Boot 中默认使用的是注解方式，即AnnotationConfigWebApplicationContext （这一段看不太懂，参考原文：https://dzone.com/articles/how-spring-mvc-really-works） DispatcherServlet1.统一请求的处理（Unifying the Request Processing）DispatcherServlet 用于统一所有请求的处理。如果说，HttpServlet.service()提供了一个底层的视角来区分HTTP请求的方法，那对 Spring MVC 来说，这些方法只是一个参数罢了。 在 HttpServlet 中区分了很多 HTTP 方法，但在 FrameworkServlet 中这些方法又被统一到 processRequest() 方法进行处理，之后才是 doService() 做具体的业务服务。 1234567891011@Overrideprotected final void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { processRequest(request, response);}@Overrideprotected final void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { processRequest(request, response);}// … 2.扩展请求（Enriching the Request）之后，DispatcherServlet 实现了 doService() 方法，它不仅仅处理 web context，还包括 locale resolver，theme resolver, theme source 等等。 12345request.setAttribute(WEB_APPLICATION_CONTEXT_ATTRIBUTE, getWebApplicationContext());request.setAttribute(LOCALE_RESOLVER_ATTRIBUTE, this.localeResolver);request.setAttribute(THEME_RESOLVER_ATTRIBUTE, this.themeResolver);request.setAttribute(THEME_SOURCE_ATTRIBUTE, getThemeSource()); 当然， doService()也准备了输入和输出的映射。Flash map是一种基本的模式，用于从一个请求传递参数到另一个请求，这在重定向的时候非常有用。 12345678FlashMap inputFlashMap = this.flashMapManager .retrieveAndUpdate(request, response);if (inputFlashMap != null) { request.setAttribute(INPUT_FLASH_MAP_ATTRIBUTE, Collections.unmodifiableMap(inputFlashMap));}request.setAttribute(OUTPUT_FLASH_MAP_ATTRIBUTE, new FlashMap()); 之后，doService()调用 doDispatch() 进行请求调度。 3.调度请求（Dispatching the Request）Dispatch()方法最主要的用途是寻找适合的 handler，handler 可以是任意 Object 而不局限于某些接口。这意味着 Spring 需要为 handler 找到合适的适配器（adapter），从而知道如何与 handler “沟通”。 Spring 用 HandlerMapping 接口来找到与 request 匹配的 handler，HandlerMapping 有多种不同的实现。例如，SimpleUrlHandlerMapping 就能够根据 URL 找到合适的处理这个 request 的 bean 。 12/welcome.html=ticketController/show.html=ticketController 最广泛使用的 HandlerMapping 是 RequestMappingHandlerMapping。它能够将 @RequestMapping 注解映射到一个 @Controller 类中。 处理请求（Handling the Request）当 Spring 通过 HandlerMapping 找到 request 对应的 handler 时，HandlerAdapter 的 .handler() 方法将决定如何处理这个 request,之后： 将数据写进 response object，然后返回 null 返回一个 ModelAndView object 用于被DispatcherServlet渲染 1234@NullableModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception; 问：HandlerMapping不是已经可以帮助我们匹配到具体的handle（或者说控制器）了吗?为什么还需要HandlerAdapter？ 答：这是因为使用了 适配器模式， 有很多种控制器(Controller) 一种是带 @Controller 注解的， 还有一种是写一个servlet 当做controller, 所以用适配器做适配，HandlerAdapter 有几个子类，每个子类都是适配某一种类型的控制器，有了 HandlerAdapter，你只需要调用 handle 方法，屏蔽了不一致的细节，否则在DispatcherServlet里面要写很多if else if else。 事实上，有多种 handler 类型。例如，SimpleControllerHandlerAdapter 处理一个 Spring MVC controller 的实例: 1234public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { return ((Controller) handler).handleRequest(request, response);} 注意，HandlerAdapter返回了一个 ModelAndView object，但是并没有渲染它。 另一个例子，SimpleServletHandlerAdapter 用于适配一个标准的 Servlet 12345public ModelAndView handle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception { ((Servlet) handler).service(request, response); return null;} Servlet 并不知道 ModelAndView ，它只是处理了 request 请求，然后把处理结果写进 response object，但是返回了一个空的 ModelAndView 而在我们开发的角度，Controller 是一个包含了一些 @RequestMapping 注解的 POJO 类。所以任何的 handler 其实都是包含在 HandlerMethod 实例里面的方法而已。Spring 用 RequestMappingHandlerAdapter 类来适配这种 handler 类型。 处理参数并返回值在编写 Spring MVC 程序时，我们发现 Controller 中并没有用 HttpServletRequest 或者 HttpServletResponsearguments 作为方法的参数，而是用具体的实体类，或者路径变量（path parameter）等。同时还能发现，我们并不返回一个 ModelAndView 实例，而是返回一个视图名字，或者 POJO（将被转为JSON）。 事实上，RequestMappingHandlerAdapter 确保了从 HttpServletRequest 方法获取中的参数被解析。以及它会从方法的返回值创建一个 ModelAndView object。 RequestMappingHandlerAdapter 的核心代码如下，上述转换就发生在这里。 12345678910ServletInvocableHandlerMethod invocableMethod = createInvocableHandlerMethod(handlerMethod);if (this.argumentResolvers != null) { invocableMethod.setHandlerMethodArgumentResolvers( this.argumentResolvers);}if (this.returnValueHandlers != null) { invocableMethod.setHandlerMethodReturnValueHandlers( this.returnValueHandlers);} 还有一些其他的比如 HandlerMethodArgumentResolver 、HandlerMethodReturnValueHandler，做的都是类似的转换的工作。 例如，当你在 controller 的 hello() 方法返回一个 string，ViewNameMethodReturnValueHandler 会处理这个值。而当你返回一个 ModelAndView ，则是 ModelAndViewMethodReturnValueHandler 来处理。 渲染视图（Rendering the View）到这一步，Spring已经处理了 HTTP request 并得到一个 ModelAndView object，之后，DispatcherServlet 的 render() 方法将使用 LocaleResolver 实例设置 response 的 locale (cookie、session、 Accept HTTP header等) 。 Spring 会根据你用的是哪种模板引擎进行对应的渲染和解析，例如 ThymeleafViewResolver 用于渲染Thymeleaf模板引擎。在 render() 方法执行结束之后，HTML 页面就可以被发送到用户的浏览器进行显示了。 REST 支持除了传统的 MVC 场景，我们也可以用 Spring MVC 框架来创建 REST web 服务。接收参数时，我们可以用 @RequestBody 注解来声明接收一个 POJO （通常是JSON转换成实体类），也可以在方法上面加 @ResponseBody 来声明这个方法返回一个 POJO（Spring会帮你转换成 JSON） 12345678910import org.springframework.web.bind.annotation.RequestBody;import org.springframework.web.bind.annotation.ResponseBody;@ResponseBody@PostMapping(\"/message\")public MyOutputResource sendMessage( @RequestBody MyInputResource inputResource) { return new MyOutputResource(\"Received: \" + inputResource.getRequestMessage());} Spring 框架是通过 HttpMessageConverter 来完成 DTO 到 REST representation 的转换的。例如，其中一个实现类 MappingJackson2HttpMessageConverter 就用来在 model object 与 JSON 之间互相转换，内部用的是 Jackson 库。 Spring 还可以在类上声明 @RestController 注解来简化REST API的创建过程。这可比在每一个方法都加上@ResponseBody方便得多。 123456789import org.springframework.web.bind.annotation.RestController;@RestControllerpublic class RestfulWebServiceController { @GetMapping(\"/message\") public MyOutputResource getMessage() { return new MyOutputResource(\"Hello!\"); }} 参考：How Spring MVC Really Works","link":"/post/3fc0f79e.html"},{"title":"Spring（一）从传统Java Web到SpirngBoot","text":"从 MVC 结构到 Web 框架Java Web 技术日新月异，如今，我们开发 Java Web 项目都是靠框架快速搭建。然而，为什么需要框架？还得从传统的 MVC 结构说起。 传统 Model-View-Controller 架构典型的Java Web应用架构如下： 浏览器发送 HTTP 请求到服务端，被 Controller(Servlet) 获取并进行处理（参数解析、请求转发） Controller 调用核心业务逻辑 —— Model Model 进行数据库存取操作，并将操作结果返回 Controller 将业务逻辑处理结果交给View（JSP），动态输出 HTML 内容 动态生成的 HTML 内容返回到浏览器显示 封装 Servlet在这个过程中，我们要操作 Servlet 写大量的功能代码，为了简化，我们可以把 Servlet 中经常要实现的功能封装起来并提供一层公共抽象，这样我们只要编写简单的 POJO 代码或者实现一些接口，就能完成复杂的 Web 请求的后端逻辑处理。 Spring MVC 就是这样的一个框架。它提供了一个DispacherServlet，我们只需实现 Spring MVC 提供的接口就可以完成复杂的操作，而不用写大量的 Servlet 代码。 封装 JDBC同理，操作数据库时要写很多 JDBC 样板代码，为什么不对数据库操作也做一个封装呢？在 Java JDBC 编程 中提到，可以将对象和关系数据库进行映射，从而把操作数据库变成操作 Java 对象，这就是大名鼎鼎的 ORM（对象关系映射）技术了。Hibernate 和 MyBatis 就是这样的 ORM 框架。 Spring Framework 简介前面提到 Spring MVC 是 Java Web 开发中对 Servlet 进行封装的框架，专注于简化 Web MVC 开发流程。实际上，Spring 是一个大家族，它是一个轻量级的 DI / IoC 和 AOP 容器的开源框架，来源于 Rod Johnson 在其著作《Expert one on one J2EE design and development》中阐述的部分理念和原型。 Spring Framework包括以下几大部分： 在学习这些之前，得先了解 Spring 最核心的两个概念：IoC 和 AOP。 IoC （Inversion of Control，反转控制）反转控制其实是一种依赖倒置原则的设计思想。也就是让底层依赖上层。具体的做法就是使用 DI （依赖注入，Dependency Inject），DI把底层类作为参数传给上层，实现上层对下层的控制。 反转控制容器采用依赖倒置原则的设计之后，会产生一个问题，假设我们要调用一个上层，由于上层需要接受下层作为参数，我们必须在构造上层前构造下层，这样我们的代码中就会写很多 new 。 例如，service 是一个上层服务， mapper 是底层数据库交互。如果一个 service 要调用多个 mapper 进行处理，就要 new 很多不同的 mapper 实例。不仅如此，由于 service 具有通用性，每一次用户请求到达服务器，都会调用 service，这时候重复 new 了非常多功能相同的 mapper 实例，造成服务器资源浪费。 123456public service(){ UserMapper usermapper = new UserMapper(); ProductMapper productMapper = new ProductMapper(); // ... 进行处理} 于是，我们想到能不能用一个工具，把这些实例都统一管理起来，当某个上层需要调用某个下层，就通过依赖注入的方式，把这个下层对象传递给上层。反转控制容器（IoC Container）就是这样的工具。这个容器可以自动对我们的代码进行初始化，而我们要做的，只是维护一个 Configuration， 具体到 Spring 中，我们可以通过 xml 配置、 注解 或 JavaConfig（推荐）的方式让 Spring 帮我们注入对象(Spring 容器通过 beanFactory 和 ApplicationContext 两种类型来实现)，我们得到对象后直接就可以使用，而不需要了解注入过程层层依赖的细节。 这样，调用类对接口实现类的依赖关系变成了由第三方（容器）注入。在 Spring 中，注入包括构造函数注入、Setter注入、接口注入。 1234567891011// 使用注解注入 mapper// 这里为了方便才这样写，更好的选择是使用构造函数注入@Autowrizedprivate UserMapper usermapper;private ProductMapper productMapper;public service(){ // 直接可以使用，无需 new usermapper.getuser();} 简单地说，当我们要使用某个对象，只需要从 Spring 容器中获取需要使用的对象，不关心对象的创建过程，把创建对象的控制权反转给了 Spring 框架，而 Spring 容器是通过 DI，在创建对象的过程中将对象依赖属性（简单值，集合，对象）通过配置设值给该对象。 对于软件来说，某一接口的实现类的选择控制权从调用类中移除，转交由第三方决定，这就是反转控制。 IoC 是如何实现的如果我们自己来实现这个依赖注入的功能，我们怎么来做？无外乎： 读取标注或者配置文件，看看 bean 依赖的是哪个 Source，拿到类名 使用反射 API，基于类名实例化对应的对象实例 将对象实例，通过构造函数或者 setter，传递给 bean 我们发现其实自己来实现也不是很难，Spring 实际也就是这么做的。IoC 就是一个工厂模式的升级版！当然，要做一个成熟的IoC框架，还是非常多细致的工作要做，Spring 不仅提供了一个已经成为业界标准的 Java IoC 框架，还提供了更多强大的功能。 参考： 知乎:Spring IoC有什么好处呢？ Spring学习(1)——快速入门 IoC 背后的Java原理，其实就是 Java 的反射机制 AOP（Aspect Oriented Program，面向切面编程）在面向切面编程的思想里面，把功能分为 核心业务功能 和 周边功能。所谓核心业务，包括登录，增加数据，删除数据等。所谓周边功能，包括性能统计，安全，日志，事务管理等等。 在登录功能中，需要输出日志，增加数据、删除数据也都需要输出日志。于是，我们的代码可能就会变成： 123456789101112131415public void login(){ logger.info(\"before log..\") // login // ... logger.info(\"after log..\")}public void insertData(){ logger.info(\"before log..\") // insert // ... logger.info(\"after log..\")} 这些日志输出，真的是 login() 方法和 insertData() 方法需要做的事情吗？就像我们每个月用了多少电一样，难道要我们用户自己来记录用电量吗？这应该是电力公司该做的事情！ 于是，AOP 出现了。我们可以对核心业务功能和切面功能分别独立进行开发，然后把切面功能和核心业务功能 “编织” 在一起，这就叫 AOP。在 Spring AOP 中，“编织”的方式可以是 xml 或者 注解。周边功能在 Spring 的面向切面编程 AOP 思想里，即被定义为切面。 AOP 的好处是允许我们把遍布应用各处的功能分离出来形成可重用的组件。 参考书籍：《Spring实战》第4版 Spring Boot 在 Spring MVC 框架中，我们不得不进行大量的配置，而在 Spring Boot 快速框架中，很多配置框架都帮你做好，拿来即用。 注意： Spring Boot使用 “习惯优于配置” （项目中存在大量的配置，此外还内置一个习惯性的配置）的理念让你的项目快速运行起来。 Spring Boot并不是什么新的框架，而是默认配置了很多框架的使用方式，就像 Maven 整合了所有的 jar 包一样，Spring Boot 整合了所有框架。 IDEA Spring Boot 实战创建工程在 IDEA 中，创建一个新的Spring Initalizr工程, Type 选择 Maven， 组件选择 Web ， IDEA 会自动帮我们新建一个基于 Maven 的 Spring Boot 工程。 或者通过 https://start.spring.io/ 初始化工程 看一下 pom.xml 大概长这样 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;project xmlns=\"http://maven.apache.org/POM/4.0.0\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd\"&gt; &lt;modelVersion&gt;4.0.0&lt;/modelVersion&gt; &lt;groupId&gt;jerrysheh&lt;/groupId&gt; &lt;artifactId&gt;springboot-demo&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;packaging&gt;jar&lt;/packaging&gt; &lt;name&gt;springboot-demo&lt;/name&gt; &lt;description&gt;Demo project for Spring Boot&lt;/description&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;2.0.1.RELEASE&lt;/version&gt; &lt;relativePath/&gt; &lt;!-- lookup parent from repository --&gt; &lt;/parent&gt; &lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;project.reporting.outputEncoding&gt;UTF-8&lt;/project.reporting.outputEncoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;/properties&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt;&lt;/project&gt; java代码在src/main/java/Example.java里面，应该已经有类似下面这样的代码了。 1234567@SpringBootApplicationpublic class ToywebApplication { public static void main(String[] args) { SpringApplication.run(ToywebApplication.class, args); }} @SpringBootApplication 是 Spring Boot 的核心注解，它是一个组合注解，该注解组合了：@SpringBootConfiguration、@EnableAutoConfiguration、@ComponentScan 写一个类：HelloController.java 12345678@RestControllerpublic class HelloController { @GetMapping(\"/\") public String hello(){ return \"Hello World\"; }} 直接运行， 访问127.0.0.1:8080， 竟然已经能看到 Hello World 了，我们还没有进行 project structure 以及 Tomcat 配置呢 ？ 事实上， Spring Boot 已经内置了这些配置，拿来即用。 注解： @RestController 注解是 @Controller 和 @ResponseBody 的合体 配置文件 Spring Boot 的配置文件为 application.properties 或 application.yml，放置在【src/main/resources】目录或者类路径的 /config 下。 排除自动配置在 Spring Initalizr 的时候，如果我们点多了组件，有可能会导致启动失败，这时候在@SpringBootApplication注解后添加排除项即可。或者在 pom.xml 中去除多余组件。 1@SpringBootApplication (exclude= {DataSourceAutoConfiguration.class}) 打包 jar确保 pom.xml 里面有 12345678&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt; 执行以下语句进行打包。 1mvn package 运行将打包的 jar 拷贝到 linux 服务器上， 执行以下命令即可启动 1java -jar spring-boot01-1.0-SNAPSHOT.jar 但是这样命令行一退出程序也跟着退出了，可以使用以下命令，将 log 输入到文件，保持程序在后台运行。 1java -jar spring-boot01-1.0-SNAPSHOT.jar &gt; log.file 2&gt;&amp;1 &amp; 这种方式看似脱离终端了，但是实际上还是受终端影响，当 SSH 退出时终端关闭，项目也会跟着关闭。 因此好的办法是将其写入到 shell 脚本中 1vim run.sh 在 run.sh 里面输入 12#!/bin/bashjava -jar spring-boot01-1.0-SNAPSHOT.jar &gt; log.file 2&gt;&amp;1 &amp; run.sh添加执行权限，再执行 12chmod +x run.sh./run.sh 热部署在 pom.xml 里面添加以下语句即可热部署，也就是我们修改了代码之后无需重启工程，即可看到效果。 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-devtools&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt; &lt;!-- 这个需要为 true 热部署才有效 --&gt;&lt;/dependency&gt;&lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;!-- 没有该配置，devtools 不生效 --&gt; &lt;fork&gt;true&lt;/fork&gt; &lt;/configuration&gt;&lt;/plugin&gt; 提示：Ctrl + Shift + F9 更新静态文件 引入静态文件application.properties 123# 静态资源spring.mvc.static-path-pattern=/static/**spring.resources.static-locations=classpath:/static html 1234&lt;head&gt; &lt;link rel=\"stylesheet\" type=\"text/css\" href=\"../static/css/materialize.css\"&gt; &lt;script src=\"../static/js/materialize.js\"&gt;&lt;/script&gt;&lt;/head&gt; 参考： Spring Boot【快速入门】 Spring官方教程：Building a RESTful Web Service how2j：SPRINGBOOT入门","link":"/post/6200df85.html"},{"title":"Spring（三）Spring MVC","text":"在 从MVC到Spring Boot 这一篇中，搭建了 Spring Boot 的 Hello World 程序。这一篇继续学习基于 Spring MVC 框架的应用程序。应用程序由Spring Boot搭建。 Spring MVC 的执行流程在 Spring MVC 框架中，控制器实际上由两部分组成： 前端控制器（DispatcherServlet）：用于拦截所有用户请求和处理通用代码 控制器（Controller）： 实现实际的业务逻辑。 1. DispatcherServlet用户请求统一被前端控制器 DispatcherServlet 捕获。DispatcherServlet 解析URL，得到URI，这个 URI 会被交给 Handle Mapping（处理器映射）。 2. Handle MappingHandle Mapping 会根据请求所携带的 URL 信息来进行决策，获取该 Handle 的所有相关对象，封装成 HandleExcutionChain 对象返回，DispatcherServlet 根据获得的 Handle，选择一个合适的 HandleAdapter。 3. HandleHandlerAdapter 是处理器适配器，Spring MVC通 过HandlerAdapter 来实际调用处理函数。简单地说，就是让 HandlerAdapter 去调用 Handle 实际处理的方法，比如我们编写的 hello 方法。 1234public ModelAndView handleRequest(javax.servlet.http.HttpServletRequest httpServletRequest, javax.servlet.http.HttpServletResponse httpServletResponse) throws Exception { // 处理逻辑 ....} 一般，Controller 是 Handler，但 Handler 不一定是 Controller。 填充 Handle 传入参数的过程中，Spring帮我们做了很多工作，包括：消息转换（json/xml -&gt; 对象）、数据转换（String -&gt; Integer）、数据格式化、数据验证等。 4. ModelAndViewHandle 处理完毕之后，会返回一个 Model， 仅仅有 Model 是不够的，用户看到一般是 View，因此把 Model 返回给 DispatcherServlet。 5. View ResolverDispatcherServlet 会根据传过来的 Model，通过视图解析器（View Resolver）匹配一个适当的视图实现。 6. View视图使用 Model 数据渲染出结果，这个输出结果会通过响应对象传递给客户端。 配置注解 @SpringBootApplication：表示这是一个Spring Boot应用程序，它其实包含了@ComponentScan、@Configuration和@EnableAutoConfiguration等多个注解。 @Configuration： 表示这是一个Java配置（相当于xml配置） @EnableAutoConfiguration：顾名思义，开启自动配置 @ComponentScan：扫描包。默认扫描跟@SpringBootApplication所在类同级目录以及子目录。 URL路由 @Controller： 表示是一个处理HTTP请求的控制器(即MVC中的C)，该类中所有被 @RequestMapping 标注的方法都会用来处理对应URL的请求。 返回字符串和对象 @ResponseBody：返回的是数据（Data），而不是视图（View）。如果数据是 Java 对象而不是字符串或基本数据类型，那么返回的就是 json 格式的（Spring MVC集成了jackson帮我们序列化）。 12345678@Controllerpublic class IndexController { @RequestMapping(\"/hello\") @ResponseBody public String hello() { return \"hello\"; }} 或者用 @RestController，是 @Controller 和 @ResponseBody 的合体 12345678@RestControllerpublic class IndexController { @RequestMapping(\"/api/city\") public String hello() { City city = cityService.getCity(); return city; }} @RequestMapping： 浏览器请求映射路由，可以标记在方法上，也可以标记在类上。（详细用法可参考CSDN） @RequestMapping还可以细分为以下几个Mapping： @GetMapping： 浏览器 GET 方法请求映射路由 @PutMapping @PostMapping @DeleteMapping 返回 HTML 页面在 pom.xml 增加 thymeleaf 依赖(thymeleaf是一种比jsp更好的模板引擎) 12345678910&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;!-- 为了让Thymeleaf能够正确的识别HTML5 --&gt; &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt; &lt;artifactId&gt;nekohtml&lt;/artifactId&gt; &lt;version&gt;1.9.22&lt;/version&gt;&lt;/dependency&gt; Thymeleaf 遇到没有闭合的HTML标签会报错，可以在 application.properties 文件增加一行 spring.thymeleaf.mode=LEGACYHTML5 以支持HTML5 123456789101112@Controllerpublic class AppController { @GetMapping(\"/\") public String index() { return \"index\"; } @GetMapping(\"/home\") public String create() { return \"home\"; }} 在 resource/templates 目录下放置 index.html 和 home.html，访问 127.0.0.1:8080/ 将跳转到 index.html，访问 127.0.0.1:8080/home 将跳转到 home.html 如果我们的项目变大了，有数十个 html 文件，我们要写很多个这样的样板方法，可以用 java config 简化样板方法 MvcConfig.java 1234567891011@Configurationpublic class MvcConfig implements WebMvcConfigurer { public void addViewControllers(ViewControllerRegistry registry) { registry.addViewController(\"/home\").setViewName(\"home\"); registry.addViewController(\"/\").setViewName(\"index\"); registry.addViewController(\"/hello\").setViewName(\"hello\"); registry.addViewController(\"/login\").setViewName(\"login\"); }} PathVariable 和 RequestParam使用PathVariable获取路径变量1234@GetMapping(\"/users/{username}\")public String userProfile(@PathVariable String username) { return String.format(\"user %s\", username);} 可以使用下列形式来匹配正则表达式，语法{变量名:正则表达式}，不匹配的URL将不会被处理，直接返回404 1@GetMapping(\"/users/{username:[a-z0-9_]+}\") [a-z0-9_]+是一个正则表达式，表示只能包含小写字母、数字和下划线。 当有多个路径变量时，用@PathVariable(value = &quot;..&quot;) 123456@PostMapping(\"api/rate/{userId}/{productId}/{rating}\")public void rate(@PathVariable(value=\"userId\") Integer userId, @PathVariable(value = \"productId\") Integer productId, @PathVariable(value = \"rating\") Integer rating){} 使用 RequestParam 获取参数有时候我们需要处理 URL 中的参数 ，比如127.0.0.1:8080/userinfo?key1=value1&amp;key2=value2 123456789@RestControllerpublic class EditPetForm { @GetMapping(\"/blogs\") public String setupForm(@RequestParam(\"id\") int blogId) { return String.format(\"blog id = %d\", blogId); }} 访问 127.0.0.1:8080/blogs?id=66， 可以看到浏览器显示了 blog id = 66 使用@RequestParam(name = &quot;id&quot;, required = false, defaultValue = &quot;1&quot;)，当参数不存在的时候，默认为1 如何选择两种方式都能获取用户输入： 通过@PathVariable，例如/blogs/1 通过@RequestParam，例如blogs?blogId=1 建议： 当URL指向的是某一具体业务资源（或者资源列表），例如博客、用户时，使用@PathVariable 当URL需要对资源或者资源列表进行过滤、筛选时，用@RequestParam 例如用/blogs?state=publish而不是/blogs/state/publish来表示处于发布状态的博客文章 其他注解 @RequestHeader：获得请求头信息，作为方法参数 123456@RequestMapping(\"/requestheaderTest\")public void requestheaderTest( @RequestHeader(\"User-Agent\") String userAgent, @RequestHeader(\"Accept\") String[] accepts) { // do something} @CookieValue：获取Cookie信息，作为方法参数 @SessionAttributes：允许我们有选择地指定 Model 中那些属性转存到 HttpSession 中。，一般注解在类上。 @ModelAttribute：将请求参数绑定到 Model 对象 使用Thymeleaf模板渲染 后台发送数据给模板引擎使用Thymeleaf作为模板引擎，在需要动态获取的地方用Thymeleaf标签替代。如 12&lt;h2 th:text=\"${title}\"&gt;博客标题&lt;/h2&gt;&lt;span th:text=\"${createdTime}\"&gt; 在HTML中增加命令空间，避免IDE错误提示 1234&lt;html xmlns=\"http://www.w3.org/1999/xhtml\" xmlns:th=\"http://www.thymeleaf.org\"&gt; ...&lt;/html&gt; 首先需要在 Controller 做一些工作 123456@GetMapping(value = \"/bookList\")public String getBookList(ModelMap map){ List&lt;book&gt; bl = bookService.findAll(); map.addAttribute(\"bookList\", bl); return \"bookList\";} 也可以简化为 12345@GetMapping(value = \"/bookList\")public String getBookList(ModelMap map){ map.addAttribute(\"bookList\", bookService.findAll()); return \"bookList\";} 这个 Controller 接收一个 ModelMap ，map.addAttribute()的第一个参数是属性名字，第二个参数是属性值，这个值就是 bookService.findAll()的返回结果。 这样就会把 bookService.findAll() 的结果（ List&lt;book&gt; 类型，在addAttribute方法里面刚刚给它命名为bookList了）传给 bookList.html 在Servlet编程中，如果希望在页面中动态渲染信息，一般需要往HttpRequest中添加属性，然后在JSP中获取。其实Model的属性实际上也是放在HttpRequest的属性中，但是Spring MVC提供了更高层的抽象，帮你屏蔽了HttpRequest，你看到的只有直接以MVC中M（即Model）。 在模板中用th:each来遍历这个 List 12345678910111213141516&lt;table class=\"table table-striped\"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;博客&lt;/th&gt; &lt;th&gt;标题&lt;/th&gt; &lt;th&gt;内容&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr th:each=\"blog: ${blogList}\"&gt; &lt;th scope=\"row\" th:text=\"${blog.blogId}\"&gt;&lt;/th&gt; &lt;td th:text=\"${blog.blogTitle}\"&gt; &lt;/td&gt; &lt;td th:text=\"${blog.blogContent}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; 有时候我们会想点击某个标题跳转到详细页面，用th:href属性 1&lt;a href=\"#\" th:href=\"@{'/blogs/'+${blog.id}}\" th:text=\"${blog.title}\"&gt;&lt;/a&gt; 从前端模板接收数据当用户进入 /create 路由，会跳转到创建博客的页面，createBlog()方法给前端传入了一个 blog 对象 1234567/** * 添加博客 */@GetMapping(value = \"/create\")public String createBlog(Blog blog){ return BLOG_CREATE_PAGE;} 创建博客页面有一个表单（form），表单提交数据 12345678910111213&lt;form role=\"form\" method='post' action=\"#\" th:action=\"@{/blog/create/post}\" th:object=\"${blog}\" &gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"blogTitle\"&gt;微博标题&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"blogTitle\" th:field=\"*{blogTitle}\" placeholder=\"输入文章标题\"&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"blogContent\"&gt;微博内容&lt;/label&gt; &lt;textarea class=\"form-control\" rows=\"10\" id=\"blogContent\" th:field=\"*{blogContent}\" placeholder=\"输入文章内容\"&gt;&lt;/textarea&gt; &lt;/div&gt; &lt;div align=\"center\" class=\"form-group\"&gt; &lt;button type=\"submit\" class=\"btn btn-default\"&gt;提交&lt;/button&gt; &lt;/div&gt;&lt;/form&gt; th:action=&quot;@{/blog/create/post}&quot;表示要提交的路由 th:object=&quot;${blog}&quot;表示接收从刚刚的路由传入的对象 th:field=&quot;*{blogTitle}&quot;和 th:field=&quot;*{blogContent}&quot;表示当按下提交按钮，这两个输入框的内容将会绑定为 blog 对象的 blogTitle属性 和 blogContent 属性。然后传回给后端。 12345678/** * 处理添加请求 */@PostMapping(value = \"/create/post\")public String postBlog(@ModelAttribute(value=\"blog\") Blog blog){ blogService.addBlog(blog.getBlogTitle(),blog.getBlogContent()); return \"redirect:/blog/\";} 后端接收 blog 对象，进行处理。 更多关于Thymeleaf的内容：使用Thymeleaf模板引擎 ModelMap 和 ModelAndView 区别在控制器方法中，我们传入了一个 ModelMap 参数，或者 ModelAndView 。区别如下： ModelMap的实例是spirng mvc框架自动创建并作为控制器方法参数传入，用户无需自己创建。 123456789public String xxxxmethod(String someparam,ModelMap model){ //省略方法处理逻辑若干 //将数据放置到ModelMap对象model中,第二个参数可以是任何java类型 model.addAttribute(\"key\",someparam); ...... //返回跳转地址 return \"path:handleok\";} ModelAndView的实例是由用户手动创建的，这也是和ModelMap的一个区别。 1234567891011public ModelAndView xxxxmethod(String someparam){ //省略方法处理逻辑若干 //构建ModelAndView实例，并设置跳转地址 ModelAndView view = new ModelAndView(\"path:handleok\"); //将数据放置到ModelAndView对象view中,第二个参数可以是任何java类型 view.addObject(\"key\",someparam); ...... //返回ModelAndView对象view return view;} ModelAndView 实际上包含了两个 object ： Model：用于渲染页面的 k-v 键值对数据 View：填充了Model里面的数据的页面模板 @ModelAttribute与@RequestBody的区别 @RequestBody: 用于接收json，如ajax请求的data参数，在接收后直接转换成Pojo。支持 POST、PUT 等多种HTTP方法。 @ModelAttribute: 在 GET 请求中，用于直接接收URL的参数，如url?id=123&amp;name=456 在接收后直接转换成Pojo。 在 POST 请求中， 用于接收POST提交的内容。 注： GET 请求参数还可用 @RequestParam 来获取。 12345678910/** * 添加商品 * @param product * @return */@PutMapping(\"\")public Integer addProduct(@RequestBody Product product){ productService.addProduct(product); return product.getId();} 使用 PageHelper 分页PageHelper 是 Mybatis 的一个分页插件。 获取最新版本：https://mvnrepository.com/artifact/com.github.pagehelper/pagehelper-spring-boot-starter 添加分页依赖 pom.xml 12345&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.10&lt;/version&gt;&lt;/dependency&gt; 控制器 123456789101112131415/** * 获取某个分类下所有在售商品 * @param cateId 分类ID * @return */@GetMapping(value = \"{cate_id}/product\")@ResponseBodypublic PageInfo&lt;Product&gt; getProductByCateId(@PathVariable(value = \"cate_id\") Integer cateId, @RequestParam(value = \"start\", defaultValue = \"1\") int start, @RequestParam(value = \"size\", defaultValue = \"9\") int size){ PageHelper.startPage(start,size,\"id desc\"); List&lt;Product&gt; products = categoryService.getProductByCateId(cateId); PageInfo&lt;Product&gt; page = new PageInfo&lt;&gt;(products); return page;} 全局配置在项目 resource 目录下，修改application.properties文件。 123456789101112131415161718192021222324## 服务器配置server.port = 8089server.context-path=/test## 数据源配置spring.datasource.url=jdbc:mysql://localhost:3306/springbootdb?useUnicode=true&amp;characterEncoding=utf8spring.datasource.username=rootspring.datasource.password=123456spring.datasource.driver-class-name=com.mysql.jdbc.Driver## Mybatis 配置（仅xml方式）mybatis.typeAliasesPackage=org.spring.springboot.domainmybatis.mapperLocations=classpath:mapper/*.xml## thymeleaf 配置spring.thymeleaf.suffix=.htmlspring.thymeleaf.prefix=classpath:templatesspring.thymeleaf.encoding=UTF-8spring.thymeleaf.cache=falsespring.thymeleaf.mode=LEGACYHTML5# JPA 相关配置# 配置在日志中打印出执行的 SQL 语句信息spring.jpa.show-sql=true","link":"/post/1459f5bc.html"},{"title":"Spring（九）SpringBoot 双数据源","text":"前言最近项目中需要用到 Springboot + Mybatis 双数据源，一边接入 Oracle，一边接入 MySQL ，折腾了一下。搞了个 demo 出来。 修改配置项先自定义两个datasource： application.yml 1234567891011spring: datasource-oracle: driver-class-name: oracle.jdbc.driver.OracleDriver jdbc-url: username: password: datasource-mysql: driver-class-name: com.mysql.jdbc.Driver jdbc-url: username: password: 定义数据源Bean通过 java config 的方式，定义两个 bean ： DSConfig 123456789101112131415@Configurationpublic class DSconfig { @Bean(name = \"ORACLE_DS\") @ConfigurationProperties(prefix = \"spring.datasource-oracle\") public DataSource primaryDataSource() { return DataSourceBuilder.create().build(); } @Bean(name = \"MYSQL_DS\") @ConfigurationProperties(prefix = \"spring.datasource-mysql\") public DataSource secondDataSource() { return DataSourceBuilder.create().build(); }} 其中，@ConfigurationProperties 对应配置项里自定义的名称。 配置双数据源有了数据源的 bean 之后，需要进行一些配置，不同的 datasource bean 创建不同的 SqlSession，注意，必须指定其中一个为 @Primary mysql 配置 12345678910111213141516171819@Configuration@MapperScan(basePackages = {\"com.jerry.demo.mysql.dao\"}, sqlSessionFactoryRef = \"sqlSessionFactoryMysqlBean\" )public class MysqlDSConfig{ @Autowired @Qualifier(\"MYSQL_DS\") private DataSource mysqlDS; @Bean(name = \"sqlSessionFactoryMysqlBean\") public SqlSessionFactoryBean SqlSessionFactoryBean() throws IOException{ SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(mysqlDS); bean.setMapperLocations(new PathMatchingResourcePatternResolver() .getResources(\"classpath:mybatis/mysql/mapper/*.xml\");) return bean; }} oracle 配置 12345678910111213141516171819@Configuration@MapperScan(basePackages = {\"com.jerry.demo.oracle.dao\"})public class OracleDSConfig{ @Autowired @Qualifier(\"ORACLE_DS\") private DataSource oracleDS; @Bean(name = \"sqlSessionFactoryOracleBean\") @Primary public SqlSessionFactoryBean SqlSessionFactoryBean() throws IOException{ SqlSessionFactoryBean bean = new SqlSessionFactoryBean(); bean.setDataSource(mysqlDS); bean.setMapperLocations(new PathMatchingResourcePatternResolver() .getResources(\"classpath:mybatis/oracle/mapper*.xml\");) return bean; }} 接下来就可以到对应的目录下编写 xml 的 SQL 语句了。 在dao层指定数据源有时候我们想通过指定某一个 dao 使用指定的数据源，可以再数据源配置的 MapperScan 注解上上加 annotationClass 12345@Configuration@MapperScan(basePackages = {\"com.jerry.demo.mysql.dao\"}, sqlSessionFactoryRef = \"sqlSessionFactoryMysqlBean\", annotationClass = me.jerrysheh.demo.annotation.MysqlMapper.class))public class MysqlDSConfig{ 然后自定义一个注解标记 12345678package me.jerrysheh.demo.annotation;/** * @author jerrysheh * @date 2020/7/4 */public @interface MysqlMapper {} 这样 mybatis 会自动去扫 basePackages 下面所有标记了 MysqlMapper 注解的接口，使用 mysql 数据源。 1234567891011121314/** * @author jerrysheh * @date 2020/7/4 */@MysqlMapperpublic interface ProductMapper { Object selectOne(); List selectAll(); // ...} demo参考github：https://github.com/JerrySheh/springboot-mybatis-multidatasource-demo","link":"/post/a0972c39.html"},{"title":"Spring（二） SpringBoot 集成 Mybatis","text":"在 使用 Mybatis 简化 JDBC 操作 中，简单描述了 Mybatis 的使用。这一篇主要记录下如何集成 Spring boot Spring Boot 集成 Mybatis 简明过程创建一个 Spring Initalizr 工程，依赖选择 web、MySQL、Mybatis 在application.properties填入以下内容 1234spring.datasource.url=jdbc:mysql://127.0.0.1:3306/neu?characterEncoding=UTF-8&amp;useSSL=falsespring.datasource.username=rootspring.datasource.password=YourPasswordspring.datasource.driver-class-name=com.mysql.jdbc.Driver 创建pojo包，创建 Student 实体类，跟数据库对应 12345678public class Student { Integer id; String name; String major; Integer grade; // 省略 getter setter} 创建mapper包，创建StudentMapper接口 在SpringBootApplication类中，添加@MapperScan(&quot;io.jerrysheh.student.mapper&quot;)注解，即可不用在 mapper 包下面的每一个接口都注解Mapper了。 123456@Mapperpublic interface StudentMapper { @Select(\"SELECT * FROM student\") List&lt;Student&gt; findAll();} 如果有多个参数，用 @Param 注解 12@Update(\"update user set password=#{password} WHERE id=#{id}\")void updatePassword(@Param(\"password\") String password, @Param(\"id\") Integer id); 创建Controller包，创建StudentController 123456789101112131415@RestControllerpublic class StudentController { @Autowired StudentMapper studentMapper; @GetMapping(\"/listStudent\") public void listStudent(){ List&lt;Student&gt; studentList = studentMapper.findAll(); for (Student student: studentList) { System.out.println(student.getName()); } }} 这样，运行后访问 127.0.0.1:8080/listStudent ，可看到控制台输出数据库查到的所有 student 名字。 xml 方式有时候为了将SQL和Java代码隔离 ，会将 SQL 抽到 xml 里面，配置方法如下： 在application.properties填入以下内容(重要！！！) 123mybatis.mapper-locations=classpath:mapper/*.xmlmybatis.type-aliases-package=com.jerrysheh.fun.entitymybatis.configuration.map-underscore-to-camel-case=true 在 resources 目录下创建 mapper 文件夹，再创建 productmapper.xml 文件 12345678910111213&lt;?xml version=\"1.0\" encoding=\"UTF-8\" ?&gt;&lt;!DOCTYPE mapper PUBLIC \"-//mybatis.org//DTD Mapper 3.0//EN\" \"http://mybatis.org/dtd/mybatis-3-mapper.dtd\" &gt;&lt;mapper namespace=\"com.jerrysheh.fun.mapper.ProductMapper\"&gt; &lt;select id=\"selectAll\" resultType=\"com.jerrysheh.fun.entity.Product\"&gt; SELECT * FROM fun_product; &lt;/select&gt; &lt;insert id=\"addProduct\" &gt; insert into fun_product(product_name, product_price) values (#{productName}, #{productPrice}) &lt;/insert&gt;&lt;/mapper&gt; 注意：namespace一定要填写对应的 mapper 接口，不能只到 package 编写单元测试 12345678910111213@SpringBootTestpublic class test { @Autowired ProductMapper productMapper; @Test public void test(){ List&lt;Product&gt; productList = productMapper.selectAll(); productList.forEach(System.out::println); }} 以下为Mybatis知识点 井字符和美元符的区别#相当于对数据加上双引号，$相当于直接显示数据 #方式能够很大程度防止sql注入。$方式无法防止Sql注入。 动态SQL虽然我们使用了注解，但是还是在注解接口CategoryMapper中使用了原生 SQL 语句。 12@Insert(\" insert into category_ ( name ) values (#{name}) \")public int add(Category category); 其实，我们可以提供一个类，专门用来生成SQL语句 CategoryDynaSqlProvider.java 123456789101112131415161718192021222324252627282930313233343536373839package com.jerrysheh.mapper;import org.apache.ibatis.jdbc.SQL;public class CategoryDynaSqlProvider { public String list() { return new SQL() .SELECT(\"*\") .FROM(\"category_\") .toString(); } public String get() { return new SQL() .SELECT(\"*\") .FROM(\"category_\") .WHERE(\"id=#{id}\") .toString(); } public String add(){ return new SQL() .INSERT_INTO(\"category_\") .VALUES(\"name\", \"#{name}\") .toString(); } public String update(){ return new SQL() .UPDATE(\"category_\") .SET(\"name=#{name}\") .WHERE(\"id=#{id}\") .toString(); } public String delete(){ return new SQL() .DELETE_FROM(\"category_\") .WHERE(\"id=#{id}\") .toString(); }} 然后修改我们的CategoryMapper接口 123456789101112131415161718192021222324package com.jerrysheh.mapper;import com.jerrysheh.pojo.Category;import org.apache.ibatis.annotations.*;import java.util.List;public interface CategoryMapper { @InsertProvider(type=CategoryDynaSqlProvider.class,method=\"add\") public int add(Category category); @DeleteProvider(type=CategoryDynaSqlProvider.class,method=\"delete\") public void delete(int id); @SelectProvider(type=CategoryDynaSqlProvider.class,method=\"get\") public Category get(int id); @UpdateProvider(type=CategoryDynaSqlProvider.class,method=\"update\") public int update(Category category); @SelectProvider(type=CategoryDynaSqlProvider.class,method=\"list\") public List&lt;Category&gt; list();} 这样就可以动态生成SQL语句了 注解中的 type= 填入我们的动态生成SQL类CategoryDynaSqlProvider.class method=填入CategoryDynaSqlProvider类里的方法 @Results结果映射如果 javabean 的属性字段 跟 数据库字段一一对应，名字保持一致，则直接可以： 12@Select(\"select *from Demo where id=#{id}\") public Demo selectById(int id); 但如果不对应，就要用@Result修饰返回的结果集，而@Results注解将指定的数据库列与指定JavaBean属性映射起来。 1234567891011121314151617@Select(\"SELECT * FROM `wx_message_config` WHERE `content_key_words` IS NOT NULL AND LENGTH(content_key_words) &gt; 0\")@Results({ @Result(property = \"msgType\", column = \"msg_type\"), @Result(property = \"eventType\", column = \"event_type\"), @Result(property = \"eventKey\",column = \"event_key\"), @Result(property = \"contentKeyWords\",column = \"content_key_words\")})List&lt;WxMessageConfig&gt; queryAllKeyWords();@Select(\"SELECT * FROM `wx_message_config` WHERE `id` = #{id}\")@Results({ @Result(property = \"msgType\", column = \"msg_type\"), @Result(property = \"eventType\", column = \"event_type\"), @Result(property = \"eventKey\",column = \"event_key\"), @Result(property = \"contentKeyWords\",column = \"content_key_words\")})WxMessageConfig queryKwById(int id); 这样会导致写很多重复内容，可以用 @ResultMap(“id”) 123456789@Select(\"SELECT id, name, password FROM user WHERE id = #{id}\")@Results(id = \"userMap\", value = { @Result(column = \"id\", property = \"id\", javaType = Integer.class), @Result(column = \"name\", property = \"name\", javaType = String.class), @Result(column = \"password\", property = \"password\", javaType = String.class) })User findById(Integer id);@Select(\"SELECT * FROM user\")@ResultMap(\"userMap\")List&lt;User&gt; fingAll(); 一对多查询假设有一张 商品表 和 一张 图片表， 一个商品对应多张图片 那么如何取出一个商品，包含商品的所有属性，以及对应的所有图片呢？ 实体类商品的所有字段，同时，要添加一个 List&lt;String&gt; 表示多张图片的集合 123456789101112131415public class Product { private Integer id; private Integer user_id; private String name; private String price; private Date gmt_create; private String description; private Integer cate_id; private Integer number; // 关键！ private List&lt;String&gt; link; // 省略 getter setter} 图片的所有属性，用 String 表示图片地址 12345public class Image { private Integer id; private Integer product_id; private String link;} Mapper接口在图片的Mapper接口中，根据商品id找到对应的所有图片 123// 根据商品id找图片@Select(\"SELECT link from image WHERE product_id = #{product_id}\")List&lt;String&gt; getImageLinksByProductId(Integer product_id); 在商品的Mapper接口中，通过 @Results 和 @Many 来进行关联 12345678910// 取出在售的所有商品，最新的排前面@Select(\"select * from product WHERE number &gt; 0 ORDER BY id DESC\")@Results({ // 这里要对id进行限定，否则 id 会为 null @Result(property = \"id\", column = \"id\"), // 将 image 的 link 和 product 的 id 绑定，通过 @Many 查询 返回 List @Result(property = \"link\", column = \"id\", javaType = List.class, many = @Many(select = \"com.zsc.tradeplatform.mapper.ImageMapper.getImageLinksByProductId\")),})List&lt;Product&gt; getAll(); 控制器12345@ResponseBody@GetMapping(\"/api/product\") public List&lt;Product&gt; getAllProduct(){ return productService.getAllProduct(); } 访问 127.0.0.1:8080/api/product 查看结果","link":"/post/72ef7508.html"},{"title":"Spring（四）使用 RESTful 风格","text":"什么是 RESTful ？REST这个词由 Roy Thomas Fielding 在他2000年的博士论文中提出。全称是 Representational State Transfer ，这个词省略了主语 Resource，因此翻译成中文是：资源表述性状态转化。 资源（Resource）之前在 HTTP之旅 一文中提到过，一个 Web 页面包含了很多对象，这些对象可以是 html ，可以是 JSON、XML，或者可以是图片、嵌入的视频，还可以是java小程序等等。这些对象都可以称为资源。我们通过 统一资源定位符（URI）去定位资源。 表述性（REpresentational）正如上面提到的，资源可以用各种形式来进行表述，我们可以使用最适合资源使用者的任意形式来表述资源。资源具体呈现出来的形式，就是资源的表述性（REpresentational）。 状态转化（State Transfer）HTTP协议是无状态协议。这意味着，资源的所有的状态都保存在服务器端。因此，如果客户端想要操作服务器，必须通过某种手段，让服务器端发生”状态转化”（State Transfer）。 客户端用到的手段，只能是HTTP协议。具体来说，就是HTTP协议里面，四个表示操作方式的动词：GET、POST、PUT、DELETE。它们分别对应四种基本操作：GET用来获取资源，POST用来新建资源（也可以用于更新资源），PUT用来更新资源，DELETE用来删除资源。 简单总结：资源通过 URL 进行识别和定位，然后通过行为(即 HTTP 方法)来定义应该完成怎样的功能。 实例说明在HTTP协议中，有GET、POST、HEAD、PUT、DELETE、OPTIONS、TRACE、CONNECT 众多方法，我们可以通过不同的HTTP方法来对应CRUD的操作。 例如： HTTP方法 CRUD操作 GET 查询(Retrieve) POST 更新(Update) PUT 增加(Create) DELETE 删除(Delete) 尽管通常来讲，HTTP 方法会映射为 CRUD 动作，但这并不是严格的限制，有时候 PUT 也可以用来创建新的资源，POST 也可以用来更新资源。实际上，POST 请求非幂等的特性(即同一个 URL 可以得到不同的结果) 使其成一个非常灵活地方法，对于无法适应其他 HTTP 方法语义的操作，它都能够胜任。 在使用 RESTful 风格之前，我们如果想要增加一条商品数据通常是这样的: 1/addCategory?name=xxx 但是使用了 RESTful 风格之后就会变成: 1/category 这就变成了使用同一个 URL ，通过约定不同的 HTTP 方法来实施不同的业务，这就是 RESTful 风格所做的事情了。 图片引自 how2j.cn Springboot 实战RESTful API设计 请求类型 URL 说明 GET /students 查询所有学生 POST /students 创建一个学生 GET /students/{id} 根据id查询一个学生 PUT /students/{id} 根据id更新一个学生 DELETE /students/{id} 根据id删除一个学生 实体类 Student.java 12345678public class Student { Integer id; String name; String number; String major; Integer grade; // 省略 setter getter} 控制器 1234567891011121314151617181920212223242526272829303132333435363738394041@RestController@RequestMapping(value = \"/students\")public class StudentAPIController { @Autowired StudentMapper studentMapper; // 查询所有学生 @GetMapping(\"/\") public List&lt;Student&gt; getStudentList(){ return studentMapper.findAll(); } // 增加学生 @PostMapping(\"/\") public Student addStudent(@ModelAttribute Student student){ studentMapper.addStudent(student); return student; } // 查询学生 @GetMapping(\"/{id}\") public Student getStudent(@PathVariable Integer id){ return studentMapper.findById(id); } // 删除学生 @DeleteMapping(\"/{id}\") public String deleteStudent(@PathVariable Integer id){ studentMapper.deleteById(id); return \"redirect:/\"; } // 更新学生 @PutMapping(\"/{id}\") public Student updateStudent(@PathVariable Integer id, @ModelAttribute Student student){ studentMapper.updateStudent(student); return student; }} 封装统一的返回样式在返回 REST 数据时，可能请求成功也可能失败，成功需要返回请求的信息，失败需要返回失败原因，如下： 请求失败： 1234{ statusCode: 401, messages: \"未登录\",} 请求成功： 12345{ statusCode: 200, messages: \"ok\", content: \"response contents\"} 参考 http://www.cnblogs.com/wmyskxz/p/9104368.html http://blog.didispace.com/springbootrestfulapi/ 理解RESTful架构 RESTful API 设计指南","link":"/post/3479b7db.html"},{"title":"Spring（八）SpringBoot 集成 JPA","text":"什么是 JPA ？之前在 Spring Boot 工程中，一直用 Mybatis 注解方式作为持久层框架。但是 Mybatis 需要手写 SQL 语句，对于简单的项目稍显麻烦。最近发现了 JPA ，使用 JPA 我们几乎可以不用写一句 SQL 语句，非常适合 CURD 场景。JPA 是 Java Persistence API（Java持久化接口） 的缩写。JPA 让我们的应用程序以统一的方式访问持久层。JPA 是 Hibernate 的一个抽象，是一种 ORM 规范，是可以理解为是 Hibernate 功能的一个子集。 Spring Boot 集成 JPA 简要过程1. 添加依赖新建工程在 Spirng initializr 中勾选 JPA 即可，如果没有勾选，可以在 pom.xml 里面添加 JPA 依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-JPA&lt;/artifactId&gt;&lt;/dependency&gt; 2.新建实体类这里推荐一个插件 lombok，使用 lombok 我们可以直接用 @Data 注解替代 getter、setter 和 toString 方法。之后，在实体类的主键字段添加@Id注解和@GeneratedValue注解。在 gmt_create 和 gmt_modified 字段添加时间注解，并用@EntityListeners监听，这样，我们可以不用在后面的代码中每次都添加修改时间。 在 IDEA 插件中搜索并安装 lombok，之后重启 IDEA，在 maven 中添加： 12345&lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; pojo类 1234567891011121314151617181920@Entity@Data@EntityListeners(AuditingEntityListener.class)public class Message { @Id @GeneratedValue(strategy=GenerationType.IDENTITY) long id; String message; @CreatedDate Date gmtCreate; @LastModifiedDate Date gmtModified; // 无需编写 getter setter toString} 几种注解的区别： @GeneratedValue(strategy = GenerationType.AUTO)主键增长方式由数据库自动选择。 @GeneratedValue(strategy = GenerationType.IDENTITY) 要求数据库选择自增方式，oracle不支持此种方式。 @GeneratedValue(strategy = GenerationType.SEQUENCE) 采用数据库提供的sequence机制生成主键。mysql不支持此种方式。 3. 编写 JPA 接口接口里面什么都不用写，就已经有了 CURD 方法了。注意泛型参数应该为 实体类 和 主键 的类型。 123456import io.jerrysheh.message_me.pojo.Message;import org.springframework.data.repository.CrudRepository;public interface MessageRepository extends CrudRepository&lt;Message, Long&gt; { // 注意泛型参数} 4. save方法使用 save 方法来新增或更新一条记录，JPA会判断是否已经有该 id，如果没有则新增，如果有则更新。这里有一个坑，有时候一个对象我们只需要修改其中某一个字段，其他字段不变，但是修改时 JPA 会把不需要变的字段也修改为 null，解决办法是先取出该对象的所有字段，让他们不为null，再修改需要改动的字段。 12345678910111213141516@Testpublic void testAdd(){ Message msg = new Message(); msg.setMessage(\"第一条message\"); messageRepository.save(msg);}@Testpublic void testUpdate(){ Optional&lt;Message&gt; opt = messageRepository.findById(4L); if (opt.isPresent()){ Message msg = opt.get(); msg.setMessage(\"修改后的心语\"); messageRepository.save(msg); }} 5. 问题锦集1. No identifier specified for entity在 id 字段加 @Id 注解 和 @GeneratedValue(strategy=GenerationType.IDENTITY) 注解。几种 GeneratedValue 的区别上面已经提及。 2. CreatedDate 的时间不对数据源加上serverTimezone=GMT%2B8 参考 Spring官方文档 - Accessing Data with JPA","link":"/post/cf93e9b3.html"},{"title":"JSON初探","text":"JSON（JavaScript Object Notation）是一种轻量级的数据交换格式，通常用于在客户端和服务器之间传递数据。 JSON 类似下面这样： 1{&quot;id&quot;:4,&quot;name&quot;:&quot;梅西&quot;,&quot;pwd&quot;:&quot;6666&quot;} JSON 的优点： 轻量级交互语言 结构简单 易于解析 JavaScript Json语法前面提到，JavaScript对象分为： 内置对象(Number,String,Array,Date,Math) 自定义对象 JSON就属于自定义对象，只不过是以JSON这样的数据组织方式表达出来。 json对象定义一个JSON对象 12345678910111213&lt;script&gt;var student = {\"name\":\"jerry\",\"id\":6606};var person = {\"name\":\"张三\",\"age\":30};//输出：[object Object]document.write(\"这是一个JSON对象: \" + student1);//输出：jerrydocument.write(\"student1对象的name元素: \" + student1.name);//输出：30document.write(\"person对象的name元素: \" + person.age);&lt;/script&gt; json数组一对{}括号表示一个json对象，一个json数组用[]括号表示。 1234567891011121314151617&lt;script&gt;var heros=[ {\"name\":\"盖伦\",\"hp\":616}, {\"name\":\"提莫\",\"hp\":313}, {\"name\":\"死哥\",\"hp\":432}, {\"name\":\"火女\",\"hp\":389}]//输出：4document.write(\"JSON数组大小\"+heros.length);//输出：火女document.write( \"第4个英雄是:\" + heros[3].name);&lt;/script&gt; 字符串转json对象JavaScript方式 12345678var s1 = \"{\\\"name\\\":\\\"盖伦\\\"\";var s2 = \",\\\"hp\\\":616}\";// s3是字符串{\"name\":\"盖伦\",\"hp\":616}var s3 = s1+s2;// j1是json对象var j1 = eval(\"(\"+s3+\")\"); JQuery方式 1var gareen = $.parseJSON(s3); 从前端发送 Json 数据到后台可以使用 Ajax 提交 json 数据到后台 前端 category.html，放在 templates 文件夹里面 12345678910111213141516171819202122232425262728293031323334353637383940414243444546&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;JSON学习&lt;/title&gt; &lt;!-- 菜鸟教程 --&gt; &lt;script src=\"http://how2j.cn/study/jquery.min.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;!-- 一个表单--&gt;&lt;form&gt; id：&lt;input type=\"text\" id=\"id\" value=\"123\"/&gt;&lt;br/&gt; 名称：&lt;input type=\"text\" id=\"name\" value=\"category xxx\"/&gt;&lt;br/&gt; &lt;input type=\"button\" value=\"提交\" id=\"sender\"&gt;&lt;/form&gt;&lt;div id=\"messageDiv\"&gt;&lt;/div&gt;&lt;script&gt; $('#sender').click(function () { var id = document.getElementById('id').value; var name = document.getElementById('name').value; var category = {\"name\": name, \"id\": id}; //使用 JSON.stringify() 来将一个JSON对象转换成了一串字符串 var jsonData = JSON.stringify(category); var page = \"category\"; //在AJAX中，我们设置了 dataType 和 contentType 来告知后台我们传输的是一个JSON数据 $.ajax({ type: \"put\", url: page, data: jsonData, dataType: \"json\", contentType: \"application/json;charset=UTF-8\", success: function (result) { } }); alert(\"提交成功，请在springboot控制台查看服务端接收到的数据\"); });&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 后台 Springboot 123456789101112131415@Controllerpublic class categoryController { //用于访问 http://127.0.0.1:8080/category @GetMapping(\"/category\") public String Category() { return \"category\"; } // 用于在 http://127.0.0.1:8080/category 点击表单的提交按钮 @PutMapping(\"/category\") public void addCategory(@RequestBody Manager manager) throws Exception { System.out.println(\"springboot接受到浏览器以JSON格式提交的数据：\" + manager.getAge() + manager.getName()); }} 效果： Java中使用 json 库Java中处理 json 格式的数据可以用 orj.json 包 或者 net.sf.json-lib 的 json-lib 包，但是提供的方法还是比较基础的。 因此可以采用一些开源框架，比如Google的 Gson、 阿里巴巴的 fastjson、 还有 jackson 。 这里以 Google 的 Gson 为例。 依赖包下载地址：mvnrepository 项目地址：github 基本数据类型（及包装类）和 Json 互转1234567891011121314151617// Serialization//基本数据类型转 JsonGson gson = new Gson();gson.toJson(1); // ==&gt; 1gson.toJson(\"abcd\"); // ==&gt; \"abcd\"gson.toJson(new Long(10)); // ==&gt; 10int[] values = { 1 };gson.toJson(values); // ==&gt; [1]// Deserialization// Json 转基本数据类型int one = gson.fromJson(\"1\", int.class);Integer one = gson.fromJson(\"1\", Integer.class);Long one = gson.fromJson(\"1\", Long.class);Boolean false = gson.fromJson(\"false\", Boolean.class);String str = gson.fromJson(\"\\\"abc\\\"\", String.class);String[] anotherStr = gson.fromJson(\"[\\\"abc\\\"]\", String[].class); 对象和 Json 互转1234567891011121314151617181920212223// 定义一个类class BagOfPrimitives { private int value1 = 1; private String value2 = \"abc\"; private transient int value3 = 3; BagOfPrimitives() { // no-args constructor }}//实例化对象BagOfPrimitives obj = new BagOfPrimitives();// Serialization//对象转Json// ==&gt; json is {\"value1\":1,\"value2\":\"abc\"}Gson gson = new Gson();String json = gson.toJson(obj); // Deserialization// Json转对象// ==&gt; obj2 is just like objBagOfPrimitives obj2 = gson.fromJson(json, BagOfPrimitives.class); 数组、集合等其余转换可参考 UserGuide 一篇不错的参考博客：CSDN 使用 Gson 解析嵌套的json对象序列化（Serialization）所谓序列化指的是将 Java 对象 映射成 json 数据。 首先由一个java类 UserNested，里面包含另一个java类 UserAddress 12345678910111213141516// UserNested.javapublic class UserNested { String name; String email; boolean isDeveloper; int age; UserAddress userAddress;}// UserAddress.javapublic class UserAddress { String street; String houseNumber; String city; String country;} 使用 Gson test.java 12345678910111213141516171819// 内部对象UserAddress userAddress = new UserAddress( \"Main Street\", \"42A\", \"Magdeburg\", \"Germany\");// 外部对象 UserNested userObject = new UserNested( \"Norman\", \"norman@futurestud.io\", true, 22, userAddress);Gson gson = new Gson();String userWithAddressJson = gson.toJson(userObject); 输出结果： 12345678910111213{ \"age\": 22, \"email\": \"jerrysheh@gmail.com\", \"isDeveloper\": true, \"name\": \"jerry\", \"userAddress\": { \"city\": \"Magdeburg\", \"country\": \"Germany\", \"houseNumber\": \"42A\", \"street\": \"Main Street\" }} Gson 中只能根据 “{}” 标志来创建一个新对象。 反序列化（deserialization）反序列化就是把 json 数据 映射成 java 对象 原始数据 12345678910111213141516171819202122{ \"name\": \"Future Studio Steak House\", \"owner\": { \"name\": \"Christian\", \"address\": { \"city\": \"Magdeburg\", \"country\": \"Germany\", \"houseNumber\": \"42A\", \"street\": \"Main Street\" } }, \"cook\": { \"age\": 18, \"name\": \"Marcus\", \"salary\": 1500 }, \"waiter\": { \"age\": 18, \"name\": \"Norman\", \"salary\": 1000 }} 手动创建相匹配的 javabean 1234567891011121314151617181920212223242526272829// resuaurant.javapublic class Restaurant { String name; Owner owner; Cook cook; Waiter waiter;}// Owner.javapublic class Owner { String name; UserAddress address;}// Cook.javapublic class Cook { String name; int age; int salary;}// Waiter.javapublic class Waiter { String name; int age; int salary;} 其实可以用内部类的形式，这样只需要写一个 bean，更加简明。 注意：如果使用内部类，需要声明为 static ，否则 Gson 无法解析。 转化 12345String restaurantJson = \"{ 'name':'Future Studio Steak House', 'owner':{ 'name':'Christian', 'address':{ 'city':'Magdeburg', 'country':'Germany', 'houseNumber':'42', 'street':'Main Street'}},'cook':{ 'age':18, 'name': 'Marcus', 'salary': 1500 }, 'waiter':{ 'age':18, 'name': 'Norman', 'salary': 1000}}\";Gson gson = new Gson();Restaurant restaurantObject = gson.fromJson(restaurantJson, Restaurant.class); 使用 IDEA / Android Studio 的 GsonFormat 插件使用 GsonFormat 插件，可以快速根据 json内容 生成 javabean 项目地址：https://github.com/zzz40500/GsonFormat 使用方法 在 IDEA 中， file -&gt; setting -&gt; plugins -&gt; 搜索 “GsonFormat” -&gt; 安装并重启IDE 创建一个装 javabean 的包（必须），然后创建一个 javabean 类 (包名和类名可随意取) Alt + S， 或者 Alt + Insert，选择 GsonFormat 复制粘贴你的 json ，点击右上角 format 进行排版 点击确定即自动生成 bean","link":"/post/c9fc16a8.html"},{"title":"Java Web（一）web容器和Servlet","text":"在聊 Servlet 之前，先讲讲什么是 Web服务器 和 应用服务器。 Web服务器无论何种 Web 资源，想被远程计算机访问，都必须有一个与之对应的网络通信程序，当用户来访问时，这个网络通信程序读取 Web 资源数据，并把数据发送给来访者。 Web服务器就是一个网络通信程序，它用于完成底层网络通迅。具体来说，它将某个主机上的资源映射为一个URL供外界访问。 使用 Web服务器，Web 应用的开发者只需要关注 Web 资源怎么编写，而不需要关心资源如何发送到客户端手中，从而极大的减轻了开发者的开发工作量。 应用服务器 - Tomcat我们的 Web 应用要运行起来，是需要部署在应用服务器上而不是Web服务器。因为web服务器只负责资源映射，而程序业务逻辑需要另外的容器来处理。 应用服务器一般装载着我们的后端应用程序，帮助我们接收请求、处理请求、响应请求。Tomcat 就是一种常见的应用服务器，但也具有web服务器的功能，所以直接访问也可以。 通常，Tomcat 装载着我们的 Servlet 对象。那什么是 Servlet 呢？下文会讲到。 在实际的生产环境中，由于负载均衡，cdn加速等原因，我们还是需要在应用服务器的前端再加一个web服务器来提高访问效率，常用的有 Nginx, Apache 这样的服务器。 ServletServlet 是什么简而言之，Servlet 就是一个接口，它规定了一个后端逻辑初始化的时候做什么、业务逻辑是什么、销毁的时候做什么。 1234567891011public interface Servlet { void init(ServletConfig var1) throws ServletException; ServletConfig getServletConfig(); void service(ServletRequest var1, ServletResponse var2) throws ServletException, IOException; String getServletInfo(); void destroy();} 如果想开发一个Java程序向浏览器输出数据，需要完成以下2个步骤： 编写一个Java类，实现servlet接口(然而现实情况是，servlet开发者已经帮我们实现了一个httpServlet的抽象类，我们只需继承httpServlet并重写doGet和doPost方法)。 把开发好的Java类部署到web服务器(tomcat)中。 按照一种约定俗成的称呼习惯，通常我们也把实现了Servlet接口的java程序，称之为Servlet。 Servlet的运行过程Servlet程序由Web服务器调用，web服务器收到客户端的Servlet访问请求后： Web服务器首先检查是否已经装载并创建了该Servlet的实例对象。如果是，则直接执行第4步，否则，执行第2步 装载并创建该Servlet的一个实例对象 调用Servlet实例对象的init()方法 创建一个用于封装HTTP请求消息的HttpServletRequest对象和一个代表HTTP响应消息的HttpServletResponse对象，然后调用Servlet的service()方法并将请求和响应对象作为参数传递进去。 Web应用程序被停止或重新启动之前，Servlet引擎将卸载Servlet，并在卸载之前调用Servlet的destroy()方法。 也就是说，web容器只有在首次访问时才创建Servlet，然后调用Servlet的init()方法。之后web容器创建请求（request）对象和响应（response）对象（响应对象此时为空），并将这两个对象作为参数，传入Servlet的service()方法。经service()方法处理后，将结果写入响应信息（此时响应对象已有内容）。最后，由web容器取出响应信息回送给浏览器。 实际上，在执行doGet()或者doPost()之前，都会先执行service()，由service()方法进行判断，到底该调用doGet()还是doPost() Servlet与普通Java类的区别 Servlet是一个供其他Java程序（Servlet引擎）调用的Java类，它不能独立运行，它的运行完全由Servlet引擎来控制和调度。 针对客户端的多次Servlet请求，通常情况下，服务器只会创建一个Servlet实例对象，也就是说Servlet实例对象一旦创建，它就会驻留在内存中，为后续的其它请求服务，直至web容器退出，servlet实例对象才会销毁。 在Servlet的整个生命周期内，Servlet的 init方法只被调用一次。而对一个Servlet的每次访问请求都导致Servlet引擎调用一次servlet的service方法。对于每次访问请求，Servlet引擎都会创建一个新的HttpServletRequest请求对象和一个新的HttpServletResponse响应对象，然后将这两个对象作为参数传递给它调用的Servlet的·方法，service方法再根据请求方式分别调用doXXX方法。 如果在&lt;servlet&gt;元素中配置了一个&lt;load-on-startup&gt;元素，那么 Web 应用程序在启动时，就会装载并创建Servlet的实例对象、以及调用Servlet实例对象的init()方法。 实战配置新建IDEA工程 新建一个IDEA Maven工程 在 pom.xml 添加 servlet-api 依赖 （依赖到 mvnrepository 或 search.maven.org 找） 右键工程名字，Add Framework Support，选择 WebApplication Edit Configurations，配置 Tomcat 服务器 Deployment 选择 Artifacts 遇到问题可参考： IntelliJ IDEA 构建maven，并用Maven创建一个web项目 IntelliJ idea 2017创建Web项目后web文件夹下没有WEB-INF的解决方法 后端：GETsrc/main/java 下，new 一个 servlet helloServlet.java 123456789101112131415161718192021222324252627import javax.servlet.annotation.WebServlet;import javax.servlet.http.HttpServlet;import javax.servlet.ServletException;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;@WebServlet(\"/hello\")public class helloServlet extends HttpServlet { private String message; public void init() throws ServletException{ message = \"hello world!!\"; } @Override public void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException { // 设置响应内容类型 response.setContentType(\"text/html\"); // 实际的逻辑是在这里 PrintWriter out = response.getWriter(); out.println(\"&lt;h1&gt;\" + message + \"&lt;/h1&gt;\"); }} 访问 localhost:8080/hello，能看到 hello world!! @WebServlet(&quot;/hello&quot;)是一个注解，我们用这种方式来表示该 Servlet 的路径是 ./hello 。更原始的，我们可以在项目工程下找到 web.xml 文件，在这里面配置映射路径。（参考：WEB PROJECT） 后端：POSTsrc/main/java 下，new 一个 servlet postServlet.java 12345678910111213141516171819@WebServlet(\"/login\")public class postServlet extends HttpServlet { protected void doPost(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException { request.setCharacterEncoding(\"UTF-8\"); // 解决中文问题 String name = request.getParameter(\"name\"); String password = request.getParameter(\"password\"); String html = null; if (\"admin\".equals(name) &amp;&amp; \"123456\".equals(password)) html = \"&lt;div style='color:green'&gt;success&lt;/div&gt;\"; else html = \"&lt;div style='color:red'&gt;fail&lt;/div&gt;\"; response.setContentType(\"text/html; charset=UTF-8\");// 解决中文问题 PrintWriter pw = response.getWriter(); pw.println(html); }} 使用request.setCharacterEncoding(&quot;UTF-8&quot;);和response.setContentType(&quot;text/html; charset=UTF-8&quot;);解决中文问题 &quot;字面量&quot;.equals(str)是个好习惯 用PrintWriter类来写html 前端：HTMLweb目录下，new 一个 login.html login.html 123456789101112131415161718&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt; &lt;meta charset=\"UTF-8\"&gt; &lt;title&gt;请登录&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div align=\"center\"&gt; &lt;h1&gt;请登录&lt;/h1&gt; &lt;form action=\"login\" method=\"post\"&gt; 账号：&lt;input type=\"text\", name=\"name\"&gt; &lt;br&gt; 密码：&lt;input type=\"password\", name=\"password\"&gt; &lt;br&gt; &lt;input type=\"submit\", value=\"登录\"&gt; &lt;input type=\"reset\", value=\"重置\"&gt; &lt;/form&gt; &lt;/div&gt;&lt;/body&gt;&lt;/html&gt; &lt;meta charset=&quot;UTF-8&quot;&gt;解决中文问题 action属性表示要提交的服务器页面地址为 ./login method属性表示HTTP方法（get or post） 参考：Head First HTML 访问 localhost:8080/login.html，能看到登录表单 输入admin，123456，可以看到网页跳转到 success 跳转登录成功或是失败后，分别会跳转到不同的页面。 跳转分为服务端跳转和客户端跳转。 服务端跳转(forward)forward 是服务器请求资源,服务器直接访问目标地址的URL,把那个URL的响应内容读取过来,然后把这些内容再发给浏览器.浏览器根本不知道服务器发送的内容从哪里来的,所以它的地址栏还是原来的地址。 因此，用户看到的网址没有变化 。 在这个过程中，控制权并没有转交给另一服务器对象。 1request.getRequestDispatcher(\"success.html\").forward(request, response); 客户端跳转(redirect)redirect是服务端根据逻辑,发送一个状态码,告诉浏览器重新去请求那个地址.所以地址栏显示的是新的URL. 1response.sendRedirect(\"fail.html\"); 用户看到的网址变为 127.0.0.1:8080/fail.html Web.xml在项目中有一个 Web.xml 文件，这个文件是一些配置参数。 1234567891011121314151617181920212223&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;web-app xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns=\"http://xmlns.jcp.org/xml/ns/javaee\" xsi:schemaLocation=\"http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd\" id=\"WebApp_ID\" version=\"3.1\"&gt; &lt;display-name&gt;JspDemo&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;login.jsp&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;context-param&gt; &lt;param-name&gt;database_driver&lt;/param-name&gt; &lt;param-value&gt;com.mysql.jdbc.Driver&lt;/param-value&gt; &lt;/context-param&gt; &lt;context-param&gt; &lt;param-name&gt;database_url&lt;/param-name&gt; &lt;param-value&gt;jdbc:mysql://localhost:3306/sms?serverTimezone=GMT%2B8&amp;amp;characterEncoding=UTF-8&lt;/param-value&gt; &lt;/context-param&gt; &lt;context-param&gt; &lt;param-name&gt;database_user&lt;/param-name&gt; &lt;param-value&gt;root&lt;/param-value&gt; &lt;/context-param&gt; &lt;context-param&gt; &lt;param-name&gt;database_pwd&lt;/param-name&gt; &lt;param-value&gt;123456&lt;/param-value&gt; &lt;/context-param&gt;&lt;/web-app&gt; 然后我们可以在 Java 中取出这些参数 1234this.driver = request.getSession().getServletContext().getInitParameter(\"database_driver\");this.url = request.getSession().getServletContext().getInitParameter(\"database_url\");this.user = request.getSession().getServletContext().getInitParameter(\"database_user\");this.pwd = request.getSession().getServletContext().getInitParameter(\"database_pwd\"); Request常用方法获取信息 方法 释义 request.getRequestURL() 浏览器发出请求时的完整URL，包括协议 主机名 端口(如果有)” request.getRequestURI() 浏览器发出请求的资源名部分，去掉了协议和主机名” request.getQueryString() 请求行中的参数部分，只能显示以get方式发出的参数，post方式的看不到 request.getRemoteAddr() 浏览器所处于的客户机的IP地址 request.getRemoteHost() 浏览器所处于的客户机的主机名 request.getRemotePort() 浏览器所处于的客户机使用的网络端口 request.getLocalAddr() 服务器的IP地址 request.getLocalName() 服务器的主机名 request.getMethod() 得到客户机请求方式，一般是GET或者POST request.getHeader() 获取头信息 request.getHeaderNames() 获取所有头信息 获取参数 方法 释义 request.getParameter() 是常见的方法，用于获取单值的参数 request.getParameterValues() 用于获取具有多值得参数，比如注册的时候提交的爱好，可以使多选的。 request.getParameterMap() 用于遍历所有的参数，并返回Map类型。 respoonse 常用方法 方法 释义 response.setContentType(“text/html”); 设置相应格式 response.setContentType(“text/html; charset=UTF-8”); 设置编码格式，服务器端使用 UTF-8 编码，同时通知浏览器使用UTF-8 response.setCharacterEncoding(“UTF-8”); 仅仅是服务器端设置UTF-8，浏览器编码由浏览器自己决定 response.sendRedirect(“fail.html”); 302 客户端跳转 可以用以下方法设置不使用缓存 123response.setDateHeader(\"Expires\",0 );response.setHeader(\"Cache-Control\",\"no-cache\");response.setHeader(\"pragma\",\"no-cache\"); Servlet的线程安全问题当多个客户端并发访问同一个Servlet时，web服务器会为每一个客户端的访问请求创建一个线程，并在这个线程上调用Servlet的service方法，因此service方法内如果访问了同一个资源的话，就有可能引发线程安全问题。 线程安全问题只存在多个线程并发操作同一个资源的情况下，所以在编写Servlet的时候，如果并发访问某一个资源(变量，集合等)，就会存在线程安全问题。 解决方案：让Servlet去实现一个SingleThreadModel接口，如果某个Servlet实现了SingleThreadModel标记接口，那么Servlet引擎将以单线程模式来调用其service方法。 对于实现了SingleThreadModel接口的Servlet，Servlet引擎仍然支持对该Servlet的多线程并发访问，其采用的方式是产生多个Servlet实例对象，并发的每个线程分别调用一个独立的Servlet实例对象。 实现SingleThreadModel接口并不能真正解决Servlet的线程安全问题，因为Servlet引擎会创建多个Servlet实例对象，而真正意义上解决多线程安全问题是指一个Servlet实例对象被多个线程同时调用的问题。 事实上，在Servlet API 2.4中，已经将SingleThreadModel标记为Deprecated（过时的）。 标记接口在Java中，把没有定义任何方法和常量的接口称之为标记接口，经常看到的一个最典型的标记接口就是”Serializable”，这个接口也是没有定义任何方法和常量的，标记接口在Java中有什么用呢？主要作用就是给某个对象打上一个标志，告诉JVM，这个对象可以做什么，比如实现了”Serializable”接口的类的对象就可以被序列化，还有一个”Cloneable”接口，这个也是一个标记接口，在默认情况下，Java中的对象是不允许被克隆的，就像现实生活中的人一样，不允许克隆，但是只要实现了”Cloneable”接口，那么对象就可以被克隆了。","link":"/post/d697e4e7.html"},{"title":"Java Web（二）JavaServer Pages （JSP）","text":"我们知道，Servlet 中可以对客户端发来的信息进行处理（doGet、doPost等），可是，在 Servlet 里面输出 HTML 代码是一件很酸爽的事情。 如果我们直接写 HTML 代码，然后在需要动态获取的地方用 Java 代码来实现，不是很方便？ JSP 就是干这个事的！ 维基百科定义: JSP（全称JavaServer Pages）是由Sun Microsystems公司主导建立的一种动态网页技术标准。 JSP部署于网络服务器上，可以响应客户端发送的请求，并根据请求内容动态地生成HTML、XML或其他格式文档的Web网页，然后返回给请求者。 JSP 如何转成 HTML 把 hello.jsp 转译为hello_jsp.java hello_jsp.java继承了HttpServlet类，因此它是一个servlet hello_jsp.java 被编译为hello_jsp.class 执行 hello_jsp，生成 html 通过 http 协议把html 响应返回给浏览器 JSP 的页面元素静态内容包括 HTML、CSS、JavaScript 等内容 指令类似于下面 以 &lt;%@ 开头，以%&gt; 结尾的 1&lt;%@ page contentType=\"text/html;charset=UTF-8\" language=\"java\" %&gt; Scriptlet类似于下面 以 &lt;% 开头，以%&gt; 结尾的 123&lt;% response.sendRedirect(&quot;hello.jsp&quot;);%&gt; 如果是&lt;%=，后面加了个 = ，比如&lt;%=&quot;hello jsp&quot;%&gt; ，其实相当于 &lt;%out.println(&quot;hello jsp&quot;);%&gt;，这是一种隐式对象。 1&lt;%=new Date().toString()%&gt; 动作在jsp页面中包含另一个页面 1&lt;jsp:include page=&quot;Filename&quot; &gt; 跳转到另一个页面（服务端跳转） 1&lt;jsp:forward page=&quot;hello.jsp&quot;/&gt; 会话跟踪会话跟踪是一种灵活、轻便的机制，它使Web上的状态编程变为可能。 HTTP是一种无状态协议，每当用户发出请求时，服务器就会做出响应，客户端与服务器之间的联系是离散的、非连续的。当用户在同一网站的多个页面之间转换时，根本无法确定是否是同一个客户，会话跟踪技术就可以解决这个问题。当一个客户在多个页面间切换时，服务器会保存该用户的信息。 有四种方法可以实现会话跟踪技术：URL重写、隐藏表单域、Cookie、Session。 隐藏表单域：&lt;input type=&quot;hidden&quot;&gt;，非常适合步需要大量数据存储的会话应用。 URL 重写：URL 可以在后面附加参数，和服务器的请求一起发送，这些参数为名字/值对。 Cookie:一个 Cookie 是一个小的，已命名数据元素。服务器使用 SET-Cookie 头标将它作为 HTTP 响应的一部分传送到客户端，客户端被请求保存 Cookie 值，在对同一服务器的后续请求使用一个 Cookie 头标将之返回到服务器。与其它技术比较，Cookie 的一个优点是在浏览器会话结束后，甚至在客户端计算机重启后它仍可以保留其值。 Session：使用 setAttribute(String str,Object obj) 方法将对象捆绑到一个会话 Cookie 和 Session关于 Cookie 和 Session 的概念，可参考 HTTP之旅 setCookie我们可以在web目录下创建一个文件 setCookie.jsp，然后用 Scriptlet&lt;%...%&gt; new一个 Cookie 对象。 用c.setMaxAge()来设置保留时间（以秒为单位）。 用c.setPath(&quot;127.0.0.1&quot;)来设置主机名 用response.addCookie(c);把这个cookie保存在浏览器端 1234567891011&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; import=&quot;javax.servlet.http.Cookie&quot;%&gt;&lt;% Cookie c = new Cookie(&quot;name&quot;, &quot;Gareen&quot;); c.setMaxAge(60 * 24 * 60); c.setPath(&quot;127.0.0.1&quot;); response.addCookie(c);%&gt;&lt;a href=&quot;getCookie.jsp&quot;&gt;跳转到获取cookie的页面&lt;/a&gt; 访问：http://127.0.0.1/setCookie.jsp ，用Chrome F12工具可看到 cookie getCookie在web目录下创建文件getCookie.jsp，填入 1234567&lt;% Cookie[] cookies = request.getCookies(); if (null != cookies) for (int d = 0; d &lt;= cookies.length - 1; d++) { out.print(cookies[d].getName() + &quot;:&quot; + cookies[d].getValue() + &quot;&lt;br&gt;&quot;); }%&gt; 然后访问 http://127.0.0.1/getCookie.jsp ，可以看到name:Gareen，这就是setCookie.jsp中设置的Cookie setSession会话指的是从用户打开浏览器访问一个网站开始，无论在这个网站中访问了多少页面，点击了多少链接，都属于同一个会话。 直到该用户关闭浏览器为止，都属于同一个会话。 setSession.jsp 12345678&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; import=&quot;javax.servlet.http.Cookie&quot;%&gt;&lt;% session.setAttribute(&quot;name&quot;, &quot;teemo&quot;);%&gt;&lt;a href=&quot;getSession.jsp&quot;&gt;跳转到获取session的页面&lt;/a&gt; 用 session.setAttribute(&quot;name&quot;, &quot;wtf&quot;); 来保存数据，其中第一个参数是键，第二个参数是值 getSessiongetSession.jsp 12345678&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; import=&quot;javax.servlet.http.Cookie&quot;%&gt;&lt;% String name = (String)session.getAttribute(&quot;name&quot;);%&gt;session中的name: &lt;%=name%&gt; 用session.getAttribute(&quot;name&quot;);获取数据，参数是键，不是值。 效果是，在getSession.jsp页面显示如下内容 session中的name: wtf 如果浏览器关闭了 Cookie如果浏览器把cookie功能关闭，那么服务端就无法获取jsessionid,每一次访问，都会生成一个新的session对象。 为了解决这个问题，可以使用 1response.encodeURL(&quot;getSession.jsp&quot;)) 于是 getSession.jsp 这个页面的URL就会被转换成 1getSession.jsp;jsessionid=22424AEA86ADBE89F335EEB649D997A8 通过这个方式，提交jsessionid到服务器。 服务器根据这个jsessionid匹配到对应的session. 与session相关的功能，就可以正常工作了。 12345678&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; import=&quot;javax.servlet.http.Cookie&quot;%&gt;&lt;% session.setAttribute(&quot;name&quot;, &quot;teemo&quot;);%&gt;&lt;a href=&quot;&lt;%=response.encodeURL(&quot;getSession.jsp&quot;)%&gt;&quot;&gt;跳转到获取session的页面&lt;/a&gt; 作用域JSP 有 4 个作用域 pageContext： 只能在当前页面访问，在其他页面就不能访问了。 requestContext： 一次请求。随着本次请求结束，其中的数据也就被回收。 sessionContext： 当前会话。从一个用户打开你的网站的那一刻起，无论访问了多少个子网页，链接都属于同一个会话，直到浏览器关闭。 applicationContext： 全局，所有用户共享 作用域示例 setContext.jsp 12345678&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;% pageContext.setAttribute(&quot;name&quot;,&quot;gareen&quot;);%&gt;&lt;%=pageContext.getAttribute(&quot;name&quot;)%&gt; getContext.jsp 1234&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot;%&gt;&lt;%=pageContext.getAttribute(&quot;name&quot;)%&gt; getContext.jsp从setContext.jsp获取了数据，由于是pageContext，所以只能在当前页面，跳转到其他页面就不能获取了。 隐式对象JSP的隐式对象指的是不需要显示定义，直接就可以使用的对象。 JSP一共有9个隐式对象，分别是 request：请求 response：响应 out：输出 pageContext：当前页面作用域 session：会话作用域 application：全局作用域 page：表示当前对象。JSP 会被编译为一个Servlet类 ，运行的时候是一个Servlet实例。 page即代表this config：config可以获取一些在web.xml中初始化的参数。 exception：异常。只有当前页面的&lt;%@page 指令设置为isErrorPage=”true”的时候才可以使用。 参考：HOW2J JSTLJSP Standard Tag Library 标准标签库 JSTL允许开人员可以像使用HTML标签 那样在JSP中开发Java功能。 JSTL库用得比较多的有 core 和 fmt EL表达式首先在 jsp 头标注isELIgnored=”false”，因为不同版本的 Tomcat 对 EL 表达式默认开关不一样。 12345678910&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; isELIgnored=&quot;false&quot;%&gt;&lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot;%&gt;&lt;c:set var=&quot;name&quot; value=&quot;${'gareen'}&quot; scope=&quot;request&quot; /&gt;通过标签获取name: &lt;c:out value=&quot;${name}&quot; /&gt; &lt;br&gt;通过 EL 获取name: ${name} 可见，JSTL输出要写成&lt;c:out value=&quot;${name}&quot; /&gt;的代码，用 EL表达式只需要写${name}，非常方便。 JavaBeanJava语言欠缺属性、事件、多重继承功能。所以，如果要在Java程序中实现一些面向对象编程的常见需求，只能手写大量胶水代码。Java Bean正是编写这套胶水代码的惯用模式或约定。这些约定包括getXxx、setXxx、isXxx、addXxxListener、XxxEvent等。遵守上述约定的类可以用于若干工具或库。 参考：Zhihu 简单地说，JavaBean是一种标准： 提供无参public的构造方法(默认提供) 每个属性，都有public的getter和setter 如果属性是boolean,那么就对应is和setter方法 我们可以用 EL 表达式来获取 JavaBean 的属性 如${student.name}，就会自动调用getName方法 完整例子来自 How2j 123456789101112131415&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; isELIgnored=&quot;false&quot; import=&quot;bean.*&quot;%&gt;&lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot;%&gt;&lt;% Hero hero =new Hero(); hero.setName(&quot;盖伦&quot;); hero.setHp(616); request.setAttribute(&quot;hero&quot;, hero);%&gt;英雄名字 ： ${hero.name} &lt;br&gt;英雄血量 ： ${hero.hp} 例子2 12345678910111213141516171819202122232425262728&lt;%@ page language=&quot;java&quot; contentType=&quot;text/html; charset=UTF-8&quot; pageEncoding=&quot;UTF-8&quot; import=&quot;java.util.*&quot;%&gt;&lt;%@ taglib uri=&quot;http://java.sun.com/jsp/jstl/core&quot; prefix=&quot;c&quot;%&gt;&lt;% List&lt;String&gt; heros = new ArrayList&lt;String&gt;(); heros.add(&quot;塔姆&quot;); heros.add(&quot;艾克&quot;); heros.add(&quot;巴德&quot;); heros.add(&quot;雷克赛&quot;); heros.add(&quot;卡莉丝塔&quot;); request.setAttribute(&quot;heros&quot;,heros);%&gt;&lt;table width=&quot;200px&quot; align=&quot;center&quot; border=&quot;1&quot; cellspacing=&quot;0&quot;&gt;&lt;tr&gt; &lt;td&gt;编号&lt;/td&gt; &lt;td&gt;英雄&lt;/td&gt;&lt;/tr&gt;&lt;c:forEach items=&quot;${heros}&quot; var=&quot;hero&quot; varStatus=&quot;st&quot; &gt; &lt;tr&gt; &lt;td&gt;${st.count}&lt;/td&gt; &lt;td&gt;${hero}&lt;/td&gt; &lt;/tr&gt;&lt;/c:forEach&gt;&lt;/table&gt;","link":"/post/dfdfe2eb.html"},{"title":"Java Web 跳坑手册","text":"这里有个坑，你要跳吗？ 从 Eclipse 导入工程到IDEA IDEA 选择 import ，选择项目下的 .project 文件 随便打开一个 Java 类，右上角出现 Setup SDK，选择你的JDK版本 Project Structure -&gt; Modules -&gt; Dependencies，把红色的删掉，然后点”+” -&gt; Jars ，添加 WEB-INF 下面的jar包。再点”+” -&gt; Libraries -&gt; Application Libraries， 选择 Tomcat Project Structure -&gt; Facets -&gt; “+”号 -&gt; Web -&gt; OK -&gt; 上面的 Path 改为 web.xml 所在路径，下面的 Web Resource Directory 改为 WebContent 文件夹所在路径 点击右下角 Create Artifacts，点击 Apply，OK Edit Configurations，添加Tomcat服务器 Deployment选项卡，点 + ，选择 Artifacts，Apply，OK IntelliJ使用指南—— 导入Eclipse的Web项目 增添字段报错新增数据库信息时，抛出 SQL Exception 1Field 'id' doesn't have a default value 解决方案： 将mysql中对应表的id字段设置为自增即可 （auto_increment） 重定向出错更新数据库信息，抛出 java.lang.IllegalStateException 1Cannot call sendRedirect() after the response has been committed 解决方案： 删除重写方法的 super.doPost(req, resp); maven工程使用 java 8 新特性，IDEA 报错使用了高版本java的新特性，结果报如下错误 1Diamond types are not supported at this language level 这是因为 maven 工程默认 jdk 支持版本是 1.5 pom.xml 添加如下代码，更改到 1.8 即可 12345678910111213141516171819202122&lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt; &lt;artifactId&gt;maven-compiler-plugin&lt;/artifactId&gt; &lt;version&gt;2.3.2&lt;/version&gt; &lt;configuration&gt; &lt;source&gt;1.8&lt;/source&gt; &lt;target&gt;1.8&lt;/target&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt;&lt;/build&gt;&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;encoding&gt;UTF-8&lt;/encoding&gt; &lt;java.version&gt;1.8&lt;/java.version&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt;&lt;/properties&gt; IDEA导入SSM工程，4042018版本的IDEA导入SSM工程可能导致部署后出现404错误。 解决办法： File -&gt; Settings -&gt; Build,Execution,Deployment -&gt; Build Tools -&gt; Maven -&gt; Importing 取消Store generated project files externally选项即可 BeanFactory not initialized从 github 获取其他人拷贝项目过来，Tomcat 无法运行，报错如下： 1BeanFactory not initialized or already closed - call ‘refresh’ before accessing beans via the ApplicationContext 原因： 没有设置 resource 目录 解决办法： 右键 resource 目录， 选择 mark Directory as … 选择 test resource derectory rebuild SpringBoot集成JPA报错：No identifier specified for entity在 id 字段加 @Id 注解 和 @GeneratedValue(strategy=GenerationType.IDENTITY) 注解。 12345678910111213@Entity@Datapublic class Message { @Id @GeneratedValue(strategy=GenerationType.IDENTITY) Integer id; String message; Date gmtCreate; Date gmtModified;} 几种注解的区别： @GeneratedValue(strategy = GenerationType.AUTO)主键增长方式由数据库自动选择。 @GeneratedValue(strategy = GenerationType.IDENTITY) 要求数据库选择自增方式，oracle不支持此种方式。 @GeneratedValue(strategy = GenerationType.SEQUENCE) 采用数据库提供的sequence机制生成主键。mysql不支持此种方式。 1'findById(java.lang.Long)' in 'org.springframework.data.repository.CrudRepository' cannot be applied","link":"/post/d772a9a7.html"},{"title":"Java简明笔记（十） 输入与输出","text":"文本输入和输出文本输入对于较短的文本，我们可以直接把文本存到一个String里 12345// 整个文本String contents = new String(readAllBytes((Paths.get(\"alice.txt\"))), StandardCharsets.UTF_8);// 以非字母为分隔符，变成一个个单词List&lt;String&gt; words = Arrays.asList(contents.split(\"\\\\PL+\")); 如果想按行读取，可以读文件并存到 List 集合里，集合的每一个元素代表每一行的一个String 12// 按行读取List&lt;String&gt; lines = Files.readAllLines(path, charset); 或者按流处理 12345try (Stream&lt;String&gt; lines = Files.lines(path, charset)) { //...} catch {} 如果想从文件读取数字或单词，可以用 Scanner 12345Scanner in = new Scanner(path, \"UTF-8\");while (in.hasNextDouble()) { double value = in.hasNextDouble(); ...} 如果输入源不是来自文件，可以将InputStream再封装到BufferedReader 123try (BufferedReader reader = new BufferedReader(new InputStreamReader(url.openStream()))) { ...} 文本输出如果我们要把文本输出到一个文件（写文件），构造一个PrintWriter 1PrintWriter out = new PrintWriter(Files.newBufferedWriter(path, charset)); 将文本写到另外一个输出流 1PrintWriter out = new PrintWriter(outstream, \"UTF-8\"); 将已有的变量写入文件 1Files.write(path, lines, charset); 追加内容到一个文件 追加 String 1Files.write(path, content.getBytes(charset), StandardOpenOption.APPEND); 追加 Collection&lt;String&gt; 1Files.write(path, lines, charset, StandardOpenOption.APPEND); 待补充","link":"/post/85d8e3e2.html"},{"title":"Spring（五）使用 Thymeleaf 模板引擎","text":"什么是 ThymeleafThymeleaf的官方定义为 Thymeleaf is a modern server-side Java template engine for both web and standalone environments。 简单地讲，Thymeleaf 是一种现代的Java服务器端模板引擎。可以达到和JSP一样的效果，但是比起JSP对于前端测试更加友好。JSP需要运行起来才能看到效果，而 Thymeleaf 本身就是html格式，无需服务器也能看到效果。 官方网站: https://www.thymeleaf.org/ 官方文档：https://www.thymeleaf.org/documentation.html Spring Boot 集成 Thymeleaf 简明过程在 Spring Initalizr 过程中选择 Thymeleaf 组件，然后在工程templates目录下创建 html 文件即可 如果 Spring Initalizr 过程中忘记添加，可以在 pom.xml 下面添加依赖： 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 一个简单的例子控制器端12345678910@GetMapping(\"/findStudent/{id}\")public String findStudent(@PathVariable Integer id, Model m){ // 通过 Mybatis 查询一个学生信息 Student s = studentMapper.findById(id); // 给 Model 添加属性，其中第一个参数属性名，第二个参数属性值 m.addAttribute(\"name\", s.getName()); return \"findStudent\";} 注意不要加@ResponseBody注解 return 的内容是模板引擎的名字 前端findStudent.html，放在 templates 目录下 123456789101112&lt;!DOCTYPE HTML&gt;&lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;head&gt; &lt;title&gt;hello&lt;/title&gt; &lt;meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" /&gt;&lt;/head&gt; &lt;body&gt; &lt;p th:text=\"${name}\" &gt;name&lt;/p&gt; &lt;p th:text=\"'Hello！ ' + ${name} + '!'\" &gt;hello world&lt;/p&gt; &lt;p th:text=\"|Hello！ ${name}!|\" &gt;hello world&lt;/p&gt; &lt;/body&gt;&lt;/html&gt; ${name}就是后台m.addAttribute(&quot;name&quot;, s.getName());中设置的name。 对象如果后台传过来的是一个对象，如： 1m.addAttribute(\"student\", s); 在 Thymeleaf 中直接取属性 1&lt;p th:text=\"${s.name}\" &gt;&lt;/p&gt; 或者也可以取方法 1&lt;p th:text=\"${s.getName()}\" &gt;&lt;/p&gt; 或者用th:object先给出对象，再用*{}的方式取出属性 123&lt;div class=\"showing\" th:object=\"${student}\"&gt; &lt;p th:text=\"*{name}\" &gt;&lt;/p&gt;&lt;/div&gt; 对象集合如果后台传过来的是一个对象集合，如： 1234567// 查找所有学生@GetMapping(\"/listStudent\")public String listStudent(ModelMap map){ List&lt;Student&gt; allStudents = studentMapper.findAll(); map.addAttribute(\"allStudents\", allStudents); return \"listStudent\";} 在 Thymeleaf 中，用 th:each 来遍历。 1234567891011121314151617181920&lt;table class=\"table table-striped\"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th&gt;ID&lt;/th&gt; &lt;th&gt;姓名&lt;/th&gt; &lt;th&gt;学号&lt;/th&gt; &lt;th&gt;专业&lt;/th&gt; &lt;th&gt;年级&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt; &lt;tbody&gt; &lt;tr th:each=\"oneStudent: ${allStudents}\"&gt; &lt;th scope=\"row\" th:text=\"${oneStudent.id}\"&gt;&lt;/th&gt; &lt;td th:text=\"${oneStudent.name}\"&gt; &lt;/td&gt; &lt;td th:text=\"${oneStudent.getNumber()}\"&gt;&lt;/td&gt; &lt;td th:text=\"${oneStudent.major}\"&gt;&lt;/td&gt; &lt;td th:text=\"${oneStudent.grade}\"&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt;&lt;/table&gt; 效果： 条件语句在控制器端有个 boolean 变量 123456@RequestMapping(\"/test\")public String test(Model m) { boolean testBoolean = true; m.addAttribute(\"testBoolean\", testBoolean); return \"test\";} Thymeleaf 前端用th:if来表示 12&lt;p th:if=\"${testBoolean}\" &gt;如果testBoolean 是 true ，本句话就会显示&lt;/p&gt;&lt;p th:if=\"${not testBoolean}\" &gt;取反&lt;/p&gt; 或者用三元表达式 如果testBoolean为真显示A，否则显示B 1&lt;p th:text=\"${testBoolean}?'A':'B'\" &gt;&lt;/p&gt; 日期控制器端 12Date now = new Date();m.addAttribute(\"now\", now); 前端 123456789&lt;div class=\"showing date\"&gt; &lt;h2&gt;格式化日期&lt;/h2&gt; 直接输出日期 ${now}: &lt;p th:text=\"${now}\"&gt;&lt;/p&gt; 默认格式化 ${#dates.format(now)}: &lt;p th:text=\"${#dates.format(now)}\"&gt;&lt;/p&gt; 自定义格式化 ${#dates.format(now,'yyyy-MM-dd HH:mm:ss')}: &lt;p th:text=\"${#dates.format(now,'yyyy-MM-dd HH:mm:ss')}\"&gt;&lt;/p&gt;&lt;/div&gt; 包含另一个HTML 假如我们的网站，每一个页面都需要包含页脚 foot.html 写一个页脚 foot.html ，把需要被包含的字段用 th:fragment 字段。 12345678 &lt;html xmlns:th=\"http://www.thymeleaf.org\"&gt;&lt;footer th:fragment=\"footer1\"&gt; &lt;p &gt;All Rights Reserved&lt;/p&gt;&lt;/footer&gt;&lt;footer th:fragment=\"footer2(start,now)\"&gt; &lt;p th:text=\"|${start} - ${now} All Rights Reserved|\"&gt;&lt;/p&gt;&lt;/footer&gt;&lt;/html&gt; page.html 在 page.html 用th:replace引用 1234&lt;div class=\"showing\"&gt; &lt;div th:replace=\"include::footer1\" &gt;&lt;/div&gt; &lt;div th:replace=\"include::footer2(2015,2018)\" &gt;&lt;/div&gt;&lt;/div&gt; 引入 CSS 和 js通过 th:href=&quot;@{/static/css/style.css}&quot; 和 th:src=&quot;@{/static/js/mybeautiful.js}&quot; 这种@语法引入 css 和 js 文件。 例子： 12&lt;link rel=\"stylesheet\" type=\"text/css\" media=\"all\" href=\"../../webapp/static/css/style.css\" th:href=\"@{/static/css/style.css}\"/&gt;&lt;script type=\"text/javascript\" src=\"../../webapp/static/js/thymeleaf.js\" th:src=\"@{/static/js/mybeautiful.js}\"&gt;&lt;/script&gt;","link":"/post/7c6dd7fa.html"},{"title":"使用 JWT 进行认证","text":"什么是 JWT ？JWT 的全称是 JSON Web Token，是一种跨域认证解决方案。 所谓认证，就是获取用户的身份信息。我们知道，Http 是一种无状态协议，为了实现认证和跟踪用户信息，开发者发明了 cookie-session 方案，该方案流程如下： 用户向服务器发送用户名和密码； 服务器验证通过后，在 session 里保存相关数据； 服务器返回一个 session_id，写入客户端的 Cookie； 之后，用户的每次请求都会通过 Cookie 把 session_id 传回给服务器； 服务器通过 session_id，找到先前保存的数据，得到用户信息。 这种方案存在几个问题： 如果是服务器集群，要求 session 数据要共享，要求每一台服务器都能够读取并同步 session； 前后端分离，跨域访问的情况下，每次请求的 session_id 都会不一样； 如果是多端（ios/Android/Web）共用一套后端 API 服务，移动端无法储存 Cookie，需要另辟蹊径。 session 数据是保存在服务器的内存中，无形中增加了服务器的压力。 而 JWT 解决了上述问题，它的思想是：服务器不保存 session 数据了，数据全部保存在客户端，每次请求的时候都发回服务器验证。 JWT 的原理用户提供用户名和密码，服务器认证通过以后，生成一个 JSON 对象，发回给用户，如： 12345{ &quot;姓名&quot;: &quot;张三&quot;, &quot;角色&quot;: &quot;管理员&quot;, &quot;到期时间&quot;: &quot;2018年7月1日0点0分&quot;} 之后，用户的每次请求，都要发回这个 JSON 对象给服务器判断身份。 JWT 的组成结构为了防止数据篡改，我们不可能明文发送像上面那样的 json，而是进行了签名之后，以字符串的形式发送给前端，大概像这样： 1eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJudWxsaiJ9.W8hfFfcMVgmlAhTRUl4GHNAq4tq_MWJGB1bv-r9wMCE 它是一个很长的字符串，中间用 . 分割成三段，这三段分别代表： Header：头部，记录了一些元数据，例如采用何种算法，令牌类型等。 Payload：负载，存储我们的关键信息。 Signature：签名，前两部分的签名，防止数据篡改。 我们主要关注 Payload，JWT 官方规定了 7 个供选择的字段： iss (issuer)：签发人 exp (expiration time)：过期时间 sub (subject)：主题 aud (audience)：受众 nbf (Not Before)：生效时间 iat (Issued At)：签发时间 jti (JWT ID)：编号 当然，除了这 7 个字段之外，我们还可以添加自定义字段。这些信息以 json 格式存储，并用 Base64URL 算法转成字符串。 原始 json 数据： 12345{ \"sub\": \"1234567890\", \"name\": \"Jerry\", \"myField\": \"something here\"} Base64URL加密后： 1eyJzdWIiOiAiMTIzNDU2Nzg5MCIsIm5hbWUiOiAiSmVycnkiLCJteUZpZWxkIjogInNvbWV0aGluZyBoZXJlIn0= 注意，Base64URL是可以解密的，因此不要存储密码等敏感信息。 Base64 和 Base64URL 的区别JWT 作为一个令牌（token），有些场合可能会放到 URL（比如 api.example.com/?token=xxx）。Base64 有三个字符+、/和=，在 URL 里面有特殊含义，所以要被替换掉：=被省略、+替换成-，/替换成_ 。这就是 Base64URL 算法。 JWT 如何使用服务器生成 JWT 之后，把加密字符串发回给客户端，客户端可以把它存储在 Cookie 里面，也可以储存在 localStorage。 此后，客户端每次与服务器通信，都要带上这个 JWT。你可以把它放在 Cookie 里面自动发送，但是这样不能跨域，所以更好的做法是放在 HTTP 请求的头信息 Authorization 字段里面。 或者，把 JWT 放在 POST 请求的数据体里面。 参考： JSON Web Token 入门教程 Shiro+JWT+Spring Boot Restful简易教程 SpringBoot 实战自己实现 JWT 并不难，但是秉着不要重复造轮子的原则，我们使用开源框架 jjwt 简化我们的步骤。 引入 jjwt 的依赖pom.xml 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt-api&lt;/artifactId&gt; &lt;version&gt;0.10.5&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt-impl&lt;/artifactId&gt; &lt;version&gt;0.10.5&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.jsonwebtoken&lt;/groupId&gt; &lt;artifactId&gt;jjwt-jackson&lt;/artifactId&gt; &lt;version&gt;0.10.5&lt;/version&gt; &lt;scope&gt;runtime&lt;/scope&gt;&lt;/dependency&gt; 创建 JwtUtil 类12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667import io.jsonwebtoken.*;import io.jsonwebtoken.security.Keys;import org.apache.tomcat.util.codec.binary.Base64;import javax.crypto.SecretKey;import java.util.Date;public class JwtUtil{ private static final String KEY1 = \"somethinghereshouldbelong\"; /** * 由字符串生成加密key * @return */ private static SecretKey generalKey(){ String stringKey = KEY1 + Constant.JWT_SECRET; byte[] encodedKey = Base64.decodeBase64(stringKey); SecretKey key = Keys.hmacShaKeyFor(encodedKey); return key; } /** * 创建jwt * @param subject * @return * @throws Exception */ public static String createJWT(String subject){ SecretKey key = generalKey(); Date now = new Date(); Date thirtyMinutes = new Date(System.currentTimeMillis() + 30*60*1000); String jws = Jwts.builder() .setSubject(subject) // 主题 .setIssuedAt(now) // 签发时间 .setExpiration(thirtyMinutes) // 过期时间 .signWith(key) .compact(); return jws; } /** * 解密jwt * @param jwt 密钥 * @return 主题 * @throws Exception 如果发生 JwtException，说明该密钥无效 */ public static String parseJWT (String jwt) throws JwtException { SecretKey key = generalKey(); try { return Jwts.parser() .setSigningKey(key) .parseClaimsJws(jwt) .getBody() .getSubject(); }catch (JwtException ex){ System.out.println(\"签证失效\"); return null; } }} 该类包含三个静态方法，分别是： generalKey()：用于生成密钥 createJWT(String subject)：用于创建一个JWT parseJWT(String jwt)：用于解密JWT generalKey()一般我们都是从服务器配置文件读取某个 Key 字符串，转换成 byte[] ，再转成 SecretKey，如下： 12byte[] keyBytes = getSigningKeyFromApplicationConfiguration();SecretKey key = Keys.hmacShaKeyFor(keyBytes); 但是如果你嫌麻烦，可以直接用 jjwt 提供的 Key 算法： 1SecretKey key = Keys.secretKeyFor(SignatureAlgorithm.HS256); //or HS384 or HS512 createJWT(String subject)创建 JWT 的过程，详细可看 jjwt github文档。 123456String jws = Jwts.builder() .setSubject(subject) // 设置主题（也就是我们的关键字） .setIssuedAt(now) // 设置签发时间 .setExpiration(thirtyMinutes) // 设置过期时间 .signWith(key) // 密钥 .compact(); parseJWT(String jwt)解密 JWT 的过程，这里注意，需要抛出异常。因为一旦解密失败(例如失效或者无效)，jjwt会抛出JwtException，需要我们在 catch 块里处理。 123456789101112Jws&lt;Claims&gt; jws;try { jws = Jwts.parser() // (1) .setSigningKey(key) // (2) .parseClaimsJws(jwsString); // (3) // we can safely trust the JWT} catch (JwtException ex) { // (4) // we *cannot* use the JWT as intended by its creator} 在 Service 层调用JwtUtil在 Servce 里面验证用户名和密码无误后，通过以下语句创建一个JWT（token） 1String token = JwtUtil.createJWT(user.getUsername()); 之后把这个 JWT（token） 返回给前端 前端保存 token在 HTML5 中，localStorage 是一个客户端（浏览器）可以存储数据的地方。 前端收到服务器 token 后，通过 localStorage 存储，直接用 javascript代码写入： 1localStorage.setItem(\"token\", token); 将 token 写入 header 中之后发起一次 ajax 请求，把 token 放进 header 的 Authorization 字段里，例如，我这里是获取登录用户信息。 1234567axios.get(\"/api/user/profile\",{ headers: { 'Authorization': localStorage.getItem(\"token\") }}).then(function (response) { // 其他处理}) 之后在这台电脑上的每一次请求 header 都会自动携带 Authorization 字段。直到 token 过期才需要重新登录。或者，你可以用 sessionStorage 。 注意：每次发起 ajax 请求，必须在方法参数里手动带上 Authorization 退出登录退出登录非常简单，只需要把 token 从 localStorage 里面删除即可。 12localStorage.removeItem(\"token\");location.reload(); 在 Service 层验证 JWT前端发回 JWT，Service进行校验 12// parseJWT 的返回值可以设置为 token 里面的 subjectString subject = JwtUtil.parseJWT(token); 引申1：JWT 过期问题JWT 的一个特点就是无状态，给用户签发一个有效期为 30 分钟的 token，如果用户第29分钟还在浏览，下一分钟可能因为 token 失效而被迫重新登录。因此需要考虑刷新 JWT 问题。参考业界主流做法，AWS、Azure 和 Auth0 都是用 JWT 为载体，ID Token + Access Token + Refresh Token 的模式： 亚马逊 AWS 微软 Azure Auth0 引申2：认证和鉴权JWT 只是实现了 认证（Authorization） 功能，事实上，在现代面向服务的应用中，不同的角色有不同的权限（例如管理员和普通用户），如何 鉴权（Authentication） 呢？ 这就要交给 shiro 或者 Spring security 等框架来做了。 说到鉴权和授权，目前很多网站支持微信授权登录、微博授权登录等，这使用到了 OAuth2.0 协议。OAuth2.0 主要用于有第三方参与的场景。例如，你是微博的开发者，豆瓣想在他的网站上设置一个“使用微博账号登录”的功能，这就需要你向豆瓣提供一些基本权限信息（例如提供用户的用户名、头像）。 关于 OAuth2 的使用场景，可参考：你可能并不需要 OAuth2","link":"/post/fd9d3113.html"},{"title":"Redis的五种数据结构","text":"什么是RedisRedis 是 Remote Dictionary Service (远程字典服务)的简称，是一个开源的、使用内存存储数据的中间件。通常用作于内存数据库、缓存、消息中间件。 Redis 用于缓存比较多。我在公司接触过的几个项目中无一不是把 Redis 当缓存用，引入 Redis 的原因也很简单：有些数据是频繁查询但不经常更新的，这样的数据可以丢一份在 Redis 里，当查询请求进来时，直接从 Redis 里读取，这样就减轻了数据库的压力。在并发高的场景下非常有用。 此外，Redis 还可以用作于分布式锁。 Redis 的五种基本数据结构字典服务的本质是 key-value 存储，我们给 Redis 一个 key，他返回一个 value 给我们，就这么简单。只不过说， Redis 的 value 可以是不同的数据结构，它可能是字符串，可能是链表，也可能是哈希表。 要体验 Redis 的功能，可以使用官方提供的 在线 redis 环境 进行试用。 stringstring存储字符数组，是一个动态的字符串，类似于Java的 ArrayList&lt;Char&gt;。常见的用法是把对象用 Json 序列化为字符串（又想起那句，Web开发的本质是拼接字符串hhh），再丢到 Redis 进去。查询的时候从 Redis 取出，再反序列化为对象。 1234567// 这里使用 fastjson 序列化和反序列化对象User user = ...String userStr = JSON.toJSONString(user);redisClient.set(\"user\"，userStr);String u = redisClient.get(\"user\");User user = JSON.parseObject(u, User.class); 在字符较少时，string会预留空间减少内存的频繁分配，小于1MB时，扩容是加倍现有空间（256KB -&gt; 512KB），大于1M时，每次扩容增加1MB空间（3MB -&gt; 4MB）。单个string最大支持512MB。 listlist 是双端链表，类似于 Java 的 LinkedList&lt;String&gt;。提供了 rpush、lpush、lpop、rpop 等操作方式，可用作队列或栈。可以发现，操作 List 时，第一个字母 l 或 r 指定了要从左边还是右边开始读取。 Redis 的 list 常用来做异步队列。将后续需要处理的数据序列化为字符串丢进列表，随后，另一个线程遍历列表依次读取数据进行处理。 list 的写入： 1&gt; rpush books python java cpp list 的读取： 1234567891011# 获取list下标为1的内容，需要遍历列表，越往后越慢，O(n)慎用&gt; lindex books 1# 获取所有元素，需要遍历列表，O(n)慎用&gt; lrange books 0 -1# 保留下标为 1 到下标为 -1 之间的元素，O(n)慎用&gt; ltrim books 1 -1# 获取长度&gt; llen books list 的删除 12# 删除books队列最右边一个元素&gt; rpop books 事实上，list不是简单的 Linkedlist，当元素较少的时候，Redis 会用连续的内存存储元素，这个结构称为 ziplist（压缩列表）。当元素变大后，再起一个 ziplist，两个 ziplist 之间串起来，这样的结构称为 quicklist。quicklist 既满足快速插入删除性能，又不会有太大空间冗余。 hashhash 类似于 Java 的 HashMap&lt;String,String&gt;，value只可以存储 string 。 Java HashMap 的 rehash 需要一次完成， map 很大时比较耗时，而 Redis hash 的 rehash 是 渐进式 的。rehash 时会保留新旧两个 hash 结构，后续慢慢将旧hash一点点搬迁到新hash。 12345678# 存&gt; hset book_1 name &quot;一往无前&quot;&gt; hset book_1 author &quot;范海涛&quot;&gt; hset book_1 category &quot;传记&quot;# 取&gt; hget book_1 name&quot;一往无前&quot; setset 类似于 Java 的 HashSet&lt;String&gt;，同样也是只能存储 string，set保证了里面存储的内容没有重复。内部实现相当于一个特殊的 hash，只不过只有 key，所有 value 都是 null。 zsetzset 类似于 Java 的 SortSet&lt;String&gt; 和 HashMap&lt;String,String&gt; 的结合体，其本质是一个 set， 但同时还为 set 里的每一个元素维护了一个 score 权重值，用来排序。底层是用 跳跃表 的数据结构实现。 zset 的应用场景可以是粉丝列表，value 是 user_id， score 是关注时间，这样我们就可以将某用户的粉丝列表按关注时间排序展示出来了。或者是考生成绩， value 是 学生ID， score 是成绩，这样就可以按成绩排序了。 12345678# 存&gt; zadd winners 98.5 &quot;Jerry&quot;&gt; zadd winners 95.0 &quot;Calm&quot;&gt; zadd winners 89 &quot;Mary&quot;# 范围取&gt; zrange 0 -1&gt; zreverange 0 -1 通用规则五种基本数据结构中，除 string 外，剩下的都是容器型结构。他们遵循两个规则： create if not exists：如果容器不存在，那就创建一个 drop if no elements：如果容器没有元素了，那就销毁，释放内存 参考： 《Redis 深度历险》 钱文品","link":"/post/dc895096.html"},{"title":"Redis的几种用途","text":"Redis常用作于缓存，但实际上它的用途不止于此： 缓存 分布式锁 延时队列 位图 Redis用于缓存在互联网应用中，Redis常作为数据库的缓存。典型的使用流程如下： Redis用于分布式锁在分布式应用中，多个服务不在同一个应用里面，因此无法在代码里面实现锁操作，这时候可以引入 Redis 作为分布式锁。但是使用 Redis 作为多个服务公共的锁，可能存在以下几个问题： 锁超时：Redis的分布式锁不能解决超时问题，不要用来做时间较长的任务； 单点/多点问题：当机部署的Redis可能挂掉，锁会丢失；多机部署的Redis若主机获得锁后挂掉，另一个服务可以在从机获得； 可重入性：在应用中对 set 进行包装，使用 Threadlocal 和 引用计数 来解决重入问题。 Redis用于延时队列Redis的 list 数据结构是链表，可以当队列使用。A服务往 redis 的 list 不断 push 数据，B服务随时 pop 取出处理。 但是，相较于专业的消息队列中间件，如 MQ、Kafka等， Redis 的消息队列显得不那么靠谱，如果对消息的可靠性有要求，不建议将 Redis 当队列用。 Redis用于位图位图其实就是普通的字符串（byte数组）。可以用 get/set 直接获取整个位图的内容，也可以用 getbit/setbit 将 byte数组 当作 位数组 来使用。 一个使用场景是，用户一年的签到记录，签了是1，未签是0，将一个字符串当作位数组，其实就可以搞定。","link":"/post/7040ae85.html"},{"title":"2019年","text":"9月1日永远不要相信苦难是值得的苦难就是苦难苦难不会带来成功苦难不值得追求磨练意志是因为苦难无法躲开 —— 余华《活着》 7月3日看见别人在读你喜欢的书时，是书在推荐这个人。 6月7日cs（计算机科学）里面随便一个领域单独拿出来，水都可以深得超过外行的想象，但在工程的场景下，更重要的是投入恰到好处的技能点去实现你现阶段的目标。 —— 尤雨溪 6月7日爱，是为了促进自己和他人心智成熟，而不断拓展自我界限，实现自我完善的一种意愿。 ——《少有人走的路》 6月6日没有愿望的原因，不一定是满足于现状吧。应该是在专注于眼前的事情的时候，愿望就被实现了。 ——日剧《我们由奇迹构成》 5月2日听到别人骂人，就不要转告给那个挨骂的人，就假装不知道吧。在你的立场上，或许如实以告就是友情的表现，但大人之间却并不如此，假装不知道就是义气，是礼仪。多此一举说出来，会让对方避着你。 4月29日目的是抽象的，目标是具体的 3月21日根本没有必要去学习如何表现得很专心，如果你确实很专心。 2月24日约着见一面就使见面的前后几天都沾着光，变成好日子。 ——钱钟书《围城》 如果你说你在下午四点来，从三点钟开始，我就开始感觉很快乐，时间越临近，我就越来越感到快乐。 ——《小王子》 2月18日每当你想要批评别人的时候，一定要记住，并不是每个人都拥有你那样的优越条件。 ——《了不起的盖茨比》 2月6日后来我们才知道相见趁早，影响我们一生信念最重要的人经常很早就出现了。暂时打发时间却无法一起前进的人，他们会自动把自己淘汰在你的生命之外，直到某天重逢他们会喂你几只记忆的尘螨让你消化不良，或喷射出一束失而复得的电流让你感激天涯有知音。 后来我们才知道相见恨晚，再欣赏彼此也已没有一起厮混到天光这样的馀裕，我们总是越忙越瞎、越瞎越忙，最后才明白相见本身已是宇宙为你精心过滤、最值得我们排除万难去履行的承诺。 ——Kay Chen（安溥电子信提到的朋友） 2月3日在回答别人问题的时候。不一定要告诉他真实的答案。很多时候，告诉他一个符合他想象的答案，可能效果更好。因为不是每一个人，都有勇气去接受他不懂的东西，愿意去理解他未知的领域。对绝大多数人来说，更倾向用已有的想法，去解释看到的一切。 2月1日女孩子可以剪短发 剃光头 看球赛 穿男装 抽烟喝酒 玩赛车 买机器人男孩子可以留长发 带耳钉 化妆 穿裙子 喜欢粉红色 收藏芭比娃娃 女孩子喜欢钱不都是拜金男孩子不是都要有车有房才能结婚 女孩子想读书就读书，可去他妈的女子无才便是德，去他妈的书读多了不好结婚男孩子想哭就可以哭，可滚犊子男儿有泪不轻弹，谁还没有崩溃的时候呢 女孩子可以喜欢女孩子男孩子可以喜欢男孩子 这个世界就像一个大素材库，我们可以从中挑选任何自己喜欢的事物。性别从来都不应该是限制因素。 ——微博网友 阿胖万事屋 1月31日「现在的娱乐方式那么多，很多年轻人都已经不读书了。对于娱乐至上的现象，您怎么看？」 林清玄： 「我觉得应该找到平衡吧，用手机或者电脑，那个都不是坏事，坏的是你因为这样放弃了生活实际的体验。 比如说躺在草地上看星星，那是你玩一百年的手机也不会有那种感受。黄昏在河边散步，这也是你在电子产品里面得不到的，就是你把电视机换成更大的电视，你也不会有这种体验。」 1月20日很多原因。看到一段话很喜欢，分享给你：when u stop being yourself in a relationship, and u start to change your habits, friends, tastes, etc. for someone… Be careful! Sth is not right. ——我的某个朋友 1月9日其实说到酷这个词，你如果觉得一个人很酷，那他肯定是做了你想做却没做的事情，不管是因为你没有能力去做，还是没有胆和勇气去做。 ——知乎网友 思凡 在问题 大学生在大学里做什么会被别人觉得很酷？下的回答 1月2日我在你们这个年纪，有段时间，远离人群，独自思索，我的人生到底应该怎样度过。某日，我偶然去图书馆，听到泰戈尔的演讲，而陪同在泰戈尔身边的人，是当时最出名的学者（梁思成、林徽因、梁启超、梅贻琦、王国维、徐志摩），这些人站在那里，自信而笃定，那种从容让我十分羡慕。而泰戈尔，正在讲“对自己的真实”有多么重要。那一刻，我从思索生命意义的羞耻感中释放出来，原来这些卓越的人物，也认为花时间思考这些，谈论这些，是重要的。今天，我把泰戈尔的诗介绍给你们，希望你们在今后的岁月里，不要放弃对生命的思索，对自己的真实。 ——《无问西东》","link":"/post/e1aa3a9a.html"},{"title":"2018年","text":"12月29日那些所有你沾沾自喜以为你原力爆发通宵达旦、日夜兼程所获得的东西都会在日后让你加倍偿还。 ——《English-level-up-tips-for-Chinese》 PART I - 认知篇 12月28日我一直觉得，伴侣的好绝不在于他在普世价值中表现出来的那些，让女生走马路内侧，说话轻声，制造浪漫之类。我喜欢的，是一个正常人灵魂里躲着的神经病，是一个智者脑子中存在的白痴，是一朵玫瑰脚下的泥土，是宇宙里最特别的那颗星，只被我看见的那部分天真。 ——网易云网友在歌曲《Star of the County Down》下的评论 12月22日「交往」这件事，不只是为了休息日能一起去哪玩，那只是附带的东西罢了。「互相支撑着对方的生活」才是交往的本质。比起在一起的时候，倒不如说不能在一起的时候，两人互相能成为对方的力量，这才是最重要的一点。 它是让人在工作很辛苦的时候，只要想起对方的脸，就能再努力一把的力量。 —— Twitter 网友 Nanami_Kuriaki 12月16日人生不能像做菜，等所有的料都准备好了才下锅。 ——《饮食男女》 11月23日成长是一个很痛的词，当你成熟了，你不一定会得到什么，却一定会失去一些东西。 ——电影《前任3》 知不足者，方知路远，知路远者，必勤慎独行。 11月20日The end is always good, if it is not good, it is not the end. 11月9日Where there is a will，there is a way. 10月3日人际关系良好的第一点，是真诚地对他人发生兴趣。 9月17日你的职责是平整土地，而非焦虑时光。你做三四月的事，在八九月自有答案。 ——余世存 《时间之书》 ​​​ 8月20日你分享音乐，没几个人点开，你发了一组自拍却收到了很多赞。其实大家一直都在关心你的外在容貌，不关心你的喜好。正如廖一梅书中写到的那样：人这一生，遇到性、遇到爱，都不稀罕，稀罕的是遇到了解。 7月23日有的人浅薄，有的人金玉其表败絮其中。有一天,你会遇到一个彩虹般绚烂的人，当你遇到这个人后，会觉得其他人都只是浮云而已。 ——《怦然心动》 Bryce’s grandfather says about Juli, “Some of us get dipped in flat, some in satin, some in gloss…. But every once in a while you find someone who’s iridescent, and when you do, nothing will ever compare.” ——《Flipped》 7月21日人们声称的最美好的岁月其实都是最痛苦的，只是事后回忆起来的时候才那么幸福。 ——白岩松 6月20日还不确定自己想做什么，至少先把目前能做到的做好。还不清楚自己适合什么样的伴，那就先懂得善待自己与身边的人，不要停止让自己变好。 —— Twitter 网友 阿飞大叔 6月19日一个懂得规则的人的坚持是尤为可贵的。 —— 知乎网友对日剧《Unnatural》中主角三澄美琴的评价。 6月18日特别喜欢日剧的一个原因，大概就是它帮你认清生活的真相之后，依然教会你如何热爱生活。 —— 网易云音乐《Lemon》歌曲下网友的评论 6月10日因为你，我愿意成为一个更好的人，不想成为你的包袱，因此发奋努力，只是为了想要证明我足以与你相配。 ——《侧耳倾听》 6月9日有時候我希望它更輕更輕。不只輕盈最好是輕浮。輕浮到我和幾個好久不見的大學死黨終於在搖滾樂震天價響的酒吧相遇，我就著半昏茫的酒意把頭靠在他們其中一人的肩膀上往外吐出煙圈，順便好像只是想到什麼的告訴他們：“欸，忘了跟你們說，我爸掛了。” 他們之中可能有幾個人來過家裡玩，吃過你買回來的小吃名產。所以會有人彈起來又驚訝又心疼地跟我說你怎麼都不說我們都不知道？ 我會告訴他們，沒關係，我也經常忘記。 是的。我經常忘記。於是它又經常不知不覺地變得很重。重到父後某月某日，我坐在香港飛往東京的班機上，看著空服員推著免稅菸酒走過，下意識提醒自己，回到台灣入境前記得給你買一條黃長壽。這個半秒鐘的念頭，讓我足足哭了一個半小時。直到繫緊安全帶的燈亮起，直到機長室廣播響起，傳出的聲音，彷彿是你。 你說：請收拾好您的情緒，我們即將降落。 ——《父后七日》 6月7日（关于感情）让情感的流动跟着你们彼此的了解加深，信任加深进行下去，而不是，你单一地就疯狂迷恋对方了。那样的情感是不理智，不成熟，也是会伤害到彼此的。 5月18日真爱的前提，就是永远有空。阅读是，音乐是，电影是，人也是。 5月14日并不是所有观点一致所以是朋友。而是存在观点分歧还能交流才是朋友。 5月9日 …then work which one hopes may be of some use; then rest, nature, books, music, love for one’s neighbor – such is my idea of happiness. —— 《Family Happiness and Other Stories》Leo Tolstoy 做一份真正有用的工作，然后休息、享受自然、读书、音乐、爱周围的人。这就是我对幸福的诠释。 句子出自列夫托尔斯泰的《家挺与幸福》，在电影《荒野求生》（Into the wild）中被引用。 5月7日如果你不喜欢桌面上仅有的两个选项，那就把桌子掀翻吧。 ——《纸牌屋》 5月6日在普通的一天里有所期待，本来就是给自己挖的一个坑。 5月1日享受当下又有什么不好，结果固然重要，但比起快乐，它犹为渺小。 4月28日Rarely can a response make somthing better, what makes something better is connection. 4月13日虽然现在已经是太空时代了，人类可以搭乘太空船到达月球，但却没办法看穿每个人心里的宇宙。 ——《大佛普拉斯》 4月2日我自己只有极少的勇气，比你少得多。 但我发现，每当我在长久的挣扎之后鼓起勇气做某事时，总是在事后感到自由得多、快乐得多。 ——《维特根斯坦传》 4月1日一帆风顺的人，认为航海也不过如此，但在你看不见的暗礁下，埋葬了无数的水手。 他们已经没有机会说出自己的经历。 3月28日愿有前程可奔赴，亦有岁月可回首。 3月26日无法理解别人的感受不是理所当然的吗？就是因为不懂才会对别人感兴趣，不懂才需要和别人交流。 ——《编舟记》 3月19日技术分为 「术」 和 「道」 两种，具体做事方法是「术」，做事的原理和原则是「道」。 很多具体的搜索技术很快会从独门绝技都普及，再到落伍，追求「术」的人一辈子工作很辛苦。只有掌握了搜索的本质和精髓才能永远游刃有余。 很多希望我介绍「术」的人是想走捷径，但是真正做好一件事没有捷径，离不开一万小时的专业训练和努力。 ——吴军《数学之美》 3月14日For those of you who could not attend, I would like to share these words from my own lecture with you: Remember to look up at the stars and not down at your feet. Be curious and however difficult life may seem, there is always something you can do and succeed at. – Stephen William Hawking 2月28日接受得起赞誉，就应该接受得起误解。 2月21日很多人结婚只是为了找个跟自己一起看电影的，而不是能够分享看电影心得的人。如果为了只是找个伴，我不愿意结婚，我自己一个人都能够去看电影。 —— 林夕 2月18日世界上最没有用的东西是什么？没有实力只能去靠诚意表真心。 但凡能拿出一丁点东西来，都比这玩意强。 2月17日don’t judge 2月14日在路边吃拉面，听到身后一桌情侣聊天。聊着聊着不知道怎么冒出一句：你这就是喜欢而已，真正的爱都是很克制的，因为喜欢才会放肆，而爱就是克制。 大家可千万别被电影里的台词和各种人生格言给蒙蔽了。我当时只是起床突发奇想，随手一写，图个押韵。当时要是写了“喜欢就是克制，但爱就会放肆”呢？似乎也没有问题吧，在很多人身上，就是这么表现的啊。人的性格各不同，没有一种表相就一定呼应了一种事实。有人热情似火，有人暗藏心动，那都是爱与喜欢。 另外，有时候听到一句喜欢好像还更心动些，全世界都是张口就来的“爱你么么哒”和“我爱你比心”，一句羞涩的“我喜欢你啊”弄不好藏着更多的爱意。 大千世界，万千境遇，感情更是说不清道不明，没有必要强行定义。 爱是浓烈，爱是淡然，爱是巨浪，爱是暗涌，爱是奋不顾身，爱是瞻前顾后，爱是每天说爱你，爱是从不说爱你，爱是你满世界疯狂找那个人的消息，爱是你不愿看那个人的任何消息，爱可能是任何样子，不要让死板的句子成为你人生的标尺。 ——韩寒 2月11日所以现在人们没事就北上广深杭，不是喜欢人多嘴杂空气差，而是在这些一线城市可以接触更多的人和事物，见更高的山，渡更宽的河。不是为了情怀，而是拥有格局。见都没见过，还同一个起跑线呢，一跑就得趴窝。所以，无论这些地方环境多恶劣，竞争多激烈，来的永远多过走的，不为别的，只是为了缓解些许绝望的感觉…… 2月10日有三件事具有生命的意义。它们是你生活当中所有事情的动机。第一是生存，第二是社会秩序，第三是娱乐。生活中所有的事情都是按这个顺序发展的，娱乐之后便一无所有。因此，从某种意义上来说，生活的意义就是要达到第三个阶段。你一旦达到了第三个阶段，就算成功了。但首先要越过前两个阶段。 ——Linus Torvalds 《Just for fun》 2月9日那些曾经不屑一顾的东西，最终还是要花更多的功夫去补上。 不读书，往往看问题的角度比较单一。而读书，可以让一个人的思考更有深度。懂的东西越少，能与人交流的东西也就越少，聊天就有了很大的局限性。别人说的东西你完全不懂，天不聊死才怪。 ——知乎用户阿喵姐说在问题经常看书的人和不看书的人有什么区别？下的回答 2月7日有一种人值得警惕，那就是永远不会自相矛盾的人，其实如果我们真诚地面对自己，就不得不承认，总有一些时候我们会做自相矛盾的事情，粗鲁地说就是打脸，但这就是真实的人，人会成长，会改变，人的理智与情感总是在交战，我们也要接纳自己这个事实，不丢人。 ——微博用户蔡尹珊珊 2月5日海底月是天上月，眼前人是心上人 向来心是看客心，奈何人是剧中人 ——张爱玲 2月3日人生实苦，但请你足够相信！ ——清华大学致魏祥的回信 2月2日用技术去生存，用艺术去生活。 ——《死亡诗社》 2月1日人生最好的三个词： 久别重逢 失而复得 虚惊一场 1月27日当你踩着高跷的时候，哪里还顾得上什么体面。 ——《地球脉动2》 1月26日开弓没有回头箭 1月25日你见过最美好的女生是什么样的？ 是糊得了墙，敲得了代码，搬得了重物。真性情却并不以此为傲。 她知道光荣与梦想需要披荆斩棘。她知道每个深夜独处的孤单会有明天的太阳作伴。 1月24日把事当事，把人当人 用心做事，用心做人","link":"/post/59165dff.html"},{"title":"2020年","text":"9月28日每一个计算机程序都是现实中的或者精神中的某个过程的一个模型，通过人的头脑孵化出来。这些过程出现在人们的经验或者思维之中，数量上数不胜数，详情琐碎繁杂，任何时候人们都只能部分地理解它们……当我们对于模型的认识更深入、更扩大、更广泛时，就需要去修改程序，直至这一模型最终到达了一种亚稳定状态。而在这时，程序中就又会出现另一个需要我们去为之奋斗的模型。计算机程序设计领域之令人兴奋的源泉，就在于它所引起的连绵不断的发现，在我们的头脑之中，在由程序所表达的计算机制之中，以及在由此所导致的认识爆炸之中。 如果说艺术解释了我们的梦想，那么计算机就是以程序的名义执行着它们。 ——《计算机程序的构造和解释》 9月8日然后我明白：公司不会因为你懂得的这些额外的知识给你支付额外的工资，如果你想把这些东西变现，只能靠你自己。 —— 知乎用户weishu在问题 你决心离职的引爆点是什么 下的 回答 9月1日你在耻辱和战争中选择了耻辱，最后你还是得去面对战争 ——丘吉尔 8月27日从来如此，便对吗？——鲁迅 8月17日我们绝大部分人在工作这个「考试」中缺的不是时间，而是思考和效率。 8月15日众利勿为，众争勿往","link":"/post/db020fc0.html"}],"tags":[{"name":"Android","slug":"Android","link":"/tags/Android/"},{"name":"大数据","slug":"大数据","link":"/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"C&#x2F;C++","slug":"C-C","link":"/tags/C-C/"},{"name":"计算机科学","slug":"计算机科学","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6/"},{"name":"数据结构和算法","slug":"数据结构和算法","link":"/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"},{"name":"SQL","slug":"SQL","link":"/tags/SQL/"},{"name":"HTML","slug":"HTML","link":"/tags/HTML/"},{"name":"前端","slug":"前端","link":"/tags/%E5%89%8D%E7%AB%AF/"},{"name":"Golang","slug":"Golang","link":"/tags/Golang/"},{"name":"读书","slug":"读书","link":"/tags/%E8%AF%BB%E4%B9%A6/"},{"name":"电影","slug":"电影","link":"/tags/%E7%94%B5%E5%BD%B1/"},{"name":"生活","slug":"生活","link":"/tags/%E7%94%9F%E6%B4%BB/"},{"name":"阅读","slug":"阅读","link":"/tags/%E9%98%85%E8%AF%BB/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"linux","slug":"linux","link":"/tags/linux/"},{"name":"计算机网络","slug":"计算机网络","link":"/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"HTTP","slug":"HTTP","link":"/tags/HTTP/"},{"name":"操作系统","slug":"操作系统","link":"/tags/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"组成原理","slug":"组成原理","link":"/tags/%E7%BB%84%E6%88%90%E5%8E%9F%E7%90%86/"},{"name":"并发","slug":"并发","link":"/tags/%E5%B9%B6%E5%8F%91/"},{"name":"设计模式","slug":"设计模式","link":"/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"Ubuntu","slug":"Ubuntu","link":"/tags/Ubuntu/"},{"name":"Hadoop","slug":"Hadoop","link":"/tags/Hadoop/"},{"name":"Scala","slug":"Scala","link":"/tags/Scala/"},{"name":"Web","slug":"Web","link":"/tags/Web/"},{"name":"Java Web","slug":"Java-Web","link":"/tags/Java-Web/"},{"name":"JavaScript","slug":"JavaScript","link":"/tags/JavaScript/"},{"name":"Java","slug":"Java","link":"/tags/Java/"},{"name":"JVM","slug":"JVM","link":"/tags/JVM/"},{"name":"微服务","slug":"微服务","link":"/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Spring Cloud","slug":"Spring-Cloud","link":"/tags/Spring-Cloud/"},{"name":"Redis","slug":"Redis","link":"/tags/Redis/"}],"categories":[{"name":"Android","slug":"Android","link":"/categories/Android/"},{"name":"大数据","slug":"大数据","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"C&#x2F;C++","slug":"C-C","link":"/categories/C-C/"},{"name":"计算机科学速成课","slug":"计算机科学速成课","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE/"},{"name":"数据结构和算法","slug":"数据结构和算法","link":"/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"},{"name":"数据库","slug":"数据库","link":"/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"前端","slug":"前端","link":"/categories/%E5%89%8D%E7%AB%AF/"},{"name":"Golang","slug":"Golang","link":"/categories/Golang/"},{"name":"读书与生活","slug":"读书与生活","link":"/categories/%E8%AF%BB%E4%B9%A6%E4%B8%8E%E7%94%9F%E6%B4%BB/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"计算机网络","slug":"计算机网络","link":"/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"},{"name":"操作系统","slug":"操作系统","link":"/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"},{"name":"设计模式","slug":"设计模式","link":"/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"技能","slug":"技能","link":"/categories/%E6%8A%80%E8%83%BD/"},{"name":"瞎折腾","slug":"瞎折腾","link":"/categories/%E7%9E%8E%E6%8A%98%E8%85%BE/"},{"name":"hadoop","slug":"大数据/hadoop","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/"},{"name":"Scala","slug":"大数据/Scala","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Scala/"},{"name":"Spark","slug":"大数据/Spark","link":"/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark/"},{"name":"Java","slug":"Java","link":"/categories/Java/"},{"name":"Effective Java","slug":"Java/Effective-Java","link":"/categories/Java/Effective-Java/"},{"name":"JDBC","slug":"Java/JDBC","link":"/categories/Java/JDBC/"},{"name":"Concurrent","slug":"Java/Concurrent","link":"/categories/Java/Concurrent/"},{"name":"JVM","slug":"Java/JVM","link":"/categories/Java/JVM/"},{"name":"Java SE","slug":"Java/Java-SE","link":"/categories/Java/Java-SE/"},{"name":"Java Web","slug":"Java-Web","link":"/categories/Java-Web/"},{"name":"中间件","slug":"中间件","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"Spring","slug":"Java-Web/Spring","link":"/categories/Java-Web/Spring/"},{"name":"微服务","slug":"Java-Web/微服务","link":"/categories/Java-Web/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"Web","slug":"Java-Web/Web","link":"/categories/Java-Web/Web/"},{"name":"redis","slug":"中间件/redis","link":"/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"}]}
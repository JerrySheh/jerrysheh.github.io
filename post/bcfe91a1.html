<!doctype html>
<html lang="zh"><head><meta charset="utf-8"><meta name="generator" content="Hexo 4.2.0"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>使用 Spark Streaming 进行实时流计算(一) - J.e</title><meta description="使用Spark Streaming 进行实时流计算，主要运用 DStream 编程模型。这种模型包括 输入、转换和输出 三个部分。这一篇主要介绍三种简单的输入。下一篇将会介绍高级数据源和转换，输出部分。"><meta property="og:type" content="blog"><meta property="og:title" content="使用 Spark Streaming 进行实时流计算(一)"><meta property="og:url" content="https://jerrysheh.me/post/bcfe91a1.html"><meta property="og:site_name" content="J.e"><meta property="og:description" content="使用Spark Streaming 进行实时流计算，主要运用 DStream 编程模型。这种模型包括 输入、转换和输出 三个部分。这一篇主要介绍三种简单的输入。下一篇将会介绍高级数据源和转换，输出部分。"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="http://spark.apache.org/docs/latest/img/streaming-arch.png"><meta property="article:published_time" content="2018-04-05T17:52:20.000Z"><meta property="article:modified_time" content="2020-03-06T15:39:44.429Z"><meta property="article:author" content="Jerry Sheh"><meta property="article:tag" content="大数据"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="http://spark.apache.org/docs/latest/img/streaming-arch.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://jerrysheh.me/post/bcfe91a1.html"},"headline":"J.e","image":["http://spark.apache.org/docs/latest/img/streaming-arch.png"],"datePublished":"2018-04-05T17:52:20.000Z","dateModified":"2020-03-06T15:39:44.429Z","author":{"@type":"Person","name":"Jerry Sheh"},"description":"使用Spark Streaming 进行实时流计算，主要运用 DStream 编程模型。这种模型包括 输入、转换和输出 三个部分。这一篇主要介绍三种简单的输入。下一篇将会介绍高级数据源和转换，输出部分。"}</script><link rel="canonical" href="https://jerrysheh.me/post/bcfe91a1.html"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://cdn.bootcdn.net/ajax/libs/font-awesome/5.13.1/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><script src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" defer></script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css"><!--!--><!--!--><!--!--></head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.png" alt="J.e" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">首页</a><a class="navbar-item" href="/archives">时间线</a><a class="navbar-item" href="/categories">分类</a><a class="navbar-item" href="/about">关于</a><a class="navbar-item" href="/sentences">醍醐灌顶</a><a class="navbar-item" href="/anpu">Anpu</a></div><div class="navbar-end"><a class="navbar-item is-hidden-tablet catalogue" title="目录" href="javascript:;"><i class="fas fa-list-ul"></i></a><a class="navbar-item search" title="搜索" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta size-small is-uppercase level is-mobile"><div class="level-left"><time class="level-item" dateTime="2018-04-05T17:52:20.000Z" title="2018-04-05T17:52:20.000Z">2018-04-06</time><span class="level-item"><a class="link-muted" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a><span> / </span><a class="link-muted" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark/">Spark</a></span><span class="level-item" id="busuanzi_container_page_pv"><i class="far fa-eye"></i>&nbsp;&nbsp;<span id="busuanzi_value_page_pv">0</span>次访问</span></div></div><h1 class="title is-3 is-size-4-mobile">使用 Spark Streaming 进行实时流计算(一)</h1><div class="content"><p>使用Spark Streaming 进行实时流计算，主要运用 DStream 编程模型。这种模型包括 <strong>输入</strong>、<strong>转换</strong>和<strong>输出</strong> 三个部分。这一篇主要介绍三种简单的输入。<a href="../post/76774483.html">下一篇</a>将会介绍高级数据源和转换，输出部分。</p>
<a id="more"></a>

<h1 id="Spark-Streaming-简介"><a href="#Spark-Streaming-简介" class="headerlink" title="Spark Streaming 简介"></a>Spark Streaming 简介</h1><p>Spark Streaming是 Spark 的实时计算框架，为Spark提供了可扩展、高吞吐、容错的流计算能力。支持多种数据输入源，如 Kafka、Flume、HDFS 或 TCP套接字。</p>
<p><img src="http://spark.apache.org/docs/latest/img/streaming-arch.png" alt="输入输出"></p>
<h2 id="基本原理"><a href="#基本原理" class="headerlink" title="基本原理"></a>基本原理</h2><p>将实时输入的数据以时间片（秒级）为单位进行拆分，经 Spark 引擎以类似批处理的方式处理每个时间片数据。</p>
<p>Spark Streaming 最主要的抽象是 DStream(Discretized Stream，离散化数据流)，表示连续不断的数据流。Spark Streaming的输入数据按照时间片分成一段一段的 DStream，每一段数据转换为 Spark 中的 RDD，并且对 DStream 的操作最终转变为相应的 RDD 操作。</p>
<p>DStream是 Spark Streaming 的编程模型，DStream 的操作包括 <strong>输入</strong>、<strong>转换</strong>和<strong>输出</strong>。</p>
<h2 id="Spark-Streaming-与-Storm-对比"><a href="#Spark-Streaming-与-Storm-对比" class="headerlink" title="Spark Streaming 与 Storm 对比"></a>Spark Streaming 与 Storm 对比</h2><ul>
<li>Spark Streaming 无法实现毫秒级别的流计算， Storm 可以。</li>
<li>Spark Streaming 小批量处理的方式可以同时兼容批量和实时数据处理的逻辑和算法，方便在需要历史数据和实时数据联合分析的应用场合。</li>
</ul>
<hr>
<h1 id="Spark-Streaming编程步骤"><a href="#Spark-Streaming编程步骤" class="headerlink" title="Spark Streaming编程步骤"></a>Spark Streaming编程步骤</h1><blockquote>
<p>Spark Streaming 应用程序可以用 Scala、Java、Python来编写， 官方提供了一种叫 spark-shell 的命令行环境，使用 Scala 语言来编写，或者使用 python 语言的 pyspark。但是我们一般是在 IDE 里编写独立的应用程序。</p>
</blockquote>
<p>编写 Spark Streaming 程序的基本步骤是：</p>
<ol>
<li>通过创建输入DStream来定义<strong>输入源</strong>;</li>
<li>通过对 DStream 应用的 <strong>转换操作</strong> 和 <strong>输出操作</strong> 来定义流计算;</li>
<li>用<code>streamingContext.start()</code>来开始接收数据和处理流程;</li>
<li>通过<code>streamingContext.awaitTermination()</code>方法来等待处理结束（手动结束或因为错误而结束）;</li>
<li>可以通过<code>streamingContext.stop()</code>来手动结束流计算进程。</li>
</ol>
<h2 id="创建对象"><a href="#创建对象" class="headerlink" title="创建对象"></a>创建对象</h2><p>如果用 pyspark，默认已经获得了一个SparkConext（sc），否则，需要手动创建，如下</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext, SparkConf</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line">conf = SparkConf()</span><br><span class="line">conf.setMaster(<span class="string">'local[2]'</span>)  <span class="comment"># 表示运行在本地模式下，并且启动2个工作线程。</span></span><br><span class="line">conf.setAppName(<span class="string">'TestDStream'</span>)</span><br><span class="line">sc = SparkContext(conf = conf)</span><br></pre></td></tr></table></figure>

<blockquote>
<p>pyspark 默认有 sc，那么如何开 local[2] ? 答案：<code>spark-submit --master local[4] your_file.py</code></p>
</blockquote>
<p>要运行一个Spark Streaming程序，首先要生成一个StreamingContext对象</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ssc = StreamingContext(sc, <span class="number">15</span>)  <span class="comment"># 15表示每隔15秒钟自动执行一次流计算</span></span><br></pre></td></tr></table></figure>

<h2 id="从文件流读取数据"><a href="#从文件流读取数据" class="headerlink" title="从文件流读取数据"></a>从文件流读取数据</h2><p>Spark支持从兼容HDFS API的文件系统中读取数据，创建数据流。</p>
<p>首先创建一个 logdir 目录，里面有 log1.txt 和 log2.txt 两个日志文件</p>
<p>然后在 python 中继续写</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">lines = ssc.textFileStream(<span class="string">'file:///home/jerrysheh/logdir'</span>)</span><br><span class="line">words = lines.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">' '</span>))</span><br><span class="line">wordCounts = words.map(<span class="keyword">lambda</span> x : (x,<span class="number">1</span>)).reduceByKey(add)</span><br><span class="line">wordCounts.pprint()</span><br><span class="line">ssc.start()  <span class="comment"># 如果用 pyspark，到这里会循环监听，下面的语句无法输入</span></span><br><span class="line">ssc.awaitTermination()</span><br></pre></td></tr></table></figure>

<p>输出：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">-------------------------------------------</span><br><span class="line">Time: 2018-04-05 23:45:00</span><br><span class="line">-------------------------------------------</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 2018-04-05 23:45:15</span><br><span class="line">-------------------------------------------</span><br><span class="line"></span><br><span class="line">-------------------------------------------</span><br><span class="line">Time: 2018-04-05 23:45:30</span><br><span class="line">-------------------------------------------</span><br></pre></td></tr></table></figure>

<p>可以发现，程序每隔10秒监听一次。但是没有把 logdir 目录下的 log1.txt 和 log2.txt 这两个文件中的内容读取出来。原因是，监听程序只监听目录下在程序<strong>启动后新增的文件</strong>，不会去处理历史上已经存在的文件。</p>
<p>现在，用 vim 在 logdir 目录里新增一个 log3.txt ，并写入 hello， 保存。</p>
<p>过一会儿，就能发现屏幕中输出了 log3.txt 里面的信息。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">-------------------------------------------</span><br><span class="line">Time: 2018-04-05 23:45:45</span><br><span class="line">-------------------------------------------</span><br><span class="line">(&#39;hello&#39;, 1)</span><br></pre></td></tr></table></figure>

<h2 id="从TCP套接字流读取数据"><a href="#从TCP套接字流读取数据" class="headerlink" title="从TCP套接字流读取数据"></a>从TCP套接字流读取数据</h2><p>pyWordCountServer.py</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> __future__ <span class="keyword">import</span> print_function</span><br><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="keyword">if</span> len(sys.argv) != <span class="number">3</span>:</span><br><span class="line">        print(<span class="string">"Usage: network_wordcount.py &lt;hostname&gt; &lt;port&gt;"</span>, file=sys.stderr)</span><br><span class="line">        exit(<span class="number">-1</span>)</span><br><span class="line">    sc = SparkContext(appName=<span class="string">"PythonStreamingNetworkWordCount"</span>)</span><br><span class="line">    ssc = StreamingContext(sc, <span class="number">5</span>)</span><br><span class="line"></span><br><span class="line">    lines = ssc.socketTextStream(sys.argv[<span class="number">1</span>], int(sys.argv[<span class="number">2</span>]))</span><br><span class="line">    counts = lines.flatMap(<span class="keyword">lambda</span> line: line.split(<span class="string">" "</span>))\</span><br><span class="line">                  .map(<span class="keyword">lambda</span> word: (word, <span class="number">1</span>))\</span><br><span class="line">                  .reduceByKey(<span class="keyword">lambda</span> a, b: a+b)</span><br><span class="line">    counts.pprint()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    ssc.awaitTermination()</span><br></pre></td></tr></table></figure>

<p>在9999端口设置网络监听</p>
<ul>
<li>-k 参数    Keep inbound sockets open for multiple connects</li>
<li>-l 参数    Listen mode, for inbound connects</li>
</ul>
<p>shell 1</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">nc -lk 9999</span><br></pre></td></tr></table></figure>

<p>shell 2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python3 pyWordCountServer.py localhost 9999</span><br></pre></td></tr></table></figure>

<p>在 shell 1 里输入一些东西， shell 2可以接收到</p>
<p>但是这里报了 WARN</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Block input-0-1522945797400 replicated to only 0 peer(s) instead of 1 peers</span><br></pre></td></tr></table></figure>

<p>而且也没有任何数据</p>
<p><a href="https://stackoverflow.com/questions/32583273/spark-streaming-get-warn-replicated-to-only-0-peers-instead-of-1-peers">stackoverflow</a> 给出了解释</p>
<blockquote>
<p>The warning in your case means that incoming data from stream are not replicated at all. The reason for that may be that you run the app with just one instance of Spark worker or running in local mode. Try to start more Spark workers and see if the warning is gone.</p>
</blockquote>
<p>所以应该跟我是单机环境有关， <a href="https://stackoverflow.com/questions/28050262/spark-streaming-network-wordcount-py-does-not-print-result">stackoverflow</a>，说</p>
<blockquote>
<p>I think you should specify more executors while submitting the application. For example:</p>
</blockquote>
<blockquote>
<p><code>spark-submit --master local[4] your_file.py</code></p>
</blockquote>
<blockquote>
<p>Do not run Spark Streaming programs locally with master configured as  local or local[1]. This allocates only one CPU for tasks and if a receiver is running on it, there is no resource left to process the received data. Use at least local[2] to have more cores.</p>
</blockquote>
<p>所以开多几个线程就好了。</p>
<p>修改程序 创建SparkContext加 master 参数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sc = SparkContext(appName=<span class="string">"PythonStreamingNetworkWordCount"</span>, master=<span class="string">"local[4]"</span>)</span><br></pre></td></tr></table></figure>

<p>重新运行，还是报了 WARN， 但是 shell 1 的数据已经能够接收了</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">2018-04-06 00:46:45 WARN  RandomBlockReplicationPolicy:66 - Expecting 1 replicas with only 0 peer&#x2F;s.</span><br><span class="line">2018-04-06 00:46:45 WARN  BlockManager:66 - Block input-0-1522946805600 replicated to only 0 peer(s) instead of 1 peers</span><br><span class="line">-------------------------------------------                                     </span><br><span class="line">Time: 2018-04-06 00:46:48</span><br><span class="line">-------------------------------------------</span><br><span class="line">(&#39;are&#39;, 5)</span><br><span class="line">(&#39;now&#39;, 1)</span><br><span class="line">(&#39;you&#39;, 2)</span><br><span class="line">(&#39;what&#39;, 1)</span><br><span class="line">(&#39;doing&#39;, 1)</span><br></pre></td></tr></table></figure>

<h2 id="从-RDD-队列流读取数据"><a href="#从-RDD-队列流读取数据" class="headerlink" title="从 RDD 队列流读取数据"></a>从 RDD 队列流读取数据</h2><p>在调试Spark Streaming应用程序的时候，我们可以使用streamingContext.queueStream(queueOfRDD)创建基于RDD队列的DStream。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.streaming <span class="keyword">import</span> StreamingContext</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line"></span><br><span class="line">    sc = SparkContext(appName=<span class="string">"PythonStreamingQueueStream"</span>)</span><br><span class="line">    ssc = StreamingContext(sc, <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create the queue through which RDDs can be pushed to</span></span><br><span class="line">    <span class="comment"># a QueueInputDStream</span></span><br><span class="line">    rddQueue = []</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">5</span>):</span><br><span class="line">        rddQueue += [ssc.sparkContext.parallelize([j <span class="keyword">for</span> j <span class="keyword">in</span> range(<span class="number">1</span>, <span class="number">1001</span>)], <span class="number">10</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Create the QueueInputDStream and use it do some processing</span></span><br><span class="line">    inputStream = ssc.queueStream(rddQueue)</span><br><span class="line">    mappedStream = inputStream.map(<span class="keyword">lambda</span> x: (x % <span class="number">10</span>, <span class="number">1</span>))</span><br><span class="line">    reducedStream = mappedStream.reduceByKey(<span class="keyword">lambda</span> a, b: a + b)</span><br><span class="line">    reducedStream.pprint()</span><br><span class="line"></span><br><span class="line">    ssc.start()</span><br><span class="line">    time.sleep(<span class="number">6</span>)</span><br><span class="line">    ssc.stop(stopSparkContext=<span class="literal">True</span>, stopGraceFully=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<hr>
<p>以上主要介绍了从三个基本数据源（文件、TCP套接字、RDD）读取数据操作。下一篇继续介绍高级数据源（Kafka、Flume）以及数据的转换操作 和 输出操作。</p>
<p>参考</p>
<ul>
<li>《大数据技术原理与应用》 林子雨</li>
</ul>
</div><div class="article-tags size-small mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据</a></div><!--!--></article></div><!--!--><nav class="post-navigation mt-4 level is-mobile"><div class="level-start"><a class="article-nav-prev level level-item link-muted" href="/post/76774483.html"><i class="level-item fas fa-chevron-left"></i><span class="level-item">使用 Spark Streaming 进行实时流计算(二)</span></a></div><div class="level-end"><a class="article-nav-next level level-item link-muted" href="/post/9c5fa7c3.html"><span class="level-item">Spark编程入门（二）RDD编程</span><i class="level-item fas fa-chevron-right"></i></a></div></nav><!--!--></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="Jerry Sheh"></figure><p class="title is-size-4 is-block line-height-inherit">Jerry Sheh</p><p class="is-size-6 is-block">车顶上绑着飞机发动机</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Shenzhen</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">文章</p><a href="/archives"><p class="title">174</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">分类</p><a href="/categories"><p class="title">31</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">标签</p><a href="/tags"><p class="title">35</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="mailto:jerrysheh@gmail.com" target="_blank" rel="noopener">联系我</a></div><div class="level is-mobile"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/Jerrysheh"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="email" href="mailto:jerrysheh@gmail.com"><i class="fa fa-envelope"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Zhihu" href="https://www.zhihu.com/people/jerrysheh"><i class="fab fa-zhihu"></i></a></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">分类</h3><ul class="menu-list"><li><a class="level is-mobile is-marginless" href="/categories/Android/"><span class="level-start"><span class="level-item">Android</span></span><span class="level-end"><span class="level-item tag">11</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/C-C/"><span class="level-start"><span class="level-item">C/C++</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Golang/"><span class="level-start"><span class="level-item">Golang</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Java/"><span class="level-start"><span class="level-item">Java</span></span><span class="level-end"><span class="level-item tag">42</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Java/Concurrent/"><span class="level-start"><span class="level-item">Concurrent</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Java/Effective-Java/"><span class="level-start"><span class="level-item">Effective Java</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Java/JDBC/"><span class="level-start"><span class="level-item">JDBC</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Java/JVM/"><span class="level-start"><span class="level-item">JVM</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Java/Java-SE/"><span class="level-start"><span class="level-item">Java SE</span></span><span class="level-end"><span class="level-item tag">20</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Java-Web/"><span class="level-start"><span class="level-item">Java Web</span></span><span class="level-end"><span class="level-item tag">15</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/Java-Web/Spring/"><span class="level-start"><span class="level-item">Spring</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Java-Web/Web/"><span class="level-start"><span class="level-item">Web</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Java-Web/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"><span class="level-start"><span class="level-item">微服务</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/Linux/"><span class="level-start"><span class="level-item">Linux</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/Python/"><span class="level-start"><span class="level-item">Python</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/"><span class="level-start"><span class="level-item">中间件</span></span><span class="level-end"><span class="level-item tag">2</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/%E4%B8%AD%E9%97%B4%E4%BB%B6/redis/"><span class="level-start"><span class="level-item">redis</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%89%8D%E7%AB%AF/"><span class="level-start"><span class="level-item">前端</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"><span class="level-start"><span class="level-item">大数据</span></span><span class="level-end"><span class="level-item tag">12</span></span></a><ul class="mr-0"><li><a class="level is-mobile is-marginless" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Scala/"><span class="level-start"><span class="level-item">Scala</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/Spark/"><span class="level-start"><span class="level-item">Spark</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/hadoop/"><span class="level-start"><span class="level-item">hadoop</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li></ul></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%8A%80%E8%83%BD/"><span class="level-start"><span class="level-item">技能</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F/"><span class="level-start"><span class="level-item">操作系统</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%B0%E6%8D%AE%E5%BA%93/"><span class="level-start"><span class="level-item">数据库</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%92%8C%E7%AE%97%E6%B3%95/"><span class="level-start"><span class="level-item">数据结构和算法</span></span><span class="level-end"><span class="level-item tag">9</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E7%9E%8E%E6%8A%98%E8%85%BE/"><span class="level-start"><span class="level-item">瞎折腾</span></span><span class="level-end"><span class="level-item tag">7</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%A7%91%E5%AD%A6%E9%80%9F%E6%88%90%E8%AF%BE/"><span class="level-start"><span class="level-item">计算机科学速成课</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/"><span class="level-start"><span class="level-item">计算机网络</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"><span class="level-start"><span class="level-item">设计模式</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile is-marginless" href="/categories/%E8%AF%BB%E4%B9%A6%E4%B8%8E%E7%94%9F%E6%B4%BB/"><span class="level-start"><span class="level-item">读书与生活</span></span><span class="level-end"><span class="level-item tag">14</span></span></a></li></ul></div></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" id="toc"><div class="card-content"><div class="menu"><h3 class="menu-label">目录</h3><ul class="menu-list"><li><a class="is-flex" href="#Spark-Streaming-简介"><span class="mr-2">1</span><span>Spark Streaming 简介</span></a><ul class="menu-list"><li><a class="is-flex" href="#基本原理"><span class="mr-2">1.1</span><span>基本原理</span></a></li><li><a class="is-flex" href="#Spark-Streaming-与-Storm-对比"><span class="mr-2">1.2</span><span>Spark Streaming 与 Storm 对比</span></a></li></ul></li><li><a class="is-flex" href="#Spark-Streaming编程步骤"><span class="mr-2">2</span><span>Spark Streaming编程步骤</span></a><ul class="menu-list"><li><a class="is-flex" href="#创建对象"><span class="mr-2">2.1</span><span>创建对象</span></a></li><li><a class="is-flex" href="#从文件流读取数据"><span class="mr-2">2.2</span><span>从文件流读取数据</span></a></li><li><a class="is-flex" href="#从TCP套接字流读取数据"><span class="mr-2">2.3</span><span>从TCP套接字流读取数据</span></a></li><li><a class="is-flex" href="#从-RDD-队列流读取数据"><span class="mr-2">2.4</span><span>从 RDD 队列流读取数据</span></a></li></ul></li></ul></div></div></div><div class="card widget"><div class="card-content"><div class="menu"><h3 class="menu-label">推荐链接</h3><ul class="menu-list"><li><a class="level is-mobile is-mobile" href="https://www.wmyskxz.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">我没有三颗心脏</span></span><span class="level-right"><span class="level-item tag">www.wmyskxz.com</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://www.cnblogs.com/vamei/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Vamei</span></span><span class="level-right"><span class="level-item tag">www.cnblogs.com</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://www.celesteheadlee.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">celesteheadlee</span></span><span class="level-right"><span class="level-item tag">www.celesteheadlee.com</span></span></a></li><li><a class="level is-mobile is-mobile" href="https://www.xaprb.com/" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Baron Schwartz</span></span><span class="level-right"><span class="level-item tag">www.xaprb.com</span></span></a></li></ul></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.png" alt="J.e" height="28"></a><p class="size-small"><span>&copy; 2021 Jerry Sheh</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a><br><span id="busuanzi_container_site_uv">共<span id="busuanzi_value_site_uv">0</span>个访客</span></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script>moment.locale("zh-CN");</script><script>var IcarusThemeSettings = {
            site: {
                url: 'https://jerrysheh.me',
                external_link: {"enable":true,"exclude":[]}
            },
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script src="/js/animation.js"></script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><div id="outdated"><h6>Your browser is out-of-date!</h6><p>Update your browser to view this website correctly.&amp;npsb;<a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update my browser now </a></p><p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">×</a></p></div><script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script><script>window.addEventListener("load", function () {
            outdatedBrowser({
                bgColor: '#f25648',
                color: '#ffffff',
                lowerThan: 'object-fit' // display on IE11 or below
            });
        });</script><a id="back-to-top" title="回到顶端" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="想要查找什么..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"想要查找什么...","untitled":"(无标题)","posts":"文章","pages":"页面","categories":"分类","tags":"标签"});
        });</script></body></html>